# 从优秀到卓越的数据科学，第1部分：相关性与置信度

> 原文：[https://www.kdnuggets.com/2019/02/good-great-data-science-correlations-confidence.html](https://www.kdnuggets.com/2019/02/good-great-data-science-correlations-confidence.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

**由 [Brian Joseph](https://www.linkedin.com/in/brian-joseph-429028118/) 提供，数据科学家**

![头图](../Images/499c86aa8800fc0cddc175a2f6b79053.png)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT 工作

* * *

### 介绍

作为数据科学家，你将花费大量时间用数据回答问题。我目前在医疗行业担任数据科学家，为医院和医疗相关组织提供指标和构建模型。在我的工作中，大部分时间都用于做两件事：

+   将定性商业问题转化为可以通过数据生成的严格解决方案

+   以编程方式实现这些解决方案

我将带你解决两个我在工作中实际遇到过的问题：

1.  我的医院是否应该更多地关注改善其死亡率？

1.  哪些药剂师发放了过多的阿片类药物？

他们的共同点在于，做这些事有正确和错误的方式。此外，回答这些问题的错误方式很容易被忽视。正如你将看到的，回答这些问题的优秀与平庸之间的差异在于是否具备一点数学背景。

**Jupyter notebook 和本文的数据** [**在 GitHub 上**](https://github.com/LearnDataSci/article-resources/tree/master/From%20Good%20to%20Great%20Data%20Science%2C%20Part%201%20Correlations%20and%20Confidence)

### 问题陈述 1

医疗保险和医疗补助服务中心（CMS）负责根据质量和表现指标对医院进行评分。

他们提供各种指标来估算医院的表现，还有一个总体指标称为`quality_rating`。另一个较不重要的指标是`mortality_rate`。

假设你被分配了调查医院的`quality_rating`与其`mortality_rate`之间关系的任务，以回答我上面提到的第一个问题。医院的死亡率对其整体`quality_rating`有多大影响？假设你的数据具有以下特征：

+   `quality_rating`：范围在 (1, 2, 3, 4, 5) 内的数值

+   `mortality_rate`：以下值之一：

    +   *高于平均*

    +   *平均*

    +   *低于平均*

假设你得到了以下数据：

```py
ratings_df = pd.read_csv('hospital_ratings.csv').drop(columns='Unnamed: 0')

print('Number of Hospitals: {}'.format(len(ratings_df.index)))

ratings_df.head(10)

```

```py
Number of Hospitals: 100

```

![表格](../Images/1cbc408406e449ea462fded949ca076b.png)

如你所见，每一行代表一家医院。每家医院都有一个死亡率和质量评分。前提是*比较*`mortality_rate`和`quality_rating`，所以一个关键的统计工具应该跃入你的脑海——**相关性**。

这是将我们的*定性*问题转化为*定量*术语的第一步。我建议你现在尝试解决这个问题——或者至少制定一个完整的计划来回答这个问题：

***这两个指标之间的相关性是什么？***

你找到解决方案了吗？让我们一起探讨一下。

****编码死亡率****

这个问题可能还剩下两个步骤。首先，我们应该注意到我们的`mortality_rate`列包含的是有序数据。我们只能对数值数据进行相关性分析，因此我们需要对此进行处理。

我们以某种方式对数据进行编码，保持其有序关系。换句话说，我们希望对***低于平均水平***`mortality_rate`的编码在数值上优于对***高于平均水平***`mortality_rate`的编码（注意医院有**较低**的死亡率更好）。

你是如何处理数据编码的？有无穷多的选项：

比如：

```py
'below average' --> 5
'average' --> 3 
'above average' --> 1

```

或者：

```py
'below average' --> 3 
'average' --> 2 
'above average' --> 1

```

或许：

```py
'below average' --> 1 
'average' --> 0 
'above average' --> -1

```

如果你决定对数据进行编码，你选择了哪个选项？哪个是正确的？正确的答案是*没有* — 或者*所有*选项，我想...

我稍后会解释原因。但现在，让我们继续映射到最后一个选项：映射到集合：(-1, 0, 1)。

```py
MORTALITY_MAP = {
    'below_average': 1,
    'average': 0,
    'above_average': -1
}

ratings_df['mortality_rate'] = ratings_df['mortality_rate'].map(MORTALITY_MAP) # apply the map
ratings_df.head()

```

![表格](../Images/900abd06c00dd8bccd36b05eddbe24cf.png)

这个问题的最后一步（表面上）是最简单的。现在我们只需要对比这两列数据对吧？

```py
ratings_df.corr()

```

![表格](../Images/f9de80477ad35170ee45b8272d11a545.png)

不完全正确。我们对数据做出了巨大的假设。我们假设数据是*有序*的。

****非参数相关性****

作为数据科学家，你应该熟悉[parametric](https://en.wikipedia.org/wiki/Parametric_statistics)和[non-parametric](https://en.wikipedia.org/wiki/Nonparametric_statistics)统计的概念。大多数统计相关性将默认使用一种称为`pearson`的参数相关性方法。在我们的案例中，我们需要使用一种称为`spearman`的非参数相关性。

这种非参数方法假设我们的数据仅仅是有序的。换句话说，无论我们做什么映射，只要顺序在映射后保持不变，Spearman相关性将返回相同的结果。

如果我们指定需要使用Spearman相关性方法，我们会发现结果发生了剧烈变化：

```py
ratings_df.corr(method='spearman')

```

![表格](../Images/7ebe3e458e6464dd573547d47cc01e8e.png)

我们刚刚将相关性降低了大约**10%**。这是一个剧烈的差异！

如果你使用 pearson 相关系数而不是 spearman 来报告这种相关性，可能会严重误导客户或同事。

这表明，**强大的统计背景对数据科学角色至关重要**。这样一个看似简单的问题实际上有一个关键的数学步骤，常常被忽视。

### 问题陈述 2

你有马萨诸塞州过去5年的数百万个药品记录，该州因阿片类药物滥用问题而闻名。因此，如果你能识别出开具过多阿片类药物的药剂师，那将非常有用。

![马萨诸塞州与阿片类药物相关的过量死亡率](../Images/e138fba1d4644e7da839c6d7f77e0cf4.png)

来源: [国家药物滥用研究所](https://www.drugabuse.gov/drugs-abuse/opioids/opioid-summaries-by-state/massachusetts-opioid-summary)

你被分配的任务是：

***生成一份开处方过多阿片类药物的药剂师名单***。

看起来很简单。假设你有以下数据集：

```py
prescribers_df = pd.read_csv('prescriptions.csv').drop(columns='Unnamed: 0')
prescribers_df.head(10)

```

![表格](../Images/ea70c7ff48d81a3f86985e98882c09ca.png)

每一行代表一天的处方

我们有以下几个列：

+   `prescriber_id`: 一个随机代码，用于识别药剂师

+   `num_opioid_prescriptions`: 某一天所开出的阿片类药物处方数量

+   `num_prescriptions`: 某一天所开出的*总*处方数量

### **对处方医生进行分组**

首先，我们应该注意到 `prescriber_id` 并不包含唯一的值，因为处方医生可能在多天内开过药。由于该指标是针对处方医生级别的——而不是每日级别的——我们应该通过 pandas 的 `groupby` 来修正这个问题。

```py
prescribers_df = prescribers_df.groupby('prescriber_id').agg('sum')
prescribers_df.head(10)

```

![表格](../Images/6585b77ff3707d13c96d545983c5f681.png)

好得多了。现在手头的任务是根据处方的阿片类药物数量对处方医生进行排名。但处方医生开的药量各不相同。这暗示我们现在应该考虑每个处方医生的阿片类药物处方比例。让我们就这样做吧。

### **阿片类药物处方比例**

```py
prescribers_df['opioid_prescription_ratio'] = (prescribers_df['num_opioid_prescriptions'] / 
                                               prescribers_df['num_prescriptions'])

```

Pandas 让这一点变得非常简单。那么我们完成了吗？只需根据 `opioid_ratio` 对处方医生进行排序，然后完成这个任务？

```py
prescribers_df.sort_values('opioid_prescription_ratio', ascending=False).head(10)

```

![表格](../Images/1044e8e1654f3acc9e2e749bed888c13.png)

并非如此。这些数据应该引起你的警惕。

真的有意义吗？将药剂师排名为滥用者，仅仅因为他们在1份处方中开了1种阿片类药物？尝试用言辞准确表达这个情况的问题所在。为什么我们不想将这些处方医生报告为最严重的违规者？希望你得到的答案是类似于：

***因为我们没有足够的信息来评判他们。***

想象一下你坐在药房里看着药剂师（我们称他为“比尔”）进行工作。假设你想报告比尔，如果他开处方的阿片类药物过多。

一个顾客进来，Bill给他开了*氢可酮*（一种常见的阿片类药物）。立即报告Bill是毫无意义的。你应该等到观察到Bill更多的行为后再做判断，因为你还不够确定你的发现。

**信心**是这里的关键词，我们很快就会发现。

### **建立信心**

那么我们如何解决这个问题？

从统计学的角度来看，开药与否可以看作是一个[Bernoulli参数](https://en.wikipedia.org/wiki/Bernoulli_distribution)（这是一个值为二进制的术语——要么是真的，要么是假的）。鉴于Bernoulli参数的观察数量，我们希望预测该参数的真实值。

这里所说的“真实值”指的是如果我们有足够的观察数据，处方医生的`opioid_prescription_ratio`将会趋近的实际值。在我们的例子中，Bill的“真实值”将等同于Bill的`opioid_prescription_ratio`，如果我们能够长时间观察并记录他的行为——比如一年。

如果你上过统计学或[优秀的数据科学课程](https://www.learndatasci.com/best-data-science-online-courses-2018/)，你可能对置信区间的概念比较熟悉。如果没有，简单来说，置信区间只是一个附加在你认为未知值存在范围上的数学信心度量。

![95 percent confidence interval.jpeg](../Images/57f67c957f13e1c0839c038799f4f755.png)

来源：[当你可以拥有置信区间时，谁还需要伴舞者？](https://medium.com/design-ibm/who-needs-backup-dancers-when-you-can-have-confidence-intervals-485f9464c06f)

例如，我可以95%有信心明天的温度将在40华氏度到70华氏度之间。

1927年，数学家Edwin Wilson将置信区间的概念应用于Bernoulli参数。这意味着我们可以根据我们拥有的数据，估计药剂师的*真实*`opioid_prescription_ratio`！

这是公式：

威尔逊置信区间下限：

![公式](../Images/00d83421f12adf17726a45493055cf80.png)

公式看起来很吓人，但如果你花时间研究一下，它其实是直观的。解释这个公式背后的数学原理是一个完整的讨论，因此超出了我们的范围。所以我们将只关注如何应用它。

```py
def wilson_ci_lower_bound(num_pos, n, confidence=.95):
    if n == 0:
        return 0

    z = stats.norm.ppf(1 - (1 - confidence) / 2) # Establish a z-score corresponding to a confidence level

    p_hat = num_pos / n

    # Rewrite formula in python
    numerator = p_hat + (z**2 / (2*n)) - (z * math.sqrt((p_hat * (1 - p_hat) + (z**2 / (4*n))) / n))
    denominator = 1 + ((z**2) / n)

    return  numerator / denominator

```

让我们以95%的置信度将这个公式应用到我们的数据框中，创建一个新列

```py
prescribers_df['wilson_opioid_prescription_ratio'] = prescribers_df \
    .apply(lambda row: wilson_ci_lower_bound(row['num_opioid_prescriptions'], row['num_prescriptions']), axis=1)

prescribers_df.sort_values('wilson_opioid_prescription_ratio', ascending=False).head(10)

```

![表格](../Images/8df13327a847e5edcb5d8baf2eeaa6ed.png)

太棒了！现在这些是我们希望报告的结果。

尽管有很多开药者的阿片类药物处方比例为1/1或2/2，但他们现在出现在我们的排名底部——这是直观的。虽然我们排名最高的开药者的`opioid_prescription_ratio`比其他一些开药者低，但排名现在考虑了数学置信度的概念。

这两种方法——使用或不使用置信区间——在*技术上*都是可接受的。然而，很明显，采用数学背景的方法会带来更有价值的结果。

### 总结...

数据科学工作的一大部分是将开放且可解释的问题转化为定量、严谨的术语。

正如这两个例子所展示的，有时这并不是一项简单的任务，许多数据科学家在这方面经常表现不足。很容易陷入在非参数场景中使用参数相关性的陷阱。而且很容易在排序伯努利试验的列表时忽视每次试验的观测数量。实际上，这种情况在实际中比你想象的更常见。

区分一个优秀的数据科学家和一个杰出的数据科学家的一部分原因是具备数学背景和直觉，以识别和处理这种情况。数据科学中，能够使解决方案与杰出解决方案之间产生差异的往往是将正确的数学工具应用于正确的上下文。

**简历：[布赖恩·约瑟夫](https://www.linkedin.com/in/brian-joseph-429028118/)** 在东北大学学习数学，研究重点为组合数学和线性代数。目前在大波士顿地区的一家初创公司担任数据科学家，热衷于数学、数据科学、形式验证和算法设计。

[原文](https://www.learndatasci.com/tutorials/good-great-data-science-correlations-and-confidence/)。经许可转载。

**相关：**

+   [数据科学统计学入门](/2018/12/introduction-statistics-data-science.html)

+   [掌握基础机器学习的7个步骤—2019版](/2019/01/7-steps-mastering-basic-machine-learning-python.html)

+   [探索Python基础](/2019/01/exploring-python-basics.html)

### 更多相关话题

+   [使用置信区间](https://www.kdnuggets.com/2023/04/working-confidence-intervals.html)

+   [对模型信心的追求：你能相信黑箱吗？](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)

+   [机器学习与大脑的不同 第七部分：神经元…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)

+   [数据质量维度：用“伟大期望”确保数据质量](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)

+   [数据质量：好、坏与丑]（https://www.kdnuggets.com/2022/01/data-quality-good-bad-ugly.html）

+   [优秀数据科学项目文档的5条规则](https://www.kdnuggets.com/2022/12/5-rules-good-data-science-project-documentation.html)
