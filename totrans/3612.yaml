- en: When to Retrain an Machine Learning Model? Run these 5 checks to decide on the
    schedule
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 何时重新训练机器学习模型？运行这5项检查来决定时间表。
- en: 原文：[https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html](https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html](https://www.kdnuggets.com/2021/07/retrain-machine-learning-model-5-checks-decide-schedule.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By** [**Emeli Dral**](https://twitter.com/EmeliDral)**, CTO and Co-founder
    of Evidently AI &** [**Elena Samuylova**](https://twitter.com/elenasamuylova/)**,
    CEO and Co-founder at Evidently AI**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者** [**Emeli Dral**](https://twitter.com/EmeliDral)**，Evidently AI 的首席技术官兼联合创始人
    &** [**Elena Samuylova**](https://twitter.com/elenasamuylova/)**，Evidently AI
    的首席执行官兼联合创始人**'
- en: The world and data are not static. But most machine learning models are. Once
    they are in production, they become less relevant with time. The [data distributions
    evolve, the behavioral patterns change](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift),
    and models need updates to keep up with new reality.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 世界和数据不是静态的。但大多数机器学习模型是静态的。一旦它们投入生产，它们随着时间变得不那么相关。[数据分布在变化，行为模式也在改变](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)，模型需要更新以跟上新的现实。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The usual process is to retrain the models at defined intervals. It looks quite
    straightforward: take the new data, the old training pipeline, and fit the model
    again.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通常的过程是在定义的时间间隔重新训练模型。这看起来相当简单：获取新数据、旧的训练流程，并再次拟合模型。
- en: But how often should we do it? Should it be done daily, weekly, or monthly?
    Or every time you get a new batch of data?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们应该多久做一次呢？是每天、每周还是每月？还是每次获取一批新数据时？
- en: '![Image](../Images/6633c2014ec57d3088ba2179d982447e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/6633c2014ec57d3088ba2179d982447e.png)'
- en: Too often, the answer is based on a gut feeling or convenience. Someone picks
    a reasonable interval and schedules a regular retraining job.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 太多时候，答案基于直觉或便利性。有人选择一个合理的时间间隔并安排定期的重新训练工作。
- en: Instead, we can approach it in a more data-driven way. To be more precise when
    planning the model maintenance, we can run a few checks in advance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以采取更数据驱动的方法。为了更精确地规划模型维护，我们可以提前进行一些检查。
- en: Depending on how critical the model is, you might go through all of them or
    only some.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 根据模型的重要性，您可能需要经历所有这些步骤或仅部分步骤。
- en: 'Check #1\. Is the model already good enough?'
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #1\. 模型是否已经足够好？'
- en: Before we make our retraining plans, it helps to check if we are done with training!
    Maybe, the model hasn’t reached its peak performance yet?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在制定重新训练计划之前，检查是否完成了训练是有帮助的！也许，模型还没有达到最佳性能？
- en: The simple way to do that is to look at good old learning curves.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一点的简单方法是查看经典的学习曲线。
- en: '![Image](../Images/f0988021c2e694e56e03bef78e14da42.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/f0988021c2e694e56e03bef78e14da42.png)'
- en: How to proceed? We can fix the test set which we use to evaluate the model performance.
    Then, run a set of experiments by training the model on different parts of the
    training data.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如何进行？我们可以固定测试集，用于评估模型性能。然后，通过在不同部分的训练数据上训练模型，运行一系列实验。
- en: We can use the random split method and iterate by changing the train size. This
    way, we focus on how the data volume impacts the performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用随机分割方法并通过更改训练大小来进行迭代。这样，我们可以专注于数据量如何影响性能。
- en: '![Image](../Images/1353e1f20c4313d1a9f55092a6d2800a.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/1353e1f20c4313d1a9f55092a6d2800a.png)'
- en: 'There are two things we can learn as a result: 1) how much data we need to
    reach the peak performance 2) whether the model reaches this plateau with the
    available training data.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从中学到两件事：1）我们需要多少数据才能达到最佳性能 2）模型是否能用现有的训练数据达到这个平稳状态。
- en: '**Sometimes we’d learn that the model doesn’t need all the data we have.**
    For example, we have multiple years of sales data, but using just one year of
    training data gets the same quality.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**有时候我们会发现模型并不需要我们拥有的所有数据。** 例如，我们有多年的销售数据，但使用仅仅一年的训练数据就能达到相同的质量。'
- en: We might drop the extra data to make the model more lightweight.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以丢弃额外的数据，使模型更加轻量化。
- en: '**In other cases, we could see that the model quality keeps going up and up**.
    The model is hungry for more data! There are more steps to be made to bring the
    model to its top shape.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，我们可能会看到模型质量持续提升**。模型渴望更多的数据！还有更多步骤需要完成，以将模型调整到最佳状态。'
- en: '![Image](../Images/7d75b4bc993a559419e6f57d29fb3c70.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/7d75b4bc993a559419e6f57d29fb3c70.png)'
- en: Rather than think about model retraining to maintain its quality, we should
    plan for continuous improvement. As soon as we get enough new data, we can use
    it to reach better performance.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 与其考虑模型重新训练以保持其质量，我们应该计划持续改进。只要我们获得足够的新数据，就可以利用它来获得更好的性能。
- en: This first test also gives a sense of scale and “density” of signal in the data.
    Do we need 10, 100, or 1000 observations to see a meaningful impact on the model
    performance? Would it take us a day or a month to collect that amount of new data?
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个测试还提供了数据中信号的规模和“密度”的感觉。我们需要10、100还是1000个观察值来看到对模型性能的有意义的影响？我们需要一天还是一个月来收集这数量的新数据？
- en: That’s a helpful thing to know!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的信息！
- en: 'Check #2\. How quickly do things change?'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #2\. 事物变化的速度有多快？'
- en: When we create our machine learning models, we assume there is some stability
    in the real-world process. Otherwise, it would make little sense to learn from
    the past!
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建机器学习模型时，我们假设现实世界的过程是有一定稳定性的。否则，从过去学习就没有多大意义了！
- en: We also know that things change. When working with a dynamic process, we can
    also assume that there is a certain speed at which these new patterns accumulate.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也知道事物在变化。当处理一个动态过程时，我们也可以假设这些新模式的积累有一定的速度。
- en: We can then try to calculate this!
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以尝试计算一下！
- en: Let’s take our model and see how long it “lasts” if we simulate its application
    in the past.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拿到我们的模型，看看如果我们模拟它在过去的应用，它能“持续”多久。
- en: '![Image](../Images/f57dc5e2baea3ed6c05cdd2eefc14927.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/f57dc5e2baea3ed6c05cdd2eefc14927.png)'
- en: We can train a model using some older part of the data and then “apply” it to
    the later periods. Just like we do with a hold-out set, but here we simply take
    several consecutive ones.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用一些较旧的数据来训练模型，然后将其“应用”到后来的时期。就像我们对待保留集一样，但这里我们只是简单地取几个连续的数据。
- en: We can start with a single-point estimate and see how fast the performance degrades.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从一个单点估计开始，看看性能下降得有多快。
- en: '![Image](../Images/886251abc0b3af2682dc5aedba2e68cd.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/886251abc0b3af2682dc5aedba2e68cd.png)'
- en: If we have enough historical data, we can repeat this check several times and
    then average the results. Just keep an eye on potential outliers and rare events!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有足够的历史数据，我们可以多次重复这个检查，然后对结果进行平均。只需留意潜在的异常值和稀有事件！
- en: '![Image](../Images/4187c122c80bd37ca886503946959293.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/4187c122c80bd37ca886503946959293.png)'
- en: '**Sometimes we’d learn that an “old” model performs as good as new.** Some
    prefer to retrain the models often to keep them “fresh,” but it is not always
    justified.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**有时候我们会发现一个“旧”模型的表现和新模型一样好。** 一些人喜欢经常重新训练模型以保持其“新鲜”，但这并不总是有理的。'
- en: Don’t fix what’s not broken!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不要修复那些没有坏的东西！
- en: If frequent retraining is not needed, you might go away with a lighter service
    architecture. You can also decrease the risks of technical errors that come with
    any change. The same goes for the organizational overhead, especially when new
    models require an approval process.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不需要频繁的重新训练，你可以选择一个更轻量的服务架构。你也可以减少与任何变化相关的技术错误风险。组织开销也是如此，尤其是当新模型需要审批过程时。
- en: '![Image](../Images/7cf2c1d846f0a3770216da28a8ebe87a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/7cf2c1d846f0a3770216da28a8ebe87a.png)'
- en: '**In other cases, you can learn that the model ages very fast!** That is good
    to know in advance to set up proper monitoring and prepare the infrastructure.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，你可能会发现模型衰老得非常快！** 提前了解这一点是好的，以便设置适当的监控并准备基础设施。'
- en: You might decide to reconsider your training approach to make the model more
    stable. For example, change feature engineering or model architecture to make
    it a bit less performant on the test set but more stable in the long run. In other
    cases, you might train the model using a shorter training period but perform frequent
    calibration or consider active learning.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会决定重新考虑你的训练方法，以使模型更加稳定。例如，改变特征工程或模型架构，使其在测试集上的表现稍微逊色，但长期来看更稳定。在其他情况下，你可能会使用较短的训练周期来训练模型，但进行频繁的校准或考虑主动学习。
- en: We might also face constraints in our ability to retrain the model.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能面临重新训练模型能力的限制。
- en: That brings us to the next check.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了下一个检查。
- en: 'Check #3\. When do we get the new data?'
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #3。我们何时获取新数据？'
- en: '![Image](../Images/ad4cb68a76433b6c053208581142e7d7.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/ad4cb68a76433b6c053208581142e7d7.png)'
- en: Here, we look at the business process rather than the data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们关注的是业务流程而非数据。
- en: Sometimes, we get real-world feedback almost immediately. For example, you recommend
    an article to read, and you quickly know if the user clicked on a link.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们几乎可以立即获得实际反馈。例如，你推荐一篇文章阅读，你很快就知道用户是否点击了链接。
- en: In other cases, the new data that you can use to retrain your model comes with
    a delay.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他情况下，你可以用来重新训练模型的新数据有延迟。
- en: If you have a long prediction horizon, you have to wait to know if your prediction
    was correct. With other tasks, you need a separate labeling process. Sometimes,
    the limitations come from how the data is moved or generated. For example, manual
    data entry is done once per month.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有较长的预测时间范围，你必须等待以了解你的预测是否正确。对于其他任务，你需要一个单独的标记过程。有时，限制来自数据的移动或生成方式。例如，手动数据输入每月进行一次。
- en: '![Image](../Images/4d963f1ef664d1112a0b9573247d2a02.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/4d963f1ef664d1112a0b9573247d2a02.png)'
- en: We can find ourselves in one of the two situations.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会发现自己处于两种情况之一。
- en: '**In some cases, the model degrades before the new data arrives.** It becomes
    a limitation.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**在某些情况下，模型在新数据到达之前就已经退化。** 这成为一种限制。'
- en: If we do not get the data in time to retrain the model, we might need to reconsider
    the approach again. For example, create an ensemble of models with different retraining
    horizons or combine machine learning with rules or human-in-the-loop. As a last
    resort, we can also adjust our performance expectations and prepare to deal with
    a lowered model quality.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有及时获取数据以重新训练模型，我们可能需要再次重新考虑方法。例如，创建一个具有不同重新训练时间的模型集成，或将机器学习与规则或人工参与结合起来。作为最后的手段，我们还可以调整我们的性能期望，并准备应对模型质量下降。
- en: '**In other cases, the new data starts accumulating before the model decay.**
    In this case, we have the luxury of choice.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**在其他情况下，新数据在模型退化之前开始积累。** 在这种情况下，我们可以选择。'
- en: We can, of course, simply initiate the retraining at any point after the data
    comes. If we want to be more precise, there is a way to do that.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以在数据到达后的任何时间点启动重新训练。如果我们想要更精确，有一种方法可以做到这一点。
- en: Read on!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 继续阅读！
- en: 'Check #4\. How much data do we need to see the improvement?'
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #4。我们需要多少数据才能看到改进？'
- en: Say the new data arrives daily, but the model degrades only after 30 days. What
    would be the optimal action? Should we retrain daily, weekly, or once per month?
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 假设新数据每天到达，但模型仅在30天后退化。那么最佳的行动是什么？我们应该每天、每周还是每月重新训练一次？
- en: '![Image](../Images/93da0c9a4e5c92b0642fc2c37d89f2a3.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/93da0c9a4e5c92b0642fc2c37d89f2a3.png)'
- en: We can make a more precise judgment by checking if the new bucket of data brings
    the improvement we want.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过检查新的数据桶是否带来了我们想要的改进来做出更精确的判断。
- en: The thing is, sometimes adding a small set of new data points does not change
    anything. There is some minimal required data size that has a visible impact on
    the performance.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是，有时添加一小组新数据点不会改变任何东西。有一个最小的数据量要求，它对性能有明显的影响。
- en: We can evaluate this.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以评估这一点。
- en: 'To do that, we choose a test set from a period of the known decay. We know
    when the performance goes down: we can then check if retraining on the new data
    improves it.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们选择一个已知退化期间的测试集。我们知道何时性能下降：然后可以检查在新数据上重新训练是否能改善性能。
- en: '![Image](../Images/36e21e33e0b86cf04f120b86ea13917b.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![Image](../Images/36e21e33e0b86cf04f120b86ea13917b.png)'
- en: We can add data in small increments as it comes. Then, we see how it affects
    the test performance.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在数据到达时逐步添加数据。然后，观察它对测试性能的影响。
- en: What often happens is that we have to wait a bit to collect a “useful” amount
    of data—for example, at least a week of it to capture the relevant seasonal patterns.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 经常发生的情况是，我们需要等待一段时间才能收集到“有用”的数据——例如，至少一周的数据以捕捉相关的季节性模式。
- en: As a result, our actual choice of retraining window might be more narrow than
    it seemed! On the side, it is limited by the speed of data provision. On the other
    side, by the need to collect enough data for retraining to bring effect.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是，我们实际选择的重新训练窗口可能比看起来要狭窄！一方面，它受到数据提供速度的限制；另一方面，则受到收集足够数据以使重新训练产生效果的需求限制。
- en: '![Image](../Images/0c8d71d262bc407a56865915a599e208.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/0c8d71d262bc407a56865915a599e208.png)'
- en: Within this time frame, you can pick the period based on what’s practical and
    makes more sense for the use case.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个时间框架内，你可以根据实际情况和使用案例选择适合的周期。
- en: 'Check #5\. Should we keep the older data?'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '检查 #5。我们应该保留旧数据吗？'
- en: There is one more question that often comes up. How should we retrain the model?
    Should we add some new data and drop some old? Should we continuously increase
    the training set?
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个经常出现的问题。我们应该如何重新训练模型？是否应该添加一些新数据并丢弃一些旧数据？是否应该持续增加训练集？
- en: This is a bonus check we can run.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们可以运行的一个额外检查。
- en: We can imitate model retraining at the chosen interval and then check how things
    change if we start dropping the old data.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在选择的间隔进行模型重新训练，然后检查如果开始丢弃旧数据会发生什么变化。
- en: '![Image](../Images/2433693530f83ace89e16563af95b574.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/2433693530f83ace89e16563af95b574.png)'
- en: We can often see that leaving out the old data makes no difference. Then, it
    is probably a sane thing to do to keep the training more lightweight.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们常常会看到，省略旧数据没有任何影响。那么，保持训练过程更轻量化可能是合理的。
- en: What’s more, sometimes it makes the model better! Keeping the old irrelevant
    data might cause the performance to go down if you have a dynamic use case. That
    is good to know in advance.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 更重要的是，有时这会使模型变得更好！保留旧的无关数据可能会导致性能下降，尤其是当你有一个动态使用案例时。这是值得事先了解的。
- en: Of course, we might also see that it makes sense to keep all you have for the
    time being. You can probably repeat the check later on.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也可能会发现暂时保留所有数据是有意义的。你可以稍后重复检查。
- en: What’s next?
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下一步是什么？
- en: With these checks, you can come prepared for the model maintenance. You can
    set up your retraining pipelines to get ready for the updates at a chosen interval.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些检查，你可以为模型维护做好准备。你可以设置你的重新训练管道，以便在选择的间隔准备好更新。
- en: Still, we cannot simply rely on our schedule. We also need a reality check.
    This means, monitoring our models once they go live.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 不过，我们不能仅仅依靠我们的计划。我们还需要进行现实检查。这意味着在模型上线后监控它们。
- en: To get the visibility, we can build a [monitoring dashboard](https://github.com/evidentlyai/evidently)
    or schedule regular checks to calculate the actual model performance (if we have
    the ground truth) or otherwise monitor the input data for statistical distribution
    drifts and outliers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得可见性，我们可以建立一个 [监控仪表板](https://github.com/evidentlyai/evidently) 或安排定期检查以计算实际模型性能（如果我们有实际数据），或者监控输入数据的统计分布漂移和异常值。
- en: '![Image](../Images/19db7390f4ca668c6a5a3a66023ce064.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/19db7390f4ca668c6a5a3a66023ce064.png)'
- en: Even stable models can face [data and concept drift](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)
    or certain rare events. In this case, we might then need to intervene earlier
    than planned.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是稳定的模型也可能面临 [数据和概念漂移](https://evidentlyai.com/blog/machine-learning-monitoring-data-and-concept-drift)
    或某些罕见事件。在这种情况下，我们可能需要比计划更早进行干预。
- en: On the other side, if things look steady, and we can skip an update for longer
    than planned.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果情况看起来稳定，我们可以跳过比计划时间更长的更新。
- en: Planning for regular retraining and complementing this with continuous monitoring
    is usually an optimal strategy to make the model live up to its promised performance!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 规划定期重新训练并结合持续监控通常是使模型达到承诺性能的最佳策略！
- en: '**Links**'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**链接**'
- en: You can find an extended version of this article [here](https://evidentlyai.com/blog/retrain-or-not-retrain).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [这里](https://evidentlyai.com/blog/retrain-or-not-retrain) 找到这篇文章的扩展版本。
- en: '[Machine learning monitoring checklist](/2021/03/machine-learning-model-monitoring-checklist.html)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[机器学习监控检查清单](/2021/03/machine-learning-model-monitoring-checklist.html)'
- en: '**Emeli Dral** is a Co-founder and CTO at Evidently AI where she creates tools
    to analyze and monitor ML models. Earlier she co-founded an industrial AI startup
    and served as the Chief Data Scientist at Yandex Data Factory. She is a co-author
    of the Machine Learning and Data Analysis curriculum at Coursera with over 100,000
    students.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Emeli Dral** 是 Evidently AI 的联合创始人兼首席技术官，她在公司开发用于分析和监控机器学习模型的工具。她曾共同创办过一家工业
    AI 初创公司，并担任 Yandex Data Factory 的首席数据科学家。她还是 Coursera 机器学习和数据分析课程的共同作者，该课程拥有超过
    100,000 名学生。'
- en: '[https://twitter.com/EmeliDral](https://twitter.com/EmeliDral)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/EmeliDral](https://twitter.com/EmeliDral)'
- en: '**Elena Samuylova** is a Co-founder and CEO at Evidently AI. Earlier she co-founded
    an industrial AI startup and led business development at Yandex Data Factory.
    Since 2014, she has worked with companies from manufacturing to retail to deliver
    ML-based solutions. In 2018, Elena was named 50 Women in Product Europe by Product
    Management Festival.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**Elena Samuylova** 是 Evidently AI 的联合创始人兼首席执行官。她曾共同创办过一家工业 AI 初创公司，并在 Yandex
    Data Factory 负责业务发展。自 2014 年以来，她与从制造业到零售业的公司合作，提供基于 ML 的解决方案。2018 年，Elena 被 Product
    Management Festival 评选为欧洲 50 位产品女性之一。'
- en: '[https://twitter.com/elenasamuylova/](https://twitter.com/elenasamuylova/)'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://twitter.com/elenasamuylova/](https://twitter.com/elenasamuylova/)'
- en: '**Related:**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Learning from machine learning mistakes](/2021/03/learning-from-machine-learning-mistakes.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从机器学习错误中学习](/2021/03/learning-from-machine-learning-mistakes.html)'
- en: '[A Machine Learning Model Monitoring Checklist: 7 Things to Track](/2021/03/machine-learning-model-monitoring-checklist.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型监控检查清单：7 个跟踪项](/2021/03/machine-learning-model-monitoring-checklist.html)'
- en: '[MLOps: Model Monitoring 101](/2021/01/mlops-model-monitoring-101.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[MLOps：模型监控 101](/2021/01/mlops-model-monitoring-101.html)'
- en: More On This Topic
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Schedule & Run ETLs with Jupysql and GitHub Actions](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Jupysql 和 GitHub Actions 调度和运行 ETL](https://www.kdnuggets.com/2023/05/schedule-run-etls-jupysql-github-actions.html)'
- en: '[Deep Learning For Compliance Checks: What''s New?](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习在合规检查中的新进展](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
- en: '[7 Essential Data Quality Checks with Pandas](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Pandas 中 7 个关键数据质量检查]https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)'
- en: '[Learn Machine Learning From These GitHub Repositories](https://www.kdnuggets.com/2023/01/learn-machine-learning-github-repositories.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这些 GitHub 仓库学习机器学习](https://www.kdnuggets.com/2023/01/learn-machine-learning-github-repositories.html)'
- en: '[Learn How to Run Alpaca-LoRA on Your Device in Just a Few Steps](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[了解如何在您的设备上仅需几个步骤即可运行 Alpaca-LoRA](https://www.kdnuggets.com/2023/05/learn-run-alpacalora-device-steps.html)'
- en: '[Run an LLM Locally with LM Studio](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 LM Studio 运行 LLM](https://www.kdnuggets.com/run-an-llm-locally-with-lm-studio)'
