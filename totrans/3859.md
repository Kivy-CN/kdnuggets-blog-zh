# 你的机器学习代码消耗了多少内存？

> 原文：[https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html](https://www.kdnuggets.com/2021/07/memory-machine-learning-code-consuming.html)

[评论](#comments)

![](../Images/e666b93a66f863d32faf7f17039496f7.png)

图片来源：[Pixabay](https://pixabay.com/photos/hourglass-clock-time-period-hours-2910951/)

### 为什么要分析内存使用情况？

假设你已经编写了一个很酷的机器学习（ML）应用程序或创建了一个炫目的神经网络模型。现在你想将这个模型部署到某个 Web 服务或 REST API 上。

或者，你可能基于来自制造工厂工业传感器的数据流开发了这个模型，现在你必须将模型部署到其中一台工业控制 PC 上，以便根据不断接收的数据做出决策。

![](../Images/d3c66c70d3e3d5a01f9a613c092c6a39.png)

“兴奋地开发了一个炫酷的机器学习模型”。图片来源：[Pixabay](https://pixabay.com/photos/children-win-success-video-game-593313/)

作为一名数据科学家，你可能会经常收到来自工程/平台团队的一个非常常见的问题：“***你的模型/代码占用多少内存？***”或“***在某些给定数据负载下，你的代码的内存峰值使用量是多少？***”

这自然会引起你的关注，因为**硬件资源可能有限**，一个 ML 模块不应该占用系统的所有内存。这在**边缘计算场景中尤为重要**，即 ML 应用可能在边缘运行，例如在工业 PC 上的虚拟化容器中。

此外，你的模型可能是运行在那块硬件上的数百个模型之一，你必须对**峰值内存使用量有一些了解**，因为如果多个模型同时达到内存使用峰值，可能会导致系统崩溃。

现在，这让你感到好奇了，不是吗？

![](../Images/60dfc75688808c42908777a9085c8b0e.png)

图片来源：[Pixabay](https://pixabay.com/photos/child-surprise-think-interactivity-2800835/)

> **…硬件资源可能有限**，一个 ML 模块不应该占用系统的所有内存。这在**边缘计算场景中尤为重要…**

### 不要犯这个根本错误

请注意，我们讨论的是整个代码的运行时内存配置（一个动态量）。这与 ML 模型的大小或压缩无关（你可能将其保存为特殊对象在磁盘上，例如[Scikit-learn Joblib dump](https://scikit-learn.org/stable/modules/model_persistence.html)，一个简单的 Python Pickle dump，一个[TensorFlow HFD5](https://www.tensorflow.org/tutorials/keras/save_and_load)，或类似的东西）。

### Scalene: 一个精巧的内存/CPU/GPU 分析工具

这里有一篇关于一些较旧的内存分析工具在 Python 中使用的文章。

[**如何管理 Python 中的内存**](https://www.pluralsight.com/guides/profiling-memory-usage-in-python)

在本文中，我们将讨论 **Scalene** —— 您的一站式解决方案，用于回答您的工程团队提出的这些问题。

根据其 [GitHub 页面](https://github.com/plasma-umass/scalene)，“*Scalene 是一个高性能的 CPU、GPU 和内存分析工具，做了许多其他 Python 分析工具无法做的事情。它运行速度比其他分析工具快几个数量级，同时提供更详细的信息。*”

该工具由马萨诸塞大学开发。请查看这个视频，了解全面介绍。

### 安装

这毕竟是一个 Python 包。因此，通常情况下请安装。

```py
**pip install scalene**
```

目前仅适用于 Linux 操作系统。我没有在 Windows 10 上进行测试。

### 在 CLI 或 Jupyter Notebook 中使用。

使用 Scalene 非常直接。

```py
**scalene <yourapp.py>**
```

另外，您也可以通过使用这个魔法命令在 Jupyter notebook 中使用它。

```py
**%load_ext scalene**
```

### 示例输出

这是一个示例输出。我们将很快深入探讨。

![](../Images/56327d172e1146bf408b00075cfc9130.png)

### 功能

以下是 Scalene 的一些酷炫功能。大多数功能是自解释的，可以从上面的截图中了解，

+   **行或函数**：报告整个函数和每一行独立代码的信息。

+   **线程**：它支持 Python 线程。

+   **多进程**：支持使用 `multiprocessing` 库。

+   **Python与C的时间**：Scalene 分析 Python 与本地代码（例如库）的时间消耗。

+   **系统时间**：它区分系统时间（例如，休眠或执行 I/O 操作）。

+   **GPU**：它还可以报告在 NVIDIA GPU 上消耗的时间（如果存在的话）。

+   **复制量**：报告每秒复制的数据量（以 MB 为单位）。

+   **检测泄漏**：Scalene 可以自动定位可能的内存泄漏行！

### 一个具体的机器学习代码示例

让我们开始将 Scalene 用于内存分析标准机器学习代码的工作。我们将查看两种不同类型的 ML 模型——原因稍后将澄清。我们将使用 Scikit-learn 库进行所有三种模型，并利用其合成数据生成函数来创建我们的数据集。

+   一个多重线性回归模型

+   使用相同数据集的深度神经网络模型。

所有三种模型的建模代码遵循完全相同的结构。外部 I/O 操作也在下图中表示，因为我们将看到这些操作可能会或可能不会主导内存配置文件，具体取决于模型的类型。

![](../Images/bad072eafb90ed13e967f39d8e78549e.png)

图片来源：作者制作（拥有版权）

### 线性回归模型

代码文件在[我的 GitHub 仓库](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)。

我们使用标准导入和两个变量 `NUM_FEATURES` 和 `NUM_SMPLES` 进行一些实验。

![](../Images/13f542dad7e5f782d08833165ac26985.png)

我们没有展示数据生成和模型拟合的代码。它们相当标准，可以在[这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/linearmodel.py)查看。我们将拟合的模型保存为一个 pickle 文件，并与测试 CSV 文件一起加载进行推理。

![](../Images/58d405dfd5cbd73c8c812d6b95f98183.png)

为了清晰起见，我们在`main`循环下运行所有内容，使用 Scalene 执行和报告（你会很快理解）。

![](../Images/ff5d40503e1cab93aaa148f919586e68.png)

当我们运行该命令时，

```py
$ scalene linearmodel.py --html >> linearmodel-scalene.html
```

我们得到这些结果作为输出。**请注意，这里我使用了`--html`标志，并将输出管道到一个 HTML 文件以便于报告**。

![](../Images/b9a015457f196fb99f274789ee2c8455.png)

![](../Images/f47459e528414a38fd1903b9ed9792b7.png)

### **那么，这个结果有什么引人注目的地方？**

内存占用几乎完全被外部 I/O 操作主导，例如 Pandas 和 Scikit-learn 估计器的加载，只有少量内存用于将测试数据写入磁盘上的 CSV 文件。

实际的机器学习建模、Numpy 或 Pandas 操作以及推理不会对内存产生任何影响！

### 当模型和数据规模扩大时会发生什么？

我们可以扩展数据集规模（行数）和模型复杂性（特征数），并进行相同的内存分析，以记录各种操作在内存消耗方面的表现。结果如图所示。

这里的**X轴表示特征数/数据点数的配对**。请注意，此图描绘的是百分比而非绝对值，以展示各种操作的相对重要性。

![](../Images/bfadee308ec5d1872491b943029cc923.png)

图片来源：作者制作（拥有版权）

### 因此，对于线性回归模型……

从这些实验中，我们得出结论，Scikit-learn 线性回归估计器相当高效，并且**在实际模型拟合或推理过程中不会消耗大量内存**。

然而，它确实在代码方面有一个固定的内存占用，并且在加载时会消耗这么多内存。然而，随着数据规模和模型复杂性的增加，这部分代码占整体的百分比会下降。

因此，如果你正在处理这样的**小型线性模型，你可能需要专注于数据文件 I/O 以优化代码**，以获得更好的内存性能。

### 深度神经网络会发生什么？

如果我们使用一个具有 2 个隐藏层的神经网络（每个隐藏层中有 50 个神经元）进行类似实验，那么结果如下所示。该[代码文件在这里](https://github.com/tirthajyoti/Machine-Learning-with-Python/blob/master/Memory-profiling/Scalene/mlp.py)。

![](../Images/bdc5ab77dc5b38015239b35d40d382bd.png)

图片来源：作者制作（拥有版权）

很明显，**神经网络模型在训练/拟合步骤中消耗大量内存，不像线性回归模型**。然而，对于特征数量较少和数据量较大的情况，拟合所需的内存量较少。

你还可以尝试各种架构和超参数，并记录内存使用情况，以找到适合你情况的设置。

### 遵循实验方法。

如果你使用相同的[代码文件](https://github.com/tirthajyoti/Machine-Learning-with-Python/tree/master/Memory-profiling/Scalene)重复实验，结果会根据你的硬件、磁盘/ CPU/ GPU/ 内存类型而大相径庭。本文的目的是让你了解如何为自己的代码进行内存分析实验，而不是关注实际数值或趋势。

### 一些关键建议。

+   尽量编写**小函数**，专注于单一任务。

+   保留一些**自由变量**，如特征数量和数据点数量，以便你可以在数据/模型扩展时，通过最小的修改运行相同的代码文件，以检查内存配置。

+   如果你在比较一个 ML 算法与另一个算法时，尽量保持**整体代码的结构和流程尽可能相同**以减少混淆。最好只更改估计器类，并比较内存配置。

+   **数据和模型 I/O**（导入语句、模型在磁盘上的持久化）根据你的建模场景，在内存占用方面可能会出乎意料地占据主导地位。在优化时千万不要忽视它们。

+   出于同样的原因，考虑比较**来自多个实现/包的相同算法**（例如 Keras 与 PyTorch 与 Scikit-learn）的内存配置。如果内存优化是你的主要目标，你可能需要寻找具有最小内存占用的实现，即使它在功能或性能方面不是绝对最好的。

+   如果数据 I/O 成为瓶颈，请探索**更快的选项或其他存储类型**，例如用 parquet 文件和 Apache Arrow 存储替换 Pandas CSV。查看这篇文章。

[**读取 Parquet 文件（使用 Arrow）与 Pandas 读取 CSV 文件的速度有多快？**](https://towardsdatascience.com/how-fast-is-reading-parquet-file-with-arrow-vs-csv-with-pandas-2f8095722e94)

### 你还可以使用 Scalene 做其他事情。

在这篇文章中，我们只是讨论了最基本的内存分析，重点是经典的 ML 建模代码。Scalene CLI 还有其他选项，你可以利用。

+   仅分析 CPU 时间而不分析内存配置。

+   仅减少具有非零内存占用的分析。

+   指定 CPU 和内存分配的最低阈值。

+   设置 CPU 采样率。

+   多线程并检查差异。

### 有时候最终验证是必要的。

对于资源有限的情况，托管一个验证环境/服务器以接受给定的建模代码（开发完成后）并通过内存分析器运行，以创建运行时统计数据，是个好主意。如果它符合预定的内存占用标准，建模代码才会被接受用于进一步部署。

![](../Images/834d9c2379f2cc82d9c48a779e04b4cc.png)

图片来源：作者制作（拥有版权）

> 如果内存优化是你的主要目标，你可能需要寻找一个内存占用最小但能令人满意地完成工作的实现。

### 总结

在这篇文章中，我们讨论了对你的ML代码进行内存分析的重要性，以便顺利地与将代码部署到服务/机器上的平台/工程团队接口。内存分析还可以展示根据你处理的数据和算法优化代码的意外方法。

我们展示了一个典型的ML建模代码示例，使用强大但轻量的Python库Scalene进行性能分析。我们演示了一些线性回归和神经网络模型的代表性结果，并提供了一些一般性建议。

希望你能在使用这些工具和技术将你的ML代码实施和部署到生产环境中获得更多成功。

你可以查看作者的[**GitHub**](https://github.com/tirthajyoti?tab=repositories)** 代码库**，获取机器学习和数据科学方面的代码、想法和资源。如果你像我一样，对AI/机器学习/数据科学充满热情，请随时[在LinkedIn上添加我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)或[在Twitter上关注我](https://twitter.com/tirthajyotiS)。

[原文](https://towardsdatascience.com/how-much-memory-is-your-ml-code-consuming-98df64074c8f)。经许可转载。

**相关：**

+   [作为数据科学家的可重用Python代码管理](/2021/06/managing-reusable-python-code-data-scientist.html)

+   [5个Python数据处理技巧与代码片段](/2021/07/python-tips-snippets-data-processing.html)

+   [GitHub Copilot: 你的AI编程伙伴 – 到底有什么大惊小怪的？](/2021/07/github-copilot-ai-pair-programmer.html)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织进行IT工作

* * *

### 更多相关话题

+   [一种（更好）的方法来评估你的机器学习模型](https://www.kdnuggets.com/2022/01/much-better-approach-evaluate-machine-learning-model.html)

+   [在数据科学中你需要多少数学知识？](https://www.kdnuggets.com/2020/06/math-data-science.html)

+   [2022年数据科学家的收入是多少？](https://www.kdnuggets.com/2022/02/much-data-scientists-make-2022.html)

+   [如何使用 Pandas 对大数据集进行内存高效操作](https://www.kdnuggets.com/how-to-perform-memory-efficient-operations-on-large-datasets-with-pandas)

+   [Transformer 的内存复杂性](https://www.kdnuggets.com/2022/12/memory-complexity-transformers.html)

+   [Python 中的内存分析简介](https://www.kdnuggets.com/introduction-to-memory-profiling-in-python)
