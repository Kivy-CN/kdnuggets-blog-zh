- en: 'Explainable AI: 10 Python Libraries for Demystifying Your Model’s Decisions'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html](https://www.kdnuggets.com/2023/01/explainable-ai-10-python-libraries-demystifying-decisions.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Explainable AI: 10 Python Libraries for Demystifying Your Model''s Decisions](../Images/8eb96b67e4f791d4df13c6b2556316e6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: XAI is artificial intelligence that allows humans to understand the results
    and decision-making processes of the model or system.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: The 3 Stages of Explanation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pre-modeling Explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Explainable AI starts with explainable data and clear, interpretable feature
    engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Modeling Explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When choosing a model for a particular problem, it is generally best to use
    the most interpretable model that still achieves good predictive results.
  prefs: []
  type: TYPE_NORMAL
- en: Post-model Explainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This includes techniques such as perturbation, where the effect of changing
    a single variable on the model's output is analyzed such as SHAP values for after
    training.
  prefs: []
  type: TYPE_NORMAL
- en: Python Libraries for AI Explainability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I found these 10 Python libraries for AI explainability:'
  prefs: []
  type: TYPE_NORMAL
- en: SHAP (SHapley Additive exPlanations)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SHAP is a model agnostic and works by breaking down the contribution of each
    feature and attributing a score to each feature.
  prefs: []
  type: TYPE_NORMAL
- en: LIME (Local Interpretable Model-agnostic Explanations)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LIME is another model agnostic method that works by approximating the behavior
    of the model locally around a specific prediction.
  prefs: []
  type: TYPE_NORMAL
- en: ELi5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Eli5 is a library for debugging and explaining classifiers. It provides feature
    importance scores, as well as "reason codes" for scikit-learn, Keras, xgboost,
    LightGBM, CatBoost.
  prefs: []
  type: TYPE_NORMAL
- en: Shapash
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Shapash is a Python library which aims to make machine learning interpretable
    and understandable to everyone. Shapash provides several types of visualization
    with explicit labels.
  prefs: []
  type: TYPE_NORMAL
- en: Anchors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Anchors is a method for generating human-interpretable rules that can be used
    to explain the predictions of a machine learning model.
  prefs: []
  type: TYPE_NORMAL
- en: XAI (eXplainable AI)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: XAI is a library for explaining and visualizing the predictions of machine learning
    models including feature importance scores.
  prefs: []
  type: TYPE_NORMAL
- en: BreakDown
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BreakDown is a tool that can be used to explain the predictions of linear models.
    It works by decomposing the model's output into the contribution of each input
    feature.
  prefs: []
  type: TYPE_NORMAL
- en: interpret-text
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: interpret-text is a library for explaining the predictions of natural language
    processing models.
  prefs: []
  type: TYPE_NORMAL
- en: iml (Interpretable Machine Learning)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: iml currently contains the interface and IO code from the Shap project, and
    it will potentially also do the same for the Lime project.
  prefs: []
  type: TYPE_NORMAL
- en: aix360 (AI Explainability 360)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: aix360 includes a comprehensive set of algorithms that cover different dimensions
  prefs: []
  type: TYPE_NORMAL
- en: OmniXAI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OmniXAI (short for Omni eXplainable AI), addresses several problems with interpreting
    judgments produced by machine learning models in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Have I forgotten any libraries?
  prefs: []
  type: TYPE_NORMAL
- en: '**Sources**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Top Explainable AI (XAI) Python Frameworks in 2022](https://lnkd.in/dzvgSe24)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Maryam Miradi](https://www.linkedin.com/in/maryammiradi/)** is an AI and
    Data Science Lead with a PhD in Machine Learning and Deep learning, specialised
    in NLP and Computer Vision. She has 15+ years of experience creating successful
    AI solutions with a track record of delivering over 40 successful projects. She
    has worked for 12 different organisations in a variety of industries, including
    Detecting Financial Crime, Energy, Banking, Retail, E-commerce, and Government.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Driving Better Business Decisions](https://www.kdnuggets.com/2022/04/informs-driving-better-business-decisions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Reinforcement Learning: Teaching Computers to Make Optimal Decisions](https://www.kdnuggets.com/2023/07/reinforcement-learning-teaching-computers-make-optimal-decisions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Demystifying Bad Science](https://www.kdnuggets.com/2022/01/demystifying-bad-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Demystifying Machine Learning](https://www.kdnuggets.com/demystifying-machine-learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Demystifying Decision Trees for the Real World](https://www.kdnuggets.com/demystifying-decision-trees-for-the-real-world)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
