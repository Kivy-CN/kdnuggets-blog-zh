- en: GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/05/gpt4-vulnerable-prompt-injection-attacks-causing-misinformation.html](https://www.kdnuggets.com/2023/05/gpt4-vulnerable-prompt-injection-attacks-causing-misinformation.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/d88a159ec0c29953e4f060d25cd52a08.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by [pch.vector](https://www.freepik.com/free-vector/too-much-information-spam-concept_13146689.htm#query=misinformation&position=2&from_view=search&track=sph)
    on [Freepik](https://www.freepik.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Recently, ChatGPT has taken the world by storm with its GPT model to provide
    a human-like response with any input given. Almost any text-related task is possible,
    such as summarizing, translation, role-playing, and providing information. Basically,
    the various text-based activities that humans can do.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: With ease, many people go to ChatGPT to get the required information. For example,
    historical facts, food nutrition, health issues, etc. All of this information
    might be ready quickly. The information accuracy is also improved with the latest
    GPT-4 model from ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is still a loophole possibility that exists in GPT-4 to provide
    misinformation during the time this article is written. How is the vulnerability
    exist? Let’s explore them.
  prefs: []
  type: TYPE_NORMAL
- en: How does the Vulnerability work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a recent [article by William Zheng](https://www.robustintelligence.com/blog-posts/prompt-injection-attack-on-gpt-4),
    we can try to trick the GPT-4 model by guiding the model into a misinformation
    bot using the consecutive false fact that was wrapped in the ChatGPT operative
    words.
  prefs: []
  type: TYPE_NORMAL
- en: To understand it in detail, let’s try an experiment to ask ChatGPT into the
    misinformation bot explicitly. Here is the detail in the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/6cacb5435b0431e2fe57a4d1e06a936f.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the image above, the GPT-4 model adamantly refuses to provide
    any false information. The model strongly tries to adhere to the reliability rule.
  prefs: []
  type: TYPE_NORMAL
- en: However, let’s try to change the given prompt. In the following prompt, I would
    input the given prompt with role tags and guide the GPT-4 model to provide false
    information.
  prefs: []
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/c5d659f18a121ec3638e1fbe5c9c1b12.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see in the result above, the GPT-4 model is now giving me false information
    about the 2020 American election and the vaccine fact. We could guide the model
    into something else by changing something on the prompt. What was changed is that
    we give role information and some prompt example of how the model should act,
    but how did it work?
  prefs: []
  type: TYPE_NORMAL
- en: In the OpenAI API, we can send a series of inputs to the API with the given
    role to guide the model. The code example can be seen in the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'From the code above, we provide the role information where each role has its
    tasks, including:'
  prefs: []
  type: TYPE_NORMAL
- en: The role “system” is the set guidelines for the model “assistant” behavior,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The role “user” represents the prompt from the person interacting with the model,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The role “assistant” is the response to the “user” prompt
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the guidance of this role input, we can guide on how we want our model
    works, and that is indeed what happened in the ChatGPT before. Let’s take a look
    at our prompt that provides false information.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: You can see in our prompt above we use the system role to direct ChatGPT into
    becoming a bot that gives misinformation. Following that, we provide an example
    of how to react when users ask for information by giving them the wrong fact.
  prefs: []
  type: TYPE_NORMAL
- en: So, is these role tags the thing that causes the model to allow themselves to
    provide false information? Let’s try the prompt without the role.
  prefs: []
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/45f38c2d0503d69cf1422615599778fa.png)'
  prefs: []
  type: TYPE_IMG
- en: As we can see, the model now corrects our attempt and provide the fact. It’s
    a given that the role tags is what guide the model to be misused.
  prefs: []
  type: TYPE_NORMAL
- en: However, the misinformation can only happen if we give the model user assistant
    interaction example. Here is an example if I don’t use the user and assistant
    role tags.
  prefs: []
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/9d5063e2f096659a64a7e78cfeaeb1ea.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that I don’t provide any user and assistant guidance. The model
    then stands to provide accurate information.
  prefs: []
  type: TYPE_NORMAL
- en: Also, misinformation can only happen if we give the model two or more user assistant
    interaction examples. Let me show an example.
  prefs: []
  type: TYPE_NORMAL
- en: '![GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation](../Images/ea910b159140b93ea38022f8fd752258.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, I only give one example, and the model still insists on providing
    accurate information and correcting any mistakes I provide.
  prefs: []
  type: TYPE_NORMAL
- en: I have shown you the possibility that ChatGPT and GPT-4 might provide false
    information using the role tags. As long as the OpenAI hasn’t fixed the content
    moderation, it might be possible for the ChatGPT to provide misinformation, and
    you should be aware.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The public widely uses ChatGPT, yet it retains a vulnerability that can lead
    to the dissemination of misinformation. Through manipulation of the prompt using
    role tags, users could potentially circumvent the model's reliability principle,
    resulting in the provision of false facts. As long as this vulnerability persists,
    caution is advised when utilizing the model.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Next Level AI Programming: Prompt Design & Building AI Products](https://www.kdnuggets.com/2023/03/corise-prompt-design-building-ai-products.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Art of Prompt Engineering: Decoding ChatGPT](https://www.kdnuggets.com/2023/06/art-prompt-engineering-decoding-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Ensuring Reliable Few-Shot Prompt Selection for LLMs](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Prompt Engineering is a Fad](https://www.kdnuggets.com/why-prompt-engineering-is-a-fad)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Rise and Fall of Prompt Engineering: Fad or Future?](https://www.kdnuggets.com/the-rise-and-fall-of-prompt-engineering-fad-or-future)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Prompt Engineering 101: Mastering Effective LLM Communication](https://www.kdnuggets.com/prompt-engineering-101-mastering-effective-llm-communication)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
