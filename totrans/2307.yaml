- en: 5 Ways to Deal with the Lack of Data in Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理数据不足的 5 种方法
- en: 原文：[https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html](https://www.kdnuggets.com/2019/06/5-ways-lack-data-machine-learning.html)
- en: '![5 Ways to Deal with the Lack of Data in Machine Learning](../Images/03ddce27b377cb1a1c82c79162e21088.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何处理机器学习中的数据不足问题](../Images/03ddce27b377cb1a1c82c79162e21088.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由编辑提供
- en: In many projects I carried out, companies, despite having fantastic AI business
    ideas, display a tendency to slowly become frustrated when they realize that they
    do not have enough data… However, solutions do exist! **The purpose of this article
    is to briefly introduce you to some of them (the ones that are proven effective
    in my practice) rather than to list all existing solutions.**
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在我进行的许多项目中，公司尽管拥有出色的 AI 商业想法，但在意识到他们没有足够的数据时，往往会逐渐感到沮丧……然而，解决方案是存在的！**本文的目的是简要介绍其中一些（我实践中证明有效的）解决方案，而不是列出所有现有的解决方案。**
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The problem of data scarcity is very important since data are at the core of
    any AI project. The size of a datasetis often responsible for poor performances
    in ML projects.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 数据稀缺的问题非常重要，因为数据是任何 AI 项目的核心。数据集的大小往往是 ML 项目表现不佳的原因。
- en: Most of the time, data related issues are the main reason why great AI projects
    cannot be accomplished. In some projects, you come to the conclusion that there
    is no relevant data or the collection process is too difficult and time-consuming.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数情况下，数据相关问题是优秀 AI 项目无法完成的主要原因。在一些项目中，你会得出结论，认为没有相关数据或者收集过程太困难且耗时。
- en: Supervised machine learning models are being successfully used to respond to
    a whole range of business challenges. However, these models are data-hungry, and
    their performance relies heavily on the size of training data available. In many
    cases, it is difficult to create training datasets that are large enough.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 监督机器学习模型已成功用于应对各种业务挑战。然而，这些模型对数据的需求很高，其性能在很大程度上依赖于可用的训练数据的大小。在许多情况下，很难创建足够大的训练数据集。
- en: Another issue I could mention is that project analysts tend to underestimate
    the amount of data necessary to handle common business problems. I remember myself
    struggling to collect big training datasets. It is even more complicated to gather
    data when working for a large company.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个我可以提到的问题是，项目分析师往往低估了处理常见业务问题所需的数据量。我记得自己曾经在收集大型训练数据集时遇到过困难。在为大公司工作时，收集数据更是复杂。
- en: '***How much data do I need?***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***我需要多少数据？***'
- en: Well, you need roughly 10 times as many examples as there are degrees of freedom
    in your model. The more complex the model, the more you are prone to overfitting,
    but that can be avoided by validation. **However, much fewer data can be used
    based on the use case.**
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，您大约需要模型自由度数量的 10 倍的示例。模型越复杂，越容易出现过拟合，但可以通过验证来避免。**然而，根据使用情况，可以使用更少的数据。**
- en: '***Overfitting:**** refers to a model that models the training data too well.
    It happens when a model learns the detail and noise in the training data to the
    extent that it negatively impacts the performance of the model on new data.*'
  id: totrans-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***过拟合：*** 指的是一个模型对训练数据建模得过于精准。当一个模型学习了训练数据中的细节和噪声到影响模型在新数据上表现的程度时，就会发生过拟合。'
- en: It is also worth discussing the issue of handling the missing values. Especially
    if the number of missing values in your data is big enough (above 5%).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失值的问题也值得讨论。特别是如果数据中缺失值的数量足够多（超过5%）。
- en: Once again, dealing with missing values will depend on certain ‘success’ criteria.Moreover,
    these criteria vary for different datasets and even for different applications,
    such as recognition, segmentation, prediction, and classification (given the same
    dataset) even for different applications (recognition, segmentation, prediction,
    classification).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，处理缺失值将取决于某些“成功”标准。此外，这些标准因数据集和不同应用（如识别、分割、预测和分类，即使是相同的数据集）而异。
- en: '*It is important to understand that there is no perfect way to deal with missing data.*'
  id: totrans-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*重要的是要理解，没有完美的方法来处理缺失数据。*'
- en: Different solutions exist, but it depends on the kind of problem — Time-series
    Analysis, ML, Regression, etc.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 存在不同的解决方案，但这取决于问题的类型——时间序列分析、机器学习、回归等。
- en: When it comes to predictive techniques, they shall be used only when missing
    values are not observed completely at random, and the variables were chosen to
    impute such missing values have some relationship with it, else it could yield
    imprecise estimates.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及预测技术时，仅在缺失值不是完全随机观测时使用它们，并且用于填补这些缺失值的变量与缺失值有某种关系，否则可能会产生不准确的估计。
- en: In general, different machine learning algorithms can be used to determine the
    missing values. This works by turning missing features to labels themselves and
    now using columns without missing values to predict columns with missing values.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，可以使用不同的机器学习算法来确定缺失值。这通过将缺失的特征转化为标签，并使用没有缺失值的列来预测缺失值的列来实现。
- en: Based on my experience, you will be confronted with a lack of data or missing
    data at some point if you decide to build an AI-powered solution, **but fortunately,
    there are ways to turn that minus into a plus.**
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，如果你决定构建一个AI驱动的解决方案，你将面临数据不足或缺失数据的问题，**但幸运的是，有办法将这个劣势转化为优势。**
- en: '**Lack of data?**'
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**数据不足？**'
- en: As noted above, it is impossible to precisely estimate the minimum amount of
    data required for an AI project. Obviously, the very nature of your project will
    influence significantly the amount of data you will need. For example, texts,
    images, and videos usually require more data. **However, many other factors should
    be considered in order to make an accurate estimate.**
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，无法精确估计AI项目所需的数据最小量。显然，你的项目性质将显著影响你所需的数据量。例如，文本、图像和视频通常需要更多的数据。**然而，为了做出准确的估计，还需要考虑许多其他因素。**
- en: '**Number of categories to be predicted**'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**预测的类别数量**'
- en: What is the expected output of your model? Basically, the fewest number or categories
    the better.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你的模型期望的输出是什么？基本上，类别或数量越少越好。
- en: '**Model Performance** If you plan on getting a product in production, you need
    more. **A small dataset might be good enough for a proof of concept, but in production,
    you’ll need way more data.**'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型性能** 如果你计划将产品投入生产，你需要更多的数据。**一个小数据集可能足够用于概念验证，但在生产中，你需要更多的数据。**'
- en: In general, small datasets require models that have low complexity (or [high
    bias](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)) to avoid [overfitting](https://en.wikipedia.org/wiki/Overfitting) the
    model to the data.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，小数据集需要具有低复杂度的模型（或[高偏差](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff)）以避免[过拟合](https://en.wikipedia.org/wiki/Overfitting)模型到数据上。
- en: Non-Technical Solutions
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 非技术解决方案
- en: Before exploring technical solutions, let’s analyze what we can do to enhance
    your dataset. It might sound obvious but before getting started with AI, please
    try to obtain as much data as possible by developing your external and internal
    tools with data collection in mind. If you know the tasks that a machine learning
    algorithm is expected to perform, then you can create a data-gathering mechanism
    in advance.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在探索技术解决方案之前，让我们分析一下我们可以做些什么来增强你的数据集。这可能听起来很明显，但在开始AI之前，请尽量通过开发外部和内部工具来获取尽可能多的数据。如果你知道机器学习算法预计要执行的任务，那么你可以提前创建数据收集机制。
- en: '*Try to establish a real data culture within your organization.*'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*尝试在组织内建立真实的数据文化。*'
- en: To initiate ML execution, you could rely on open source data. There are a lot
    of data available for ML, and some companies are ready to give it away.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了启动机器学习执行，你可以依赖开源数据。有很多机器学习数据可用，一些公司愿意将其免费提供。
- en: If you need external data for your project, it can be beneficial to form partnerships
    with other organizations in order to get relevant data. Forming partnerships will
    obviously cost you some time, but the proprietary data gained will build a natural
    barrier to any rivals.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要外部数据来进行项目，与其他组织建立合作关系以获取相关数据可能会很有益。建立合作关系显然会花费一些时间，但获得的专有数据将为任何竞争对手建立自然障碍。
- en: Build a useful application, give it away, use the data
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个有用的应用程序，将其免费提供，并利用数据。
- en: Another approach that I used in my previous project was to give away access
    to a cloud application to customers. The data that makes it into the app can be
    used to build machine learning models. My previous client built an application
    for hospitals and made it free. We gathered a lot of data thanks to it and managed
    to create a unique dataset for our ML solution. It really helps to tell customers
    or investors that you have built your own and unique dataset.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我在之前的项目中使用的另一种方法是向客户免费提供对云应用程序的访问权限。进入应用程序的数据可以用于构建机器学习模型。我的前一个客户为医院构建了一个应用程序，并将其免费提供。我们因此收集了大量数据，并成功创建了一个独特的数据集用于我们的机器学习解决方案。确实有助于向客户或投资者展示你已经构建了自己的独特数据集。
- en: '![](../Images/e81a847a79f65283b88220dbf58ca256.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e81a847a79f65283b88220dbf58ca256.png)'
- en: Small datasets
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 小数据集
- en: 'Based on my experience, some common approaches that can help with building
    predictive models from small data sets are:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，一些常见的方法可以帮助从小数据集中构建预测模型：
- en: '![](../Images/417db596333fed2ef9abd993607d884a.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/417db596333fed2ef9abd993607d884a.png)'
- en: In general, the simpler the machine learning algorithm, the better it will learn
    from small data sets. From an ML perspective, **small** data requires models that
    have low complexity (or high bias) to avoid overfitting the model to the data.
    I noticed that the Naive Bayes algorithm is among the simplest classifiers and
    as a result learns remarkably well from relatively small data sets.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，机器学习算法越简单，它从小数据集中学习得越好。从机器学习的角度看，**小**数据需要具有低复杂性（或高偏差）的模型，以避免过拟合数据。我注意到朴素贝叶斯算法是最简单的分类器之一，因此在相对较小的数据集上学习得非常好。
- en: '***Naive Bayes methods:**** the set of supervised learning algorithms based
    on applying Bayes’ theorem with the “naive” assumption of conditional independence
    between every pair of features given the value of the class variable.*'
  id: totrans-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***朴素贝叶斯方法：**** 一组基于应用贝叶斯定理并假设特征对条件独立性的监督学习算法。*'
- en: You can also rely on other linear models and decision trees. Indeed, they can
    also perform relatively well on small data sets. Basically, simple models are
    able to learn from small data sets better than more complicated models (neural
    networks) since they are essentially trying to learn less.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以依赖其他线性模型和决策树。确实，它们在小数据集上也能表现相对良好。基本上，简单模型能比复杂模型（神经网络）更好地从小数据集中学习，因为它们本质上尝试学习的内容更少。
- en: For very **small datasets**, Bayesian methods are generally the best in class,
    although the results can be sensitive **to your choice of prior.** I think that
    the naive Bayes classifier and ridge regression are the best predictive models.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非常**小的数据集**，贝叶斯方法通常是最优秀的，尽管结果可能对**先验选择**敏感。我认为朴素贝叶斯分类器和岭回归是最佳的预测模型。
- en: When it comes to **small** datasets, you need models that have few parameters
    (low complexity) and/or a strong prior. You can also interpret the “prior” as
    an assumption you can make on how the data behaves.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 对于**小**数据集，你需要具有少量参数（低复杂性）和/或强先验的模型。你也可以将“先验”解释为你对数据行为的假设。
- en: '![](../Images/56e0048653663ded6790e3c968772657.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56e0048653663ded6790e3c968772657.png)'
- en: '**Many other solutions do exist depending on the exact nature of your business
    issues and the size of your dataset.**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**根据你的业务问题的具体性质和数据集的大小，确实存在许多其他解决方案。**'
- en: Transfer learning
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 迁移学习
- en: '***Definition:**** a framework that leverages existing relevant data or models
    while building a machine learning model.*'
  id: totrans-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***定义：**** 利用现有相关数据或模型来构建机器学习模型的框架。*'
- en: Transfer learning uses knowledge from a learned task to improve the performance
    on a related task, typically reducing the amount of required training data.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习利用从已学习任务中获得的知识来提升相关任务的性能，通常可以减少所需的训练数据量。
- en: Transfer learning techniques are useful because they allow models to make predictions
    for a new domain or task (known as the target domain) using knowledge learned
    from another dataset or existing machine learning models (the source domain).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习技术非常有用，因为它们允许模型利用从另一个数据集或现有机器学习模型中学到的知识，对新领域或任务（即目标领域）进行预测。
- en: '**Transfer learning techniques should be considered when you do not have enough
    target training data, and the source and target domains have some similarities
    but are not identical.**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**当你没有足够的目标训练数据，而源领域和目标领域有一些相似但并不完全相同时，迁移学习技术应该被考虑。**'
- en: '![](../Images/f3571fe02830ac79f4da7148726c51f8.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f3571fe02830ac79f4da7148726c51f8.png)'
- en: Naively aggregating models or different datasets would not always work! If the
    existing datasets are very different from the target data, then the new learner
    can be negatively impacted by existing data or models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 天真地聚合模型或不同数据集并不总是有效！如果现有数据集与目标数据非常不同，那么新学习者可能会受到现有数据或模型的负面影响。
- en: Transfer learning works well when you have other datasets you can use to infer
    knowledge, but what happens when you have no data at all? This is where data generation
    can play a role. It is used when no data is available or when you need to create
    more data than you could amass even through aggregation.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习在你有其他数据集可以用来推断知识时效果很好，但如果你根本没有数据会发生什么呢？这就是数据生成可以发挥作用的地方。当没有数据可用或需要创建比通过聚合获得更多的数据时，就需要使用数据生成。
- en: In this case, the small amount of data that does exist is modified to create
    variations on that data to train the model. For example, many images of a car
    can be generated by cropping and downsizing one single image of a car.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，存在的小量数据被修改以创建数据的变体来训练模型。例如，可以通过裁剪和缩小一张汽车图片来生成许多汽车的图片。
- en: Unfortunately, the lack of quality labeled data is also one of the largest challenges
    facing data science teams, but by using techniques, such as transfer learning
    and data generation, it is possible to overcome data scarcity.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，缺乏高质量标记数据也是数据科学团队面临的最大挑战之一，但通过使用迁移学习和数据生成等技术，可以克服数据稀缺的问题。
- en: Another common application of transfer learning is to train models on cross-customer
    datasets to overcome the cold-start problems. I noticed that SaaS companies often
    have to deal with this when onboarding new customers to their ML products. Indeed,
    until the new customer has collected enough data to achieve good model performance
    (which could take several months), it’s hard to provide value.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习的另一个常见应用是训练跨客户数据集的模型，以克服冷启动问题。我注意到SaaS公司在将新客户接入其机器学习产品时经常会遇到这个问题。确实，在新客户收集到足够的数据以实现良好的模型性能之前（这可能需要几个月），很难提供价值。
- en: Data Augmentation
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据增强
- en: Data augmentation means increasing the number of data points. In my latest project,
    we used data augmentation techniques to increase the number of images in our dataset.
    In terms of traditional row/column format data, it means increasing the number
    of rows or objects.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强意味着增加数据点的数量。在我最新的项目中，我们使用数据增强技术来增加数据集中图像的数量。对于传统的行/列格式数据来说，这意味着增加行数或对象数。
- en: 'We had no choice but to rely on data augmentation for two reasons: time and
    accuracy. Every data collection process is associated with a cost. This cost can
    be in terms of dollars, human effort, computational resources, and, of course,
    time consumed in the process.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们别无选择，只能依赖数据增强，原因有二：时间和准确性。每个数据收集过程都涉及成本。这些成本可能是金钱、人力、计算资源，当然还有过程中的时间消耗。
- en: '![](../Images/ddc94ff72772016c5a35396446926fd9.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ddc94ff72772016c5a35396446926fd9.png)'
- en: As a consequence, we had to augment existing data to increase the data size
    that we feed to our ML classifiers and to compensate for the cost involved in
    further data collection.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们不得不增强现有数据，以增加输入到机器学习分类器中的数据量，并补偿进一步数据收集所涉及的成本。
- en: '*There are many ways to augment data.*'
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*有很多方法可以增强数据。*'
- en: In our case, you can rotate the original image, change lighting conditions,
    crop it differently, so for one image you can generate different sub-samples. **This
    way, you can reduce overfitting your classifier.**
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，你可以旋转原始图像，改变光照条件，或以不同方式裁剪图像，因此可以为一张图像生成不同的子样本。**这样，你可以减少对分类器的过拟合。**
- en: However, if you are generating artificial data using over-sampling methods,
    such as SMOTE, then there is a fair chance you may introduce overfitting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你使用过采样方法如SMOTE来生成人工数据，那么很可能会引入过拟合。
- en: '***Overfitting:**** An overfitted model is a model with a trend line that reflects
    the errors in the data that it is trained with, instead of accurately predicting
    unseen data.*'
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***过拟合：*** 过拟合模型是指趋势线反映了训练数据中的错误，而不是准确预测未见数据的模型。'
- en: '**This is something you must take into consideration when developing your AI
    solution.**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是在开发AI解决方案时必须考虑的因素。**'
- en: '![](../Images/197d6782b71346bdea402a2e0f249df1.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/197d6782b71346bdea402a2e0f249df1.png)'
- en: '**Synthetic Data**'
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '**合成数据**'
- en: Synthetic data means fake data that contains the same schema and statistical
    properties as its “real” counterpart. Basically, it looks so real that it’s nearly
    impossible to tell that it’s not.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 合成数据指的是具有与其“真实”对应物相同的模式和统计属性的虚假数据。基本上，它看起来非常真实，以至于几乎无法判断它不是。
- en: '**So what’s the point of synthetic data, and why does it matter if we already
    have access to the real thing?**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么，合成数据的意义是什么？如果我们已经有真实数据，这点为什么重要？**'
- en: I have seen synthetic data applied, especially when we were dealing with private
    data (banking, healthcare, etc.), which makes the use of synthetic data a more
    secure approach to development in certain instances.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我见过合成数据的应用，尤其是在我们处理私密数据（如银行、医疗等）时，这使得在某些情况下使用合成数据成为一种更安全的开发方法。
- en: Synthetic data is used mostly when there is not enough real data, or there is
    not enough real data for specific patterns you know about. Its usage is mostly
    the same for training and testing datasets.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 当真实数据不足时，或者针对特定模式的真实数据不足时，通常使用合成数据。其在训练和测试数据集中的使用大致相同。
- en: Synthetic Minority Over-sampling Technique (SMOTE) and Modified-SMOTE are two
    techniques which generate synthetic data. Simply put, SMOTE takes the minority
    class data points and creates new data points that lie between any two nearest
    data points joined by a straight line.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 合成少数类过采样技术（SMOTE）和修改版SMOTE是两种生成合成数据的技术。简单来说，SMOTE将少数类数据点连接起来，创建位于任何两个最近数据点之间直线上的新数据点。
- en: The algorithm calculates the distance between two data points in the feature
    space, multiplies the distance by a random number between 0 and 1, and places
    the new data point at this new distance from one of the data points used for distance
    calculation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 算法计算特征空间中两个数据点之间的距离，将这个距离乘以一个介于0和1之间的随机数，并将新数据点放置在用于距离计算的其中一个数据点的新距离上。
- en: In order to generate synthetic data, you have to use a training set to define
    a model, which would require validation, and then by changing the parameters of
    interest, you can generate synthetic data, through simulation. The domain/data
    type is significant since it affects the complexity of the entire process.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了生成合成数据，你必须使用训练集来定义模型，这需要验证，然后通过改变感兴趣的参数，可以通过模拟生成合成数据。领域/数据类型很重要，因为它影响整个过程的复杂性。
- en: '![](../Images/db543549aa9d731746875d090d0f3264.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/db543549aa9d731746875d090d0f3264.png)'
- en: In my opinion, asking yourself if you have enough data will reveal inconsistencies
    that you have probably never spotted before. It will help to highlight issues
    in your business processes that you thought were perfect and make you understand
    why it is the key to creating a successful data strategy within your organization.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，问自己是否拥有足够的数据会揭示出你可能从未发现的不一致性。它有助于突出你认为完美的业务流程中的问题，并使你理解在组织内创建成功数据策略的关键所在。
- en: '**[Alexandre Gonfalonieri](https://twitter.com/AGonfalonieri)** is a AI consultant
    & writer based in Basel. He writes about Brain-Computer Interfaces, the M2M economy,
    and new AI business models. He was featured in HBR and ABC News.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Alexandre Gonfalonieri](https://twitter.com/AGonfalonieri)** 是一位驻扎在巴塞尔的AI顾问和作家。他写作关于脑机接口、M2M经济和新的AI商业模式。他曾在哈佛商业评论和ABC新闻中出现。'
- en: '[Original](https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92).
    Reposted with permission.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/predict/dealing-with-the-lack-of-data-in-machine-learning-725f2abd2b92)。转载需经许可。'
- en: More On This Topic
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How to Deal with Categorical Data for Machine Learning](https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何处理机器学习中的分类数据](https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html)'
- en: '[Black Friday Deal - Master Machine Learning for Less with DataCamp](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑色星期五优惠 - 通过 DataCamp 以更低的价格掌握机器学习](https://www.kdnuggets.com/2022/11/datacamp-black-friday-deal-master-machine-learning-less-datacamp.html)'
- en: '[How to Deal with Missing Data Using Interpolation Techniques in Pandas](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用插值技术处理缺失数据](https://www.kdnuggets.com/how-to-deal-with-missing-data-using-interpolation-techniques-in-pandas)'
- en: '[6 Ways Businesses Can Benefit From Machine Learning](https://www.kdnuggets.com/2022/08/6-ways-businesses-benefit-machine-learning.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[企业如何从机器学习中受益的六种方法](https://www.kdnuggets.com/2022/08/6-ways-businesses-benefit-machine-learning.html)'
- en: '[7 Ways to Improve Your Machine Learning Models](https://www.kdnuggets.com/7-ways-to-improve-your-machine-learning-models)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升你的机器学习模型的七种方法](https://www.kdnuggets.com/7-ways-to-improve-your-machine-learning-models)'
- en: '[3 Ways Understanding Bayes Theorem Will Improve Your Data Science](https://www.kdnuggets.com/2022/06/3-ways-understanding-bayes-theorem-improve-data-science.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解贝叶斯定理将如何提升你的数据科学能力的三种方法](https://www.kdnuggets.com/2022/06/3-ways-understanding-bayes-theorem-improve-data-science.html)'
