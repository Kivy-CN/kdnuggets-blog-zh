# 精通 Python 机器学习的 7 个步骤

> 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)

所以，你一直在考虑学习机器学习，但由于网络上信息混乱，你不知道从哪里开始？或者你已经完成了[前 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)并希望找到一些后续材料，超出入门内容？

![机器学习算法](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)

机器学习算法。

本文是[精通 Python 机器学习的 7 个步骤](/2015/11/seven-steps-machine-learning-python.html)系列的第二部分（既然有两个部分，我想它现在算是一个系列）。如果你已经开始阅读[原始文章](/2015/11/seven-steps-machine-learning-python.html)，你应该已经在技能上有所进步。如果没有，你可能需要先回顾那篇文章，这可能需要一些时间，具体取决于你当前的理解水平；不过，我保证这样做会值得你的努力。

在快速回顾——以及提供几种新视角的选项之后——这篇文章将更系统地聚焦于几组相关的机器学习任务。由于这次我们可以安全地跳过基础模块——如 Python 基础、机器学习基础等——我们将直接进入各种机器学习算法。这次我们还可以更好地按功能对教程进行分类。

我再次声明，本文所含材料都在网上免费提供，所有权利和荣誉归原作者所有。如果有任何内容未被适当归属，请随时[告诉我](https://twitter.com/mattmayo13)。

### 第一步：机器学习基础回顾与新视角

仅作回顾，这些是[原始文章](/2015/11/seven-steps-machine-learning-python.html)中涵盖的步骤：

1.  基础 Python 技能

1.  基础机器学习技能

1.  科学 Python 包概述

1.  开始使用 Python 进行机器学习：介绍 & 模型评估

1.  使用 Python 的机器学习主题：k-means 聚类、决策树、线性回归 & 逻辑回归

1.  高级机器学习主题：支持向量机、随机森林、PCA 降维

1.  Python 中的深度学习

如上所述，如果你希望从头开始，我建议回到第一篇文章并按照顺序进行。我还要说明，适当的*入门*材料，包括所有安装说明，都包含在前一篇文章中。

如果你真的很基础，我建议从以下内容开始，涵盖绝对基础：

+   [机器学习关键术语解释](/2016/05/machine-learning-key-terms-explained.html)，作者 Matthew Mayo

+   [维基百科上的统计分类](https://en.wikipedia.org/wiki/Statistical_classification)

+   [机器学习：完整而详细的概述](/2016/10/machine-learning-complete-detailed-overview.html)，作者 Alex Castrounis

如果你在寻找一些替代或补充的方式来学习机器学习的基础，我最近一直在欣赏 Shai Ben-David 的视频讲座和与 Shai Shalev-Shwartz 合著的免费教科书。你可以在这里找到这两者：

+   [Shai Ben-David 的机器学习入门视频讲座](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm)，滑铁卢大学

+   [理解机器学习：从理论到算法](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html)，作者 Shai Ben-David 和 Shai Shalev-Shwartz

记住，入门材料并不需要在继续其他步骤之前完全消化（无论是在此帖子中还是在原始内容中）。在实施模型时可以查阅视频讲座、文本和其他资源，或者在后续步骤中实际应用相关概念时使用。请自行判断。

### 第2步：更多分类

我们首先通过加强分类知识和引入一些额外算法来开始学习新材料。虽然我们帖子中的第1部分涵盖了决策树、支持向量机和逻辑回归——以及集成分类器随机森林——我们还将加入k最近邻、朴素贝叶斯分类器和多层感知器。

![Scikit-learn 分类器](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)

Scikit-learn 分类器。

**k最近邻（kNN）** 是一种简单的分类器，是懒惰学习者的一个例子，其中所有计算发生在分类时（而不是在训练阶段提前发生）。kNN 是 [非参数的](https://en.wikipedia.org/wiki/Nonparametric_statistics)，通过在做出分类决策时将数据实例与 *k* 个最近实例进行比较来工作。

+   [使用 Python 进行 K-最近邻分类](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)

**朴素贝叶斯** 是一种基于 [贝叶斯定理](https://en.wikipedia.org/wiki/Bayes'_theorem) 的分类器。它假设特征之间是独立的，并且某个类中特定特征的存在与同一类中其他特征的存在没有关系。

+   [使用 scikit-learn 进行文档分类](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html)，作者 Zac Stewart

**多层感知器（MLP）** 是一种简单的 [前馈](https://en.wikipedia.org/wiki/Feedforward_neural_network) 神经网络，由多个节点层组成，每一层与其后续层完全连接。MLP 在 Scikit-learn 版本 0.18 中引入。

首先阅读 Scikit-learn 文档中的 MLP 分类器概述，然后通过教程进行实践。

+   [神经网络模型（有监督）](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)，Scikit-learn 文档

+   [使用 Python 和 SciKit Learn 0.18 的神经网络入门指南!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html)，作者 Jose Portilla

### 第 3 步：更多聚类

现在我们转向聚类，这是一种无监督学习形式。在第一篇文章中，我们介绍了 k-means 算法；本文将介绍 DBSCAN 和期望最大化（EM）。

![Scikit-learn 聚类算法](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)

Scikit-learn 聚类算法。

首先，阅读这些介绍性文章；第一篇是对 k-means 和 EM 聚类技术的快速比较，是进入新型聚类形式的良好过渡，第二篇则是 Scikit-learn 中可用聚类技术的概述：

+   [比较聚类技术：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)，作者 Matthew Mayo

+   [在玩具数据集上比较不同的聚类算法](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)，Scikit-learn 文档

**期望最大化（EM）** 是一种概率聚类算法，涉及确定实例属于特定簇的概率。EM "接近最大似然或最大后验估计统计模型中的参数"（Han, Kamber & Pei）。EM 过程从一组参数开始，迭代直到聚类在 *k* 个簇的情况下最大化。

首先阅读有关 EM 算法的教程。接下来，查看相关的 Scikit-learn 文档。最后，跟随教程并用 Python 实现 EM 聚类。

+   [期望最大化（EM）算法教程](/2016/08/tutorial-expectation-maximization-algorithm.html)，作者 Elena Sharova

+   [高斯混合模型](http://scikit-learn.org/stable/modules/mixture.html)，Scikit-learn 文档

+   [用 Python 快速介绍高斯混合模型](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/)，作者 Tiago Ramalho

如果"[高斯混合模型](https://en.wikipedia.org/wiki/Mixture_model)"乍一看让人感到困惑，这部分来自 Scikit-learn 文档的内容应该能缓解你的不必要的担忧：

> `GaussianMixture` 对象实现了期望最大化（EM）算法，用于拟合高斯混合模型。

**基于密度的空间聚类算法（DBSCAN）**通过将密集的数据点分组在一起，并将低密度的数据点标记为异常值来进行操作。

首先阅读并遵循Scikit-learn文档中的DBSCAN示例实现，然后跟随简明教程：

+   [DBSCAN聚类算法演示](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)，Scikit-learn文档

+   [基于密度的聚类算法（DBSCAN）及其实现](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持组织的IT工作

* * *

### 更多相关话题

+   [使用管道编写干净的Python代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [建立坚实的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [是什么使Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应了解的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以寻找目标，并通过寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
