- en: Hands on Hyperparameter Tuning with Keras Tuner
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/02/hyperparameter-tuning-keras-tuner.html](https://www.kdnuggets.com/2020/02/hyperparameter-tuning-keras-tuner.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Julie Prost](https://www.linkedin.com/in/julie-prost-a169b1129/), Data
    Scientist @ Sicara**'
  prefs: []
  type: TYPE_NORMAL
- en: This post will explain how to perform automatic hyperparameter tuning with Keras
    Tuner and Tensorflow 2.0 to boost accuracy on a computer vision problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e8b6551630e4efbbb2e97530dbd9eab2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Here you are : your model is running and producing a first set of results.
    However they fall far from the top results you were expecting. You''re missing
    one crucial step : hyperparameter tuning!'
  prefs: []
  type: TYPE_NORMAL
- en: In this post, we'll go through a whole hyperparameter tuning pipeline step by
    step. Full code is available on [Github](https://github.com/JulieProst/keras-tuner-tutorial).
  prefs: []
  type: TYPE_NORMAL
- en: What is hyperparameter tuning and why you should care
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A machine learning model has two types of parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: trainable parameters, which are learned by the algorithm during training. For
    instance, the weights of a neural network are trainable parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: hyperparameters, which need to be set before launching the learning process.
    The learning rate or the number of units in a dense layer are hyperparameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hyperparameters can be numerous even for small models. Tuning them can be a
    real brain teaser but worth the challenge: a good hyperparameter combination can
    highly improve your model''s performance. Here we''ll see that on a simple CNN
    model, it can help you gain 10% accuracy on the test set!'
  prefs: []
  type: TYPE_NORMAL
- en: Thankfully, open-source libraries are available to automatically perform this
    step for you!
  prefs: []
  type: TYPE_NORMAL
- en: Tensorflow 2.0 and Keras Tuner
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Tensorflow](https://www.tensorflow.org/) is a vastly used, open-source, machine
    learning library. In September 2019, [Tensorflow 2.0 was released](https://blog.tensorflow.org/2019/09/tensorflow-20-is-now-available.html)
    with major improvements, notably in user-friendliness. With this new version,
    [Keras](https://keras.io/), a higher-level Python deep learning API, became Tensorflow''s
    main API.'
  prefs: []
  type: TYPE_NORMAL
- en: Shortly after, the Keras team released [Keras Tuner](https://keras-team.github.io/keras-tuner/),
    a library to easily perform hyperparameter tuning with Tensorflow 2.0\. This post
    will show how to use it with an application to object classification. It will
    also include a comparison of the different hyperparameter tuning methods available
    in the library.
  prefs: []
  type: TYPE_NORMAL
- en: Keras Tuner is now out of beta! v1 is out on PyPI.[https://t.co/riqnIr4auA](https://t.co/riqnIr4auA)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Fully-featured, scalable, easy-to-use hyperparameter tuning for Keras & beyond.
    [pic.twitter.com/zUDISXPdBw](https://t.co/zUDISXPdBw)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — François Chollet (@fchollet) [October 31, 2019](https://twitter.com/fchollet/status/1189992078991708160?ref_src=twsrc%5Etfw)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Hyperparameter tuning with Keras Tuner
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before diving into the code, a bit of theory about Keras Tuner. How does it
    work?
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/097f871695d5bde58ac8cb0c6ea3ce37.png)'
  prefs: []
  type: TYPE_IMG
- en: Hyperparameter tuning process with Keras Tuner
  prefs: []
  type: TYPE_NORMAL
- en: First, a tuner is defined. Its role is to determine which hyperparameter combinations
    should be tested. The library search function performs the iteration loop, which
    evaluates a certain number of hyperparameter combinations. Evaluation is performed
    by computing the trained model's accuracy on a held-out validation set.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the best hyperparameter combination in terms of validation accuracy
    can be tested on a held-out test set.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let's get started! With this tutorial, you'll have an end-to-end pipeline to
    tune a simple convolutional network's hyperparameters for object classification
    on the CIFAR10 dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**Installation step**'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install Keras Tuner from your terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can now open your favorite IDE/text editor and start a Python script for
    the rest of the tutorial!
  prefs: []
  type: TYPE_NORMAL
- en: '**Dataset**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/e672a903de2a97375208768a28755d49.png)'
  prefs: []
  type: TYPE_IMG
- en: CIFAR10 random samples. [The dataset](https://www.cs.toronto.edu/~kriz/cifar.html) is
    composed of 60000 images belonging to one out of 10 object classes.
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial uses the CIFAR10 dataset. CIFAR10 is a common benchmarking dataset
    in computer vision. It contains 10 classes and is relatively small, with 60000
    images. This size allows for a relatively short training time which we'll take
    advantage of to perform multiple hyperparameter tuning iterations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Load and pre-process data:'
  prefs: []
  type: TYPE_NORMAL
- en: The tuner expects floats as inputs, and the division by 255 is a data normalization
    step.
  prefs: []
  type: TYPE_NORMAL
- en: Model definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Here, we'll experiment with a simple convolutional model to classify each image
    into one of the 10 available classes.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/abe25951bd2ac4c9f7e89b929e7ae541.png)'
  prefs: []
  type: TYPE_IMG
- en: Simple CNN representation, from this great [blog post about CNNs](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)
  prefs: []
  type: TYPE_NORMAL
- en: Each input image will go through two convolutional blocks (2 convolution layers
    followed by a pooling layer) and a dropout layer for regularization purposes.
    Finally, each output is flattened and goes through a dense layer that classify
    the image into one of the 10 classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Keras, this model can be defined as below :'
  prefs: []
  type: TYPE_NORMAL
- en: Search Space definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To perform hyperparameter tuning, we need to define the search space, that
    is to say which hyperparameters need to be optimized and in what range. Here,
    for this relatively small model, there are already 6 hyperparameters that can
    be tuned:'
  prefs: []
  type: TYPE_NORMAL
- en: the dropout rate for the three dropout layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of filters for the convolutional layers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the number of units for the dense layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: its activation function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In Keras Tuner, hyperparameters have a type (possibilities are Float, Int,
    Boolean, and Choice) and a unique name. Then, a set of options to help guide the
    search need to be set:'
  prefs: []
  type: TYPE_NORMAL
- en: a minimal, a maximal and a default value for the Float and the Int types
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a set of possible values for the Choice type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optionally, a sampling method within linear, log or reversed log. Setting this
    parameter allows to add prior knowledge you might have about the tuned parameter.
    We'll see in the next section how it can be used to tune the learning rate for
    instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optionally, a step value, i.e the minimal step between two hyperparameter values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For instance, to set the hyperparameter ''number of filters'' you can use:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The dense layer has two hyperparameters, the number of units and the activation
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: Model Compilation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Then let''s move to model compilation, where other hyperparameters are also
    present. The compilation step is where the optimizer along with the loss function
    and the metric are defined. Here, we''ll use categorical entropy as a loss function
    and accuracy as a metric. For the optimizer, different options are available.
    We''ll use the popular [Adam](https://keras.io/optimizers/):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, the learning rate, which represents how fast the learning algorithm progresses,
    is often an important hyperparameter. Usually, the learning rate is chosen on
    a log scale. This prior knowledge can be incorporated in the search through the
    setting of the sampling method:'
  prefs: []
  type: TYPE_NORMAL
- en: Keras Tuner Hypermodels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To put the whole hyperparameter search space together and perform hyperparameter
    tuning, Keras Tuners uses `HyperModel` instances. Hypermodels are reusable class
    object introduced with the library, defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The library already offers two on-the-shelf hypermodels for computer vision,
    HyperResNet and HyperXception.
  prefs: []
  type: TYPE_NORMAL
- en: Choose the tuner
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Keras Tuner offers the main hyperparameter tuning methods: random search, Hyperband,
    and Bayesian optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this tutorial, we''ll focus on random search and Hyperband. We won''t go
    into theory, but if you want to know more about random search and Bayesian Optimization,
    I wrote a post about it: [Bayesian optimization for hyperparameter tuning](https://www.sicara.ai/blog/2019-14-07-determine-network-hyper-parameters-with-bayesian-optimization).
    As for [Hyperband](https://arxiv.org/abs/1603.06560), its main idea is to optimize
    Random Search in terms of search time.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For every tuner, a seed parameter can be defined for experiments reproducibility:
    `SEED = 1`.'
  prefs: []
  type: TYPE_NORMAL
- en: Random Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most intuitive way to perform hyperparameter tuning is to randomly sample
    hyperparameter combinations and test them out. This is exactly what the RandomSearch
    tuner does!
  prefs: []
  type: TYPE_NORMAL
- en: The objective is the function to optimize. The tuner infers if it is a maximization
    or a minimization problem based on its value.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the `max_trials` variable represents the number of hyperparameter combinations
    that will be tested by the tuner, while the `execution_per_trial` variable is
    the number of models that should be built and fit for each trial for robustness
    purposes. The next section explains how to set them
  prefs: []
  type: TYPE_NORMAL
- en: Hyperband
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hyperband is an optimized version of random search which uses early-stopping
    to speed up the hyperparameter tuning process. The main idea is to fit a large
    number of models for a small number of epochs and to only continue training for
    the models achieving the highest accuracy on the validation set. The max_epochs
    variable is the max number of epochs that a model can be trained for.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameters for the tuners?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Figure](../Images/4e6e124d63e9ac6346050b824b2c95da.png)'
  prefs: []
  type: TYPE_IMG
- en: 'You might be wondering how useful this whole process is seeing that several
    parameters also have to be set for the different tuners:'
  prefs: []
  type: TYPE_NORMAL
- en: But here the problem is slightly different than the determination of hyperparameters.
    Indeed, these settings here will mostly depend on your computing time and resources.
    The highest number of trials you can perform, the better! Regarding the number
    of epochs, it's best if you know how many epochs your model needs to converge.
    You can also use early-stopping to prevent overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Hyperparameter tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the model and the tuner are set up, a summary of the task is easily available:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/9866d12d58e70a81d56062254cc937bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Search space summary output
  prefs: []
  type: TYPE_NORMAL
- en: Tuning can start!
  prefs: []
  type: TYPE_NORMAL
- en: The search function takes as input the training data and a validation split
    to perform hyperparameter combinations evaluation. The epochs parameter is used
    in random search and Bayesian Optimization to define the number of training epochs
    for each hyperparameter combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the search results can be summarized and used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Results
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find this post code on [Github](https://github.com/JulieProst/keras-tuner-tutorial).
    The following results were obtained after running it on an RTX 2080 GPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/3291ad3fb8c89275b14bac5f57f30281.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Keras Tuner results. Worst baseline: model achieving the worst validation accuracy
    with one of random search''s set of hyperparameters. Default baseline : obtained
    by setting all hyperparameters to their default value.'
  prefs: []
  type: TYPE_NORMAL
- en: These results are far from the 99.3% accuracy achieved by [state-of-the-art
    models on the CIFAR10 dataset](https://paperswithcode.com/sota/image-classification-on-cifar-10)
    but not so bad for such a simple network structure. You can already see notable
    improvement between the baselines and the tuned models, with a boost of more than
    10% in accuracy between Random Search and the first baseline.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the Keras Tuner library is a nice and easy to learn option to perform
    hyperparameter tuning for your Keras and Tensorflow 2.O models. The main step
    you'll have to work on is adapting your model to fit the hypermodel format. Indeed,
    few standard hypermodels are available in the library for now.
  prefs: []
  type: TYPE_NORMAL
- en: Complementary documentation and tutorials are available on [Keras Tuner’s website](https://keras-team.github.io/keras-tuner/)
    and their [Github repo](https://github.com/keras-team/keras-tuner)!
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Julie Prost](https://www.linkedin.com/in/julie-prost-a169b1129/)**
    ([**@JPro20**](https://twitter.com/JPro20)) is a Data Scientist at Sicara.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner). Reposted
    with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Automated Machine Learning Project Implementation Complexities](/2019/11/automl-implementation-complexities.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Advanced Keras — Constructing Complex Custom Losses and Metrics](/2019/04/advanced-keras-constructing-complex-custom-losses-metrics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convolutional Neural Networks: A Python Tutorial Using TensorFlow and Keras](/2019/07/convolutional-neural-networks-python-tutorial-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning Using Grid Search and Random Search in Python](https://www.kdnuggets.com/2022/10/hyperparameter-tuning-grid-search-random-search-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Tuning: GridSearchCV and RandomizedSearchCV, Explained](https://www.kdnuggets.com/hyperparameter-tuning-gridsearchcv-and-randomizedsearchcv-explained)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building and Training Your First Neural Network with TensorFlow and Keras](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Keras 3.0: Everything You Need To Know](https://www.kdnuggets.com/2023/07/keras-30-everything-need-know.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hyperparameter Optimization: 10 Top Python Libraries](https://www.kdnuggets.com/2023/01/hyperparameter-optimization-10-top-python-libraries.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hands-on Reinforcement Learning Course Part 3: SARSA](https://www.kdnuggets.com/2022/01/handson-reinforcement-learning-course-part-3-sarsa.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
