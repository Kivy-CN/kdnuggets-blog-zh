- en: A checklist to track your Data Science progress
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 跟踪你数据科学进展的检查清单
- en: 原文：[https://www.kdnuggets.com/2021/05/checklist-data-science-progress.html](https://www.kdnuggets.com/2021/05/checklist-data-science-progress.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/05/checklist-data-science-progress.html](https://www.kdnuggets.com/2021/05/checklist-data-science-progress.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Pascal Janetzky](https://pascaljanetzky.medium.com/), Computer science
    student, sports fan.**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Pascal Janetzky](https://pascaljanetzky.medium.com/)，计算机科学学生，体育爱好者。**'
- en: There are many awesome courses to learn data science. And there are plenty of
    certificates that certify your success.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多很棒的课程可以学习数据科学，还有很多证书可以证明你的成功。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析水平'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: But, how do you track your progress? How do you know what you have already achieved
    and what’s still there to get your hands on?
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你如何跟踪你的进展呢？你如何知道自己已经取得了哪些成就，还有哪些尚待实现的目标？
- en: 'The following checklist can help you get an overview of your progress. It’s
    intended for users looking for a general outline of where they are on their journey.
    Rather than emphasizing specific guides, courses, and software packages, it focuses
    on general concepts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 以下检查清单可以帮助你概览自己的进度。它旨在为那些寻找自己在旅程中大致位置的用户提供一个总体概述。它并不强调特定的指南、课程和软件包，而是专注于一般概念：
- en: '![](../Images/8aa744f86264be3e544544378299e67b.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8aa744f86264be3e544544378299e67b.png)'
- en: '*Image by the author. Available on Notion [here](https://www.notion.so/A-checklist-to-track-your-Data-Science-progress-9de80b1b23c04634904168991247b651),
    as a PDF [here](https://drive.google.com/file/d/1CjuSlqhzjq1rUX5JYvJhx7YWIjxs5tdF/view?usp=sharing),
    and GitHub [here](https://github.com/phrasenmaeher/data-science-checklist).*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*作者提供的图片。可在Notion [这里](https://www.notion.so/A-checklist-to-track-your-Data-Science-progress-9de80b1b23c04634904168991247b651)查看，PDF格式 [这里](https://drive.google.com/file/d/1CjuSlqhzjq1rUX5JYvJhx7YWIjxs5tdF/view?usp=sharing)，以及GitHub [这里](https://github.com/phrasenmaeher/data-science-checklist)下载。*'
- en: Let’s cover the levels in detail, beginning with the Entry level, continuing
    with the Intermediate level, and ending on the wide fields of the Advanced level.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细介绍这些级别，从入门级开始，继续到中级，最后到广泛的高级领域。
- en: Entry level
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 入门级
- en: This is the place to start. It covers the fundamentals of your further journey.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是开始的地方。它涵盖了你进一步旅程的基础。
- en: '**Data handling**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据处理**'
- en: 'The intention behind this category is to focus on being able to handle the
    most common data types:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此类别的意图是专注于能够处理最常见的数据类型：
- en: Images
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图片
- en: Text
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文字
- en: Audio/Time-Series
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频/时间序列
- en: In general, the datasets at this stage are quite small, and there is no (mental)
    overhead from handling larger-than-memory datasets. Good examples are the classic
    MNIST image dataset ([PyTorch](https://pytorch.org/vision/stable/datasets.html#mnist), [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist)),
    the IMDB reviews text dataset ([PyTorch](https://pytorch.org/text/stable/datasets.html#imdb), [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)),
    and small audio or time-series datasets. They are only a few hundred MBs at most
    and comfortably fit into the RAM.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，此阶段的数据集非常小，处理比内存大的数据集不会带来（心理）负担。好的例子包括经典的MNIST图像数据集（[PyTorch](https://pytorch.org/vision/stable/datasets.html#mnist)，[TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist)），IMDB评论文本数据集（[PyTorch](https://pytorch.org/text/stable/datasets.html#imdb)，[TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)），以及小型音频或时间序列数据集。它们最多只有几百MB，非常适合放入RAM中。
- en: Some of these datasets require minimal pre-processing (scaling images, shortening
    sentences), which is usually not more than a few lines of code. Since the number
    of examples is either very low or they are of small size only, you can easily
    do the processing during runtime (as opposed to running separate complex scripts
    in advance).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据集中的一些需要最少的预处理（缩放图像、缩短句子），通常不超过几行代码。由于示例数量要么非常少，要么仅为小尺寸，你可以在运行时轻松完成处理（与提前运行复杂的脚本相比）。
- en: In summary, this category emphasizes handling small audio/time-series, image,
    and text datasets and applying simple operations to pre-process the data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这一类别强调处理小型音频/时间序列、图像和文本数据集，并应用简单的操作进行数据预处理。
- en: '**Networks**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**网络**'
- en: 'The intention behind this category is to transition from classic machine learning
    towards neural networks and knowing the common building blocks:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类别的意图是从经典的机器学习过渡到神经网络，并了解常见的构建块：
- en: Classic machine learning techniques include Support Vector Machines, Linear
    Regression, and clustering algorithms. Even though the more sophisticated relatives,
    the neural networks, seem to dominate the recent research, they come in handy
    for small problems — or as a baseline. Knowing how to use them is also handy when
    it comes to analyzing the data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的机器学习技术包括支持向量机、线性回归和聚类算法。尽管更复杂的神经网络在最近的研究中似乎占据主导地位，但它们在处理小问题时也很有用——或者作为一个基准。在分析数据时，了解如何使用它们也是很有帮助的。
- en: When progressing towards deep learning, dense layers are a good start. I guess
    that they are used in nearly every (classification) model, at least to build the
    output layer.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入学习的过程中，密集层是一个很好的起点。我猜它们几乎在每个（分类）模型中都会用到，至少用于构建输出层。
- en: 'The second commonly used network type is the Convolutional Neural Network,
    which uses convolution operation at its core. It’s hard to think about any successful
    research that has not used and benefited from this simple operation: You slide
    a kernel over your input and then calculate the inner product between the kernel
    with the patch that it covers. The convolution operation extracts a small set
    of features from every possible location of the input data. It’s no wonder that
    they are very successful in classifying images, where important characteristics
    are scattered all around.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种常用的网络类型是卷积神经网络，它的核心使用卷积操作。很难想象有哪个成功的研究没有使用并受益于这一简单操作：你将一个卷积核滑动在输入上，然后计算卷积核与其覆盖的图像块之间的内积。卷积操作从输入数据的每一个可能位置中提取一小组特征。难怪它们在分类图像时非常成功，因为重要的特征分散在各处。
- en: 'The previous two network types are mainly used for static inputs, where we
    know the data’s shape in advance. When you have data of varying shapes, take sentences
    as an example, you might look for more flexible approaches. That is where Recurrent
    Neural Networks come in: They can retain information over long periods, which
    enables connecting the “I” in “I, after getting up this morning and dressing,
    took a walk with my dog” and the “took a walk with my dog” to answer the question
    “Who took a walk with the dog?”'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 前两种网络类型主要用于静态输入，即我们提前知道数据的形状。当你拥有形状各异的数据时，例如句子，你可能会寻找更灵活的方法。这就是递归神经网络的用武之地：它们可以保留长时间的信息，这使得将“我在早上起床穿衣后和我的狗散步”中的“我”和“和我的狗散步”连接起来，以回答“谁和狗散步？”这个问题成为可能。
- en: In summary, this category focuses on working with simple Dense, Convolutional,
    and Recurrent neural networks to classify image, text, and time-series data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这一类别专注于使用简单的密集层、卷积层和递归神经网络来分类图像、文本和时间序列数据。
- en: '**General**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**通用**'
- en: The intention behind this category is to learn the general handling of Data
    Science related tasks.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类别的意图是学习数据科学相关任务的一般处理方法。
- en: 'An important step is to get to know the data itself. This is not limited to
    image data or text data alone but also covers time-series and audio data and any
    further data type. The term exploratory data analysis (thanks to [Andryas Waurzenczak](https://medium.com/@andryaas) for
    pointing this out) describes this step best: Using techniques to find patterns,
    outliers (data points that exceed a common range), substructures, label distributions,
    and also visualizing the data. This might incorporate PCA or dimensionality reduction
    techniques. The datasets that you work with at this point are usually already
    explored in detail (try a search for the dataset''s name to find interesting characteristics),
    but learning this now will pay off once you proceed to custom datasets.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的步骤是了解数据本身。这不仅限于图像数据或文本数据，还包括时间序列数据、音频数据以及其他任何数据类型。术语探索性数据分析（感谢[Andryas
    Waurzenczak](https://medium.com/@andryaas)指出这一点）最能描述这个步骤：使用技术来寻找模式、异常值（超出常见范围的数据点）、子结构、标签分布，以及对数据进行可视化。这可能涉及主成分分析（PCA）或降维技术。你在这一阶段处理的数据集通常已经被详细探索过（尝试搜索数据集的名称以找到有趣的特征），但现在学习这些知识会在你继续处理自定义数据集时带来回报。
- en: 'You will also learn how to load and save those models above so that you can
    re-use them later. What’s also common is to store data about the data, the *metadata*,
    in separate files. Take a CSV file as an example: The first column stores the
    file paths to your data samples, and the second column stores the class for the
    samples. Being able to parse this is mandatory, but thanks to many libraries,
    that is a straightforward task.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你还将学习如何加载和保存上述模型，以便以后可以重用它们。常见的做法是将关于数据的数据，即*元数据*，存储在单独的文件中。以CSV文件为例：第一列存储数据样本的文件路径，第二列存储样本的类别。能够解析这些信息是必要的，但
    thanks to 许多库，这是一项简单的任务。
- en: 'When you begin training your basic networks on those small datasets, with those
    architectures above, you’ll gradually uncover the helpfulness of callbacks. Callbacks
    are code that gets executed during training, and they implement many functionalities:
    Periodically saving your model to make it fail-safe, stopping the training, or
    changing parameters. The most common ones are already built-in with most libraries,
    and a short function call is all it takes to use them!'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始在这些小型数据集上训练你的基础网络时，使用上述架构，你会逐渐发现回调的有用性。回调是训练过程中执行的代码，它实现了许多功能：定期保存模型以确保其安全，停止训练，或改变参数。最常见的回调已经内置于大多数库中，只需简短的函数调用即可使用它们！
- en: In summary, this category has you learn to handle the tasks around running neural
    networks on small datasets.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 总而言之，这个类别让你学会处理在小型数据集上运行神经网络的任务。
- en: Intermediate level
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 中级阶段
- en: 'In my opinion, this is where the great fun begins, and you’ll reach it faster
    than you might expect! I found the shift to happen quite naturally: You look for
    a more efficient way to process data — and before you realize it, you have written
    a custom pipeline for a large dataset.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，这里是乐趣开始的地方，而且你会比你预期的更快到达这个阶段！我发现这个转变发生得非常自然：你寻找一种更高效的数据处理方式——而在你意识到之前，你已经为大型数据集编写了自定义管道。
- en: '**Data handling**'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据处理**'
- en: The intention behind this stage is to be able to handle larger or more complex
    datasets which might require special treatment in the form of augmentation and
    custom pre-processing pipelines.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段的意图是能够处理更大或更复杂的数据集，这可能需要特殊处理，如增强和自定义预处理管道。
- en: At this stage, the datasets tend to become larger and might no longer fit into
    your RAM. Efficient pre-processing becomes more important, as you won’t let your
    hardware idle around. Also, you might have to write your own generators when you
    handle samples of unequal shapes, fetch samples from a database, or do custom
    pre-processing.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，数据集趋向于变得更大，可能不再适合放入你的内存中。高效的预处理变得更加重要，因为你不会让你的硬件闲置。此外，当你处理形状不等的样本、从数据库中提取样本或进行自定义预处理时，你可能需要编写自己的生成器。
- en: 'Or you work with complex and unbalanced datasets, where the majority of your
    samples is of one class, and only a minority of samples is of the desired class.
    There are a few helpful techniques you’ll learn: Augmenting the data to generate
    more samples of the minor class or downsampling the major class.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 或者你处理复杂且不平衡的数据集，其中大多数样本属于一个类别，而只有少数样本属于所需类别。你将学习一些有用的技术：增加数据以生成更多的少数类别样本，或减少主要类别的样本数量。
- en: For both dataset types, custom pipelines become more important. When you quickly
    want to iterate settings, for example, cropping an image to 32x32 rather than
    50x50, you rarely want to start long-running scripts. Incorporating such possibilities
    into your pipeline enables quick experimentation.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这两种数据集类型，自定义管道变得更加重要。例如，当你希望快速迭代设置时，比如将图像裁剪为32x32而不是50x50时，你很少会想要启动长期运行的脚本。将这种可能性纳入你的管道可以实现快速实验。
- en: In summary, the datasets tend to become more complex (think unbalanced) and
    larger (think up to 30—40 GBs) and require more sophisticated handling.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，数据集往往变得更加复杂（例如，不平衡）和更大（例如，达到30—40 GB），并且需要更复杂的处理。
- en: '**Custom projects**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**自定义项目**'
- en: This is the heart of the Intermediate level. The intention behind this is to
    work on custom projects and thereby learning and using many of the other categories’
    items.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是中级水平的核心。其背后的意图是处理自定义项目，从而学习和使用许多其他类别的内容。
- en: The first level might have led you through training a network on the MNIST datasets.
    On this level, you’ll naturally focus more on your own data and how to parse it.
    I have only listed the three major domains audio, images, and text, but there
    are many more.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第一级可能已经引导你通过在MNIST数据集上训练网络。在这个层级，你将自然地更加关注自己的数据以及如何解析它。我只列出了音频、图像和文本这三个主要领域，但还有许多其他领域。
- en: By working on your own projects, you connect what you have learned earlier to
    solve your challenges.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 通过自己进行项目，你可以将之前学到的知识与解决挑战联系起来。
- en: '**Training**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练**'
- en: The intention behind this category is to learn more about training neural networks.
    This category is the largest category on the Intermediate level, which is due
    to the focus on more advanced topics.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类别的意图是了解更多关于训练神经网络的知识。这个类别是中级水平中最大的类别，原因在于它集中于更高级的主题。
- en: A first step to customizing training is using transfer learning and fine-tuning.
    Before, you will usually have used the standard methods to train and test your
    models, but now you might require something more powerful. That’s where it comes
    in handy to simply re-use models that other practitioners trained. You load their
    models and carefully train them on your own datasets.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义训练的第一步是使用迁移学习和微调。之前，你通常会使用标准方法来训练和测试模型，但现在你可能需要更强大的方法。这时，重新利用其他从业者训练的模型就很有用。你加载他们的模型，并在自己的数据集上仔细训练它们。
- en: In case you miss some feature, this is the point where you begin to write custom
    training loops and custom callbacks. Want to print some statistics every 20 batches?
    Write a custom callback. Want to accumulate gradients over 20 batches? Write a
    custom training loop.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遗漏了一些功能，这时你需要编写自定义训练循环和自定义回调函数。想要每20个批次打印一些统计信息？编写一个自定义回调。想要在20个批次中累积梯度？编写一个自定义训练循环。
- en: 'More complex loops might need more resources: multi-GPU training is coming!
    However, it’s not simply adding a second, a third, or even more resources; you
    have to fetch the data fast enough. Keep in mind that multi-device training increases
    the complexity. Most of the background work is already done by PyTorch and TensorFlow,
    which handle this case with a few minor code changes only, but the front-end part
    is left to you. (But fret not, there are many guides out there to help you get
    this done!)'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 更复杂的循环可能需要更多的资源：多GPU训练即将到来！不过，这不仅仅是增加第二、第三个或更多的资源；你必须足够快地获取数据。请记住，多设备训练增加了复杂性。大部分后台工作已经由PyTorch和TensorFlow完成，它们只需少量代码更改就能处理这种情况，但前端部分仍由你负责。（不过不要担心，那里有许多指南可以帮助你完成这项工作！）
- en: 'If you are like me and do not have access to multiple GPUs, then training on
    the cloud is a possible next step. All major cloud services provide you with the
    requested resources. At first, there will be some (mental) overhead while transitioning
    from local setups to cloud computing. After some attempts, this gets way easier.
    (When I started to run scripts on a Kubernetes cluster, things were very overwhelming:
    What is a Dockerfile? How to run jobs? How to use local resources? How to get
    data in and out? After experimenting around, I got used to it, and now it’s a
    few simple commands to get my scripts running).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你像我一样没有多张GPU，那么在云上训练可能是下一步的选择。所有主要的云服务提供了你所需的资源。刚开始时，从本地环境转到云计算会有一些（心理上的）开销。但经过几次尝试，这会变得容易得多。（当我开始在Kubernetes集群上运行脚本时，事情非常让人不知所措：什么是Dockerfile？如何运行作业？如何使用本地资源？如何进出数据？经过一番实验，我逐渐习惯了，现在只需几个简单的命令就能运行我的脚本。）
- en: 'When you are already in the cloud, why not try TPU training? TPUs are Google’s
    custom-made chips. And they are fast: A year ago, I worked with a team to classify
    a large text corpus, around 20,000 documents, and each document had about 10 pages
    of text. We ran our first experiments on a CPU only, and one epoch took 8 hours.
    In the next step, we improved pre-processing, caching, and used a single GPU:
    The time went down to 15 minutes, which was a huge leap. After reading TensorFlow’s
    documentation and playing around with our code, I then managed to make TPU training
    possible, and one epoch went down to *15 seconds*. So, I encourage you to upgrade
    your pipeline and run your training on TPUs.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当你已经在云端时，为什么不尝试 TPU 训练呢？TPU 是 Google 定制的芯片。而且它们很快：一年前，我与一个团队一起对一个大型文本语料库（大约
    20,000 个文档，每个文档约 10 页文本）进行了分类。我们在 CPU 上进行的第一次实验中，一个 epoch 花费了 8 小时。在接下来的步骤中，我们改进了预处理、缓存，并使用了一个
    GPU：时间缩短到 15 分钟，这是一个巨大的飞跃。在阅读 TensorFlow 文档并调整代码后，我成功实现了 TPU 训练，一个 epoch 缩短到 *15
    秒*。因此，我鼓励你升级你的管道，并在 TPU 上运行训练。
- en: In summary, this category focuses on expanding the actual training parts towards
    more complex training loops and custom callbacks.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这一类别专注于将实际训练部分扩展到更复杂的训练循环和自定义回调。
- en: '**General**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**概述**'
- en: The intention behind this category is to learn more about what’s possible beyond
    using the normal architectures.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类别的意图是了解使用普通架构之外的更多可能性。
- en: 'Now that you are dealing with custom datasets, it becomes important to get
    a grasp on problem thinking. Let me explain it this way: Say you are working with
    an audio dataset. You have done your initial data analysis, and it turns out that
    your data is not only imbalanced, but the samples are of different lengths. Some
    are only three seconds long, others 20 seconds and more. Further, you want to
    classify only segments of the audio, not the whole clip as is. And lastly, this
    is for an industry project, so restrictions apply. Bringing all this together
    is what’s required from you.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你正在处理自定义数据集，理解问题思维变得重要。让我这样解释：假设你正在处理一个音频数据集。你已经完成了初步数据分析，结果发现你的数据不仅不平衡，而且样本长度各异。有的仅三秒钟长，有的则长达
    20 秒或更多。此外，你只想分类音频的片段，而不是整个剪辑。最后，这还是一个工业项目，因此有一些限制。将这一切整合在一起是你需要完成的任务。
- en: Luckily, you are not alone at this. Data analysis is ticked already, and pre-processing
    custom data is ticked too. It’s the industrial part that gets the main attention
    here. Check what other folks have done (and published on GitHub), ask your people,
    and experiment with different techniques.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你并不孤单。数据分析已经完成，自定义数据的预处理也已完成。这里主要关注的是工业部分。查看其他人所做的（并发布在 GitHub 上）、询问你的团队，并尝试不同的技术。
- en: Say you want a network layer that normalizes your data following a custom scheme.
    Looking into your library’s documentation, you don’t find anything similar already
    implemented. Now is the time to implement such functionality yourself. As before, [TensorFlow](https://www.tensorflow.org/tutorials/customization/custom_layers) and
    PyTorch (which makes this an even simpler approach) provide some good resources
    to begin with.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 比如，你想要一个网络层来按照自定义方案规范化你的数据。查看你的库文档，你没有找到类似的实现。现在是时候自己实现这种功能了。如前所述，[TensorFlow](https://www.tensorflow.org/tutorials/customization/custom_layers)和
    PyTorch（这使得方法更简单）提供了一些很好的资源来开始。
- en: For a project a while ago, I wanted to write a custom embedding layer. After
    finding no implementation, I decided to tackle this by writing a custom one. Now,
    that was a challenge! After many trial and error loops, I finally came up with
    a working TensorFlow layer. (Ironically, in the end, it did not prove better than
    the existing ones.)
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 不久前，我想编写一个自定义嵌入层。找到没有实现后，我决定自己动手编写一个。这确实是一个挑战！经过多次试错，我最终制作出了一个有效的 TensorFlow
    层。（具有讽刺意味的是，最终它并没有比现有的更好。）
- en: 'Another large field in Deep Learning opens up now: Generative networks. Before,
    you mainly worked with classifying existing data, but nothing is holding you back
    from also generating it. That’s exactly what generative networks do, and a large
    part of their recent success comes from one single paper: [Generative Adversarial
    Networks](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf).
    The researchers really came up with something clever: Instead of training one
    network, two networks are trained, and both get better over time. Examining their
    workings in detail is out of scope here, but Joseph and Baptiste Rocca did a terrific
    job explaining them [here](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在深度学习中广泛领域是生成网络。在此之前，你主要是对现有数据进行分类，但现在你可以尝试生成数据。这正是生成网络的作用，它们最近的大部分成功来自于一篇论文：[生成对抗网络](https://papers.nips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf)。研究人员确实提出了一个聪明的办法：不是训练一个网络，而是训练两个网络，并且两个网络都随着时间的推移变得更好。详细检查它们的工作超出了本讨论的范围，但
    Joseph 和 Baptiste Rocca 对它们的解释非常出色，可以在 [这里](https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)
    查看。
- en: Besides only using a wider variety of models, you’ll also want to track your
    experiments. This is helpful when you want to comprehend how your model’s metrics
    are influenced by its parameters. Speaking of which, you might also start a parameter
    search, which aims to find the best set of parameter which optimizes a target
    metric.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用更多种类的模型外，你还需要跟踪你的实验。这对于理解模型的指标如何受到其参数影响非常有帮助。说到这一点，你可能还会开始进行参数搜索，旨在找到优化目标指标的最佳参数组合。
- en: As in the last part, you will definitely use more advanced models. Besides those
    generative networks, there are also huge language models. Have you ever heard
    of Transformers (not the movie)? I bet you have, and now comes the time to use
    them for your own projects. Or try getting access to GPT-3, and discuss AI with
    it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一部分一样，你将使用更先进的模型。除了这些生成网络，还有巨大的语言模型。你听说过 Transformer（不是电影）吗？我敢打赌你听说过，现在是时候将它们应用到自己的项目中了。或者尝试获得
    GPT-3 的访问权限，并与之讨论 AI。
- en: In summary, this category expands beyond the normal models and explores further
    techniques around.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这一类别超越了常规模型，探索了更多技术。
- en: Advanced level
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高级阶段
- en: This is the last stage, though the boundaries to the previous stage are admittedly
    blurry. Congratulations on getting here! There is only one category for you to
    explore since the items build on your previous experience.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最后阶段，尽管与前一阶段的界限确实模糊。恭喜你来到这里！由于项目是建立在你之前的经验基础上的，因此你只需探索一个类别。
- en: '**General**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**概述**'
- en: Even if you have come this far, there are still further things to explore.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你已经走到了这一步，仍然有更多的内容可以探索。
- en: 'The first item is *huge datasets*. While starting the training process is a
    routine task for you now, the focus here is on making training fast, despite huge
    datasets. With *huge* I mean datasets of several hundred GBs and more. Think ImageNet
    scale or [The Pile](https://github.com/EleutherAI/the-pile) scale. Tackling them
    requires thinking through your storage options, data fetching, and pre-processing
    pipelines. And not only the size increases, but also the complexity: A multi-model
    dataset of a few hundred GBs, where each image is accompanied by a textual and
    auditive description? Now that requires some thinking.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个项目是 *巨大的数据集*。虽然启动训练过程现在对你来说是一个常规任务，但这里的重点是尽管数据集庞大，仍要让训练变得迅速。所谓的 *巨大的* 意味着数据集达到几百GB甚至更多。考虑像
    ImageNet 规模或 [The Pile](https://github.com/EleutherAI/the-pile) 规模的数据集。处理这些数据需要考虑你的存储选项、数据获取和预处理管道。不仅仅是数据的大小增加了，复杂性也随之上升：一个几百GB的多模型数据集，每张图片都附带文本和听觉描述？这确实需要仔细思考。
- en: When working with such enormous datasets, it might be required to run a multi-worker
    training setup. The GPUs are no longer installed on a single machine but distributed
    across multiple machines, the workers. Managing the distribution of your workload
    and your data becomes necessary. Thankfully, [PyTorch](https://pytorch.org/tutorials/intermediate/dist_tuto.html) and [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras?hl=en) have
    some resources on this, too.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理如此庞大的数据集时，可能需要运行多工作节点的训练设置。GPU 不再安装在单一的机器上，而是分布在多个机器上，也就是工作节点。管理工作负载和数据的分布变得必要。值得庆幸的是，[PyTorch](https://pytorch.org/tutorials/intermediate/dist_tuto.html)
    和 [TensorFlow](https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras?hl=en)
    在这方面也提供了一些资源。
- en: After you have spent hours setting up your models, why not deploy them? Use
    some libraries that let you build a nice GUI easily (such as [streamlit.io](http://streamlit.io/))
    and deploy your models so that other practitioners can see your work live.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在你花费了几个小时设置模型之后，为什么不部署它们呢？使用一些让你轻松构建漂亮GUI的库（如[streamlit.io](http://streamlit.io/)），并部署你的模型，以便其他从业者可以实时查看你的工作。
- en: When you have also done that, get into Reinforcement Learning. Placing it in
    the advanced section might not be 100 percent correct (the basics can be grasped
    quite early), but it’s mostly distinct from the fields you have worked on so far.
    As always, there are [some](https://www.tensorflow.org/agents/overview) [resources](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf) [available](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html) to
    get you started.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成了这些之后，进入强化学习。将其放在高级部分可能不完全正确（基础知识可以很早掌握），但它与迄今为止你所研究的领域大多不同。与往常一样，有一些[some](https://www.tensorflow.org/agents/overview)[resources](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)[available](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)帮助你入门。
- en: Now that you have gained some vast experience and knowledge, it’s time to do
    research. Have you noticed anything on your journey that could be improved? That
    could be the first thing to work on. Or contribute to other research projects
    by providing code to their repositories. Collaborate with other enthusiasts and
    keep learning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经积累了一些丰富的经验和知识，是时候进行研究了。你在旅途中是否注意到有任何可以改进的地方？这可能是第一个要着手的事情。或者通过向其他研究项目的代码库提供代码来贡献。与其他爱好者合作，持续学习。
- en: 'That might be the last thing that’s left here: Staying up-to-date. Data Science
    is a fast-moving field, with many new exciting things coming up day after day.
    Keeping track of what matters is hard, so choose some newsletters (I read Andrew
    Ng and deeplearning.ai’s [The Batch](https://www.deeplearning.ai/the-batch/))
    to get condensed information. To narrow down, you can also use Andrew Karpathy’s
    Arxiv [Sanity Preserver](http://www.arxiv-sanity.com/), which helps you filter
    papers that meet your interests.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是剩下的最后一件事：保持最新。数据科学是一个快速发展的领域，每天都有许多令人兴奋的新事物出现。跟踪重要信息很困难，所以选择一些新闻通讯（我阅读Andrew
    Ng和deeplearning.ai的[The Batch](https://www.deeplearning.ai/the-batch/)）以获取精华信息。为了缩小范围，你还可以使用Andrew
    Karpathy的Arxiv [Sanity Preserver](http://www.arxiv-sanity.com/)，它帮助你筛选出符合你兴趣的论文。
- en: In summary, this category focuses on exploring Reinforcement Learning as a completely
    new field, contributing to research, and staying up-to-date—the last two points
    are never truly ticked.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，这个类别专注于将强化学习作为一个全新的领域进行探索，贡献于研究，并保持最新——最后两点从未真正完成。
- en: Where to go next?
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 接下来该去哪里？
- en: You can find the checklist on Notion [here](https://www.notion.so/A-checklist-to-track-your-Data-Science-progress-9de80b1b23c04634904168991247b651) and
    a PDF [here](https://drive.google.com/file/d/1CjuSlqhzjq1rUX5JYvJhx7YWIjxs5tdF/view?usp=sharing).
    Make a copy, customize it, and then gradually tick it off.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Notion上找到清单[这里](https://www.notion.so/A-checklist-to-track-your-Data-Science-progress-9de80b1b23c04634904168991247b651)，PDF版本[这里](https://drive.google.com/file/d/1CjuSlqhzjq1rUX5JYvJhx7YWIjxs5tdF/view?usp=sharing)。制作副本，自定义它，然后逐步勾选。
- en: Please leave any suggestions or remarks on [GitHub](https://github.com/phrasenmaeher/data-science-checklist).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 请在[GitHub](https://github.com/phrasenmaeher/data-science-checklist)上留下任何建议或备注。
- en: 'If you are looking for specific resources:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在寻找具体的资源：
- en: Most of the entry-level is covered by deeplearning.ai’s [TensorFlow Developer
    Professional Certificate](https://www.coursera.org/professional-certificates/tensorflow-in-practice)
    (try the TF exam afterward to see what you have already learned!)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 大部分入门级内容由deeplearning.ai的[TensorFlow Developer Professional Certificate](https://www.coursera.org/professional-certificates/tensorflow-in-practice)涵盖（尝试在之后参加TF考试，看看你已经学到了什么！）
- en: Parts of the entry and intermediate and advanced levels are covered by Berkley’s [Full
    Stack Deep Learning](https://fall2019.fullstackdeeplearning.com/#who-is-this-for)
    course
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 入门级和中级以及高级部分由伯克利的[Full Stack Deep Learning](https://fall2019.fullstackdeeplearning.com/#who-is-this-for)课程涵盖。
- en: Some parts of the intermediate and advanced levels are covered by DeepMind’s [Advanced
    Deep Learning & Reinforcement Learning](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)
    lecture
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深度学习和强化学习的一些中级和高级部分由DeepMind的[Advanced Deep Learning & Reinforcement Learning](https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs)讲座涵盖。
- en: 'Parts of the intermediate and advanced levels are covered by deeplearning.ai’s [TensorFlow:
    Data and Deployment Specialization](https://www.coursera.org/specializations/tensorflow-data-and-deployment) and [TensorFlow:
    Advanced Techniques Specialization](https://www.coursera.org/specializations/tensorflow-advanced-techniques)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '中级和高级水平的一部分由deeplearning.ai的[TensorFlow: 数据与部署专项课程](https://www.coursera.org/specializations/tensorflow-data-and-deployment)和[TensorFlow:
    高级技术专项课程](https://www.coursera.org/specializations/tensorflow-advanced-techniques)涵盖。'
- en: If you are looking for a more concrete list you can check Daniel Bourke’s roadmap [here](https://whimsical.com/machine-learning-roadmap-2020-CA7f3ykvXpnJ9Az32vYXva).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在寻找更具体的列表，可以查看Daniel Bourke的路线图[这里](https://whimsical.com/machine-learning-roadmap-2020-CA7f3ykvXpnJ9Az32vYXva)。
- en: Questions
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 问题
- en: '*… is missing.*'
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*… 缺失了。*'
- en: Leave a comment and let me know. Keep in mind that this checklist is intended
    as a general overview and does not contain *working with NumPy/pandas/TensorFlow/…* or
    similar specific items.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 留下评论告诉我。请记住，这个检查清单旨在作为一般概述，并不包含*使用NumPy/pandas/TensorFlow/…*或类似的具体项目。
- en: '*Isn’t there an overlap between some categories?*'
  id: totrans-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*不同类别之间是否存在重叠？*'
- en: Yes, definitely. There are no distinct dividing lines between some items from
    different categories. For example, when you work with images, you might have stored
    them on disk, and a CSV file holds all the file paths and labels. You can thus
    tick two items in one go.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，确实如此。不同类别之间有些项目没有明确的分界线。例如，当你处理图像时，你可能已经将它们存储在磁盘上，而CSV文件保存了所有的文件路径和标签。这样你可以一次完成两个项目。
- en: Similarly, there is sometimes an overlap between two items within the same category.
    This happens when they mostly go hand-in-hand but are still somewhat different.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在同一类别内，有时也会存在两个项目之间的重叠。这发生在它们大部分时间是一起进行的，但仍然有所不同。
- en: '*Is there an order?*'
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*是否有顺序？*'
- en: 'I originally tried to maintain order within each category (e.g., within *Training*),
    with the easiest task at the top and the harder tasks at the bottom. But there
    is not always a clear difficulty ranking between two items. Take *transfer learning* and *fine-tuning* as
    two examples: Both are tightly intertwined, and there’s no clear order.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我最初尝试在每个类别内保持顺序（例如，在*训练*类别中），将最简单的任务放在顶部，较难的任务放在底部。但有时两个项目之间没有明确的难度排名。以*迁移学习*和*微调*为例：两者紧密相关，没有明确的顺序。
- en: '*What’s so special about TPUs to give them a separate place?*'
  id: totrans-97
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*TPU有何特别之处，使其独立成一个类别？*'
- en: While it’s thankfully easy to go to [Colab](https://colab.research.google.com/) and
    select a TPU, it’s crucial to get the data ready first. My intention behind this
    point is not to simply having run a model with the help of TPUs, but to have made
    your pipelines very efficient so that data gets to the TPU on time. The focus
    is thus more on efficient pre-processing rather than on speeding up your computations.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然幸运的是可以轻松地访问[Colab](https://colab.research.google.com/)并选择TPU，但首先准备数据是至关重要的。我提出这个点的目的是为了让你的管道非常高效，以便数据能够及时到达TPU。因此，重点更多是放在高效的预处理上，而不是加快计算速度。
- en: And it’s admittedly quite cool to run your code on TPUs.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在TPU上运行代码确实很酷。
- en: '*The list is quite long. How can I complete it?*'
  id: totrans-100
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*列表很长。我该如何完成它？*'
- en: 'Two short answers:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 两个简短的答案：
- en: — You don’t have to; I am myself far away from this point. Use it as a mere
    guideline for your next endeavors.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: — 你不必这样做；我自己距离这个点还很远。将其作为你下一个努力的简单指南。
- en: — You don’t have to complete one level or category before advancing to the next
    one.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: — 你不必在进入下一个级别之前完成一个级别或类别。
- en: 'And a longer answer:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 更长的答案：
- en: Take one day per week, block all other things out.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 每周腾出一天，屏蔽其他所有事情。
- en: On the other days, you can do your studies. Take a course on Wednesday, on Thursday,
    and Friday. Studying on the weekends is a bonus.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他的日子里，你可以进行学习。可以在星期三、星期四和星期五上课。周末学习是额外的奖励。
- en: Then, on Monday, you repeat what you have learned over the last days, using
    the weekend to consolidate things.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在星期一，你复习过去几天学到的内容，利用周末巩固知识。
- en: And on your blocked Tuesday, you apply your new knowledge to your own projects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在你封闭的星期二，你将新的知识应用到自己的项目中。
- en: 'These projects don’t have to be big:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这些项目不一定要很大：
- en: Learned something about efficient data processing? Set up a pipeline for your
    own data (and tick *custom pipelines*).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 学到了关于高效数据处理的知识？为自己的数据建立一个管道（并勾选*自定义管道*）。
- en: Learned how to classify images? Take some images of stuff in your room, and
    classify them (and tick *custom image project*).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 学会了如何分类图像？拍摄你房间里的一些物品的图像，并对它们进行分类（并勾选*自定义图像项目*）。
- en: Learned about a specific network architecture? Use a library of your choice
    and simply re-implement it (and tick *advanced architectures* or *convolutional
    neural networks* or both).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 学习了特定的网络架构？使用你选择的库并简单地重新实现它（并勾选*高级架构*或*卷积神经网络*或两者）。
- en: Use these short standalone projects to get your hands on a broad range of topics.
    The more small topics you work on, the easier you can get started with those large
    projects that seemed daunting at first—because they only consist of many small
    steps you have already taken.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些简短的独立项目来接触广泛的主题。你处理的小主题越多，越容易开始那些起初看起来令人畏惧的大项目——因为它们只是由你已经完成的许多小步骤组成。
- en: '[Original](https://towardsdatascience.com/a-checklist-to-track-your-data-science-progress-bf92e878edf2).
    Reposted with permission.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始文档](https://towardsdatascience.com/a-checklist-to-track-your-data-science-progress-bf92e878edf2)。经许可转载。'
- en: '**Related:**'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[How to organize your data science project in 2021](https://www.kdnuggets.com/2021/04/how-organize-your-data-science-project-2021.html)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在2021年组织你的数据科学项目](https://www.kdnuggets.com/2021/04/how-organize-your-data-science-project-2021.html)'
- en: '[How to frame the right questions to be answered using data](https://www.kdnuggets.com/2021/03/right-questions-answered-using-data.html)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何用数据提出正确的问题](https://www.kdnuggets.com/2021/03/right-questions-answered-using-data.html)'
- en: '[Advice to aspiring Data Scientists – your most common questions answered](https://www.kdnuggets.com/2021/01/advice-aspiring-data-scientists.html)'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[给有志数据科学家的建议——你最常见的问题解答](https://www.kdnuggets.com/2021/01/advice-aspiring-data-scientists.html)'
- en: More On This Topic
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学，找到目的，并找到目的去…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学统计学习的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应了解的三种R语言库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的人工智能失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
