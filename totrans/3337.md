# 掌握 Python 中机器学习的 7 个额外步骤

> 原文：[https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html](https://www.kdnuggets.com/2017/03/seven-more-steps-machine-learning-python.html)

所以，你一直在考虑学习机器学习，但由于网络上的混乱状态，你不知道从哪里开始？或者你已经完成了[前 7 步](/2015/11/seven-steps-machine-learning-python.html)，正在寻找一些进一步的材料，超出入门内容？

![机器学习算法](../Images/1c10caeff60f2a083a05b54eaf6eb1fb.png)

机器学习算法。

本文是[掌握 Python 中机器学习的 7 步骤](/2015/11/seven-steps-machine-learning-python.html)系列的第二部分（既然有两部分，我想这现在可以算作一个系列）。如果你已经开始阅读[原文](/2015/11/seven-steps-machine-learning-python.html)，你应该已经在技能上达到了令人满意的水平。如果没有，你可能需要先回顾那篇文章，根据你目前的理解水平，这可能需要一些时间；然而，我保证这样做会值得你的努力。

在快速回顾之后——并提供几种新的视角——这篇文章将更系统地集中于几组相关的机器学习任务。由于这次我们可以安全地跳过基础模块——Python 基础、机器学习基础等——我们将直接跳入各种机器学习算法。这次我们还可以根据功能线更好地分类我们的教程。

我再次声明，本文所含的所有材料都可以在网上自由获取，所有作品的权利和认可归其原作者所有。如果有任何内容没有得到适当的归属，请随时[告诉我](https://twitter.com/mattmayo13)。

### 步骤 1：机器学习基础回顾与新视角

仅供回顾，这些是[原文](/2015/11/seven-steps-machine-learning-python.html)中涵盖的步骤：

1.  基础 Python 技能

1.  基础机器学习技能

1.  科学 Python 包概述

1.  Python 中机器学习的入门：介绍与模型评估

1.  Python 中的机器学习主题：k-means 聚类、决策树、线性回归和逻辑回归

1.  Python 中的高级机器学习主题：支持向量机、随机森林、主成分分析（PCA）的降维

1.  Python 中的深度学习

如上所述，如果你打算从头开始，我建议你回到第一篇文章，并按照相关内容继续。我还要说明，适当的*入门*材料，包括所有安装说明，都包含在上一篇文章中。

然而，如果你真的很基础，我会从以下内容开始，涵盖绝对基础知识：

+   [机器学习关键术语解释](/2016/05/machine-learning-key-terms-explained.html)，作者：马修·梅奥

+   [维基百科上的统计分类](https://en.wikipedia.org/wiki/Statistical_classification)

+   [机器学习：完整且详细的概述](/2016/10/machine-learning-complete-detailed-overview.html)，作者：亚历克斯·卡斯特罗尼斯

如果你在寻找学习机器学习基础的替代或补充方法，我最近很喜欢沙伊·本-大卫的讲座视频和他与沙伊·沙莱夫-施瓦茨共同编写的免费教材。你可以在这里找到这两者：

+   [沙伊·本-大卫的机器学习入门讲座视频](https://www.youtube.com/watch?v=b5NlRg8SjZg&index=1&list=PLFze15KrfxbH8SE4FgOHpMSY1h5HiRLMm)，滑铁卢大学

+   [理解机器学习：从理论到算法](http://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/copy.html)，作者：沙伊·本-大卫与沙伊·沙莱夫-施瓦茨

记住，入门材料不需要在继续进行其余步骤之前完全消化（无论是在这篇文章中还是原文中）。在实施模型时，可以参考视频讲座、文本和其他资源，或在后续步骤中实际使用适用的概念。请自行判断。

### 第 2 步：更多分类

我们通过首先加强分类知识和介绍一些额外的算法来开始学习新材料。虽然我们文章的第 1 部分涵盖了决策树、支持向量机和逻辑回归——以及集成分类器随机森林——但我们将加入 k-最近邻、朴素贝叶斯分类器和多层感知器。

![Scikit-learn 分类器](../Images/98e47c639ae115438b94fe52b9ea7cd7.png)

Scikit-learn 分类器。

**k-最近邻 (kNN)** 是一种简单的分类器，也是懒惰学习者的一个例子，在这种方法中，所有计算都在分类时进行（而不是在训练阶段提前进行）。kNN 是[非参数的](https://en.wikipedia.org/wiki/Nonparametric_statistics)，其工作原理是通过比较数据实例与* k * 个最接近的实例来决定如何对其进行分类。

+   [使用 python 进行 k-最近邻分类](https://ashokharnal.wordpress.com/2015/01/21/k-nearest-neighbor-classification-using-python/)

**朴素贝叶斯**是一种基于[贝叶斯定理](https://en.wikipedia.org/wiki/Bayes'_theorem)的分类器。它假设特征之间是独立的，即一个类别中特定特征的存在与该类别中其他特征的存在无关。

+   [使用 scikit-learn 的文档分类](http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html)，作者：扎克·斯图尔特

**多层感知器 (MLP)** 是一种简单的 [前馈](https://en.wikipedia.org/wiki/Feedforward_neural_network) 神经网络，由多个节点层组成，每一层都与下一层完全连接。MLP 在 Scikit-learn 0.18 版本中引入。

首先阅读 Scikit-learn 文档中的 MLP 分类器概述，然后通过教程练习实现。

+   [神经网络模型（监督学习）](http://scikit-learn.org/stable/modules/neural_networks_supervised.html)，Scikit-learn 文档

+   [Python 和 SciKit Learn 0.18 的神经网络初学者指南!](/2016/10/beginners-guide-neural-networks-python-scikit-learn.html)，作者：荷西·波蒂利亚

### 步骤 3：更多聚类

我们现在进入聚类部分，这是一种无监督学习形式。在第一篇文章中我们介绍了 k-means 算法；在这里我们将介绍 DBSCAN 和期望最大化（EM）。

![Scikit-learn 聚类算法](../Images/7c9c8013dab7634a2fb3cf9f4a254d5e.png)

Scikit-learn 聚类算法。

首先，阅读这些入门帖子；第一个是 k-means 和 EM 聚类技术的快速比较，是新型聚类形式的一个很好的过渡，第二个是 Scikit-learn 中可用的聚类技术概述：

+   [比较聚类技术：简明技术概述](/2016/09/comparing-clustering-techniques-concise-technical-overview.html)，作者：马修·梅奥

+   [在玩具数据集上比较不同的聚类算法](http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)，Scikit-learn 文档

**期望最大化（EM）** 是一种概率聚类算法，因此涉及确定实例属于特定簇的概率。EM “接近最大似然估计或统计模型中参数的最大后验估计”（Han, Kamber & Pei）。EM 过程从一组参数开始，迭代直到聚类相对于 *k* 簇最大化。

首先阅读关于 EM 算法的教程。接下来，查看相关的 Scikit-learn 文档。最后，跟随教程并用 Python 实现 EM 聚类。

+   [期望最大化 (EM) 算法教程](/2016/08/tutorial-expectation-maximization-algorithm.html)，作者：埃琳娜·沙罗娃

+   [高斯混合模型](http://scikit-learn.org/stable/modules/mixture.html)，Scikit-learn 文档

+   [使用 Python 快速介绍高斯混合模型](http://www.nehalemlabs.net/prototype/blog/2014/04/03/quick-introduction-to-gaussian-mixture-models-with-python/)，作者：蒂亚戈·拉马略

如果“[高斯混合模型](https://en.wikipedia.org/wiki/Mixture_model)”初看起来令人困惑，这部分相关的 Scikit-learn 文档应能缓解任何不必要的担忧：

> `GaussianMixture` 对象实现了用于拟合高斯混合模型的期望最大化（EM）算法。

**基于密度的空间聚类应用与噪声（DBSCAN）** 通过将密集的数据点分组在一起，并将低密度的数据点指定为异常值来进行操作。

首先阅读并按照 Scikit-learn 文档中的 DBSCAN 示例实现，然后跟随一个简洁的教程：

+   [DBSCAN 聚类算法演示](http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html)，Scikit-learn 文档

+   [基于密度的聚类算法（DBSCAN）及其实现](http://madhukaudantha.blogspot.ca/2015/04/density-based-clustering-algorithm.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT

* * *

### 了解更多此主题

+   [使用管道编写干净的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)

+   [建立一个强大的数据团队](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)

+   [是什么使得 Python 成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [停止学习数据科学以找到目的，并找到目的…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
