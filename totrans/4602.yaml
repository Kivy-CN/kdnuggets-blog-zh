- en: Pytorch Lightning vs PyTorch Ignite vs Fast.ai
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pytorch Lightning 与 PyTorch Ignite 与 Fast.ai
- en: 原文：[https://www.kdnuggets.com/2019/08/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai.html](https://www.kdnuggets.com/2019/08/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/08/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai.html](https://www.kdnuggets.com/2019/08/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [William Falcon](https://www.linkedin.com/in/wfalcon/), AI Researcher**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[威廉·法尔孔](https://www.linkedin.com/in/wfalcon/)，AI 研究员**'
- en: '![Figure](../Images/631434f0400fb0206fffbdd18564e11f.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/631434f0400fb0206fffbdd18564e11f.png)'
- en: Apparently a lion, bear, and tiger are friends
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，狮子、熊和老虎是朋友
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[PyTorch-lightning](https://github.com/williamFalcon/pytorch-lightning) is
    a recently released library which is a Keras-like ML library for PyTorch. It leaves
    core training and validation logic to you and automates the rest. (BTW, by Keras
    I mean no boilerplate, not overly-simplified).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[PyTorch-lightning](https://github.com/williamFalcon/pytorch-lightning) 是一个最近发布的库，是一个类似
    Keras 的 PyTorch 机器学习库。它将核心训练和验证逻辑留给你，并自动化其他部分。（顺便提一下，这里的 Keras 意味着没有样板代码，而不是过于简化）。'
- en: As the core author of lightning, I’ve been asked a few times about the core
    differences between lightning and fast.ai, [PyTorch ignite](https://github.com/pytorch/ignite).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Lightning 的核心作者，我曾多次被问及 Lightning 与 fast.ai、[PyTorch ignite](https://github.com/pytorch/ignite)之间的核心差异。
- en: Here, I will **attempt** an objective comparison between all three frameworks.
    This comparison comes from laying out similarities and differences objectively
    found in tutorials and documentation of all three frameworks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我将**尝试**对这三种框架进行客观比较。这一比较基于在所有三个框架的教程和文档中客观发现的相似性和差异性。
- en: Motivations
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 动机
- en: Fast.ai was originally created to facilitate teaching the [fast.ai curriculum](https://www.fast.ai/2018/10/02/fastai-ai/).
    It’s recently also morphed into a library of implementations of common approaches
    such as GANs, RL and transfer learning.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Fast.ai 最初是为了方便教学[fast.ai 课程](https://www.fast.ai/2018/10/02/fastai-ai/)而创建的。最近，它还转变成了一个实现常见方法（如
    GANs、RL 和迁移学习）的库。
- en: '[PyTorch Ignite](https://github.com/pytorch/ignite#why-ignite) and [Pytorch
    Lightning](https://github.com/williamFalcon/pytorch-lightning#why-do-i-want-to-use-lightning) were
    both created to give the researchers as much flexibility by requiring them to
    define functions for what happens in the training loop and validation loop.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[PyTorch Ignite](https://github.com/pytorch/ignite#why-ignite)和[Pytorch Lightning](https://github.com/williamFalcon/pytorch-lightning#why-do-i-want-to-use-lightning)都是为了给予研究人员尽可能多的灵活性，要求他们定义训练循环和验证循环中的操作。'
- en: 'Lightning has two additional, more ambitious motivations: reproducibility and
    democratizing best practices which only PyTorch power-users would implement (Distributed
    training, 16-bit precision, etc…). I’ll discuss these motivations in detail in
    later sections.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning 有两个额外的、更雄心勃勃的目标：可重复性和普及最佳实践，只有 PyTorch 高级用户会实现（分布式训练、16 位精度等）。我将在后续章节中详细讨论这些目标。
- en: 'So, at a base level, the target user is clear: For fast.ai it’s **people interested
    in getting into deep learning**, while the other two are focused on **active researchers** either
    in ML or who use ML (ie: biologists, neuroscientists, etc…)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从基本层面上讲，目标用户是明确的：对于 fast.ai，目标用户是**对深度学习感兴趣的人**，而另外两个框架则专注于**活跃的研究人员**，无论是从事机器学习还是使用机器学习（例如：生物学家、神经科学家等）。
- en: Learning Curve
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习曲线
- en: Both Lightning and Ignite have very simple interfaces, as most of the work is
    still done in pure PyTorch by the user. The main work happens inside the [Engine](https://pytorch.org/ignite/engine.html) and [Trainer](https://williamfalcon.github.io/pytorch-lightning/Trainer/) objects
    respectively.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning 和 Ignite 都具有非常简单的接口，因为大部分工作仍然由用户在纯 PyTorch 中完成。主要的工作发生在 [Engine](https://pytorch.org/ignite/engine.html) 和 [Trainer](https://williamfalcon.github.io/pytorch-lightning/Trainer/) 对象中。
- en: Fast.ai however, does require learning another library on top of PyTorch. The
    API doesn’t operate directly on pure PyTorch code most of the time (there are
    places it does), but it requires abstractions like [DataBunches](https://docs.fast.ai/basic_data.html#DataBunch), [DataBlocs](https://docs.fast.ai/data_block.html#The-data-block-API),
    etc… Those APIs are extremely useful when the “best” way of doing something isn’t
    obvious.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Fast.ai 确实需要在 PyTorch 之上学习另一个库。API 大部分时间并不直接操作纯 PyTorch 代码（也有一些地方会），但它需要像 [DataBunches](https://docs.fast.ai/basic_data.html#DataBunch)、 [DataBlocs](https://docs.fast.ai/data_block.html#The-data-block-API) 等抽象。当“最佳”方法不明显时，这些
    API 非常有用。
- en: For researchers, however, it’s crucial to not have to learn yet another library,
    and directly control key parts of research such as data-processing without having
    other abstractions operate on those.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于研究人员来说，关键在于不需要再学习另一个库，直接控制研究的关键部分，如数据处理，而不需要其他抽象来操作这些部分。
- en: In this case, the fast.ai library has a much higher learning curve, but it’s
    worth it if you don’t necessarily know the “best” way to do something and just
    want to take good approaches as black-boxes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，fast.ai 库有更高的学习曲线，但如果你不一定知道“最佳”方法是什么，并且只是想把好的方法作为黑箱来使用，这一点是值得的。
- en: Lightning vs Ignite
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lightning vs Ignite
- en: '![Figure](../Images/44b0a765c5c71a65d171a63c0a797a65.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/44b0a765c5c71a65d171a63c0a797a65.png)'
- en: More like sharing
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 更像是共享
- en: It’s clear from the above that comparing fast.ai to these two frameworks isn’t
    fair given that the use cases and users are different (However, I’ll still add
    fast.ai to the comparison table at the end of this article).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 从上述内容可以明显看出，将 fast.ai 与这两个框架进行比较是不公平的，因为使用案例和用户群体不同（然而，我仍会在本文末尾的比较表中添加 fast.ai）。
- en: The first major difference between Lightning and ignite is the interface in
    which it operates on.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning 和 Ignite 之间的第一个主要区别是它们操作的接口。
- en: In Lightning, there is a standard interface (see [LightningModule](https://williamfalcon.github.io/pytorch-lightning/LightningModule/RequiredTrainerInterface/))
    of 9 required methods EVERY model has to follow.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Lightning 中，有一个标准接口（见 [LightningModule](https://williamfalcon.github.io/pytorch-lightning/LightningModule/RequiredTrainerInterface/)），每个模型都必须遵循这
    9 个必需的方法。
- en: This flexible format allows for the most freedom in training and validating.
    This interface should be thought of as a ***system,*** not as a model. The system
    might have multiple models (GANs, seq-2-seq, etc…) or it might be as model, such
    as this simple MNIST example.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这种灵活的格式允许在训练和验证中获得最大的自由。这个接口应该被视为一个 ***系统***，而不是一个模型。系统可能有多个模型（GANs、seq-2-seq
    等），或者它可能是一个模型，比如这个简单的 MNIST 示例。
- en: Thus researchers are free to try as many crazy things as they want, and ONLY
    have to worry about these 9 methods.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，研究人员可以自由尝试各种疯狂的东西，并且只需要担心这 9 个方法。
- en: Ignite requires a very similar setup, but does not have a ***standard*** interface
    which every model needs to follow.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Ignite 需要非常类似的设置，但没有一个 ***标准*** 接口，每个模型都需要遵循。
- en: 'Notice the **run** function might be defined differently, ie: there could be
    many different events added to the trainer, or it could even be named something
    different such as ***main, train, etc…***'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，**run** 函数可能会有不同的定义，即：可能有许多不同的事件添加到训练器中，或者它甚至可能被命名为其他名称，如 ***main, train,
    etc…***
- en: In a complicated system where training might be happening in strange ways (looking
    at you GANs and RL), it wouldn’t be immediately obvious to people looking at this
    code what is happening. Whereas in Lightning, you’d know to look at the training_step
    to figure out what’s happening.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个复杂的系统中，比如训练可能以奇怪的方式进行（看着你们，GAN 和 RL），代码的运行情况可能不容易被直观理解。而在 Lightning 中，你可以查看
    training_step 来弄清楚发生了什么。
- en: Reproducibility
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可重复性
- en: '![Figure](../Images/04f9431f398d5f0d0a8b1e65afbd8c1b.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/04f9431f398d5f0d0a8b1e65afbd8c1b.png)'
- en: When you try to reproduce work
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 当你尝试重现工作时
- en: As I mentioned, Lightning was created with a second more ambitious broad motivation: **Reproducibility**.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如我所提到的，Lightning 是在第二个更雄心勃勃的广泛动机下创建的：**可重复性**。
- en: If you’ve tried to read someone’s implementation of a paper, it’s very hard
    to figure out what’s happening. Long gone are the days where we were just designing
    different neural network architectures.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试阅读某人的论文实现，往往很难弄清楚发生了什么。我们早已不再只是设计不同的神经网络架构。
- en: Modern SOTA models are actually ***systems*, **which employ many models or training
    techniques to achieve specific results.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现代的SOTA模型实际上是***系统***，**这些系统使用了多种模型或训练技术来实现特定的结果**。
- en: As I said earlier, a LightningModule is a ***system***, not a model. Thus if
    you want to know where all the crazy tricks and super complicated training is
    happening you can look at the training_step and validation_step.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前所说，LightningModule是一个***系统***，而不是一个模型。因此，如果你想知道所有那些复杂的技巧和超级复杂的训练发生在哪里，你可以查看training_step和validation_step。
- en: If every research project and paper is implemented using the LightningModule
    template, it will be **very** easy to find out what’s going on (but perhaps not
    easy to understand haha).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果每个研究项目和论文都使用LightningModule模板进行实现，那么**了解发生了什么将变得非常**容易（但可能不容易理解，哈哈）。
- en: A standardization of this kind across the AI community would also allow an ecosystem
    to flourish which could use the LightningModule interface to do cool things like
    automate deployments, audit systems for biases, or even support hashing weights
    into a blockchain backend to reconstruct models used for key predictions which
    may need to be audited.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI社区中进行这种标准化将允许一个生态系统蓬勃发展，该生态系统可以使用LightningModule接口来执行一些很酷的功能，比如自动化部署、审计系统中的偏差，甚至支持将权重哈希到区块链后端以重建用于关键预测的模型，这些模型可能需要进行审计。
- en: Out-of-the-box Features
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开箱即用的功能
- en: Another major difference between Ignite and Lightning are the features Lightning
    supports out of the box. Out-of-the-box means there’s **no**additional code on
    your part.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Ignite和Lightning之间的另一个主要区别在于Lightning开箱即用的功能。开箱即用意味着你**无需**额外编写代码。
- en: To illustrate, let’s try to train a model on multiple GPUs on the same machine
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 举例来说，让我们尝试在同一台机器上的多个GPU上训练一个模型。
- en: '**Ignite (**[**demo**](https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist_dist.py)**)**'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ignite** (**[**demo**](https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist_dist.py)**)**'
- en: '**Lightning (**[**demo**](https://github.com/williamFalcon/pytorch-lightning/blob/master/examples/new_project_templates/single_gpu_node_ddp_template.py)**)**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lightning** (**[**demo**](https://github.com/williamFalcon/pytorch-lightning/blob/master/examples/new_project_templates/single_gpu_node_ddp_template.py)**)**'
- en: Ok, neither is bad… But what about if we want to use multiple-GPUs across many
    machines? Let’s train on 200 GPUs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，没有哪个是坏的……但如果我们想在多台机器上使用多个GPU呢？让我们在200个GPU上进行训练。
- en: '**Ignite**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ignite**'
- en: …
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: …
- en: Well, there’s no built-in support for this… You’d have to extend [this example](https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist_dist.py) quite
    a bit and add a way to submit scripts easily. Then you’d have to take care of
    loading/saving, not overwriting weights/logs with all the processes, etc… you
    get the idea.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，这里没有内置支持……你需要扩展 [这个示例](https://github.com/pytorch/ignite/blob/master/examples/mnist/mnist_dist.py)
    并添加一种提交脚本的简便方法。然后，你还需要处理加载/保存、确保不会覆盖权重/日志与所有进程等……你明白了。
- en: '**Lightning**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**Lightning**'
- en: With lightning, you just set the number of nodes and submit the appropriate
    job. [Here’s an in-depth tutorial on configuring jobs correctly](https://medium.com/@_willfalcon/trivial-multi-node-training-with-pytorch-lightning-ff75dfb809bd).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Lightning，你只需设置节点数量并提交适当的作业。 [这里有一个关于如何正确配置作业的详细教程](https://medium.com/@_willfalcon/trivial-multi-node-training-with-pytorch-lightning-ff75dfb809bd)。
- en: Out-of-the-box features are these features you ***don’t need to do anything
    to get.* **That means you may not need most of them right now, but when you need
    to say… accumulate gradients, or gradient clip, or 16-bit train, you won’t spend
    days/weeks reading through tutorials to get it to work.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 开箱即用的功能是指那些你***无需做任何事即可使用的功能***。这意味着你可能现在不需要它们，但当你需要例如...累积梯度、梯度裁剪或16位训练时，你不会花费数天/数周的时间阅读教程来使其工作。
- en: Just set the appropriate Lightning flag and move on with your research.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 只需设置适当的Lightning标志，然后继续进行你的研究。
- en: Lightning comes prebuilt with these features so users spend more time researching
    and not engineering. This is especially useful for non-CS/DS researchers such
    as physicists, biologists, etc… who may not be as well-versed in the programming
    department.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Lightning预构建了这些功能，以便用户花更多时间进行研究，而不是进行工程开发。这对于非计算机科学/数据科学研究人员，如物理学家、生物学家等尤其有用，他们可能在编程方面不那么精通。
- en: These features democratize features of PyTorch only a power-user might take
    the time to implement.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能使 PyTorch 的特性变得普及，只有高级用户可能会花时间去实现。
- en: Here are tables comparing the features across all 3 frameworks grouped by sets
    of functionality.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有表格比较了所有三个框架在不同功能集上的特性。
- en: '*If I missed anything critical please post a comment and I will update the
    table!*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '*如果我遗漏了任何重要内容，请留言，我会更新表格！*'
- en: High-Performance Computing
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 高性能计算
- en: Debugging Tools
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调试工具
- en: Usability
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可用性
- en: Closing Thoughts
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: Here we did a deep comparison on multiple levels for the three frameworks. Each
    is great in its own regard.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们对三个框架进行了多层次的深入比较。每个框架都有其自身的优点。
- en: If you’re just learning or aren’t up-to-date with all the latest best practices,
    don’t need super-advanced training tricks, and can afford time to learn a new
    library, then go with fast.ai.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你刚刚学习或没有跟上所有最新的最佳实践，不需要超高级的训练技巧，并且有时间学习新的库，那么选择 fast.ai。
- en: If you need the most flexibility, go with either Ignite of Lightning.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要最大的灵活性，可以选择 Ignite 或 Lightning。
- en: If you don’t need super-advanced features and are OK with adding your Tensorboard
    support, accumulated gradients, distributed training, etc… then go with Ignite.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不需要超高级的功能，并且可以接受添加 Tensorboard 支持、累积梯度、分布式训练等，那么选择 Ignite。
- en: If you need more advanced features, distributed training, the latest and greatest
    deep-learning training tricks, and would love to see a world where implementations
    are standardized across the world then use Lightning.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要更高级的功能、分布式训练、最新的深度学习训练技巧，并且希望看到一个标准化的实现世界，那就使用 Lightning。
- en: '**Bio: [William Falcon](https://www.linkedin.com/in/wfalcon/)** is an AI Researcher,
    startup founder, CTO, Google Deepmind Fellow, and current PhD AI research intern
    at Facebook AI.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [威廉·法尔肯](https://www.linkedin.com/in/wfalcon/)** 是 AI 研究员、初创公司创始人、CTO、Google
    Deepmind 学者以及 Facebook AI 的现任博士研究实习生。'
- en: '[Original](https://towardsdatascience.com/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai-61dc7480ad8a).
    Reposted with permission.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/pytorch-lightning-vs-pytorch-ignite-vs-fast-ai-61dc7480ad8a)。经许可转载。'
- en: '**Related:**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Pytorch Cheat Sheet for Beginners and Udacity Deep Learning Nanodegree](/2019/08/pytorch-cheat-sheet-beginners.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者和 Udacity 深度学习纳米学位的 PyTorch 备忘单](/2019/08/pytorch-cheat-sheet-beginners.html)'
- en: '[Getting started with NLP using the PyTorch framework](/2019/04/nlp-pytorch.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 PyTorch 框架入门 NLP](/2019/04/nlp-pytorch.html)'
- en: '[XLNet Outperforms BERT on Several NLP Tasks](/2019/07/xlnet-outperforms-bert-several-nlp-tasks.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XLNet 在多个 NLP 任务中超越 BERT](/2019/07/xlnet-outperforms-bert-several-nlp-tasks.html)'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[入门 PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Introduction to Deep Learning Libraries: PyTorch and Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度学习库介绍：PyTorch 和 Lightning AI](https://www.kdnuggets.com/introduction-to-deep-learning-libraries-pytorch-and-lightning-ai)'
- en: '[Using Lightning AI Studio For Free](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[免费使用 Lightning AI Studio](https://www.kdnuggets.com/using-lightning-ai-studio-for-free)'
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过快速克里金（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 在稀疏性下能有多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
- en: '[Simple and Fast Data Streaming for Machine Learning Projects](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习项目的简单快速数据流](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
