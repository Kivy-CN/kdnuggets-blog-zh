- en: Here’s how you can accelerate your Data Science on GPU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/07/accelerate-data-science-on-gpu.html](https://www.kdnuggets.com/2019/07/accelerate-data-science-on-gpu.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: Data Scientists need computing power. Whether you’re processing a big dataset
    with Pandas or running some computation on a massive matrix with Numpy, you’ll
    need a powerful machine to get the job done in a reasonable amount of time.
  prefs: []
  type: TYPE_NORMAL
- en: Over the past several years, Python libraries commonly used by Data Scientists
    have gotten pretty good at leveraging CPU power.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Pandas, with its underlying base code written in C, does a fine job of being
    able to handle datasets that go over even 100GB in size. And if you don’t have
    enough RAM to fit such a dataset, you can always use the convenient chunking functions
    that can process the data one piece at a time.
  prefs: []
  type: TYPE_NORMAL
- en: 'GPUs vs CPUs: Parallel Processing'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With massive data, a CPU just isn’t going to cut it.
  prefs: []
  type: TYPE_NORMAL
- en: A dataset that goes over 100GB in size is going to have many many data points,
    within the *millions* or even *billions* ballpark range. With that many points
    to process, it doesn’t matter how fast your CPU is, it simply doesn’t have enough
    cores to do efficient parallel processing. If your CPU has 20 cores (which would
    be fairly expensive CPU), you can only process 20 data points at a time!
  prefs: []
  type: TYPE_NORMAL
- en: CPUs are going to be better in tasks where clock-speed is more important — or
    you simply don’t have a GPU implementation. If there is a GPU implementation for
    the process you are trying to perform, then a GPU will be far more effective if
    that task can benefit from parallel processing.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/45f79f5c92359a10ccb30f2b8fbbef83.png)How a Multi-core
    system can process data faster. For a single core system (left), all 10 tasks
    go to a single node. For the dual-core system (right), each node takes on 5 tasks,
    thereby doubling the processing speed'
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning has already seen its fair share of leveraging GPUs. Many of the
    convolution operations done in Deep Learning are repetitive and as such can be
    greatly accelerated on GPUs, even up to 100s of times.
  prefs: []
  type: TYPE_NORMAL
- en: Data Science today is no different as many repetitive operations are performed
    on large datasets with libraries like Pandas, Numpy, and Scikit-Learn. These operations
    aren’t too complex to implement on the GPU either.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there’s a solution.
  prefs: []
  type: TYPE_NORMAL
- en: GPU Acceleration with Rapids
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Rapids](https://rapids.ai/?source=post_page---------------------------) is
    a suite of software libraries designed for accelerating Data Science by leveraging
    GPUs. It uses low-level CUDA code for fast, GPU-optimized implementations of algorithms
    while still having an easy to use Python layer on top.'
  prefs: []
  type: TYPE_NORMAL
- en: The beauty of Rapids is that it’s integrated smoothly with Data Science libraries
    — things like Pandas dataframes are easily passed through to Rapids for GPU acceleration.
    The diagram below illustrates how Rapids achieves low-level acceleration while
    maintaining an easy to use top-layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/f511cd54476f8f41e8586d8a442db6e8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Rapids leverages several Python libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**cuDF**](https://github.com/rapidsai/cudf?source=post_page---------------------------) —Python
    GPU DataFrames. It can do almost everything Pandas can in terms of data handling
    and manipulation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**cuML**](https://github.com/rapidsai/cuml?source=post_page---------------------------) —
    Python GPU Machine Learning. It contains many of the ML algorithms that Scikit-Learn
    has, all in a very similar format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[**cuGraph**](https://github.com/rapidsai/cuml?source=post_page---------------------------) —
    Python GPU graph processing. It contains many common graph analytics algorithms
    including PageRank and various similarity metrics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Tutorial for how to use Rapids
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Installation**'
  prefs: []
  type: TYPE_NORMAL
- en: Now you’ll see how to use Rapids!
  prefs: []
  type: TYPE_NORMAL
- en: To install it, head on over to the [website](https://rapids.ai/start.html?source=post_page---------------------------) where
    you’ll see how to install Rapids. You can install it directly on your machine
    through [Conda](https://anaconda.org/anaconda/conda?source=post_page---------------------------) or
    simply pull the Docker container.
  prefs: []
  type: TYPE_NORMAL
- en: 'When installing, you can set your system specs such as CUDA version and which
    libraries you would like to install. For example, I have CUDA 10.0 and wanted
    to install all the libraries, so my install command was:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Once that command finishing running, you’re ready to start doing GPU-accelerated
    Data Science.
  prefs: []
  type: TYPE_NORMAL
- en: '**Setting up our data**'
  prefs: []
  type: TYPE_NORMAL
- en: For this tutorial, we’re going to go through a modified version of the [DBSCAN
    demo](https://github.com/rapidsai/notebooks/blob/branch-0.8/tutorials/DBSCAN_Demo_Full.ipynb?source=post_page---------------------------).
    I’ll be using the [Nvidia Data Science Work Station](https://towardsdatascience.com/nvidias-new-data-science-workstation-a-review-and-benchmark-e451db600551?source=post_page---------------------------) to
    run the testing which came with 2 GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: DBSCAN is a density-based [clustering algorithm](https://towardsdatascience.com/the-5-clustering-algorithms-data-scientists-need-to-know-a36d136ef68?source=post_page---------------------------) that
    can automatically classify groups of data, without the user having to specify
    how many groups there are. There’s an implementation of it in [Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html?source=post_page---------------------------).
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by getting all of our imports setup. Libraries for loading data,
    visualising data, and applying ML models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The *make_circles* functions will automatically create a complex distribution
    of data resembling two circles that we’ll apply DBSCAN on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by creating our dataset of 100,000 points and visualising it in
    a plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![figure-name](../Images/12a054c98c39b6df2d4aecb2381e666c.png)'
  prefs: []
  type: TYPE_IMG
- en: '**DBSCAN on CPU**'
  prefs: []
  type: TYPE_NORMAL
- en: Running DBSCAN on CPU is easy with Scikit-Learn. We’ll import our algorithm
    and setup some parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We can now apply DBSCAN on our circle data with a single function call from
    Scikit-Learn. Putting a `%%time` before our function tells Jupyter Notebook to
    measure its run time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For those 100, 000 points, the run time was 8.31 seconds. The resulting plot
    is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/d3b76a1e32d8538015ea451df118ecf2.png)Result of running
    DBSCAN on the CPU using Scikit-Learn'
  prefs: []
  type: TYPE_NORMAL
- en: '**DBSCAN with Rapids on GPU**'
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s make things faster with Rapids!
  prefs: []
  type: TYPE_NORMAL
- en: First, we’ll convert our data to a `pandas.DataFrame` and use that to create
    a `cudf.DataFrame`. Pandas dataframes are converted seamlessly to cuDF dataframes
    without any change in the data format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We’ll then import and initialise a *special* version of DBSCAN from cuML, one
    that is GPU accelerated. The function format of the cuML version of DBSCAN is
    the exact same as that of Scikit-Learn — same parameters, same style, same functions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can run our prediction function for the GPU DBSCAN while measuring
    the run time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The GPU version has a run time of 4.22 seconds — almost a 2X speedup. The resulting
    plot is the exact same as the CPU version too, since we are using the same algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/d3b76a1e32d8538015ea451df118ecf2.png)Result of running
    DBSCAN on the GPU using cuML'
  prefs: []
  type: TYPE_NORMAL
- en: Getting super speed with Rapids GPU
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The amount of speedup we get from Rapids depends on how much data we are processing.
    A good rule of thumb is that larger datasets will benefit from GPU acceleration.
    There is some overhead time associated with transferring data between the CPU
    and GPU — that overhead time becomes more “worth it” with larger datasets.
  prefs: []
  type: TYPE_NORMAL
- en: We can illustrate this with a simple example.
  prefs: []
  type: TYPE_NORMAL
- en: We’re going to create a Numpy array of random numbers and apply DBSCAN on it.
    We’ll compare the speed of our regular CPU DBSCAN and the GPU version from cuML,
    while increasing and decreasing the number of data points to see how it effects
    our run time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code below illustrates this test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Check out the plot of the results from Matplotlib down below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure-name](../Images/6ec9f65915ba982f6379a5af54f22934.png)'
  prefs: []
  type: TYPE_IMG
- en: The amount of rises quite drastically when using the GPU instead of CPU. Even
    at 10,000 points (far left) we still get a speedup of 4.54X. On the higher end
    of things, with 10,000,000 points we get a speedup of 88.04X when switching to
    GPU!
  prefs: []
  type: TYPE_NORMAL
- en: Like to learn?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Follow me on[ twitter](https://twitter.com/GeorgeSeif94?source=post_page---------------------------) where
    I post all about the latest and greatest AI, Technology, and Science! Connect
    with me on [LinkedIn](https://www.linkedin.com/in/georgeseif/?source=post_page---------------------------) too!
  prefs: []
  type: TYPE_NORMAL
- en: Recommended Reading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Want to learn more about Data Science? The [***Python Data Science Handbook***](https://amzn.to/2GZN4Xv?source=post_page---------------------------) book
    is the best resource out there for learning how to do *real* Data Science with
    Python!
  prefs: []
  type: TYPE_NORMAL
- en: And just a heads up, I support this blog with Amazon affiliate links to great
    books, because sharing great books helps everyone! As an Amazon Associate I earn
    from qualifying purchases.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [George Seif](https://towardsdatascience.com/@george.seif94)** is a
    Certified Nerd and AI / Machine Learning Engineer.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/heres-how-you-can-accelerate-your-data-science-on-gpu-4ecf99db3430).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Nvidia’s New Data Science Workstation — a Review and Benchmark](/2019/07/nvidia-new-data-science-workstation.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Examining the Transformer Architecture – Part 2: A Brief Description of How
    Transformers Work](/2019/07/transformer-architecture-part-2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[XGBoost on GPUs: Unlocking Machine Learning Performance and Productivity](/2018/12/nvidia-xgboost-gpu-machine-learning-performance-productivity.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building a GPU Machine vs. Using the GPU Cloud](https://www.kdnuggets.com/building-a-gpu-machine-vs-using-the-gpu-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Accelerate Your Machine Learning Journey with Uplimit''s Metaflow…](https://www.kdnuggets.com/2023/10/uplimit-accelerate-your-machine-learning-journey-metaflow-mastery-course)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Use Analytics to Accelerate Business Growth?](https://www.kdnuggets.com/2022/12/analytics-accelerate-business-growth.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using RAPIDS cuDF to Leverage GPU in Feature Engineering](https://www.kdnuggets.com/2023/06/rapids-cudf-leverage-gpu-feature-engineering.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mastering GPUs: A Beginner''s Guide to GPU-Accelerated DataFrames in Python](https://www.kdnuggets.com/2023/07/mastering-gpus-beginners-guide-gpu-accelerated-dataframes-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
