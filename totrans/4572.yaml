- en: The 5 Classification Evaluation Metrics Every Data Scientist Must Know
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个数据科学家必须了解的5种分类评价指标
- en: 原文：[https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html](https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html](https://www.kdnuggets.com/2019/10/5-classification-evaluation-metrics-every-data-scientist-must-know.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[comments](#comments)'
- en: '***What do we want to optimize for? ***Most of the businesses fail to answer
    this simple question.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '***我们想要优化什么？*** 大多数企业无法回答这个简单的问题。'
- en: '***Every business problem is a little different, and it should be optimized
    differently.***'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '***每个业务问题都有些许不同，因此需要不同的优化方式。***'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We all have created classification models. A lot of time we try to increase
    evaluate our models on accuracy.*** But do we really want accuracy as a metric
    of our model performance?***
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都创建过分类模型。很多时候我们尝试通过准确率来评估我们的模型。***但我们真的希望准确率作为模型性能的指标吗？***
- en: '***What if we are predicting the number of asteroids that will hit the earth.***'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '***如果我们预测的是会撞击地球的小行星数量呢？***'
- en: Just say zero all the time. And you will be 99% accurate. My model can be reasonably
    accurate, but not at all valuable. What should we do in such cases?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 只需始终说零。你将会99%准确。我的模型可能相对准确，但完全没有价值。在这种情况下我们应该怎么办？
- en: '*Designing a Data Science project is much more important than the modeling
    itself.*'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*设计数据科学项目比建模本身更为重要。*'
- en: '***This post is about various evaluation metrics and how and when to use them.***'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***这篇文章讨论了各种评价指标以及如何和何时使用它们。***'
- en: '1\. Accuracy, Precision, and Recall:'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 准确率、精确率和召回率：
- en: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
- en: A. Accuracy
  id: totrans-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A. 准确率
- en: Accuracy is the quintessential classification metric. It is pretty easy to understand.
    And easily suited for binary as well as a multiclass classification problem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是经典的分类指标。它很容易理解，并且适用于二分类以及多分类问题。
- en: '`Accuracy = (TP+TN)/(TP+FP+FN+TN)`'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '`Accuracy = (TP+TN)/(TP+FP+FN+TN)`'
- en: Accuracy is the proportion of true results among the total number of cases examined.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率是指所有检查的案例中真实结果所占的比例。
- en: '**When to use?**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: Accuracy is a valid choice of evaluation for classification problems which are
    well balanced and not skewed or No class imbalance.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 准确率对于平衡且没有偏斜或没有类别不平衡的分类问题是一个有效的评价指标。
- en: '**Caveats**'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: Let us say that our target class is very sparse. Do we want accuracy as a metric
    of our model performance? ***What if we are predicting if an asteroid will hit
    the earth? ***Just say `No` all the time. And you will be 99% accurate. My model
    can be reasonably accurate, but not at all valuable.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的目标类别非常稀疏。我们是否希望准确率作为模型性能的衡量标准？***如果我们预测的是小行星是否会撞击地球？*** 只需始终回答`No`。你将会99%准确。我的模型可能相对准确，但完全没有价值。
- en: B. Precision
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: B. 精确率
- en: 'Let’s start with *precision*, which answers the following question: what proportion
    of **predicted Positives **is truly Positive?'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从*精确率*开始，它回答以下问题：**预测为正的比例中真正的正例占多少？**
- en: '`Precision = (TP)/(TP+FP)`'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '`Precision = (TP)/(TP+FP)`'
- en: In the asteroid prediction problem, we never predicted a true positive.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在小行星预测问题中，我们从未预测过一个真实的正例。
- en: And thus precision = 0
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此精确率 = 0
- en: '**When to use?**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: 'Precision is a valid choice of evaluation metric when we want to be very sure
    of our prediction. For example: If we are building a system to predict if we should
    decrease the credit limit on a particular account, we want to be very sure about
    our prediction or it may result in customer dissatisfaction.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度是一个有效的评估指标，当我们想要对我们的预测非常确定时。例如：如果我们在构建一个系统来预测是否应该减少特定账户的信用额度，我们希望对我们的预测非常确定，否则可能会导致客户不满。
- en: '**Caveats**'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: '*Being very precise means our model will leave a lot of credit defaulters untouched
    and hence lose money.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*非常精确意味着我们的模型将有很多信用违约者未被触及，从而导致损失。*'
- en: C. Recall
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: C. 回忆率
- en: 'Another very useful measure is* recall*, which answers a different question:
    what proportion of **actual Positives **is correctly classified?'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常有用的度量是*回忆率*，它回答了一个不同的问题：**实际正例**的比例被正确分类了多少？
- en: '`Recall = (TP)/(TP+FN)`'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '`Recall = (TP)/(TP+FN)`'
- en: In the asteroid prediction problem, we never predicted a true positive.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在小行星预测问题中，我们从未预测到真正的正例。
- en: And thus recall is also equal to 0.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此回忆率也等于0。
- en: '**When to use?**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: 'Recall is a valid choice of evaluation metric when we want to capture as many
    positives as possible. For example: If we are building a system to predict if
    a person has cancer or not, we want to capture the disease even if we are not
    very sure.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望捕捉尽可能多的正例时，回忆率是一个有效的评估指标。例如：如果我们在构建一个系统来预测一个人是否患有癌症，我们希望即使不太确定也要捕捉到疾病。
- en: '**Caveats**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: '***Recall is 1 if we predict 1 for all examples.***'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '***回忆率为1当我们对所有样本预测1时。***'
- en: And thus comes the idea of utilizing tradeoff of precision vs. recall — ***F1
    Score***.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，出现了利用精确度与回忆率权衡的想法—— ***F1分数***。
- en: '2\. F1 Score:'
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. F1 分数：
- en: This is my ***favorite evaluation metric*** and I tend to use this a lot in
    my classification projects.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我***最喜欢的评估指标***，我在分类项目中经常使用这个指标。
- en: The F1 score is a number between 0 and 1 and is the harmonic mean of precision
    and recall.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数是0到1之间的数字，是精确度和回忆率的调和平均数。
- en: '![](../Images/d13bce6c7f3757567b2860521e727525.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d13bce6c7f3757567b2860521e727525.png)'
- en: Let us start with a binary prediction problem. ***We are predicting if an asteroid
    will hit the earth or not.***
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个二分类预测问题开始。 ***我们正在预测小行星是否会撞击地球。***
- en: So if we say “No” for the whole training set. Our precision here is 0\. What
    is the recall of our positive class? It is zero. What is the accuracy? It is more
    than 99%.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们对整个训练集说“否”。我们的精确度为0。我们的正类回忆率是多少？是零。准确率是多少？超过99%。
- en: And hence the F1 score is also 0\. And thus we get to know that the classifier
    that has an accuracy of 99% is basically worthless for our case. And hence it
    solves our problem.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，F1分数也是0。因此我们了解到，准确率为99%的分类器在我们的情况下基本上毫无用处。因此它解决了我们的问题。
- en: '**When to use?**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: We want to have a model with both good precision and recall.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望拥有一个精确度和回忆率都很好的模型。
- en: '![Figure](../Images/588de63fd8749e1cfea448c9144f6dbe.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/588de63fd8749e1cfea448c9144f6dbe.png)'
- en: Precision-Recall Tradeoff
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 精确度-回忆率权衡
- en: Simply stated the ***F1 score sort of maintains a balance between the precision
    and recall for your classifier***. If your precision is low, the F1 is low and
    if the recall is low again your F1 score is low.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 简单地说，***F1分数在你的分类器中在精确度和回忆率之间保持了一种平衡***。如果你的精确度低，F1分数低；如果回忆率低，F1分数同样低。
- en: If you are a police inspector and you want to catch criminals, you want to be
    sure that the person you catch is a criminal (Precision) and you also want to
    capture as many criminals (Recall) as possible. The F1 score manages this tradeoff.
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果你是警察检查员，并且你想抓住罪犯，你希望确保你抓到的人是罪犯（精确度），同时你也希望捕捉到尽可能多的罪犯（回忆率）。F1分数处理了这种权衡。
- en: '**How to Use?**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: 'You can calculate the F1 score for binary prediction problems using:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下方法计算二分类预测问题的F1分数：
- en: '[PRE0]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is one of my functions which I use to get the best threshold for maximizing
    F1 score for binary predictions. The below function iterates through possible
    threshold values to find the one that gives the best F1 score.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我用来获得最大化F1分数的最佳阈值的函数。下面的函数迭代可能的阈值，以找到提供最佳F1分数的阈值。
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Caveats**'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告**'
- en: The main problem with the F1 score is that it gives equal weight to precision
    and recall. We might sometimes need to include domain knowledge in our evaluation
    where we want to have more recall or more precision.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数的主要问题是它对精确度和回忆率给予相等的权重。我们有时可能需要在评估中包含领域知识，以便我们想要更多的回忆率或更多的精确度。
- en: To solve this, we can do this by creating a weighted F1 metric as below where
    beta manages the tradeoff between precision and recall.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为解决此问题，我们可以通过创建加权的F1指标来实现，下面的公式中β管理精确度和召回率之间的权衡。
- en: '![](../Images/642e02997e7d35b1a68750374c0e6542.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/642e02997e7d35b1a68750374c0e6542.png)'
- en: Here we give β times as much importance to recall as precision.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们给予召回率β倍的权重，而不是精确度。
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: F1 Score can also be used for Multiclass problems. See [this](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1) awesome
    blog post by [Boaz Shmueli](https://medium.com/u/57ee515c83c5?source=post_page-----aa97784ff226----------------------) for
    details.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: F1分数也可以用于多类问题。请参阅[这篇](https://towardsdatascience.com/multi-class-metrics-made-simple-part-ii-the-f1-score-ebe8b2c2ca1)精彩博客文章，由[Boaz
    Shmueli](https://medium.com/u/57ee515c83c5?source=post_page-----aa97784ff226----------------------)提供详细信息。
- en: 3\. Log Loss/Binary Cross-entropy
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 日志损失/二元交叉熵
- en: Log loss is a pretty good evaluation metric for binary classifiers and it is
    sometimes the optimization objective as well in case of Logistic regression and
    Neural Networks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 日志损失是评估二元分类器的一个相当好的指标，并且在逻辑回归和神经网络中有时也是优化目标。
- en: Binary Log loss for an example is given by the below formula where p is the
    probability of predicting 1.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 二元日志损失的示例如下公式，其中p是预测1的概率。
- en: '![](../Images/589f6701243bff934d5bab0dac0f4793.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/589f6701243bff934d5bab0dac0f4793.png)'
- en: '![](../Images/5eb3b742cca4ae0ee23b80a85487d7f6.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5eb3b742cca4ae0ee23b80a85487d7f6.png)'
- en: As you can see the log loss decreases as we are fairly certain in our prediction
    of 1 and the true label is 1.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，当我们对1的预测相当确定且实际标签为1时，日志损失减少。
- en: '**When to Use?**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: '*When the output of a classifier is prediction probabilities. ****Log Loss
    takes into account the uncertainty of your prediction based on how much it varies
    from the actual label. ***This gives us a more nuanced view of the performance
    of our model. In general, minimizing Log Loss gives greater accuracy for the classifier.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*当分类器的输出是预测概率时。****日志损失考虑了你的预测的不确定性，基于其与实际标签的差异。***这为我们的模型性能提供了更细致的视角。一般来说，最小化日志损失可以提高分类器的准确性。'
- en: '**How to Use?**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE3]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Caveats**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: It is susceptible in case of [imbalanced](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) datasets.
    You might have to introduce class weights to penalize minority errors more or
    you may use this after balancing your dataset.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在[不平衡](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c)数据集的情况下，它容易受到影响。你可能需要引入类别权重，以更多地惩罚少数类错误，或者在平衡数据集后使用此方法。
- en: 4\. Categorical Cross-entropy
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4\. 分类交叉熵
- en: 'The log loss also generalizes to the multiclass problem. The classifier in
    a multiclass setting must assign a probability to each class for all examples.
    If there are N samples belonging to M classes, then the *Categorical Cross-entropy* is
    the summation of -`ylogp` values:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 日志损失也可以推广到多类问题。在多类情况下，分类器必须为所有示例分配每个类别的概率。如果有N个样本属于M个类别，则*分类交叉熵*是-`ylogp`值的总和：
- en: '![](../Images/607c37a49856b1fa9722078f40518ccb.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/607c37a49856b1fa9722078f40518ccb.png)'
- en: '`y_ij` is 1 if the sample `i` belongs to class `j` else 0'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_ij`是1如果样本`i`属于类别`j`，否则为0'
- en: '`p_ij` is the probability our classifier predicts of sample `i` belonging to
    class `j`.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`p_ij`是我们分类器预测样本`i`属于类别`j`的概率。'
- en: '**When to Use?**'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: '*When the output of a classifier is multiclass prediction probabilities. We
    generally use Categorical Crossentropy in case of Neural Nets. *In general, minimizing
    Categorical cross-entropy gives greater accuracy for the classifier.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '*当分类器的输出是多类预测概率时，我们通常在神经网络中使用分类交叉熵。*一般来说，最小化分类交叉熵可以提高分类器的准确性。'
- en: '**How to Use?**'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE4]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Caveats:**'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项：**'
- en: It is susceptible in case of [imbalanced](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c) datasets.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在[不平衡](https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c)数据集的情况下，它容易受到影响。
- en: 5\. AUC
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5\. AUC
- en: AUC is the area under the ROC curve.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: AUC是ROC曲线下的面积。
- en: '***AUC ROC indicates how well the probabilities from the positive classes are
    separated from the negative classes***'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '***AUC ROC指标显示正类概率与负类概率的分离程度***'
- en: '***What is the ROC curve?***'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '***ROC曲线是什么？***'
- en: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fe2bc86aaaf0cf9b6c68d2768751a9ed.png)'
- en: We have got the probabilities from our classifier. We can use various threshold
    values to plot our sensitivity(TPR) and (1-specificity)(FPR) on the cure and we
    will have a ROC curve.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从分类器得到了概率。我们可以使用各种阈值来绘制我们的灵敏度（TPR）和（1-特异度）（FPR）的曲线，这样我们就会得到ROC曲线。
- en: Where True positive rate or TPR is just the proportion of trues we are capturing
    using our algorithm.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，真正的阳性率（True Positive Rate，TPR）只是我们使用算法捕获的真正阳性的比例。
- en: '`Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)`'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sensitivty = TPR(True Positive Rate)= Recall = TP/(TP+FN)`'
- en: and False positive rate or FPR is just the proportion of false we are capturing
    using our algorithm.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 假阳性率（False Positive Rate，FPR）只是我们使用算法捕获的假阳性的比例。
- en: '`1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)`'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '`1- Specificity = FPR(False Positive Rate)= FP/(TN+FP)`'
- en: '![Figure](../Images/c1344e1d0fb96baffeb0c4d68b4b55aa.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/c1344e1d0fb96baffeb0c4d68b4b55aa.png)'
- en: ROC Curve
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线
- en: Here we can use the ROC curves to decide on a Threshold value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们可以使用ROC曲线来决定阈值。
- en: The choice of threshold value will also depend on how the classifier is intended
    to be used.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 阈值的选择还将取决于分类器的使用意图。
- en: If it is a cancer classification application you don’t want your threshold to
    be as big as 0.5\. Even if a patient has a 0.3 probability of having cancer you
    would classify him to be 1.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个癌症分类应用，你不希望你的阈值设为0.5。即使一个患者的癌症概率是0.3，你也会将他分类为1。
- en: Otherwise, in an application for reducing the limits on the credit card, you
    don’t want your threshold to be as less as 0.5\. You are here a little worried
    about the negative effect of decreasing limits on customer satisfaction.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，在降低信用卡限额的应用中，你不希望你的阈值设为0.5。你此时更担心降低限额对客户满意度的负面影响。
- en: '**When to Use?**'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**何时使用？**'
- en: AUC is **scale-invariant**. It measures how well predictions are ranked, rather
    than their absolute values. So, for example, if you as a marketer want to find
    a list of users who will respond to a marketing campaign. AUC is a good metric
    to use since the predictions ranked by probability is the order in which you will
    create a list of users to send the marketing campaign.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: AUC是**尺度不变的**。它衡量的是预测的排名情况，而不是其绝对值。因此，例如，如果你作为市场营销人员想要找出响应营销活动的用户列表。AUC是一个好的指标，因为按概率排名的预测就是你将创建营销活动用户列表的顺序。
- en: Another benefit of using AUC is that it is **classification-threshold-invariant **like
    log loss. It measures the quality of the model’s predictions irrespective of what
    classification threshold is chosen, unlike F1 score or accuracy which depend on
    the choice of threshold.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AUC的另一个好处是它是**分类阈值不变的**，类似于对数损失。它衡量模型预测的质量，而不管选择了什么分类阈值，这与F1分数或准确度不同，它们依赖于阈值的选择。
- en: '**How to Use?**'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**如何使用？**'
- en: '[PRE5]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '**Caveats**'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意事项**'
- en: Sometimes we will need well-calibrated probability outputs from our models and
    AUC doesn’t help with that.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们需要从模型中获得良好的概率输出，而AUC对此无济于事。
- en: Conclusion
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: An important step while creating our [machine learning pipeline](https://towardsdatascience.com/6-important-steps-to-build-a-machine-learning-system-d75e3b83686) is
    evaluating our different models against each other. A bad choice of an evaluation
    metric could wreak havoc to your whole system.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 创建我们的[machine learning pipeline](https://towardsdatascience.com/6-important-steps-to-build-a-machine-learning-system-d75e3b83686)的一个重要步骤是将不同的模型相互评估。选择不当的评价指标可能会对整个系统造成严重影响。
- en: '***So, always be watchful of what you are predicting and how the choice of
    evaluation metric might affect/alter your final predictions.***'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '***因此，始终要注意你预测的内容以及评价指标的选择如何影响/改变你的最终预测。***'
- en: Also, the choice of an evaluation metric should be well aligned with the business
    objective and hence it is a bit subjective. And you can come up with your own
    evaluation metric as well.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，选择评价指标应与业务目标良好对齐，因此这有些主观。你也可以提出自己的评价指标。
- en: Continue Learning
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 继续学习
- en: If you want to [learn](https://towardsdatascience.com/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------) more
    about how to structure a Machine Learning project and the best practices, I would
    like to call out his awesome [third course](https://click.linksynergy.com/link?id=lVarvwc5BD0&offerid=467035.11421702016&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fmachine-learning-projects) named
    Structuring Machine learning projects in the Coursera [Deep Learning Specialization](https://click.linksynergy.com/deeplink?id=lVarvwc5BD0&mid=40328&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fdeep-learning).
    Do check it out. It talks about the pitfalls and a lot of basic ideas to improve
    your models.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要[了解](https://towardsdatascience.com/how-did-i-start-with-data-science-3f4de6b501b0?source=---------8------------------)
    更多关于如何构建机器学习项目和最佳实践的内容，我推荐他的精彩[第三门课程](https://click.linksynergy.com/link?id=lVarvwc5BD0&offerid=467035.11421702016&type=2&murl=https%3A%2F%2Fwww.coursera.org%2Flearn%2Fmachine-learning-projects)，这门课程名为《构建机器学习项目》，在
    Coursera 的[深度学习专业课程](https://click.linksynergy.com/deeplink?id=lVarvwc5BD0&mid=40328&murl=https%3A%2F%2Fwww.coursera.org%2Fspecializations%2Fdeep-learning)中提供。一定要看看，它讲述了许多基本概念和改进模型的陷阱。
- en: Thanks for the read. I am going to be writing more beginner-friendly posts in
    the future too. Follow me up at [**Medium**](https://medium.com/@rahul_agarwal?source=post_page---------------------------) or
    Subscribe to my [**blog**](http://eepurl.com/dbQnuX?source=post_page---------------------------) to
    be informed about them. As always, I welcome feedback and constructive criticism
    and can be reached on Twitter [@mlwhiz](https://twitter.com/MLWhiz?source=post_page---------------------------)
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢阅读。我将来还会写更多适合初学者的文章。可以在[**Medium**](https://medium.com/@rahul_agarwal?source=post_page---------------------------)上关注我，或订阅我的[**博客**](http://eepurl.com/dbQnuX?source=post_page---------------------------)以获取最新动态。一直以来，我欢迎反馈和建设性的批评，可以通过
    Twitter [@mlwhiz](https://twitter.com/MLWhiz?source=post_page---------------------------)
    联系我。
- en: Also, a small disclaimer — There might be some affiliate links in this post
    to relevant resources as sharing knowledge is never a bad idea.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，附个小免责声明——这篇文章可能包含一些相关资源的推荐链接，因为分享知识永远是个好主意。
- en: '**Bio: [Rahul Agarwal](https://www.linkedin.com/in/rahulagwl/)** is Senior
    Statistical Analyst at WalmartLabs. Follow him on Twitter [@mlwhiz](https://twitter.com/MLWhiz).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Rahul Agarwal](https://www.linkedin.com/in/rahulagwl/)** 是 WalmartLabs
    的高级统计分析师。可以在 Twitter 上关注他 [@mlwhiz](https://twitter.com/MLWhiz)。'
- en: '[Original](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226).
    Reposted with permission.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/the-5-classification-evaluation-metrics-you-must-know-aa97784ff226)。已获许可转载。'
- en: '**Related:**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[The 5 Graph Algorithms That Data Scientists Should Know](/2019/09/5-graph-algorithms-data-scientists-know.html)'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家应该了解的5种图算法](/2019/09/5-graph-algorithms-data-scientists-know.html)'
- en: '[The Hitchhiker’s Guide to Feature Extraction](/2019/06/hitchhikers-guide-feature-extraction.html)'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[特征提取的向导](/2019/06/hitchhikers-guide-feature-extraction.html)'
- en: '[6 bits of advice for Data Scientists](/2019/09/advice-data-scientists.html)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家的6条建议](/2019/09/advice-data-scientists.html)'
- en: More On This Topic
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[More Performance Evaluation Metrics for Classification Problems You…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[更多分类问题的性能评估指标](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
- en: '[Machine Learning Evaluation Metrics: Theory and Overview](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习评估指标：理论与概述](https://www.kdnuggets.com/machine-learning-evaluation-metrics-theory-and-overview)'
- en: '[Classification Metrics Walkthrough: Logistic Regression with…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类指标详解：逻辑回归与…](https://www.kdnuggets.com/2022/10/classification-metrics-walkthrough-logistic-regression-accuracy-precision-recall-roc.html)'
- en: '[Understanding Classification Metrics: Your Guide to Assessing Model…](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解分类指标：评估模型准确性的指南](https://www.kdnuggets.com/understanding-classification-metrics-your-guide-to-assessing-model-accuracy)'
- en: '[KDnuggets News, May 25: The 6 Python Machine Learning Tools Every…](https://www.kdnuggets.com/2022/n21.html)'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，5月25日：每个数据科学家都应该了解的6种Python机器学习工具](https://www.kdnuggets.com/2022/n21.html)'
- en: '[The 6 Python Machine Learning Tools Every Data Scientist Should Know About](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的6种Python机器学习工具](https://www.kdnuggets.com/2022/05/6-python-machine-learning-tools-every-data-scientist-know.html)'
