["```py\n\n```", "```py\n\nThe values below or equal to zero go negative infinite when they are in log scale, I made a function to convert those values into 1 and applied it to `Recency` and `Monetary` column, using list comprehension like above. And then, a log transformation is applied for each RFM values. The next preprocessing step is scaling but it’s simpler than the previous step. Using **StandardScaler()**, we can get the standardized values like below.\n\n```", "```py\n\n![StandardScaler()](../Images/8639a07780dedd6acbca1d131af0fd5d.png)\nThe plot on the left is the distributions of RFM before preprocessing, and the plot on the right is the distributions of RFM after normalization. By making them in the somewhat normal distribution, we can give hints to our model to grasp the trends between values easily and accurately. Now, we are done with preprocessing.\nWhat is the next? The next step will be selecting the right number of clusters. We have to choose how many groups we’re going to make. If there is prior knowledge, we can just give the number right ahead to the algorithm. But most of the case in unsupervised learning, there isn’t. So we need to choose the optimized number, and the Elbow method is one of the solutions where we can get the hints.\n\n```", "```py\n# the Elbow method\nwcss = {}\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters= k, init= 'k-means++', max_iter= 300)\n    kmeans.fit(rfm_scaled)\n    wcss[k] = kmeans.inertia_\n# plot the WCSS values\nsns.pointplot(x = list(wcss.keys()), y = list(wcss.values()))\nplt.xlabel('K Numbers')\nplt.ylabel('WCSS')\nplt.show()\n\n```", "```py\n# clustering\nclus = KMeans(n_clusters= 3, init= 'k-means++', max_iter= 300)\nclus.fit(rfm_scaled)\n# Assign the clusters to datamart\nrfm['K_Cluster'] = clus.labels_\nrfm.head()\n\n```", "```py\n# assign cluster column \nrfm_scaled['K_Cluster'] = clus.labels_\nrfm_scaled['RFM_Level'] = rfm.RFM_Level\nrfm_scaled.reset_index(inplace = True)\n# melt the dataframe\nrfm_melted = pd.melt(frame= rfm_scaled, id_vars= ['CustomerID', 'RFM_Level', 'K_Cluster'], var_name = 'Metrics', value_name = 'Value')\nrfm_melted.head()\n\n```", "```py\n# a snake plot with RFM\nsns.lineplot(x = 'Metrics', y = 'Value', hue = 'RFM_Level', data = rfm_melted)\nplt.title('Snake Plot of RFM')\nplt.legend(loc = 'upper right')\n# a snake plot with K-Means\nsns.lineplot(x = 'Metrics', y = 'Value', hue = 'K_Cluster', data = rfm_melted)\nplt.title('Snake Plot of RFM')\nplt.legend(loc = 'upper right')\n\n```", "```py\n# the mean value in total \ntotal_avg = rfm.iloc[:, 0:3].mean()\ntotal_avg\n# calculate the proportional gap with total mean\ncluster_avg = rfm.groupby('RFM_Level').mean().iloc[:, 0:3]\nprop_rfm = cluster_avg/total_avg - 1\n# heatmap with RFM\nsns.heatmap(prop_rfm, cmap= 'Oranges', fmt= '.2f', annot = True)\nplt.title('Heatmap of RFM quantile')\nplt.plot()\n\n```", "```py\n# calculate the proportional gap with total mean\ncluster_avg_K = rfm.groupby('K_Cluster').mean().iloc[:, 0:3]\nprop_rfm_K = cluster_avg_K/total_avg - 1\n# heatmap with K-means\nsns.heatmap(prop_rfm_K, cmap= 'Blues', fmt= '.2f', annot = True)\nplt.title('Heatmap of K-Means')\nplt.plot()\n\n```", "```py\n\n```"]