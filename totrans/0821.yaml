- en: Data Cleaning with Pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/data-cleaning-with-pandas](https://www.kdnuggets.com/data-cleaning-with-pandas)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Data Cleaning with Pandas](../Images/4d7ef9a022460c8e9009883084da54ff.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: If you are into Data Science, then data cleaning might sound like a familiar
    term to you. If not, let me explain that to you. Our data often comes from multiple
    resources and is not clean. It may contain missing values, duplicates, wrong or
    undesired formats, etc.  Running your experiments on this messy data leads to
    incorrect results. Therefore, it is necessary to prepare your data before it is
    fed to your model. This preparation of the data by identifying and resolving the
    potential errors, inaccuracies, and inconsistencies is termed as **Data Cleaning**.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, I will walk you through the process of cleaning the data using
    Pandas.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I will be working with the famous [Iris](https://archive.ics.uci.edu/dataset/53/iris)
    dataset. The Iris dataset contains measurements of four features of three species
    of Iris flowers: sepal length, sepal width, petal length, and petal width.  We
    will be using the following libraries:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '***   **Pandas:** Powerful library for data manipulation and analysis'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Scikit-learn:** Provides tools for data preprocessing and machine learning'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Steps for Data Cleaning
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 1\. Loading the Dataset
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Load the Iris dataset using Pandas'' **read_csv()** function:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Output:**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '| **id** | **sepal_length** | **sepal_width** | **petal_length** | **petal_width**
    | **species** |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| 1 | 5.1 | 3.5 | 1.4 | 0.2 | Iris-setosa |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| 2 | 4.9 | 3.0 | 1.4 | 0.2 | Iris-setosa |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| 3 | 4.7 | 3.2 | 1.3 | 0.2 | Iris-setosa |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| 4 | 4.6 | 3.1 | 1.5 | 0.2 | Iris-setosa |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| 5 | 5.0 | 3.6 | 1.4 | 0.2 | Iris-setosa |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: The **header=0** parameter indicates that the first row of the CSV file contains
    the column names (header).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Explore the dataset
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To get insights about our dataset, we will print some basic information using
    the built-in functions in pandas
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Output:**'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Data Cleaning with Pandas](../Images/2358828d44ba39e3f759d6dc9986b6e8.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Output for iris_data.describe()
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: The **info() function** is useful to understand the overall structure of the
    data frame, the number of non-null values in each column, and the memory usage.
    While the summary statistics provide an overview of numerical features in your
    dataset.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Checking Class Distribution
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 检查类别分布
- en: This is an important step in understanding how the classes are distributed in
    categorical columns, which is an important task for classification. You can perform
    this step using the value_counts() function in pandas.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这是理解分类列中类别分布的重要步骤，这对于分类任务至关重要。你可以使用 pandas 中的 value_counts() 函数执行这一步。
- en: '[PRE3]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Output:**'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE4]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Our results show that the dataset is balanced with an equal number of representations
    of each species. This sets the base for a fair evaluation and comparison across
    all 3 classes.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的结果显示数据集是平衡的，每个物种的表示数量相等。这为在所有 3 个类别之间进行公平评估和比较奠定了基础。
- en: 4\. Removing Missing Values
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 删除缺失值
- en: 'Since it is evident from the **info()** method that we have 5 columns with
    no missing values, we will skip this step. But if you encounter any missing values,
    use the following command to handle them:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 由于从**info()**方法中可以明显看出我们有 5 列数据没有缺失值，因此我们将跳过这一步。但如果遇到任何缺失值，请使用以下命令处理它们：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 5\. Removing Duplicates
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 删除重复项
- en: 'Duplicates can distort our analysis so we remove them from our dataset. We
    will first check their existence using the below-mentioned command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 由于重复项可能扭曲我们的分析，因此我们从数据集中删除它们。我们将首先使用以下命令检查它们的存在：
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '**Output:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We do not have any duplicates for this dataset. Nonetheless, the duplicates
    can be removed via the **drop_duplicates()** function.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的这个数据集没有重复项。不过，可以通过**drop_duplicates()**函数删除重复项。
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 6\. One-Hot Encoding
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 独热编码
- en: For categorical analysis, we will perform one-hot encoding on the species column.
    This step is performed due to the tendency of Machine Learning algorithms to work
    better with numerical data. The one-hot encoding process transforms categorical
    variables into a binary (0 or 1) format.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类分析，我们将对物种列执行独热编码。进行这一步的原因是机器学习算法更倾向于使用数值数据。独热编码过程将分类变量转换为二进制（0 或 1）格式。
- en: '[PRE9]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![Data Cleaning with Pandas](../Images/476d06368bc9b14541a405819bc3d427.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据清洗](../Images/476d06368bc9b14541a405819bc3d427.png)'
- en: Image by Author
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：作者
- en: 7\. Normalization of Float Value Columns
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 浮点值列的归一化
- en: Normalization is the process of scaling numerical features to have a mean of
    0 and a standard deviation of 1\. This process is done to ensure that the features
    contribute equally to the analysis. We will normalize the float value columns
    for consistent scaling.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化是将数值特征缩放到均值为 0 和标准差为 1 的过程。进行此过程是为了确保特征对分析的贡献相等。我们将对浮点值列进行归一化，以实现一致的缩放。
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![Data Cleaning with Pandas](../Images/69e35ac2ad4d8fff336dc543bc02288c.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Pandas 进行数据清洗](../Images/69e35ac2ad4d8fff336dc543bc02288c.png)'
- en: Output for iris_data.describe() after normalization
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 归一化后的 iris_data.describe() 输出
- en: 8\. Save the cleaned dataset
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 保存清洗后的数据集
- en: Save the cleaned dataset to the new CSV file.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 将清洗后的数据集保存到新的 CSV 文件中。
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Wrapping Up
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Congratulations! You have successfully cleaned your first dataset using pandas.
    You may encounter additional challenges while dealing with complex datasets. However,
    the fundamental techniques mentioned here will help you get started and prepare
    your data for analysis.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已经成功使用 pandas 清洗了第一个数据集。在处理复杂数据集时，你可能会遇到额外的挑战。然而，这里提到的基本技术将帮助你入门并准备数据以进行分析。
- en: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** is an aspiring
    software developer with a keen interest in data science and applications of AI
    in medicine. Kanwal was selected as the Google Generation Scholar 2022 for the
    APAC region. Kanwal loves to share technical knowledge by writing articles on
    trending topics, and is passionate about improving the representation of women
    in tech industry.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1)** 是一位有志于成为软件开发者的人员，对数据科学和
    AI 在医学中的应用充满兴趣。Kanwal 被选为 2022 年 APAC 区域的 Google Generation 学者。Kanwal 喜欢通过撰写有关热门话题的文章分享技术知识，并热衷于提高女性在科技行业中的代表性。'
- en: More On This Topic
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[7 Steps to Mastering Data Cleaning with Python and Pandas](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握 Python 和 Pandas 数据清洗的 7 个步骤](https://www.kdnuggets.com/7-steps-to-mastering-data-cleaning-with-python-and-pandas)'
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清洗和预处理文本数据以进行 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[Collection of Guides on Mastering SQL, Python, Data Cleaning, Data…](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握SQL、Python、数据清洗、数据整理及探索性数据分析的指南合集](https://www.kdnuggets.com/collection-of-guides-on-mastering-sql-python-data-cleaning-data-wrangling-and-exploratory-data-analysis)'
- en: '[The Importance of Data Cleaning in Data Science](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学中数据清洗的重要性](https://www.kdnuggets.com/2023/08/importance-data-cleaning-data-science.html)'
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费电子书学习数据清洗和数据预处理](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
- en: '[Data Cleaning in SQL: How To Prepare Messy Data for Analysis](https://www.kdnuggets.com/data-cleaning-in-sql-how-to-prepare-messy-data-for-analysis)**'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SQL中的数据清洗：如何为分析准备混乱的数据](https://www.kdnuggets.com/data-cleaning-in-sql-how-to-prepare-messy-data-for-analysis)**'
