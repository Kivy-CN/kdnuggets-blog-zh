- en: Supervised vs. Unsupervised Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/04/supervised-vs-unsupervised-learning.html](https://www.kdnuggets.com/2018/04/supervised-vs-unsupervised-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Devin Soni](https://www.linkedin.com/in/devinsoni/), Computer Science
    Student**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Within the field of machine learning, there are two main types of tasks: supervised,
    and unsupervised. The main difference between the two types is that supervised
    learning is done using a **ground truth**, or in other words, we have prior knowledge
    of what the output values for our samples should be. Therefore, the goal of supervised
    learning is to learn a function that, given a sample of data and desired outputs,
    best approximates the relationship between input and output observable in the
    data. Unsupervised learning, on the other hand, does not have labeled outputs,
    so its goal is to infer the natural structure present within a set of data points.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '**Supervised Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fdcbabef85fee7ab67ce1d8c1bed14a0.png)'
  prefs: []
  type: TYPE_IMG
- en: Supervised learning is typically done in the context of classification, when
    we want to map input to output labels, or regression, when we want to map input
    to a continuous output. Common algorithms in supervised learning include logistic
    regression, naive bayes, support vector machines, artificial neural networks,
    and random forests. In both regression and classification, the goal is to find
    specific relationships or structure in the input data that allow us to effectively
    produce correct output data. Note that “correct” output is determined entirely
    from the training data, so while we do have a ground truth that our model will
    assume is true, it is not to say that data labels are always correct in real-world
    situations. Noisy, or incorrect, data labels will clearly reduce the effectiveness
    of your model.
  prefs: []
  type: TYPE_NORMAL
- en: When conducting supervised learning, the main considerations are model complexity,
    and the bias-variance tradeoff. Note that both of these are interrelated.
  prefs: []
  type: TYPE_NORMAL
- en: Model complexity refers to the complexity of the function you are attempting
    to learn — similar to the degree of a polynomial. The proper level of model complexity
    is generally determined by the nature of your training data. If you have a small
    amount of data, or if your data is not uniformly spread throughout different possible
    scenarios, you should opt for a low-complexity model. This is because a high-complexity
    model will **overfit** if used on a small number of data points. Overfitting refers
    to learning a function that fits your training data very well, but does not **generalize**
    to other data points — in other words, you are strictly learning to produce your
    training data without learning the actual trend or structure in the data that
    leads to this output. Imagine trying to fit a curve between 2 points. In theory,
    you can use a function of any degree, but in practice, you would parsimoniously
    add complexity, and go with a linear function.
  prefs: []
  type: TYPE_NORMAL
- en: The bias-variance tradeoff also relates to model generalization. In any model,
    there is a balance between bias, which is the constant error term, and variance,
    which is the amount by which the error may vary between different training sets.
    So, high bias and low variance would be a model that is consistently wrong 20%
    of the time, whereas a low bias and high variance model would be a model that
    can be wrong anywhere from 5%-50% of the time, depending on the data used to train
    it. Note that bias and variance typically move in opposite directions of each
    other; increasing bias will usually lead to lower variance, and vice versa. When
    making your model, your specific problem and the nature of your data should allow
    you to make an informed decision on where to fall on the bias-variance spectrum.
    Generally, increasing bias (and decreasing variance) results in models with relatively
    guaranteed baseline levels of performance, which may be critical in certain tasks.
    Additionally, in order to produce models that generalize well, the variance of
    your model should scale with the size and complexity of your training data — small,
    simple data-sets should usually be learned with low-variance models, and large,
    complex data-sets will often require higher-variance models to fully learn the
    structure of the data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Unsupervised Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d69aa6c7c9c75e9894d819952844cf5e.png)'
  prefs: []
  type: TYPE_IMG
- en: The most common tasks within unsupervised learning are clustering, representation
    learning, and density estimation. In all of these cases, we wish to learn the
    inherent structure of our data without using explicitly-provided labels. Some
    common algorithms include k-means clustering, principal component analysis, and
    autoencoders. Since no labels are provided, there is no specific way to compare
    model performance in most unsupervised learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: Two common use-cases for unsupervised learning are exploratory analysis and
    dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning is very useful in exploratory analysis because it can
    automatically identify structure in data. For example, if an analyst were trying
    to segment consumers, unsupervised clustering methods would be a great starting
    point for their analysis. In situations where it is either impossible or impractical
    for a human to propose trends in the data, unsupervised learning can provide initial
    insights that can then be used to test individual hypotheses.
  prefs: []
  type: TYPE_NORMAL
- en: Dimensionality reduction, which refers to the methods used to represent data
    using less columns or features, can be accomplished through unsupervised methods.
    In representation learning, we wish to learn relationships between individual
    features, allowing us to represent our data using the latent features that interrelate
    our initial features. This sparse latent structure is often represented using
    far fewer features than we started with, so it can make further data processing
    much less intensive, and can eliminate redundant features.
  prefs: []
  type: TYPE_NORMAL
- en: '**TLDR:**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c316b4cd9604e4034c545e55d5fffac1.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Bio: [Devin Soni](https://www.linkedin.com/in/devinsoni/)** is a computer
    science student interested in machine learning and data science. He will be a
    software engineering intern at Airbnb in 2018\. He can be reached [via LinkedIn](https://www.linkedin.com/in/devinsoni/).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Machine Learning Algorithms: Which One to Choose for Your Problem](/2017/11/machine-learning-algorithms-choose-your-problem.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to k-Nearest Neighbors](/2018/03/introduction-k-nearest-neighbors.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introduction to Markov Chains](/2018/03/introduction-markov-chains.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
