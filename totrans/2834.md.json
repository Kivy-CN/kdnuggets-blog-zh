["```py\n####load the dataset\nbanking=read.csv(“bank-additional-full.csv”,sep =”;”,header=T)##check for missing data and make sure no missing data\nbanking[!complete.cases(banking),]#re-code qualitative (factor) variables into numeric\nbanking$job= recode(banking$job, “‘admin.’=1;’blue-collar’=2;’entrepreneur’=3;’housemaid’=4;’management’=5;’retired’=6;’self-employed’=7;’services’=8;’student’=9;’technician’=10;’unemployed’=11;’unknown’=12”)#recode variable again\nbanking$marital = recode(banking$marital, “‘divorced’=1;’married’=2;’single’=3;’unknown’=4”)banking$education = recode(banking$education, “‘basic.4y’=1;’basic.6y’=2;’basic.9y’=3;’high.school’=4;’illiterate’=5;’professional.course’=6;’university.degree’=7;’unknown’=8”)banking$default = recode(banking$default, “‘no’=1;’yes’=2;’unknown’=3”)banking$housing = recode(banking$housing, “‘no’=1;’yes’=2;’unknown’=3”)banking$loan = recode(banking$loan, “‘no’=1;’yes’=2;’unknown’=3”)\nbanking$contact = recode(banking$loan, “‘cellular’=1;’telephone’=2;”)banking$month = recode(banking$month, “‘mar’=1;’apr’=2;’may’=3;’jun’=4;’jul’=5;’aug’=6;’sep’=7;’oct’=8;’nov’=9;’dec’=10”)banking$day_of_week = recode(banking$day_of_week, “‘mon’=1;’tue’=2;’wed’=3;’thu’=4;’fri’=5;”)banking$poutcome = recode(banking$poutcome, “‘failure’=1;’nonexistent’=2;’success’=3;”)#remove variable “pdays”, b/c it has no variation\nbanking$pdays=NULL #remove variable “pdays”, b/c itis collinear with the DV\nbanking$duration=NULL\n```", "```py\n#EDA of the DV\nplot(banking$y,main=\"Plot 1: Distribution of Dependent Variable\")\n```", "```py\n#split the dataset into training and test sets randomly \nset.seed(1)#set seed so as to generate the same value each time we run the code#create an index to split the data: 80% training and 20% test\nindex = round(nrow(banking)*0.2,digits=0)#sample randomly throughout the dataset and keep the total number equal to the value of index\ntest.indices = sample(1:nrow(banking), index)#80% training set\nbanking.train=banking[-test.indices,] #20% test set\nbanking.test=banking[test.indices,] #Select the training set except the DV\nYTrain = banking.train$y\nXTrain = banking.train %>% select(-y)# Select the test set except the DV\nYTest = banking.test$y\nXTest = banking.test %>% select(-y)\n```", "```py\nrecords = matrix(NA, nrow=5, ncol=2) \ncolnames(records) <- c(“train.error”,”test.error”)\nrownames(records) <- c(“Logistic”,”Tree”,”KNN”,”Random Forests”,”SVM”)\n```", "```py\ncalc_error_rate <- function(predicted.value, true.value)\n                    {return(mean(true.value!=predicted.value))}\n```", "```py\nglm.fit = glm(y ~ age+factor(job)+factor(marital)+factor(education)+factor(default)+factor(housing)+factor(loan)+factor(contact)+factor(month)+factor(day_of_week)+campaign+previous+factor(poutcome)+emp.var.rate+cons.price.idx+cons.conf.idx+euribor3m+nr.employed, data=banking.train, family=binomial)\n```", "```py\nprob.training = predict(glm.fit,type=”response”)banking.train_glm = banking.train %>% #select all rows of the train\n mutate(predicted.value=as.factor(ifelse(prob.training<=0.5, “no”, “yes”))) #create a new variable using mutate and set a majority rule using ifelse# get the training error\nlogit_traing_error <-  calc_error_rate(predicted.value=banking.train_glm$predicted.value,  true.value=YTrain)# get the test error of the logistic model\nprob.test = predict(glm.fit,banking.test,type=”response”)banking.test_glm = banking.test %>% # select rows\n mutate(predicted.value2=as.factor(ifelse(prob.test<=0.5, “no”, “yes”))) # set ruleslogit_test_error <- calc_error_rate(predicted.value=banking.test_glm$predicted.value2, true.value=YTest)# write down the training and test errors of the logistic model \nrecords[1,] <- c(logit_traing_error,logit_test_error)#write into the first row\n```", "```py\n# finding the best nodes\n# the total number of rows\nnobs = nrow(banking.train)#build a DT model; \n#please refer to this document (here) for constructing a DT model\nbank_tree = tree(y~., data= banking.train,na.action = na.pass,\n control = tree.control(nobs , mincut =2, minsize = 10, mindev = 1e-3))#cross validation to prune the tree\nset.seed(3)\ncv = cv.tree(bank_tree,FUN=prune.misclass, K=10)\ncv#identify the best cv\nbest.size.cv = cv$size[which.min(cv$dev)]\nbest.size.cv#best = 3bank_tree.pruned<-prune.misclass(bank_tree, best=3)\nsummary(bank_tree.pruned)\n```", "```py\n# Training and test errors of bank_tree.pruned\npred_train = predict(bank_tree.pruned, banking.train, type=”class”)\npred_test = predict(bank_tree.pruned, banking.test, type=”class”)# training error\nDT_training_error <- calc_error_rate(predicted.value=pred_train, true.value=YTrain)# test error\nDT_test_error <- calc_error_rate(predicted.value=pred_test, true.value=YTest)# write down the errors\nrecords[2,] <- c(DT_training_error,DT_test_error)\n```", "```py\nnfold = 10\nset.seed(1)# cut() divides the range into several intervals\nfolds = seq.int(nrow(banking.train)) %>%\n     cut(breaks = nfold, labels=FALSE) %>%  \n     sampledo.chunk <- function(chunkid, folddef, Xdat, Ydat, k){ \n     train = (folddef!=chunkid)# training indexXtr = Xdat[train,] # training set by the indexYtr = Ydat[train] # true label in training setXvl = Xdat[!train,] # test setYvl = Ydat[!train] # true label in test setpredYtr = knn(train = Xtr, test = Xtr, cl = Ytr, k = k) # predict training labelspredYvl = knn(train = Xtr, test = Xvl, cl = Ytr, k = k) # predict test labelsdata.frame(fold =chunkid, # k folds \ntrain.error = calc_error_rate(predYtr, Ytr),#training error per fold \n val.error = calc_error_rate(predYvl, Yvl)) # test error per fold\n }# set error.folds to save validation errors\nerror.folds=NULL# create a sequence of data with an interval of 10\nkvec = c(1, seq(10, 50, length.out=5))set.seed(1)for (j in kvec){\n tmp = ldply(1:nfold, do.chunk, # apply do.function to each fold\n folddef=folds, Xdat=XTrain, Ydat=YTrain, k=j) # required arguments\n tmp$neighbors = j # track each value of neighbors\n error.folds = rbind(error.folds, tmp) # combine the results \n }#melt() in the package reshape2 melts wide-format data into long-format data errors = melt(error.folds, id.vars=c(“fold”,”neighbors”), value.name= “error”)\n```", "```py\nval.error.means = errors %>%\n filter(variable== “val.error” ) %>%\n group_by(neighbors, variable) %>%\n summarise_each(funs(mean), error) %>%\n ungroup() %>%\n filter(error==min(error))#the best number of neighbors =20\nnumneighbor = max(val.error.means$neighbors)\nnumneighbor## [20]\n```", "```py\n#training error\nset.seed(20)\npred.YTtrain = knn(train=XTrain, test=XTrain, cl=YTrain, k=20)\nknn_traing_error <- calc_error_rate(predicted.value=pred.YTtrain, true.value=YTrain)#test error =0.095set.seed(20)\npred.YTest = knn(train=XTrain, test=XTest, cl=YTrain, k=20)\nknn_test_error <- calc_error_rate(predicted.value=pred.YTest, true.value=YTest)records[3,] <- c(knn_traing_error,knn_test_error)\n```", "```py\n# build a RF model with default settings \nset.seed(1)\nRF_banking_train = randomForest(y ~ ., data=banking.train, importance=TRUE)# predicting outcome classes using training and test sets\n\npred_train_RF = predict(RF_banking_train, banking.train, type=”class”)pred_test_RF = predict(RF_banking_train, banking.test, type=”class”)# training error\nRF_training_error <- calc_error_rate(predicted.value=pred_train_RF, true.value=YTrain)# test error\nRF_test_error <- calc_error_rate(predicted.value=pred_test_RF, true.value=YTest)records[4,] <- c(RF_training_error,RF_test_error)\n```", "```py\nset.seed(1)\ntune.out=tune(svm, y ~., data=banking.train,\nkernel=”radial”,ranges=list(cost=c(0.1,1,10)))# find the best parameters\nsummary(tune.out)$best.parameters# the best model\nbest_model = tune.out$best.modelsvm_fit=svm(y~., data=banking.train,kernel=”radial”,gamma=0.05555556,cost=1,probability=TRUE)# using training/test sets to predict outcome classes\nsvm_best_train = predict(svm_fit,banking.train,type=”class”)\nsvm_best_test = predict(svm_fit,banking.test,type=”class”)# training error\nsvm_training_error <- calc_error_rate(predicted.value=svm_best_train, true.value=YTrain)# test error\nsvm_test_error <- calc_error_rate(predicted.value=svm_best_test, true.value=YTest)records[5,] <- c(svm_training_error,svm_test_error)\n```", "```py\nrecords\n```", "```py\n# load the library\nlibrary(ROCR)#creating a tracking record\nArea_Under_the_Curve = matrix(NA, nrow=5, ncol=1)\ncolnames(Area_Under_the_Curve) <- c(“AUC”) \nrownames(Area_Under_the_Curve) <- c(“Logistic”,”Tree”,”KNN”,”Random Forests”,”SVM”)########### logistic regression ###########\n# ROC\nprob_test <- predict(glm.fit,banking.test,type=”response”)\npred_logit<- prediction(prob_test,banking.test$y)\nperformance_logit <- performance(pred_logit,measure = “tpr”, x.measure=”fpr”)########### Decision Tree ###########\n# ROC\npred_DT<-predict(bank_tree.pruned, banking.test,type=”vector”)\npred_DT <- prediction(pred_DT[,2],banking.test$y)\nperformance_DT <- performance(pred_DT,measure = “tpr”,x.measure= “fpr”)########### KNN ########### \n# ROC\nknn_model = knn(train=XTrain, test=XTrain, cl=YTrain, k=20,prob=TRUE)prob <- attr(knn_model, “prob”)\nprob <- 2*ifelse(knn_model == “-1”, prob,1-prob) — 1\npred_knn <- prediction(prob, YTrain)\nperformance_knn <- performance(pred_knn, “tpr”, “fpr”)########### Random Forests ###########\n# ROC\npred_RF<-predict(RF_banking_train, banking.test,type=”prob”)\npred_class_RF <- prediction(pred_RF[,2],banking.test$y)\nperformance_RF <- performance(pred_class_RF,measure = “tpr”,x.measure= “fpr”)########### SVM ########### \n# ROC\nsvm_fit_prob = predict(svm_fit,type=”prob”,newdata=banking.test,probability=TRUE)\nsvm_fit_prob_ROCR = prediction(attr(svm_fit_prob,”probabilities”)[,2],banking.test$y==”yes”)\nperformance_svm <- performance(svm_fit_prob_ROCR, “tpr”,”fpr”)\n```", "```py\n#logit\nplot(performance_logit,col=2,lwd=2,main=”ROC Curves for These Five Classification Methods”)legend(0.6, 0.6, c(‘logistic’, ‘Decision Tree’, ‘KNN’,’Random Forests’,’SVM’), 2:6)#decision tree\nplot(performance_DT,col=3,lwd=2,add=TRUE)#knn\nplot(performance_knn,col=4,lwd=2,add=TRUE)#RF\nplot(performance_RF,col=5,lwd=2,add=TRUE)# SVM\nplot(performance_svm,col=6,lwd=2,add=TRUE)abline(0,1)\n```", "```py\n########### Logit ########### \nauc_logit = performance(pred_logit, “auc”)@y.values\nArea_Under_the_Curve[1,] <-c(as.numeric(auc_logit))########### Decision Tree ###########\nauc_dt = performance(pred_DT,”auc”)@y.values\nArea_Under_the_Curve[2,] <- c(as.numeric(auc_dt))########### KNN ###########\nauc_knn <- performance(pred_knn,”auc”)@y.values\nArea_Under_the_Curve[3,] <- c(as.numeric(auc_knn))########### Random Forests ###########\nauc_RF = performance(pred_class_RF,”auc”)@y.values\nArea_Under_the_Curve[4,] <- c(as.numeric(auc_RF))########### SVM ########### \nauc_svm<-performance(svm_fit_prob_ROCR,”auc”)@y.values[[1]]\nArea_Under_the_Curve[5,] <- c(as.numeric(auc_svm))\n```", "```py\nArea_Under_the_Curve\n```"]