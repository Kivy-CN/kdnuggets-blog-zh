- en: 'Graduating in GANs: Going From Understanding Generative Adversarial Networks
    to Running Your Own'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 毕业于 GAN：从理解生成对抗网络到运行自己的网络
- en: 原文：[https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2](https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2](https://www.kdnuggets.com/2019/04/graduating-gans-understanding-generative-adversarial-networks.html/2)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2019/04/graduating-gans-understanding-generative-adversarial-networks.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/04/graduating-gans-understanding-generative-adversarial-networks.html?page=2#comments)'
- en: Inception Score
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Inception Score
- en: Invented in Salimans et al. 2016 in ‘[Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)’,
    the Inception Score is based on a heuristic that realistic samples should be able
    to be classified when passed through a pre-trained network, such as Inception
    on ImageNet. Technically, this means that the sample should have a low entropy
    softmax prediction vector.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 发明于 Salimans 等人 2016 年的 ‘[改进的 GAN 训练技术](https://arxiv.org/abs/1606.03498)’，Inception
    Score 基于一个启发式方法，即真实的样本在通过预训练网络（如 ImageNet 上的 Inception）时应能够被分类。技术上，这意味着样本的熵软最大化预测向量应该较低。
- en: Besides high predictability (low entropy), the Inception Score also evaluates
    a GAN based on how diverse the generated samples are (e.g. high variance or entropy
    over the distribution of generated samples). This means that there should not
    be any dominating classes.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 除了高可预测性（低熵）外，Inception Score 还根据生成样本的多样性来评估生成对抗网络（GAN）（例如，生成样本分布的方差或熵）。这意味着不应存在任何主导类别。
- en: If both these traits are satisfied, there should be a large Inception Score.
    The way that you combine the two criteria is by evaluating the Kullback-Leibler
    (KL) divergence between the conditional label distribution of samples and the
    marginal distribution from all the samples.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果满足这两个特性，那么应该会有一个较大的 Inception Score。结合这两个标准的方法是通过评估样本的条件标签分布与所有样本的边际分布之间的
    Kullback-Leibler（KL）散度来实现的。
- en: Fréchet Inception Distance
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Fréchet Inception Distance
- en: Introduced by [Heusel et al. 2017](https://arxiv.org/abs/1706.08500), FID estimates
    realism by measuring the distance between the generated distribution of images
    and the true distribution. FID embeds a set of generated samples into a feature
    space given by a specific layer of Inception Net. This embedding layer is viewed
    as as a continuous multivariate Gaussian, then the mean and covariance are estimated
    for both the generated data and the real data. The Fréchet distance between these
    two Gaussians (a.k.a Wasserstein-2 distance) is then used to quantify the quality
    of generated samples. A lower FID corresponds to more similar real and generated
    samples.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Heusel 等人 2017](https://arxiv.org/abs/1706.08500) 提出的 FID 通过测量生成图像分布与真实分布之间的距离来估计现实性。FID
    将一组生成样本嵌入到由 Inception Net 的特定层给出的特征空间中。这个嵌入层被视为一个连续的多元高斯分布，然后为生成数据和真实数据估计均值和协方差。这两个高斯分布（也称为
    Wasserstein-2 距离）之间的 Fréchet 距离用于量化生成样本的质量。较低的 FID 表示真实样本和生成样本更相似。
- en: An important note is that FID needs a decent sample size to give good results
    (suggested size = 50k samples ). If you use too few samples, you will end up over-estimating
    your actual FID and the estimates will have a large variance.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的注意事项是，FID 需要足够的样本量才能给出良好的结果（建议样本量 = 50k 样本）。如果样本过少，你将会高估实际 FID，估计值的方差也会很大。
- en: For a comparison of how Inception Scores and FID scores have differed across
    papers, see Neal Jean’s post [here](https://nealjean.com/ml/frechet-inception-distance/).
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 要查看 Inception Scores 和 FID 分数在不同论文中的差异，请参阅 Neal Jean 的帖子 [这里](https://nealjean.com/ml/frechet-inception-distance/)。
- en: Want to see more?
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要查看更多？
- en: 'Aji Borji’s paper, ‘[Pros and Cons of GAN Evaluation Measures](http://Pros%20and%20Cons%20of%20GAN%20Evaluation%20Measures)’
    includes an excellent table with more exhaustive coverage of GAN evaluation metrics:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Aji Borji 的论文 ‘[GAN 评估度量的优缺点](http://Pros%20and%20Cons%20of%20GAN%20Evaluation%20Measures)’
    包含了一张包含更全面 GAN 评估度量的优秀表格：
- en: '![gan-evaluation-metrics](../Images/9bed7abab406224cd9e80f00edf9ca18.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![gan-evaluation-metrics](../Images/9bed7abab406224cd9e80f00edf9ca18.png)'
- en: '**Interestingly, other researchers are taking different approaches by using
    domain-specific evaluation metrics.** For text GANs, Guy Tevet and his team proposed
    using traditional probability-based language model metrics to evaluate the distribution
    of text generated by a GAN in their paper ‘[Evaluating Text GANs as Language Models](https://arxiv.org/abs/1810.12686)’.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**有趣的是，其他研究者正在通过使用特定领域的评估指标来采取不同的方法。** 对于文本GAN，Guy Tevet及其团队在他们的论文‘[Evaluating
    Text GANs as Language Models](https://arxiv.org/abs/1810.12686)’中提出使用传统的基于概率的语言模型指标来评估GAN生成的文本的分布。'
- en: In ‘[How good is my GAN?](https://arxiv.org/abs/1807.09499)’, Konstantin Shmelkov
    and his team use two measures based on image classification, GAN-train and GAN-test,
    which approximate the recall (diversity) and precision (quality of the image)
    of GANs respectively. You can see these evaluation metrics in action in the Google
    Brain research paper, ‘[Are GANS created equal](https://arxiv.org/abs/1711.10337)’,
    where they used a dataset of triangles to measure the precision and the recall
    of different GAN models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在‘[How good is my GAN?](https://arxiv.org/abs/1807.09499)’中，Konstantin Shmelkov及其团队使用了基于图像分类的两个度量，GAN-train和GAN-test，分别近似GAN的召回率（多样性）和精确度（图像质量）。你可以在Google
    Brain的研究论文‘[Are GANs created equal](https://arxiv.org/abs/1711.10337)’中看到这些评估指标的实际应用，他们使用了一个三角形数据集来测量不同GAN模型的精确度和召回率。
- en: '![figure-name](../Images/40d228fcf571b101b154fe25f0a2a047.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/40d228fcf571b101b154fe25f0a2a047.png)'
- en: Running your own GAN
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行你自己的GAN
- en: To illustrate GANs, we’ll be adapting [this excellent tutorial](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/)
    from Wouter Bulten that uses Keras and the MNIST dataset to generate written digits.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明GAN，我们将采用[这个优秀的教程](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/)，该教程使用Keras和MNIST数据集生成手写数字。
- en: See the full tutorial notebook [here](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完整的教程笔记本 [这里](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6)。
- en: '![figure-name](../Images/8e6ad138242a7689b6244e6831462044.png)We’ll be tracking
    our GAN’s progress by visualizing our loss and accuracy curves but also by checking
    test outputs using [Comet.ml](http://bit.ly/2WGduCM)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/8e6ad138242a7689b6244e6831462044.png)我们将通过可视化我们的损失和准确率曲线来跟踪GAN的进展，同时通过[Comet.ml](http://bit.ly/2WGduCM)检查测试输出。'
- en: 'This GAN model takes in the MNIST training data and random noise as an input
    (specifically, random vectors of noise) to generate:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个GAN模型将MNIST训练数据和随机噪声作为输入（具体来说，是随机噪声向量）来生成：
- en: images (in this case, image of handwritten digits). *Eventually, these generated
    images will resemble the data distribution of the MNIST dataset.*
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像（在这种情况下，是手写数字的图像）。*最终，这些生成的图像将类似于MNIST数据集的数据分布。*
- en: the discriminator’s prediction on the generated images
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器对生成图像的预测
- en: The **Generator** and **Discriminator** models together form the adversarial
    model — for this example, the generator will perform well if the adversarial model
    serves an output classifying the generated images as real for all inputs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成器**和**判别器**模型共同构成了对抗模型——在这个例子中，如果对抗模型将生成的图像分类为真实，那么生成器将表现良好。'
- en: See the full code [here](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6)
    and the full Comet Experiment with results [here](https://www.comet.ml/ceceshao1/mnist-gan)
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 查看完整代码 [这里](https://gist.github.com/ceceshao1/935ea6000c8509a28130d4c55b32fcd6)
    和完整的Comet实验结果 [这里](https://www.comet.ml/ceceshao1/mnist-gan)
- en: Tracking your model’s progress
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跟踪模型的进展
- en: We’re able to track the training progress for both our **Generator** and **Discriminator**
    models using [Comet.ml](http://bit.ly/2WGduCM).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够通过[Comet.ml](http://bit.ly/2WGduCM)跟踪我们**生成器**和**判别器**模型的训练进展。
- en: 'We’re plotting both the accuracy and loss for our discriminator and adversarial
    models — the most important metrics to track here are:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们绘制了判别器和对抗模型的准确率和损失——这里最重要的指标是：
- en: the discriminator’s loss (see blue line on the right chart)— *dis_loss*
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器的损失（见右侧图表中的蓝线）——*dis_loss*
- en: the adversarial model’s accuracy (see blue line on the left chart) — *acc_adv*
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对抗模型的准确率（见左侧图表中的蓝线）——*acc_adv*
- en: '**See the training progression for this experiment** [**here**](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/chart)**.**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**查看此实验的训练进展** [**这里**](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/chart)**。**'
- en: '![comet.ml](../Images/5bec2780460c28d933adb6f423a0cdca.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![comet.ml](../Images/5bec2780460c28d933adb6f423a0cdca.png)'
- en: You also want to confirm that your training process is actually using GPUs,
    which you can check in [the Comet System Metrics tab](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/systemMetrics).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要确认你的训练过程实际上在使用GPU，你可以在[Comet系统指标选项卡](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/systemMetrics)中检查这一点。
- en: '![comet-ml-metrics](../Images/ae2c79999a6b58beabcd2ba493254f4e.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![comet-ml-metrics](../Images/ae2c79999a6b58beabcd2ba493254f4e.png)'
- en: 'You notice that our training for-loop includes code to report images from the
    test vector:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到我们的训练循环包括报告测试向量图像的代码：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Part of the reason why we want to report generated output every few steps is
    so that we can visually analyze how our generator and discriminator models are
    performing in terms of generating realistic handwritten digits and correctly classifying
    the generated digits as ‘real’ or ‘fake, respectively.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们每隔几个步骤报告生成的输出部分原因是为了便于我们视觉上分析生成器和判别器模型在生成逼真的手写数字和正确分类生成的数字（分别为‘真实’或‘虚假’）方面的表现。
- en: Let’s take a look at these generated outputs!
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 让我们来看看这些生成的输出！
- en: See the generated outputs on your own in [this Comet Experiment](https://www.comet.ml/ceceshao1/mnist-gan)
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在[这个Comet实验](https://www.comet.ml/ceceshao1/mnist-gan)中查看生成的输出
- en: You can see how the Generator models starts off with this fuzzy, grayish output
    (see 0.png below)that doesn’t really look like the handwritten digits we expect.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到生成器模型开始时输出的是模糊的灰色图像（见下图0.png），看起来并不像我们预期的手写数字。
- en: '![figure-name](../Images/bfd48dfdbc0df6119f3796a3aa78d990.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/bfd48dfdbc0df6119f3796a3aa78d990.png)'
- en: 'As training progresses and our models’ losses decline, the generated digits
    become clearer and clear. Check out the generated outputs at:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 随着训练的进展和模型损失的下降，生成的数字变得越来越清晰。查看生成的输出：
- en: '**Step 500:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**第500步：**'
- en: '![/gan-generated-model-step500](../Images/a20a84c9f5cc70f38fa59c038f0416a4.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![/gan-generated-model-step500](../Images/a20a84c9f5cc70f38fa59c038f0416a4.png)'
- en: '**Step 1000:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**第1000步：**'
- en: '![gan-generated-model-step1000](../Images/c587d867da942c19e25c4bb42760a442.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![gan-generated-model-step1000](../Images/c587d867da942c19e25c4bb42760a442.png)'
- en: '**Step 1500:**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**第1500步：**'
- en: '![gan-generated-model-step1500](../Images/c8926b4f60d178941d027fa1fb909afc.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![gan-generated-model-step1500](../Images/c8926b4f60d178941d027fa1fb909afc.png)'
- en: And finally at **Step 10,000 — **you can see some samples of the GAN-generated
    digits in the red outlined boxes below
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最终在**第10,000步**——你可以看到下面红色轮廓框中的一些GAN生成的数字样本
- en: '![figure-name](../Images/8140571c3f508b590341ba0587a5fe66.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/8140571c3f508b590341ba0587a5fe66.png)'
- en: Once our GAN model is done training, we can even review our reported outputs
    as a movie in [Comet’s Graphics tab](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/images)
    (just press the play button!).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的GAN模型训练完成，我们甚至可以在[Comet的图形选项卡](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/images)中查看我们报告的输出作为一部电影（只需按播放按钮！）。
- en: '![figure-name](../Images/7e655afefb6f4bc95d4903258e70baf2.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/7e655afefb6f4bc95d4903258e70baf2.png)'
- en: To complete the experiment, make you sure run `experiment.end()` to see some
    summary statistics around the model and GPU usage.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了完成实验，请确保运行`experiment.end()`以查看有关模型和GPU使用的一些总结统计数据。
- en: '![figure-name](../Images/76b77f6a519c53762080bd8fff0cdf72.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/76b77f6a519c53762080bd8fff0cdf72.png)'
- en: Iterating with your model
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用你的模型进行迭代
- en: We could train the model longer to see how that impacts performance, but let’s
    try iterating with a few different parameters.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将模型训练得更久，看看这对性能的影响，但我们可以尝试使用几个不同的参数进行迭代。
- en: 'Some of the parameters we play around with are:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试的一些参数包括：
- en: the discriminator’s optimizer
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 判别器的优化器
- en: the learning rate
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习率
- en: dropout probability
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: dropout概率
- en: batch size
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批量大小
- en: 'From Wouter’s [original blog post](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/),
    he mentions his own efforts with testing parameters:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 从Wouter的[原始博客文章](https://www.wouterbulten.nl/blog/tech/getting-started-with-generative-adversarial-networks/)中，他提到他在测试参数时的努力：
- en: I have tested both `SGD`, `RMSprop` and `Adam` for the optimizer of the discriminator
    but `RMSprop` performed best. `RMSprop` is used a low learning rate and I clip
    the values between -1 and 1\. A small decay in the learning rate can help with
    stabilizing
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我测试了`SGD`、`RMSprop`和`Adam`作为判别器的优化器，但`RMSprop`表现最佳。`RMSprop`使用了较低的学习率，并且我将值剪裁在-1和1之间。学习率的小幅衰减可以帮助稳定训练过程。
- en: We’ll try increasing the discriminator’s dropout probability from 0.4 to 0.5
    and increasing both the discriminator’s learning rate (from 0.008 to 0.0009) and
    the generator’s learning rate (from 0.0004 to 0.0006). Easy to see how these changes
    can get out of hand and difficult to track…????
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试将判别器的丢弃概率从 0.4 提高到 0.5，同时将判别器的学习率（从 0.008 提高到 0.0009）和生成器的学习率（从 0.0004
    提高到 0.0006）也提高。很容易看出这些变化可能失控且难以跟踪…????
- en: 'To create a different experiment, simply run the experiment definition cell
    again and [Comet](http://www.comet.ml) will issue you a new url for your new experiment!
    It’s nice to keep track of your experiments, so you can compare the differences:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建不同的实验，只需再次运行实验定义单元，[Comet](http://www.comet.ml) 将为你的新实验发出一个新的网址！跟踪你的实验很有用，这样你可以比较不同之处：
- en: '![figure-name](../Images/4be1d8f6090453b6919dd766cacf90fb.png)[See the difference](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/e7cdcbf789674be6af8d9c7cfade1922/compare?experiment-tab=params)
    between the two experiments’ hyperparameters. Can you spot the differences in
    learning rate and dropout probability that we made?'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '![figure-name](../Images/4be1d8f6090453b6919dd766cacf90fb.png)[查看两个实验超参数之间的差异](https://www.comet.ml/ceceshao1/mnist-gan/cf310adacd724bf280323e2eef92d1cd/e7cdcbf789674be6af8d9c7cfade1922/compare?experiment-tab=params)。你能找到我们在学习率和丢弃概率方面做出的差异吗？'
- en: 'Unfortunately, our adjustments did not improve the model’s performance! In
    fact, it generated some funky outputs:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，我们的调整并没有改善模型的表现！实际上，它生成了一些奇怪的输出：
- en: '![figure-name](../Images/d609c27ab35a28346a6de8f5e5a34525.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![figure-name](../Images/d609c27ab35a28346a6de8f5e5a34525.png)'
- en: That’s it for this tutorial! If you enjoyed this post, feel free to share with
    a friend who might find it useful ????
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程到此为止！如果你喜欢这篇文章，请随时分享给可能觉得有用的朋友????
- en: '**Bio: [Cecilia Shao](https://www.linkedin.com/in/ceceliashao/)** is heading
    Product Growth at [comet.ml](https://www.comet.ml/).'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Cecilia Shao](https://www.linkedin.com/in/ceceliashao/)** 负责 [comet.ml](https://www.comet.ml/)
    的产品增长。'
- en: '[Original](https://towardsdatascience.com/graduating-in-gans-going-from-understanding-generative-adversarial-networks-to-running-your-own-39804c283399).
    Reposted with permission.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/graduating-in-gans-going-from-understanding-generative-adversarial-networks-to-running-your-own-39804c283399)。转载经许可。'
- en: '**Related:**'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[MNIST Generative Adversarial Model in Keras](/2016/07/mnist-generative-adversarial-model-keras.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Keras 中的 MNIST 生成对抗模型](/2016/07/mnist-generative-adversarial-model-keras.html)'
- en: '[GANs in TensorFlow from the Command Line: Creating Your First GitHub Project](/2018/05/zimbres-first-github-project-gans.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在命令行中使用 TensorFlow 创建你的第一个 GitHub 项目](/2018/05/zimbres-first-github-project-gans.html)'
- en: '[Building a Basic Keras Neural Network Sequential Model](/2018/06/basic-keras-neural-network-sequential-model.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[构建一个基本的 Keras 神经网络顺序模型](/2018/06/basic-keras-neural-network-sequential-model.html)'
- en: '* * *'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[How to Stay on Top of What''s Going on in the AI World](https://www.kdnuggets.com/2022/03/stay-top-going-ai-world.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何掌握 AI 世界的最新动态](https://www.kdnuggets.com/2022/03/stay-top-going-ai-world.html)'
- en: '[Sentiment Analysis in Python: Going Beyond Bag of Words](https://www.kdnuggets.com/sentiment-analysis-in-python-going-beyond-bag-of-words)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 中的情感分析：超越词袋模型](https://www.kdnuggets.com/sentiment-analysis-in-python-going-beyond-bag-of-words)'
- en: '[LangChain 101: Build Your Own GPT-Powered Applications](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LangChain 101：构建你自己的 GPT 驱动应用程序](https://www.kdnuggets.com/2023/04/langchain-101-build-gptpowered-applications.html)'
- en: '[Build Your Own PandasAI with LlamaIndex](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 LlamaIndex 构建你自己的 PandasAI](https://www.kdnuggets.com/build-your-own-pandasai-with-llamaindex)'
- en: '[Make Your Own GPTs with ChatGPT''s GPTs!](https://www.kdnuggets.com/make-your-own-gpts-with-chatgpts-gpts)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 ChatGPT 的 GPTs 创建属于你自己的 GPTs！](https://www.kdnuggets.com/make-your-own-gpts-with-chatgpts-gpts)'
- en: '[What is Adversarial Machine Learning?](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是对抗性机器学习？](https://www.kdnuggets.com/2022/03/adversarial-machine-learning.html)'
