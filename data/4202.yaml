- en: Parallelizing Python Code
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 并行化 Python 代码
- en: 原文：[https://www.kdnuggets.com/2021/10/parallelizing-python-code.html](https://www.kdnuggets.com/2021/10/parallelizing-python-code.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/parallelizing-python-code.html](https://www.kdnuggets.com/2021/10/parallelizing-python-code.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Dawid Borycki](https://www.linkedin.com/in/dawidborycki/), Biomedical
    Researcher and Software Engineer & [Michael Galarnyk](https://www.linkedin.com/in/michaelgalarnyk/),
    Data Science Professional**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Dawid Borycki](https://www.linkedin.com/in/dawidborycki/)，生物医学研究员和软件工程师
    & [Michael Galarnyk](https://www.linkedin.com/in/michaelgalarnyk/)，数据科学专家**'
- en: Python is great for tasks like training machine learning models, performing
    numerical simulations, and quickly developing proof-of-concept solutions without
    setting up development tools and installing several dependencies. When performing
    these tasks, you also want to use your underlying hardware as much as possible
    for quick results. Parallelizing Python code enables this. However, using the
    standard CPython implementation means you cannot fully use the underlying hardware
    because of the global interpreter lock (GIL) that prevents running the bytecode
    from multiple threads simultaneously.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Python 非常适合用于训练机器学习模型、执行数值模拟和快速开发概念验证解决方案，而无需设置开发工具和安装多个依赖项。在执行这些任务时，你还希望尽可能多地使用底层硬件以获得快速结果。并行化
    Python 代码可以实现这一点。然而，使用标准 CPython 实现意味着你无法充分利用底层硬件，因为全局解释器锁（GIL）阻止了字节码在多个线程中同时运行。
- en: 'This article reviews some common options for parallelizing Python code including:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本文回顾了几种常见的并行化 Python 代码的选项，包括：
- en: '[Process-based parallelism](https://docs.python.org/3/library/multiprocessing.html)'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[基于进程的并行处理](https://docs.python.org/3/library/multiprocessing.html)'
- en: Specialized libraries
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专门的库
- en: '[IPython Parallel](https://ipython.readthedocs.io/en/stable/)'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[IPython Parallel](https://ipython.readthedocs.io/en/stable/)'
- en: '[Ray](https://docs.ray.io/en/master/)'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Ray](https://docs.ray.io/en/master/)'
- en: For each technique, this article lists some advantages and disadvantages and
    shows a code sample to help you understand what it’s like to use.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每种技术，本文列出了一些优点和缺点，并展示了代码示例，帮助你理解使用它的感觉。
- en: How to Parallelize Python Code
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何并行化 Python 代码
- en: There are several common ways to parallelize Python code. You can launch several
    application instances or a script to perform jobs in parallel. This approach is
    great when you don’t need to exchange data between parallel jobs. Otherwise, sharing
    data between processes significantly reduces performance when aggregating data.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化 Python 代码有几种常见的方法。你可以启动多个应用程序实例或脚本以并行执行作业。这种方法非常适合当你不需要在并行作业之间交换数据时。否则，在进程之间共享数据会显著降低性能，特别是在汇总数据时。
- en: Starting multiple threads within the same process allows you to share data between
    jobs more efficiently. In this case, thread-based parallelization can offload
    some work to the background. However, the standard CPython implementation’s global
    interpreter lock (GIL) prevents running the bytecode in multiple threads simultaneously.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一进程内启动多个线程可以更有效地在作业之间共享数据。在这种情况下，基于线程的并行化可以将一些工作卸载到后台。然而，标准 CPython 实现的全局解释器锁（GIL）阻止了字节码在多个线程中同时运行。
- en: The sample function below simulates complex calculations (meant to mimic activation
    functions)
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例函数模拟复杂计算（旨在模仿激活函数）
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`complex_operation` executes several times to better estimate the processing
    time. It divides the long-running operation into a batch of smaller ones. It does
    this by dividing the input values into several subsets and then processing the
    inputs from those subsets in parallel.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`complex_operation` 执行多次以更好地估计处理时间。它将长时间运行的操作分成一批较小的操作。它通过将输入值划分为多个子集，并从这些子集中并行处理输入来实现这一点。'
- en: 'Here’s the code that runs `complex_operation` several times (input range of
    ten) and measures the execution time with the timebudget package:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是运行 `complex_operation` 多次（输入范围为十）的代码，并使用 timebudget 包测量执行时间：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After executing [this script](https://gist.github.com/mGalarnyk/8c491fbdfe6ce3e498a7f62f03fa9ca4),
    you will get an output similar to the one below:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 [这个脚本](https://gist.github.com/mGalarnyk/8c491fbdfe6ce3e498a7f62f03fa9ca4)后，你将获得类似于下面的输出：
- en: '![parallelizing blog 1](../Images/556b374ed5ce8fe0d936731ac27c8969.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 1](../Images/556b374ed5ce8fe0d936731ac27c8969.png)'
- en: As you can see, it took about 39 seconds to execute this code on the laptop
    used in this tutorial. Let’s see how to improve this result.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在本教程中使用的笔记本电脑上执行此代码大约花费了 39 秒。让我们看看如何改进这个结果。
- en: Process-Based Parallelism
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于进程的并行ism
- en: The first approach is to use process-based parallelism. With this approach,
    it is possible to start several processes at the same time (concurrently). This
    way, they can concurrently perform calculations.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种方法是使用基于进程的并行ism。通过这种方法，可以同时启动多个进程。这种方式可以使它们并行地执行计算。
- en: Starting from Python 3, the[ multiprocessing package](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing) is
    preinstalled and gives us a convenient syntax for launching concurrent processes.
    It provides the Pool object, which automatically divides input into subsets and
    distributes them among many processes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Python 3 开始，[multiprocessing 包](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing) 已经预装，并且为我们提供了启动并发进程的便捷语法。它提供了
    Pool 对象，该对象自动将输入划分为子集，并在多个进程中分配它们。
- en: '[Here is an example](https://gist.github.com/mGalarnyk/b5455b0454815b04363ef9994f22fbf3) of
    how to use a Pool object to launch ten processes:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[这是一个示例](https://gist.github.com/mGalarnyk/b5455b0454815b04363ef9994f22fbf3) 展示了如何使用
    Pool 对象启动十个进程：'
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[Code sample](https://gist.github.com/mGalarnyk/b5455b0454815b04363ef9994f22fbf3)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[代码示例](https://gist.github.com/mGalarnyk/b5455b0454815b04363ef9994f22fbf3)'
- en: Each process concurrently performs the complex operation. So, the code could
    theoretically reduce the total execution time by up to ten times. However, the
    output from the code below only shows about a fourfold improvement (39 seconds
    in the previous section vs 9.4 in this section).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 每个进程并行执行复杂的操作。因此，理论上代码可以将总执行时间减少最多十倍。然而，下面的代码输出仅显示了大约四倍的改进（上一节的39秒 vs 本节的9.4秒）。
- en: '![parallelizing blog 2](../Images/586ee96a1d06dc9d5c7323aed2b130ef.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![parallelizing blog 2](../Images/586ee96a1d06dc9d5c7323aed2b130ef.png)'
- en: There are a couple reasons why the improvement is not tenfold. First, the maximum
    number of processes that can run concurrently depends on the the number of CPUs
    in the system. You can find out how many CPUs your system has by using the `os.cpu_count()` method.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 改进效果没有达到十倍的原因有几个。首先，能够同时运行的最大进程数取决于系统中的 CPU 数量。你可以通过使用`os.cpu_count()`方法来查看系统中的
    CPU 数量。
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure](../Images/e533ca816283748e2fbec835c8a9607d.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/e533ca816283748e2fbec835c8a9607d.png)'
- en: The machine used in this tutorial has eight CPUs
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程中使用的机器有八个 CPU。
- en: The next reason why the improvement is not more is that the computations in
    this tutorial are relatively small. Finally, it is important to note that there
    is usually some overhead when parallelizing computation as processes that want
    to communicate must utilize [interprocess communication mechanisms](https://en.wikipedia.org/wiki/Inter-process_communication).
    This means that for very small tasks parallelizing computation is often slower
    than serial computation (normal Python). If you are interested in learning more
    about multiprocessing, Selva Prabhakaran has an [excellent blog](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray) which
    inspired this section of the tutorial. If you would like to learn about some more
    of the trade-offs in parallel/distributed computing, [check out this tutorial](https://towardsdatascience.com/writing-your-first-distributed-python-application-with-ray-4248ebc07f41).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 改进效果没有更好的原因是，本教程中的计算相对较小。最后，需要注意的是，进行并行计算时通常会有一些开销，因为需要通信的进程必须利用[进程间通信机制](https://en.wikipedia.org/wiki/Inter-process_communication)。这意味着对于非常小的任务，并行计算往往比串行计算（普通
    Python）要慢。如果你对了解更多关于 multiprocessing 的内容感兴趣，Selva Prabhakaran 有一篇[优秀的博客](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray) ，这篇博客启发了本教程的这一部分。如果你想了解更多关于并行/分布式计算的权衡，[可以查看这个教程](https://towardsdatascience.com/writing-your-first-distributed-python-application-with-ray-4248ebc07f41)。
- en: '![parallelizing blog 4](../Images/0950f9777fafefce27b2135f25e3ebea.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![parallelizing blog 4](../Images/0950f9777fafefce27b2135f25e3ebea.png)'
- en: Specialized Libraries
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 专用库
- en: '[Many calculations for specialized libraries like NumPy are unaffected by the
    GIL](https://stackoverflow.com/questions/36479159/why-are-numpy-calculations-not-affected-by-the-global-interpreter-lock) and
    can use threads and other techniques to work in parallel. This section of the
    tutorial goes over the benefits of combining NumPy and multiprocessing'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[像 NumPy 这样的专用库的许多计算不受 GIL 影响](https://stackoverflow.com/questions/36479159/why-are-numpy-calculations-not-affected-by-the-global-interpreter-lock) ，能够使用线程和其他技术进行并行计算。本教程的这一部分讲解了结合
    NumPy 和 multiprocessing 的好处。'
- en: 'To demonstrate the differences between the naïve implementation and the NumPy-based
    implementation, an additional function needs to be implemented:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示原始实现和基于 NumPy 的实现之间的差异，需要实现一个额外的函数：
- en: '[PRE4]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The code now uses the NumPy exp and sinh functions to perform calculations
    on the input sequence. Then, the code executes complex_operation and complex_operation_numpy
    ten times using the processes pool to compare their performance:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 代码现在使用 NumPy 的 exp 和 sinh 函数对输入序列进行计算。然后，代码使用进程池执行 complex_operation 和 complex_operation_numpy
    十次，以比较它们的性能：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The output below shows the performance with and without NumPy for [this script](https://gist.github.com/mGalarnyk/703c53bb98aa94d66bb6c49d48ce5c09).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示了使用和不使用 NumPy 的性能对比，针对 [这个脚本](https://gist.github.com/mGalarnyk/703c53bb98aa94d66bb6c49d48ce5c09)。
- en: '![parallelizing blog 5](../Images/674158bdcd5d5338901af10c077dfd72.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 5](../Images/674158bdcd5d5338901af10c077dfd72.png)'
- en: NumPy offers a rapid boost in performance. Here, NumPy reduced the computation
    time to about 10 percent of the original time (859ms vs 9.515sec). One reason
    why it is faster is because most processing in NumPy is vectorized. With vectorization,
    the underlying code is effectively “parallelized” because the operation can calculate
    multiple array elements at once, rather than looping through them one at a time.
    If you are interested in learning more about this, Jake Vanderplas gave an excellent
    talk on the subject [here](https://youtu.be/EEUXKG97YRw?t=613).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: NumPy 提供了显著的性能提升。在这里，NumPy 将计算时间减少到原始时间的大约 10%（859ms 对比 9.515秒）。它更快的原因之一是因为
    NumPy 中的大部分处理都是向量化的。通过向量化，底层代码有效地被“并行化”，因为操作可以一次计算多个数组元素，而不是逐一循环处理。如果你对了解更多内容感兴趣，Jake
    Vanderplas 进行了一次很好的讲座，[可以在这里](https://youtu.be/EEUXKG97YRw?t=613)观看。
- en: '![parallelizing blog 6](../Images/5202adfec876af490cac38a2ffebf8a9.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 6](../Images/5202adfec876af490cac38a2ffebf8a9.png)'
- en: IPython Parallel
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IPython Parallel
- en: The IPython shell supports interactive parallel and distributed computing across
    multiple IPython instances. IPython Parallel was developed (almost) together with
    IPython.  When IPython was renamed to Jupyter, they split out IPython Parallel
    into its own package. [IPython Parallel](https://ipython.org/ipython-doc/3/parallel/parallel_intro.html) has
    a number of advantages, but perhaps the biggest advantage is that it enables parallel
    applications to be developed, executed, and monitored interactively. When using
    IPython Parallel for parallel computing, you typically start with the ipcluster
    command.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: IPython shell 支持在多个 IPython 实例之间进行交互式并行和分布式计算。IPython Parallel 几乎是与 IPython
    一起开发的。当 IPython 被更名为 Jupyter 时，它们将 IPython Parallel 分离成了一个独立的包。[IPython Parallel](https://ipython.org/ipython-doc/3/parallel/parallel_intro.html)
    有许多优势，但也许最大的优势是它使得并行应用程序可以以交互的方式开发、执行和监控。在使用 IPython Parallel 进行并行计算时，你通常会从 ipcluster
    命令开始。
- en: '[PRE6]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The last parameter controls the number of engines (nodes) to launch. The command
    above becomes available after [installing the ipyparallel Python package](https://ipyparallel.readthedocs.io/en/latest/).
    Below is a sample output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的参数控制要启动的引擎（节点）数量。上述命令在 [安装 ipyparallel Python 包](https://ipyparallel.readthedocs.io/en/latest/)后变得可用。以下是一个示例输出：
- en: '![parallelizing blog 7](../Images/49b3a897c2a925662927af084c4d024c.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 7](../Images/49b3a897c2a925662927af084c4d024c.png)'
- en: 'The next step is to provide Python code that should connect to ipcluster and
    start parallel jobs. Fortunately, IPython provides a convenient API for doing
    this. The code looks like process-based parallelism based on the Pool object:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是提供应该连接到 ipcluster 并启动并行作业的 Python 代码。幸运的是，IPython 提供了一个方便的 API 来实现这一点。代码看起来像是基于
    Pool 对象的进程并行：
- en: '[PRE7]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[Code sample](https://gist.github.com/mGalarnyk/6dab23cc6485f145d2b148fc64d34b3c)'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[代码示例](https://gist.github.com/mGalarnyk/6dab23cc6485f145d2b148fc64d34b3c)'
- en: 'The code above executed in a new tab in the terminal produces the output shown
    below:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端中新标签页中执行的代码生成了如下输出：
- en: '![parallelizing blog 8](../Images/e475926323d5f6e832d388f481c8efc1.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 8](../Images/e475926323d5f6e832d388f481c8efc1.png)'
- en: The execution times with and without NumPy for IPython Parallel are 13.88 ms
    and 9.98 ms, respectively. Note, there are no logs included in the standard output,
    however they can be assessed with additional commands.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 IPython Parallel，使用和不使用 NumPy 的执行时间分别为 13.88 毫秒和 9.98 毫秒。注意，标准输出中没有包含日志，但可以通过额外的命令进行评估。
- en: '![parallelizing blog 9](../Images/433106b430695e82862e568760b0396d.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![并行化博客 9](../Images/433106b430695e82862e568760b0396d.png)'
- en: Ray
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Ray
- en: Like IPython Parallel, [Ray](https://docs.ray.io/en/master/index.html) can be
    used for parallel **and** distributed computing. Ray is a fast, simple distributed
    execution framework that makes it easy to scale your applications and to leverage
    state of the art machine learning libraries. Using Ray, you can take Python code
    that runs sequentially and transform it into a distributed application with minimal
    code changes.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 IPython Parallel，[Ray](https://docs.ray.io/en/master/index.html) 可以用于并行
    **和** 分布式计算。Ray 是一个快速、简单的分布式执行框架，使得扩展应用程序和利用最先进的机器学习库变得容易。使用 Ray，你可以将顺序运行的 Python
    代码转化为分布式应用程序，代码修改最小。
- en: '![Figure](../Images/8e1afe4eff7de3591f54c705e0083009.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/8e1afe4eff7de3591f54c705e0083009.png)'
- en: While this tutorial briefly goes over how Ray makes it easy to parallelize plain
    Python code, it is important to note that Ray and its ecosystem also make it easy
    to parallelize existing libraries like [scikit-learn](https://medium.com/distributed-computing-with-ray/how-to-speed-up-scikit-learn-model-training-aaf17e2d1e1), [XGBoost](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray), [LightGBM](https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray), [PyTorch](https://medium.com/pytorch/getting-started-with-distributed-machine-learning-with-pytorch-and-ray-fd83c98fdead),
    and much more.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个教程简要讲解了 Ray 如何简化普通 Python 代码的并行化，但值得注意的是，Ray 及其生态系统也使得并行化现有库变得容易，如 [scikit-learn](https://medium.com/distributed-computing-with-ray/how-to-speed-up-scikit-learn-model-training-aaf17e2d1e1)、[XGBoost](https://www.anyscale.com/blog/distributed-xgboost-training-with-ray)、[LightGBM](https://www.anyscale.com/blog/introducing-distributed-lightgbm-training-with-ray)、[PyTorch](https://medium.com/pytorch/getting-started-with-distributed-machine-learning-with-pytorch-and-ray-fd83c98fdead)
    等等。
- en: To use Ray, ray.init() is needed to start all of the relevant Ray processes.
    By default, Ray creates one worker process per CPU core. If you would want to
    run Ray on a cluster, you would need to pass in a cluster address with something
    like ray.init(address='insertAddressHere').
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Ray 时，需要 ray.init() 来启动所有相关的 Ray 进程。默认情况下，Ray 为每个 CPU 核心创建一个工作进程。如果你想在集群上运行
    Ray，你需要传入类似 ray.init(address='insertAddressHere') 的集群地址。
- en: '[PRE8]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The next step is to create a Ray task. This can be done by decorating a normal
    Python function with the @ray.remote decorator. This creates a task which can
    be scheduled across your laptop’s CPU cores (or Ray cluster). Here’s an example
    for the previously created complex_operation_numpy:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是创建一个 Ray 任务。这可以通过使用 @ray.remote 装饰器装饰一个普通的 Python 函数来完成。这会创建一个可以在你的笔记本电脑的
    CPU 核心（或 Ray 集群）上调度的任务。下面是对之前创建的 complex_operation_numpy 的一个示例：
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'In the last step, execute these functions within the ray runtime, like so:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一步，在 Ray 运行时执行这些函数，如下所示：
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'After executing [this script](https://gist.github.com/mGalarnyk/30c8672620c8655a37940be935899a57),
    you will get an output similar to the one below:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 [这个脚本](https://gist.github.com/mGalarnyk/30c8672620c8655a37940be935899a57)
    后，你将得到类似以下的输出：
- en: '![parallelizing blog 11](../Images/464768f1d47ae3ef302ee401e8f70cac.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![parallelizing blog 11](../Images/464768f1d47ae3ef302ee401e8f70cac.png)'
- en: The execution times with and without NumPy for Ray are 3.382sec and 419.98ms,
    respectively. It is important to remember that the performance benefits of Ray
    will be more pronounced when executing long-running tasks like the graph below
    shows.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 使用和不使用 NumPy 的 Ray 执行时间分别为 3.382 秒和 419.98 毫秒。重要的是要记住，当执行长时间运行的任务时，Ray 的性能优势会更加明显，如下图所示。
- en: '![Figure](../Images/da5f3e3440818c336832cd06dfbab026.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![Figure](../Images/da5f3e3440818c336832cd06dfbab026.png)'
- en: Ray has more pronounced benefits when running bigger jobs [(image source)](https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1)
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当运行更大规模的任务时，Ray 的好处更为明显 [(image source)](https://towardsdatascience.com/10x-faster-parallel-python-without-python-multiprocessing-e5017c93cce1)
- en: If you would like to learn about Ray’s syntax, there is an introductory tutorial
    on it [here](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解 Ray 的语法，可以在 [这里](https://www.anyscale.com/blog/writing-your-first-distributed-python-application-with-ray)
    查阅介绍教程。
- en: '![parallelizing blog 13](../Images/ff1bcf03b91977091f603a756bd3e9a3.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![parallelizing blog 13](../Images/ff1bcf03b91977091f603a756bd3e9a3.png)'
- en: Alternative Python Implementations
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他 Python 实现
- en: One final consideration is that you can apply multithreading using other Python
    implementations. Examples include IronPython for .NET and Jython for Java. In
    such cases, you could use the low-level threading support from the underlying
    frameworks. This approach is beneficial if you already have experience with the
    multi-processing capabilities of .NET or Java.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一个最终的考虑是，你可以使用其他 Python 实现来应用多线程。例如，IronPython 用于 .NET，Jython 用于 Java。在这种情况下，你可以使用底层框架的低级线程支持。如果你已经有
    .NET 或 Java 的多处理经验，这种方法会非常有利。
- en: Conclusion
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: This article reviewed common approaches for parallelizing Python through code
    samples and by highlighting some of their advantages and disadvantages. We performed
    tests using benchmarks on simple numerical data. It is important to keep in mind
    that parallelized code often introduces some overhead and that the benefits of
    parallelization are more pronounced with bigger jobs rather than the short computations
    in this tutorial.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章回顾了通过代码示例并突出一些优缺点来并行化 Python 的常见方法。我们使用简单的数值数据进行了基准测试。重要的是要记住，并行化的代码通常会引入一些开销，并且并行化的好处在处理较大的任务时更为明显，而不是在本教程中的短期计算。
- en: Keep in mind that the parallelization can be more powerful for other applications.
    Especially when dealing with typical AI-based tasks in which you must perform
    repetitive fine-tuning of your models. In such cases, [Ray](https://github.com/ray-project/ray) offers
    the best support due to its rich ecosystem, autoscaling, fault tolerance, and
    capability of using remote machines.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，并行化对于其他应用可能更为强大。尤其是在处理典型的基于 AI 的任务时，你必须对模型进行重复的微调。在这种情况下，[Ray](https://github.com/ray-project/ray)
    由于其丰富的生态系统、自动扩展、容错能力和使用远程机器的能力，提供了最佳支持。
- en: '**[Dawid Borycki](https://www.linkedin.com/in/dawidborycki/)** is a Biomedical
    Researcher and Software Engineer, book author and conference speaker.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Dawid Borycki](https://www.linkedin.com/in/dawidborycki/)** 是生物医学研究员和软件工程师，书籍作者和会议讲者。'
- en: '**[Michael Galarnyk](https://www.linkedin.com/in/michaelgalarnyk/)** is a Data
    Science Professional, and works in Developer Relations at Anyscale.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Michael Galarnyk](https://www.linkedin.com/in/michaelgalarnyk/)** 是数据科学专业人士，并在
    Anyscale 从事开发者关系工作。'
- en: '[Original](https://www.anyscale.com/blog/parallelizing-python-code). Reposted
    with permission.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.anyscale.com/blog/parallelizing-python-code)。已获得许可重新发布。'
- en: '**Related:**'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[How to Speed up Scikit-Learn Model Training](/2021/02/speed-up-scikit-learn-model-training.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何加速 Scikit-Learn 模型训练](/2021/02/speed-up-scikit-learn-model-training.html)'
- en: '[Writing Your First Distributed Python Application with Ray](/2021/08/distributed-python-application-ray.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Ray 编写你的第一个分布式 Python 应用程序](/2021/08/distributed-python-application-ray.html)'
- en: '[Dask and Pandas: No Such Thing as Too Much Data](/2021/03/dask-pandas-data.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Dask 和 Pandas：数据量再多也不为过](/2021/03/dask-pandas-data.html)'
- en: '* * *'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Optimizing Python Code Performance: A Deep Dive into Python Profilers](https://www.kdnuggets.com/2023/02/optimizing-python-code-performance-deep-dive-python-profilers.html)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化 Python 代码性能：深入探讨 Python 分析工具](https://www.kdnuggets.com/2023/02/optimizing-python-code-performance-deep-dive-python-profilers.html)'
- en: '[Managing Your Reusable Python Code as a Data Scientist](https://www.kdnuggets.com/2021/06/managing-reusable-python-code-data-scientist.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[作为数据科学家管理你的可重用 Python 代码](https://www.kdnuggets.com/2021/06/managing-reusable-python-code-data-scientist.html)'
- en: '[Announcing PyCaret 3.0: Open-source, Low-code Machine Learning in Python](https://www.kdnuggets.com/2023/03/announcing-pycaret-30-opensource-lowcode-machine-learning-python.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[宣布 PyCaret 3.0：Python 中的开源低代码机器学习](https://www.kdnuggets.com/2023/03/announcing-pycaret-30-opensource-lowcode-machine-learning-python.html)'
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用管道编写清晰的 Python 代码](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
- en: '[3 Tools to Track and Visualize the Execution of Your Python Code](https://www.kdnuggets.com/2021/12/3-tools-track-visualize-execution-python-code.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[跟踪和可视化 Python 代码执行的 3 个工具](https://www.kdnuggets.com/2021/12/3-tools-track-visualize-execution-python-code.html)'
- en: '[Profiling Python Code Using timeit and cProfile](https://www.kdnuggets.com/profiling-python-code-using-timeit-and-cprofile)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 timeit 和 cProfile 进行 Python 代码性能分析](https://www.kdnuggets.com/profiling-python-code-using-timeit-and-cprofile)'
