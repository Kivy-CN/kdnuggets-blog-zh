["```py\n!nvidia-smi\n```", "```py\n!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n!python rapidsai-csp-utils/colab/pip-install.py\n```", "```py\nimport cudf, cuml\ncudf.__version__\n```", "```py\n!pip install -q kaggle\n```", "```py\n!mkdir ~/.kaggle\n```", "```py\n!cp kaggle.json ~/.kaggle/\n```", "```py\n!chmod 600 ~/.kaggle/kaggle.json\n```", "```py\n!kaggle competitions download optiver-realized-volatility-prediction\n```", "```py\n!mkdir train\n```", "```py\n!unzip optiver-realized-volatility-prediction.zip -d train\n```", "```py\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom cudf import DataFrame\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nfrom collections import defaultdict\nfrom IPython.display import display\nimport gc\nimport time\nimport warnings\n%matplotlib inline\n```", "```py\npd.set_option(\"display.max_colwidth\", None)\npd.set_option(\"display.max_columns\", None)\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"Threshold:\", gc.get_threshold())\nprint(\"Count:\", gc.get_count())\n```", "```py\n# Data directory that contains files\nDIR = \"/content/train/\"\n\n# Number of execution cycles\nROUNDS = 30\n```", "```py\n# Get order and trade books\norder_files = glob.glob(DIR + \"book_train.parquet\" + \"/*\")\ntrade_files = glob.glob(DIR + \"trade_train.parquet\" + \"/*\")\nprint(order_files[:5])\nprint(\"\\n\")\nprint(trade_files[:5])\nprint(\"\\n\")\n\n# Get stock_ids as a list\nstock_ids = sorted([int(file.split('=')[1]) for file in order_files])\nprint(f\"{len(stock_ids)} stocks: \\n {stock_ids} \\n\")\n```", "```py\ndef load_dataframe(files, dframe=0):\n\n   print(\"LOADING DATA FRAMES\", \"\\n\")\n\n   # Load the pandas dataframe\n   if dframe == 0:\n     print(\"Loading pandas dataframe..\", \"\\n\")\n     start = time.time()\n     df_pandas = pd.read_parquet(files[0])\n     end = time.time()\n     elapsed_time = round(end-start, 3)\n     print(f\"For pandas dataframe: \\n start time: {start} \\n end time: {end} \\n elapsed time: {elapsed_time} \\n\")\n     return df_pandas, elapsed_time\n\n   # Load the cuDF dataframe\n   else:\n     print(\"Loading cuDF dataframe..\", \"\\n\")\n     start = time.time()\n     df_cudf = cudf.read_parquet(files[0])\n     end = time.time()\n     elapsed_time = round(end-start, 3)\n     print(f\"For cuDF dataframe: \\n start time: {start} \\n end time: {end} \\n elapsed time: {elapsed_time} \\n \")\n\n     return df_cudf, elapsed_time\n```", "```py\n# Load pandas order dataframe and calculate time\ndf_pd_order, _ = load_dataframe(order_files, dframe=0)\ndisplay(df_pd_order.head())\n```", "```py\n# Load cuDF book dataframe and calculate time\ndf_cudf_order, _ = load_dataframe(order_files, dframe=1)\ndisplay(df_cudf_order.head())\n```", "```py\n# Order dataframe info\ndisplay(df_pd_order.info())\n```", "```py\n# Forward fill data\ndef ffill(df, df_name=\"order\"):\n\n   # Forward fill\n   df_pandas = df.set_index(['time_id', 'seconds_in_bucket'])\n\n   if df_name == \"order\":\n     df_pandas = df_pandas.reindex(pd.MultiIndex.from_product([df_pandas.index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']), method='ffill')\n     df_pandas = df_pandas.reset_index()\n\n   else:\n     df_pandas = df_pandas.reindex(pd.MultiIndex.from_product([df_pandas.index.levels[0], np.arange(0,600)], names = ['time_id', 'seconds_in_bucket']))\n     # Fill nan values with 0\n     df_pandas = df_pandas.fillna(0)\n     df_pandas = df_pandas.reset_index()   \n\n   # Convert to a cudf dataframe\n   df_cudf = cudf.DataFrame.from_pandas(df_pandas)\n\n   return df_pandas, df_cudf \n```", "```py\n# Forward fill order dataframes\nexpanded_df_pd_order, expanded_df_cudf_order = ffill(df_pd_order, df_name=\"order\")\ndisplay(expanded_df_cudf_order.head())\n```", "```py\ndef merge_dataframes(df1, df2, dframe=0):\n\n   print(\"MERGING DATA FRAMES\", \"\\n\")\n\n   if dframe == 0:\n     df_type = \"Pandas\"\n   else:\n     df_type = \"cuDF\"\n\n   # Merge dataframes\n   print(f\"Merging {df_type} dataframes..\", \"\\n\")\n   start = time.time()\n   df = df1.merge(df2, how=\"left\", on=[\"time_id\", \"seconds_in_bucket\"], sort=True)\n   end = time.time()\n   elapsed_time = round(end-start, 3)\n   print(f\"For {df_type} dataframes: \\n start time: {start} \\n end time: {end} \\n elapsed time: {elapsed_time} \\n\")\n\n   return df, elapsed_time\n```", "```py\n# Merge cuDF order and trade dataframes\ndf_cudf, cudf_merge_time = merge_dataframes(expanded_df_cudf_order, expanded_df_cudf_trade, dframe=1)\ndisplay(df_cudf.head())\n```", "```py\n# Make dtype changes\ndef change_dtype(df, dframe=0):\n\n   print(\"CHANGING DTYPES\", \"\\n\")\n\n   convert_dict = {\"time_id\": \"int16\",\n                   \"seconds_in_bucket\": \"int16\",\n                   \"bid_size1\": \"int16\",\n                   \"ask_size1\": \"int16\",\n                   \"bid_size2\": \"int16\",\n                   \"ask_size2\": \"int16\",\n                   \"size\": \"int16\",\n                   \"order_count\": \"int16\"\n                   } \n\n   df = df.astype(convert_dict)\n\n   return df, dframe\n```", "```py\n# Make dtype changes for cuDF data frame\ndf_cudf, _ = change_dtype(df_cudf)\ndisplay(df_cudf.info())\n```", "```py\n# Get unique values in time_id column and put them in a list\ndef get_unique_timeids(df, dframe=0):\n\n   global time_ids\n\n   print(\"GETTING UNIQUE VALUES\", \"\\n\")\n\n   # Get unique time_ids\n   if dframe == 0:\n     print(f\"Getting sorted unique time_ids from Pandas dataframe..\", \"\\n\")\n     start = time.time()\n     time_ids = sorted(df['time_id'].unique().tolist())\n     end = time.time()\n     elapsed_time = round(end-start, 3)\n     print(f\"Unique time_ids from Pandas dataframe: \\n start time: {start} \\n end time: {end} \\n elapsed time: {elapsed_time} \\n\")\n\n   else:\n     print(f\"Getting sorted unique time_ids from cuDF dataframe..\", \"\\n\")\n     start = time.time()\n     time_ids = sorted(df['time_id'].unique().to_arrow().to_pylist())\n     end = time.time()\n     elapsed_time = round(end-start, 3)\n     print(f\"Unique time_ids from cuDF dataframe: \\n start time: {start} \\n end time: {end} \\n elapsed time: {elapsed_time} \\n\")\n\n   print(f\"{len(time_ids)} time buckets: \\n {time_ids[:10]}...\")\n   print(\"\\n\")\n\n   return df, time_ids\n```", "```py\n# Get time_ids from cuDF dataframe\ntime_ids = get_unique_timeids(df_cudf_order, dframe=1)\n```", "```py\n# Check df null values\ndef check_null_values(df, dframe=0):\n\n   print(\"CHECKING NULL VALUES\", \"\\n\")\n\n   print(\"Checking dataframe null values..\", \"\\n\")\n   display(df.isna().values.any())\n   display(df.isnull().sum())\n\n   return df, dframe\n```", "```py\n# Check null values for cuDF dataframe\ndf_cudf, _ = check_null_values(df_cudf, dframe=0)\n```", "```py\n# Add columns\ndef add_column(df, dframe=0):\n\n   print(\"ADDING COLUMNS\", \"\\n\")\n\n   # Calculate WAPs\n   df['wap1'] = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n   df['wap2'] = (df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']) / (df['bid_size2'] + df['ask_size2'])\n\n   # Calculate order volumes\n   df['bid1_volume'] = df['bid_price1'] * df['bid_size1']\n   df['bid2_volume'] = df['bid_price2'] * df['bid_size2']\n   df['ask1_volume'] = df['ask_price1'] * df['ask_size1']\n   df['ask2_volume'] = df['ask_price2'] * df['ask_size2']\n\n   # Calculate volume imbalance\n   df['imbalance'] = np.absolute((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n\n   # Calculate trade volume imbalance\n   df['volume_imbalance'] = np.absolute((df['bid_price1'] * df['bid_size1']) - (df['ask_price1'] * df['ask_size1']))\n\n   return df, dframe\n```", "```py\n# Add a column in cuDF dataframe\ndf_cudf, _ = add_column(df_cudf)\ndisplay(df_cudf.head())\n```", "```py\n# Drop columns\ndef drop_column(df, dframe=0):\n\n   print(\"DROPPING COLUMNS\", \"\\n\")\n\n   df.drop(columns=['wap1', 'wap2'], inplace=True)\n\n   return df, dframe\n```", "```py\n# Add a column in cuDF dataframe\ndf_cudf, _ = drop_column(df_cudf)\ndisplay(df_cudf.head())\n```", "```py\n# Calculate statistics by selected features\ndef calc_agg_stats(df, dframe=0):\n\n   print(\"CALCULATING STATISTICS\", \"\\n\")\n\n   # Statistical calculations to be made \n   operations = [\"mean\", \"median\", \"max\", \"min\", \"std\", \"sum\"]\n\n   # Features for which statistical calculations will be made\n   features_list = [\"bid1_volume\", \"bid2_volume\", \"ask1_volume\", \"ask2_volume\"]\n\n   # Create a dictionary to store feature-calculation pairs\n   stats_dict = defaultdict(list)\n   for feature in features_list:\n       stats_dict[feature].extend(operations)\n\n   # Calculate aggregate statistics\n   df_stats = df.groupby('time_id', as_index=False, sort=True).agg(stats_dict)\n\n   return df, df_stats\n```", "```py\n# Calculate statistics by selected features in cuDF dataframe\n_, df_cudf_stats = calc_agg_stats(df_cudf)\ndisplay(df_cudf_stats.head())\n```", "```py\n# Merge data frame with stats\ndef merge_dataframes_2(df, dframe=0):\n\n   if dframe == 0:\n     df = df.merge(df_pd_stats, how=\"left\", on=\"time_id\", sort=True)\n\n   else:\n     df = df.to_pandas()\n     df = df.merge(df_pd_stats, how=\"left\", on=\"time_id\", sort=True)\n     df = cudf.DataFrame.from_pandas(df)\n\n   return df, dframe\n\n# Merge cuDF data frames\ndf_cudf, _ = merge_dataframes_2(df_cudf, dframe=1)\ndisplay(df_cudf.head())\n```", "```py\n# Calculate correlation between two selected features\ndef calc_corr(df, dframe=0):\n\n correlation = df[[\"bid1_volume\", \"ask1_volume\"]].corr()\n print(f\"Correlation between 'bid1_volume' and 'ask1_volume' is {correlation} \\n\")\n\n return df, correlation\n```", "```py\n# Calculate correlation in cuDF dataframe\n_ = calc_corr(df_cudf)\n```", "```py\n# Rename columns\ndef rename_cols(df, dframe=0):\n\n   print(\"RENAMING COLUMNS\", \"\\n\")\n\n   df = df.rename(columns={\"imbalance\": \"volume_imbalance\", \"volume_imbalance\": \"trade_volume_imbalance\"})\n\n   return df, dframe\n```", "```py\n# Bin a selected column\ndef bin_col(df, dframe=0):\n\n   print(\"BINNING A COLUMN\", \"\\n\")\n\n   if dframe == 0:\n     df['bid1_volume_cut'] = pd.cut(df[\"bid1_volume\"], bins=5, labels=[\"very high\", \"high\", \"average\", \"low\", \"very low\"], ordered=True)\n\n   else:\n     df['bid1_volume_cut'] = cudf.cut(df[\"bid1_volume\"], bins=5, labels=[\"very high\", \"high\", \"average\", \"low\", \"very low\"], ordered=True)\n\n   return df, dframe\n```", "```py\n# Bin a selected column in cuDF dataframe\ndf_cudf, _ = bin_col(df_cudf, dframe=1)\ndisplay(df_cudf.head())\n```", "```py\n# Display data frame\ndef display_df(df, dframe=0):\n\n   print(\"DISPLAYING DATA FRAMES\", \"\\n\")\n\n   display(df.head())\n   print(\"\\n\")\n\n   return df, dframe\n\n# Display dataframe info\ndef display_info(df, dframe=0):\n\n   print(\"DISPLAYING DATA FRAME INFO\", \"\\n\")\n\n   display(df.info())\n   print(\"\\n\")\n\n   return df, dframe\n\n# Display dataframe info\ndef describe_df(df, dframe=0):\n\n   print(\"DESCRIBING DATA FRAMES\", \"\\n\")\n\n   display(df.describe())\n   print(\"\\n\")\n\n   return df, dframe\n```", "```py\n# Display cuDF dataframe and info\n_, _ = display_df(df_cudf, dframe=1)\n_, _ = display_info(df_cudf, dframe=1)\n_, _ = describe_df(df_cudf, dframe=1)\n```", "```py\ndef run_and_report():\n\n   # Create a dictionary to store elapsed times\n   time_dict = defaultdict(list)\n\n   # List operations to be performed\n   labels = [\"changing_dtype\",\n             \"getting_unique_timeids\",\n             \"checking_null_values\",\n             \"adding_column\",\n             \"dropping_column\",\n             \"calculating_agg_stats\",\n             \"merging_dataframes\",\n             \"renaming_columns\",\n             \"binning_col\",\n             \"calculating_corr\",\n             \"displaying_dfs\",\n             \"displaying_info\",\n             \"describing_dfs\"]\n\n   # Load pandas order dataframe and calculate time\n   df_pd_order, pd_order_loading_time = load_dataframe(order_files, dframe=0)\n   print(\"-\"*150, \"\\n\")\n\n   # Load cuDF book dataframe and calculate time\n   df_cudf_order, cudf_order_loading_time = load_dataframe(order_files, dframe=1)\n   print(\"-\"*150, \"\\n\")\n\n   # Load pandas trade dataframe and calculate time\n   df_pd_trade, pd_trade_loading_time = load_dataframe(trade_files, dframe=0)\n   print(\"-\"*150, \"\\n\")\n\n   # Load cuDF trade dataframe and calculate time\n   df_cudf_trade, cudf_trade_loading_time = load_dataframe(trade_files, dframe=1)\n   print(\"-\"*150, \"\\n\")\n\n   # Get time_ids from Pandas data frame\n   _, time_ids = get_unique_timeids(df_pd_order, dframe=0)\n   print(\"-\"*150, \"\\n\")\n\n   # Get time_ids from cuDF dataframe\n   _, time_ids = get_unique_timeids(df_cudf_order, dframe=1)\n   print(\"-\"*150, \"\\n\")\n\n   # Store loading times\n   time_dict[\"loading_dfs\"].extend([pd_order_loading_time, cudf_order_loading_time])\n\n   # Forward fill order dataframes\n   expanded_df_pd_order, expanded_df_cudf_order = ffill(df_pd_order, df_name=\"order\")\n\n   # Forward fill trade dataframes\n   expanded_df_pd_trade, expanded_df_cudf_trade = ffill(df_pd_trade, df_name=\"trade\")\n\n   # Merge pandas order and trade dataframes\n   df_pd, pd_merge_time = merge_dataframes(expanded_df_pd_order, expanded_df_pd_trade, dframe=0)\n   print(\"-\"*150, \"\\n\")\n\n   # Merge pandas order and trade dataframes\n   df_cudf, cudf_merge_time = merge_dataframes(expanded_df_cudf_order, expanded_df_cudf_trade, dframe=1)\n   print(\"-\"*150, \"\\n\")\n\n   # Store merge times\n   time_dict[\"merging_dfs\"].extend([pd_merge_time, cudf_merge_time])\n\n   # Apply functions\n   functions = [change_dtype,\n                get_unique_timeids,\n                check_null_values,\n                add_column,\n                drop_column,\n                calc_agg_stats,\n                merge_dataframes_2,\n                rename_cols,\n                bin_col,\n                calc_corr,\n                display_df,\n                display_info,\n                describe_df]\n\n   for label, function in enumerate(functions):\n\n     # Function for pandas\n     start_pd = time.time()\n     df_pd, x = function(df_pd, dframe=0)\n     end_pd = time.time()\n     elapsed_time_for_pd = round(end_pd-start_pd, 3)\n     print(f\"For pandas dataframe: \\n start time: {start_pd} \\n end time: {end_pd} \\n elapsed time: {elapsed_time_for_pd} \\n\")     \n\n     # Function for cuDF\n     start_cudf = time.time()\n     df_cudf, x = function(df_cudf, dframe=1)\n     end_cudf = time.time()\n     elapsed_time_for_cudf = round(end_cudf-start_cudf, 3)\n     print(f\"For cuDF dataframe: \\n start time: {start_cudf} \\n end time: {end_cudf} \\n elapsed time: {elapsed_time_for_cudf} \\n\")\n     print(\"-\"*150, \"\\n\")\n\n     # Store elapsed times\n     time_dict[labels[label]].extend([elapsed_time_for_pd, elapsed_time_for_cudf])\n\n   # Delete the unsolicited time duration\n   del time_dict[\"merging_dataframes\"]\n   labels.remove(\"merging_dataframes\")\n   labels.insert(0, \"merging_dfs\")\n   labels.insert(0, \"loading_dfs\")\n\n   print(time_dict)\n\n   return time_dict, labels, df_pd, df_cudf\n```", "```py\ntime_dict, labels, df_pd, df_cudf = run_and_report()\n```", "```py\ndef calc_exec_times():\n\n   exec_times_by_round = {}\n\n   # Calculate execution times of operations in each round\n   for round_no in range(1, ROUNDS+1):\n     # cycle_no += 1\n     time_dict, labels, df_pd, df_cudf = run_and_report()\n     exec_times_by_round[round_no] = time_dict\n\n   print(\"exec_times_by_round: \", exec_times_by_round)\n\n   # Get durations by operation for each data frame\n   pd_summary, cudf_summary = get_statistics(exec_times_by_round, labels)\n\n   # Get durations by rounds for each data frame\n   round_total = get_total(exec_times_by_round)\n   print(\"\\n\"*3)\n\n   # Plot durations\n   plt.style.use('dark_background')\n   X_axis = np.arange(len(labels))\n\n   # Plot average duration of operation\n   plot_avg_by_df(pd_summary, cudf_summary, labels, X_axis)\n   print(\"\\n\"*3)\n\n   # Plot total and difference in duration by operation\n   plot_diff_by_df(pd_summary, cudf_summary, labels)\n   print(\"\\n\"*3)\n\n   # Plot total and difference in duration by round\n   plot_total_by_df(round_total)\n   print(\"\\n\"*3)\n```", "```py\ndef get_statistics(exec_times_by_round, labels):\n\n   # Separate and store duration statistics by data frame\n   pd_performance = defaultdict(list)\n   cudf_performance = defaultdict(list)\n\n   # Get and store durations for each operation by data frame\n   for label in labels:\n     for key, values in exec_times_by_round.items():\n\n       pd_performance[label].append(values[label][0])\n       cudf_performance[label].append(values[label][1])\n\n   print(\"pd_performance: \", pd_performance)\n   print(\"cudf_performance: \", cudf_performance)\n\n   # Compute average and total durations for each operation by data frame\n   pd_summary = {key: [round(sum(value), 3), round(np.average(value), 3)] for key, value in pd_performance.items()}\n   cudf_summary = {key: [round(sum(value), 3), round(np.average(value), 3)] for key, value in cudf_performance.items()}\n\n   print(\"pd_summary: \", pd_summary)\n   print(\"cudf_summary: \", cudf_summary) \n\n   return pd_summary, cudf_summary\n```", "```py\ndef get_total(exec_times_by_round):\n\n   def get_round_total(stat_list):\n\n     # Get total duration by round for each data frame\n     pd_round_total = round(sum([x[0] for x in stat_list]), 3)\n     cudf_round_total = round(sum([x[1] for x in stat_list]), 3)\n\n     return pd_round_total, cudf_round_total\n\n   # Collect total durations by round\n   for key, value in exec_times_by_round.items():\n     round_total = {key: get_round_total(list(value.values())) for key, value in exec_times_by_round.items()}\n\n   print(\"round_total\", round_total)\n\n   return round_total\n```", "```py\ndef plot_avg_by_df(pd_summary, cudf_summary, labels, X_axis):\n\n   # Figure size\n   fig = plt.subplots(figsize =(10, 4))\n\n   # Average duration by operation for each data frame\n   pd_avg = [value[1] for key, value in pd_summary.items()]\n   cudf_avg = [value[1] for key, value in cudf_summary.items()]\n\n   plt.bar(X_axis - 0.2, pd_avg, 0.4, color = '#5A5AAF', label = 'pandas', align='center')\n   plt.bar(X_axis + 0.2, cudf_avg, 0.4, color = '#C8C8FF', label = 'cuDF', align='center')\n\n   plt.xticks(X_axis, labels, fontsize=9, rotation=90)\n   plt.yticks(fontsize=9)\n   plt.xlabel(\"Operations\", fontsize=10)\n   plt.ylabel(\"Average Duration in Seconds\", fontsize=10)\n   plt.grid(axis='y', color=\"#E4E4E4\", alpha=0.5)\n   plt.title(\"Average Duration of Operation by Data Frame\", fontsize=12)\n   plt.legend()\n   plt.show()\n```", "```py\ndef plot_diff_by_df(pd_summary, cudf_summary, labels):\n\n   # Figure size\n   fig = plt.subplots(figsize =(12, 6))\n\n   # Total duration by operation for each data frame\n   pd_total = [value[0] for key, value in pd_summary.items()]\n   cudf_total = [value[0] for key, value in cudf_summary.items()]\n\n   # Difference of total duration by operation for each data frame\n   diff = [x[0]-x[1] for x in zip(pd_total, cudf_total)]\n\n   # Set width of bar\n   barWidth = 0.25\n\n   # Set position of bar on X axis\n   br1 = np.arange(len(labels))\n   br2 = [x + barWidth for x in br1]\n   br3 = [x + barWidth for x in br2]\n\n   plt.bar(br1, pd_total, barWidth, color = '#5A5AAF', label = 'pandas', align='center')\n   plt.bar(br2, cudf_total, barWidth, color = '#C8C8FF', label = 'cuDF', align='center')\n   plt.bar(br3, diff, barWidth, color = '#AA1E1E', label = 'difference', align='center')\n\n   plt.xticks([r + barWidth for r in range(len(labels))], labels, fontsize=9, rotation=90)\n   plt.yticks(fontsize=9)\n   plt.xlabel(\"Operations\", fontsize=10)\n   plt.ylabel(\"Total Duration in Seconds\", fontsize=10)\n   plt.grid(axis='y', color=\"#E4E4E4\", alpha=0.5)\n   plt.title(\"Total Duration of Operation by Data Frame\", fontsize=12)\n   plt.legend()\n   plt.show()\n```", "```py\ndef plot_total_by_df(round_total):\n\n    # Figure size\n   fig = plt.subplots(figsize =(10, 6))\n\n   X_axis = np.arange(1, ROUNDS+1)\n\n   # Total duration by round for each data frame\n   pd_round_total = [value[0] for key, value in round_total.items()]\n   cudf_round_total = [value[1] for key, value in round_total.items()]\n\n   # Difference of total duration by round for each data frame\n   diff = [x[0]-x[1] for x in zip(pd_round_total, cudf_round_total)]\n\n   plt.plot(X_axis, pd_round_total, linestyle=\"-\", linewidth=3, color = '#5A5AAF', label = \"pandas\")\n   plt.plot(X_axis, cudf_round_total, linestyle=\"-\", linewidth=3, color = '#B0B05A', label = \"cuDF\")\n   plt.plot(X_axis, diff, linestyle=\"--\", linewidth=3, color = '#AA1E1E', label = \"difference\")\n\n   plt.xticks(X_axis, fontsize=9)\n   plt.yticks(fontsize=9)\n   plt.xlabel(\"Rounds\", fontsize=10)\n   plt.ylabel(\"Total Duration in Seconds\", fontsize=10)\n   plt.grid(axis='y', color=\"#E4E4E4\", alpha=0.5)\n   plt.title(\"Total Duration by Round\", fontsize=12)\n   plt.legend()\n   plt.show()\n```"]