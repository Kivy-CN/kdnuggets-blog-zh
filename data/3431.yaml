- en: Approaching (Almost) Any Machine Learning Problem
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理（几乎）任何机器学习问题
- en: 原文：[https://www.kdnuggets.com/2016/08/approaching-almost-any-machine-learning-problem.html/2](https://www.kdnuggets.com/2016/08/approaching-almost-any-machine-learning-problem.html/2)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/08/approaching-almost-any-machine-learning-problem.html/2](https://www.kdnuggets.com/2016/08/approaching-almost-any-machine-learning-problem.html/2)
- en: Next, we come to the stacker module. Stacker module is not a model stacker but
    a feature stacker. The different features after the processing steps described
    above can be combined using the stacker module.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们来到了堆叠模块。堆叠模块不是模型堆叠器，而是特征堆叠器。经过上述处理步骤后的不同特征可以使用堆叠模块进行组合。
- en: '![](../Images/0d2fc441e33e2479dc1398c5c92db1e8.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0d2fc441e33e2479dc1398c5c92db1e8.png)'
- en: You can horizontally stack all the features before putting them through further
    processing by using numpy hstack or sparse hstack depending on whether you have
    dense or sparse features.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在进一步处理之前，使用 numpy hstack 或 sparse hstack 将所有特征水平堆叠，这取决于你有密集特征还是稀疏特征。
- en: '![](../Images/534f1f2ac0d4c9ea55dda8088c038ad7.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/534f1f2ac0d4c9ea55dda8088c038ad7.png)'
- en: And can also be achieved by FeatureUnion module in case there are other processing
    steps such as pca or feature selection (we will visit decomposition and feature
    selection later in this post).
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果还有其他处理步骤，如 pca 或特征选择，也可以通过 FeatureUnion 模块实现（稍后我们会讨论降解和特征选择）。
- en: '![](../Images/226c8c202aa480e3cafff0426108d0ab.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/226c8c202aa480e3cafff0426108d0ab.png)'
- en: 'Once, we have stacked the features together, we can start applying machine
    learning models. At this stage only models you should go for should be ensemble
    tree based models. These models include:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们将特征堆叠在一起，我们可以开始应用机器学习模型。在这个阶段，你应该选择的模型是集成树模型。这些模型包括：
- en: RandomForestClassifier
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RandomForestClassifier
- en: RandomForestRegressor
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RandomForestRegressor
- en: ExtraTreesClassifier
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ExtraTreesClassifier
- en: ExtraTreesRegressor
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ExtraTreesRegressor
- en: XGBClassifier
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBClassifier
- en: XGBRegressor
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XGBRegressor
- en: We cannot apply linear models to the above features since they are not normalized.
    To use linear models, one can use Normalizer or StandardScaler from scikit-learn.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述特征未经过归一化，我们不能应用线性模型。要使用线性模型，可以使用 scikit-learn 中的 Normalizer 或 StandardScaler。
- en: 'These normalization methods work only on dense features and don’t give very
    good results if applied on sparse features. Yes, one can apply StandardScaler
    on sparse matrices without using the mean (parameter: with_mean=False).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些归一化方法仅适用于密集特征，如果应用于稀疏特征，效果不是很好。是的，可以在稀疏矩阵上应用 StandardScaler，而不使用均值（参数：with_mean=False）。
- en: If the above steps give a “good” model, we can go for optimization of hyperparameters
    and in case it doesn’t we can go for the following steps and improve our model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果上述步骤生成了一个“好”的模型，我们可以进行超参数优化，如果没有，我们可以采取以下步骤改进模型。
- en: 'The next steps include decomposition methods:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤包括降解方法：
- en: '![](../Images/2ea88d8b389703c648a4ba1fbb629e14.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2ea88d8b389703c648a4ba1fbb629e14.png)'
- en: For the sake of simplicity, we will leave out LDA and QDA transformations. For
    high dimensional data, generally PCA is used decompose the data. For images start
    with 10-15 components and increase this number as long as the quality of result
    improves substantially. For other type of data, we select 50-60 components initially
    (we tend to avoid PCA as long as we can deal with the numerical data as it is).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简单起见，我们将忽略 LDA 和 QDA 转换。对于高维数据，通常使用 PCA 来降解数据。对于图像，从 10-15 个组件开始，如果结果质量显著提高，则增加这个数字。对于其他类型的数据，我们初步选择
    50-60 个组件（只要可以处理数字数据，我们倾向于避免 PCA）。
- en: '![](../Images/932bf19fff5e1fdbc2d3d4278c273f24.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/932bf19fff5e1fdbc2d3d4278c273f24.png)'
- en: 'can be found here:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 可以在这里找到：
- en: For text data, after conversion of text to sparse matrix, go for Singular Value
    Decomposition (SVD). A variation of SVD called TruncatedSVD can be found in scikit-learn.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于文本数据，在将文本转换为稀疏矩阵后，使用奇异值分解（SVD）。在 scikit-learn 中可以找到一个 SVD 的变体，称为 TruncatedSVD。
- en: '![](../Images/4283cfbfce157dff2410f4c7bf25e78b.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4283cfbfce157dff2410f4c7bf25e78b.png)'
- en: The number of SVD components that generally work for TF-IDF or counts are between
    120-200\. Any number above this might improve the performance but not substantially
    and comes at the cost of computing power.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常适用于 TF-IDF 或计数的 SVD 组件数量在 120-200 之间。高于这个数量可能会提高性能，但不会显著增加，并且会增加计算成本。
- en: After evaluating further performance of the models, we move to scaling of the
    datasets, so that we can evaluate linear models too. The normalized or scaled
    features can then be sent to the machine learning models or feature selection
    modules.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在进一步评估模型的表现后，我们转向数据集的扩展，以便也能评估线性模型。归一化或缩放的特征可以发送到机器学习模型或特征选择模块。
- en: '![](../Images/1f724aaae7b4f9ab788d90bf2c4aea82.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1f724aaae7b4f9ab788d90bf2c4aea82.png)'
- en: 'There are multiple ways in which feature selection can be achieved. One of
    the most common way is greedy feature selection (forward or backward). In greedy
    feature selection we choose one feature, train a model and evaluate the performance
    of the model on a fixed evaluation metric. We keep adding and removing features
    one-by-one and record performance of the model at every step. We then select the
    features which have the best evaluation score. One implementation of greedy feature
    selection with AUC as evaluation metric can be found here: [https://github.com/abhishekkrthakur/greedyFeatureSelection](https://github.com/abhishekkrthakur/greedyFeatureSelection).
    It must be noted that this implementation is not perfect and must be changed/modified
    according to the requirements.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择可以通过多种方式实现。最常见的一种是贪婪特征选择（前向或后向）。在贪婪特征选择中，我们选择一个特征，训练一个模型并在固定的评估指标上评估模型的表现。我们逐一添加和删除特征，并记录每一步的模型表现。然后选择具有最佳评估分数的特征。一个以AUC作为评估指标的贪婪特征选择实现可以在这里找到：[https://github.com/abhishekkrthakur/greedyFeatureSelection](https://github.com/abhishekkrthakur/greedyFeatureSelection)。需要注意的是，这个实现并不完美，需要根据要求进行更改/修改。
- en: Other faster methods of feature selection include selecting best features from
    a model. We can either look at coefficients of a logit model or we can train a
    random forest to select best features and then use them later with other machine
    learning models.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 其他更快的特征选择方法包括从模型中选择最佳特征。我们可以查看logit模型的系数，或者训练一个随机森林来选择最佳特征，然后将其与其他机器学习模型一起使用。
- en: '![](../Images/f4689040f98c60eb3104949992f9d01d.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f4689040f98c60eb3104949992f9d01d.png)'
- en: Remember to keep low number of estimators and minimal optimization of hyper
    parameters so that you don’t overfit.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 记住保持较少的估计器数量和最小化超参数优化，以免过拟合。
- en: The feature selection can also be achieved using Gradient Boosting Machines.
    It is good if we use xgboost instead of the implementation of GBM in scikit-learn
    since xgboost is much faster and more scalable.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择也可以使用梯度提升机来实现。如果我们使用xgboost而不是scikit-learn中的GBM实现，这将更好，因为xgboost更快且更具可扩展性。
- en: '![](../Images/fb2c548d2699931784540723a0f77760.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/fb2c548d2699931784540723a0f77760.png)'
- en: We can also do feature selection of sparse datasets using RandomForestClassifier
    / RandomForestRegressor and xgboost.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用RandomForestClassifier / RandomForestRegressor和xgboost进行稀疏数据集的特征选择。
- en: Another popular method for feature selection from positive sparse datasets is
    chi-2 based feature selection and we also have that implemented in scikit-learn.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从正稀疏数据集中选择特征的另一种流行方法是基于chi-2的特征选择，我们在scikit-learn中也实现了这种方法。
- en: '![](../Images/be57230fe837bc13a2b4b0ca2914c157.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/be57230fe837bc13a2b4b0ca2914c157.png)'
- en: Here, we use chi2 in conjunction with SelectKBest to select 20 features from
    the data. This also becomes a hyperparameter we want to optimize to improve the
    result of our machine learning models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用chi2结合SelectKBest从数据中选择20个特征。这也成为我们要优化的超参数，以改进机器学习模型的结果。
- en: Don’t forget to dump any kinds of transformers you use at all the steps. You
    will need them to evaluate performance on the validation set.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 不要忘记在所有步骤中保存你使用的任何类型的变换器。你将需要它们来评估验证集上的表现。
- en: Next (or intermediate) major step is model selection + hyperparameter optimization.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个（或中间）主要步骤是模型选择 + 超参数优化。
- en: '![](../Images/02a6679552c13c5f074c5f62ed401777.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/02a6679552c13c5f074c5f62ed401777.png)'
- en: 'We generally use the following algorithms in the process of selecting a machine
    learning model:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常在选择机器学习模型的过程中使用以下算法：
- en: '**Classification**:'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**分类**：'
- en: Random Forest
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: GBM
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GBM
- en: Logistic Regression
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 逻辑回归
- en: Naive Bayes
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 朴素贝叶斯
- en: Support Vector Machines
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机
- en: k-Nearest Neighbors
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: k-最近邻
- en: '**Regression**'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回归**'
- en: Random Forest
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机森林
- en: GBM
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: GBM
- en: Linear Regression
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 线性回归
- en: Ridge
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 岭回归
- en: Lasso
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lasso
- en: SVR
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVR
- en: Which parameters should I optimize? How do I choose parameters closest to the
    best ones? These are a couple of questions people come up with most of the time.
    One cannot get answers to these questions without experience with different models
    + parameters on a large number of datasets. Also people who have experience are
    not willing to share their secrets. Luckily, I have quite a bit of experience
    too and I’m willing to give away some of the stuff.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该优化哪些参数？我如何选择最接近最佳的参数？这些是人们最常提出的问题。没有在大量数据集上使用不同模型 + 参数的经验，无法回答这些问题。同时，有经验的人也不愿意分享他们的秘密。幸运的是，我也有相当多的经验，并且愿意分享一些内容。
- en: 'Let’s break down the hyperparameters, model wise:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨一下超参数，按模型分类：
- en: '[![](../Images/999cce9d8f4839d8aa947045af1c85d4.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAilAAAAJDhiNGE5YTVmLTJhNTAtNGNkZS1hNDAwLTY5YTJiMTE1ZmI3Zg.png)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/999cce9d8f4839d8aa947045af1c85d4.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAilAAAAJDhiNGE5YTVmLTJhNTAtNGNkZS1hNDAwLTY5YTJiMTE1ZmI3Zg.png)'
- en: RS* = Cannot say about proper values, go for Random Search in these hyperparameters.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: RS* = 无法确定适当值，请在这些超参数中使用随机搜索。
- en: In my opinion, and strictly my opinion, the above models will out-perform any
    others and we don’t need to evaluate any other models.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，严格来说，我认为上述模型将优于其他任何模型，我们不需要评估其他模型。
- en: 'Once again, remember to save the transformers:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，记得保存变换器：
- en: '[![](../Images/e03f6db43132da2f4d6b3b4ab2aa98cd.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAhzAAAAJGNhOTU4MGRjLWE3YzAtNDFmMi1hMjg0LWUyOGIwMDBlNzUxYw.png)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/e03f6db43132da2f4d6b3b4ab2aa98cd.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAhzAAAAJGNhOTU4MGRjLWE3YzAtNDFmMi1hMjg0LWUyOGIwMDBlNzUxYw.png)'
- en: 'And apply them on validation set separately:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 然后分别应用于验证集：
- en: '[![](../Images/da94fbdea0582fd1492738a7335435b4.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAllAAAAJDgxZjdjNjcwLTQ0ZDktNDU0Mi04YzQzLThjMGM1NWY5ZWFkNQ.png)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/da94fbdea0582fd1492738a7335435b4.png)](https://media.licdn.com/mpr/mpr/shrinknp_800_800/AAEAAQAAAAAAAAllAAAAJDgxZjdjNjcwLTQ0ZDktNDU0Mi04YzQzLThjMGM1NWY5ZWFkNQ.png)'
- en: The above rules and the framework has performed very well in most of the datasets
    I have dealt with. Of course, it has also failed for very complicated tasks. Nothing
    is perfect and we keep on improving on what we learn. Just like in machine learning.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以上规则和框架在我处理的大多数数据集上表现非常好。当然，对于非常复杂的任务，它们也会失败。没有什么是完美的，我们不断改进所学。就像机器学习一样。
- en: 'Get in touch with me with any doubts: abhishek4 [at] gmail [dot] com'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如有疑问，请与我联系：abhishek4 [at] gmail [dot] com
- en: '**Bio: [Abhishek Thakur](https://www.linkedin.com/in/abhisvnit)** holds a Master''s
    degree in Computer Science from University of Bonn, and is a Senior Data Scientist
    on the Data Science team at Searchmetrics Inc., working on some of the most interesting
    data driven studies, applied machine learning algorithms and deriving insights
    from huge amounts of data. He is also a Kaggle competition Grandmaster.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介： [Abhishek Thakur](https://www.linkedin.com/in/abhisvnit)** 拥有波恩大学计算机科学硕士学位，目前是
    Searchmetrics Inc. 数据科学团队的高级数据科学家，从事一些最有趣的数据驱动研究、应用机器学习算法以及从海量数据中提取洞见。他还是 Kaggle
    竞赛大师。'
- en: '[Original](https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur).
    Reposted with permission.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.linkedin.com/pulse/approaching-almost-any-machine-learning-problem-abhishek-thakur)。经许可重新发布。'
- en: '**Related:**'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Contest Winner: Winning the AutoML Challenge with Auto-sklearn](/2016/08/winning-automl-challenge-auto-sklearn.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比赛冠军：使用 Auto-sklearn 赢得 AutoML 挑战](/2016/08/winning-automl-challenge-auto-sklearn.html)'
- en: '[Contest 2nd Place: Automating Data Science](/2016/08/automating-data-science.html)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[比赛二等奖：自动化数据科学](/2016/08/automating-data-science.html)'
- en: '[TPOT: A Python Tool for Automating Data Science](/2016/05/tpot-python-automating-data-science.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TPOT：用于自动化数据科学的 Python 工具](/2016/05/tpot-python-automating-data-science.html)'
- en: '* * *'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Introduction to NExT-GPT: Any-to-Any Multimodal Large Language Model](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[NExT-GPT简介：任意对任意的多模态大型语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)'
- en: '[Frameworks for Approaching the Machine Learning Process](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[处理机器学习过程的框架](https://www.kdnuggets.com/2018/05/general-approaches-machine-learning-process.html)'
- en: '[SHAP: Explain Any Machine Learning Model in Python](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SHAP：在Python中解释任何机器学习模型](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)'
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在没有任何工作经验的情况下获得你的第一份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
- en: '[Read This Before You Take Any Free Data Science Course](https://www.kdnuggets.com/read-this-before-you-take-any-free-data-science-course)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在参加任何免费的数据科学课程之前阅读此内容](https://www.kdnuggets.com/read-this-before-you-take-any-free-data-science-course)'
- en: '[The Range of NLP Applications in the Real World: A Different…](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[现实世界中NLP应用的范围：一种不同的解决方案](https://www.kdnuggets.com/2022/03/different-solution-problem-range-nlp-applications-real-world.html)'
