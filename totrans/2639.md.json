["```py\nfrom sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n\n```", "```py\nfrom sklearn.cluster import KMeans\nmodel = KMeans(n_clusters = number_of_clusters)\nmodel.fit(X)\n\n```", "```py\nmodel.labels_\n\n```", "```py\ndata['Label'] = model.labels_\n\n```", "```py\ndata.predict(new_data)\n\n```", "```py\ndata.cluster_centers_\n\n```", "```py\nfrom sklearn.metrics import silhouette_score\nscores = []\nfor cluster_num in range(lower_bound, upper_bound):\n     model = KMeans(n_clusters=cluster_num)\n     model.fit(data)\n     score = silhouette_score(data, model.predict(data))\n\n```", "```py\nfrom sklearn.decomposition import PCA\nmodel = PCA(n_components=number)\ndata = model.fit_transform(data)\n\n```", "```py\nfrom sklearn.decomposition import LatentDirichletAllocation\nlda = LatentDirichletAllocation(n_components = number)\ntransformed = lda.fit_transform(X, y)\n\n```", "```py\nimport eli5\nfrom eli5.sklearn import PermutationImportance\nmodel = PermutationImportance(model)\nmodel.fit(X,y)\neli5.show_weights(model, feature_names = X.columns.tolist())\n\n```", "```py\nimport shap\nexplainer = shap.TreeExplainer(model)\nshap_values = explainer.shap_values(X)\nshap.summary_plot(shap_values, X, plot_type=\"bar\")\n\n```", "```py\nfrom pdpbox import pdp, info_plots\nimport matplotlib.pyplot as plt\n\n```", "```py\nfeat_name = 'sqft_living'\npdp_dist = pdp.pdp_isolate(model=model, \n                           dataset=X, \n                           model_features=X.columns,\n                           feature=feat_name)\npdp.pdp_plot(pdp_dist, feat_name)\nplt.show()\n\n```", "```py\ncompared_features = ['sqft_living', 'grade']\ninter = pdp.pdp_interact(model=model, \n                          dataset=X, \n                          model_features=X.columns, \n                          features=compared_features)\npdp.pdp_interact_plot(pdp_interact_out=inter,\n                      feature_names=compared_features),\n                      plot_type='contour')\nplt.show()\n\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(data)\ntransformed_data = scaler.transform(data)\n\n```", "```py\ndata = scaler.inverse_transform(output_data)\n\n```", "```py\nfrom sklearn.preprocessing import Normalizer\nnormalize = Normalizer()\ntransformed_data = normalize.fit_transform(data)\n\n```", "```py\nfrom sklearn.preprocessing import PowerTransformer\ntransformer = PowerTransformer(method='box-cox')\ntransformed_data = transformer.fit_transform(data)\n\n```"]