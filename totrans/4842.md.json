["```py\n\nimport argparse\n\nparser = argparse.ArgumentParser(description='')\nparser.add_argument('--epoch', dest='nb_epoch', type=int, default=5000, help='# of epochs')\nparser.add_argument('--learning_rate', dest='lr', type=float, default=0.0001, help='# learning rate')\nparser.add_argument('--sample_size', dest='sample_size', type=int, default=60, help='# sample size')\nparser.add_argument('--gen_hidden', dest='gen_hidden', type=int, default=80, help='# hidden nodes in generator')\nparser.add_argument('--disc_hidden', dest='disc_hidden', type=int, default=80, help='# hidden nodes in discriminator')\nparser.add_argument('--your_login', dest='your_login', type=str, default='rubens', help='# your login name')\n\nargs = vars(parser.parse_args())\n\n```", "```py\n\nvar0 = input(\"Are you using Linux? [y|n]\")\n\nif str(var0)=='n':\n        logs_path = 'C:/Users/'+args['your_login']+'/Anaconda3/envs/Scripts/plot_1'\n    else:\n        logs_path = '/home/'+args['your_login']+'/anaconda3/envs/plot_1'\n\n```", "```py\n\ndef GAN(sample_size):\n\n    tf.reset_default_graph() \n    def generator(x, reuse=False):\n        with tf.variable_scope('Generator', reuse=reuse):\n            x = tf.layers.dense(x, units=6 * 6 * 64)\n            x = tf.nn.relu(x)\n            x = tf.reshape(x, shape=[-1, 6, 6, 64])\n            x = tf.layers.conv2d_transpose(x, 32, 4, strides=2)\n            x = tf.layers.conv2d_transpose(x, 1, 2, strides=2)\n            x = tf.nn.relu(x)\n            x = tf.reshape(x, [n,784])\n            return x\n\n    def discriminator(x, reuse=False):\n        with tf.variable_scope('Discriminator', reuse=reuse):\n            x = tf.reshape(x, [n,28,28,1])\n            x = tf.layers.conv2d(x, 32, 5)\n            x = tf.nn.relu(x)\n            x = tf.layers.average_pooling2d(x, 2, 2,padding='same')\n            x = tf.layers.conv2d(x, 64, 5,padding='same')\n            x = tf.nn.relu(x)\n            x = tf.layers.average_pooling2d(x, 8, 8)\n            x = tf.contrib.layers.flatten(x)\n            x = tf.layers.dense(x, 784)\n            x = tf.nn.sigmoid(x)\n        return x\n```", "```py\n\ntf.summary.scalar(\"Generator_Loss\", gen_loss)\ntf.summary.scalar(\"Discriminator_Loss\", disc_loss)\n\n```", "```py\n\ntf.summary.image('GenSample', tf.reshape(gen_sample, [-1, 28, 28, 1]), 4)\ntf.summary.image('stacked_gan', tf.reshape(stacked_gan, [-1, 28, 28, 1]), 4)\n\n```", "```py\n\nfor i in range(0,11):\n    with tf.name_scope('layer'+str(i)):\n        pesos=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n        tf.summary.histogram('pesos'+str(i), pesos[i])\n\n```", "```py\n\nwith tf.Session() as sess:\n    sess.run(init)\n    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n    for i in range(1, num_steps+1):\n        batch_x, batch_y=next_batch(batch_size, x_train\n                                    , x_train_noisy)        \n        feed_dict = {real_image_input: batch_x, noise_input: batch_y,\n                     disc_target: batch_x, gen_target: batch_y}\n        _, _, gl, dl,summary2 = sess.run([train_gen, train_disc, gen_loss, disc_loss,summary],\n                                feed_dict=feed_dict)\n        g = sess.run([stacked_gan], feed_dict={noise_input: batch_y})\n        h = sess.run([gen_sample], feed_dict={noise_input: batch_y})\n        summary_writer.add_summary(summary2, i)\n        if i % show_steps == 0 or i == 1:\n            print('Epoch %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))\n\n```", "```py\n\nif __name__ == '__main__':\n   GAN(args[‘sample_size’])\n```", "```py\n\n$ git clone https://github.com/RubensZimbres/GAN-Project-2018\n\n$ cd GAN-Project-2018\n\n$ conda install --yes --file requirements.txt\n\n$ python main.py --epoch=4000 --learning_rate=0.0001 –your_login=rubens\n\n```", "```py\n\nArguments:\n--epoch: default=5000\n--learning_rate: default=0.0001\n--sample_size: default=60\n--gen_hidden: # hidden nodes in generator: default=80\n--disc_hidden: # hidden nodes in discriminator: default=80\n--your_login: your login in your OS: default:rubens\n\n```", "```py\n\nnum_steps = args['nb_epoch']\nlearning_rate1=args['lr']\nimage_dim = 784 \ngen_hidden_dim = args['gen_hidden']\ndisc_hidden_dim = args['disc_hidden']\n\n```", "```py\n\nos.system('tensorboard –logdir='+logs_path)\n```"]