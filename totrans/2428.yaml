- en: A Simple Guide to Machine Learning Visualisations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/04/simple-guide-machine-learning-visualisations.html](https://www.kdnuggets.com/2022/04/simple-guide-machine-learning-visualisations.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/ad2eca1e3eec3967c7ed1edf0895eed3.png)'
  prefs: []
  type: TYPE_IMG
- en: Residual plot. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: An important step in developing machine learning models is to evaluate the performance.
    Depending on the type of machine learning problem that you are dealing with, there
    is generally a choice of metrics to choose from to perform this step.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: However, simply looking at one or two numbers in isolation cannot always enable
    us to make the right choice for model selection. For example, a single error metric
    doesn’t give us any information about the distribution of the errors. It does
    not answer questions like is the model wrong in a big way a small number of times,
    or is it producing lots of smaller errors?
  prefs: []
  type: TYPE_NORMAL
- en: It is essential to also inspect the model performance visually, as a chart or
    graph can reveal information we may otherwise miss from observing a single metric.
  prefs: []
  type: TYPE_NORMAL
- en: '[Yellowbrick](https://www.scikit-yb.org/en/latest/) is a Python library dedicated
    to making it easy to create rich visualisations for machine learning models developed
    using [Scikit-learn](https://scikit-learn.org/stable/).'
  prefs: []
  type: TYPE_NORMAL
- en: In the following article, I will give an introduction to this handy machine
    learning tool and provide code samples to create some of the most common machine
    learning visualisations.
  prefs: []
  type: TYPE_NORMAL
- en: Confusion Matrix
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A confusion matrix is a simple way to visually evaluate how often the predictions
    from a classifier are right.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the confusion matrix I am using a dataset known as ‘diabetes’.
    This dataset consists of a number of features for patients such as body mass index,
    2-Hour serum insulin measurements and age, and a column indicating if the patient
    has tested positive or negative for diabetes. The aim is to use this data to build
    a model that can predict a positive diabetes result.
  prefs: []
  type: TYPE_NORMAL
- en: The below code imports this dataset via the Scikit-learn API.
  prefs: []
  type: TYPE_NORMAL
- en: In a binary classification problem, there can be four potential outcomes for
    a prediction that the model makes.
  prefs: []
  type: TYPE_NORMAL
- en: '**True positive:** The model has **correctly** predicted the positive outcome,
    e.g. the patient''s diabetes test was positive and the model prediction was positive.'
  prefs: []
  type: TYPE_NORMAL
- en: '**False-positive:** The model has **incorrectly** predicted the positive outcome,
    e.g. the patient''s diabetes test was negative but the model prediction was positive.'
  prefs: []
  type: TYPE_NORMAL
- en: '**True negative:** The model has **correctly** predicted the negative outcome,
    e.g. the patient''s diabetes test was negative and the model prediction was negative.'
  prefs: []
  type: TYPE_NORMAL
- en: '**False-negative:** The model has **incorrectly** predicted the negative outcome,
    e.g. the patient''s diabetes test was positive but the model prediction was negative.'
  prefs: []
  type: TYPE_NORMAL
- en: The confusion matrix visualises the count of each of these possible outcomes
    in a grid. The below code uses the Yellowbrick ConfusionMatrix visualiser to generate
    a confusion matrix for the model.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/6a41109335f5e3a03d774ed006d491ce.png)'
  prefs: []
  type: TYPE_IMG
- en: Confusion matrix. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: ROC Curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The initial output of a classifier is not a label, instead, it is the probability
    that a particular observation belongs to a certain class.
  prefs: []
  type: TYPE_NORMAL
- en: This probability is then turned into a class by selecting a threshold. For example,
    we might say that if the probability of the patient testing positive is above
    0.5 then we assign the positive label.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the model, data and use case, we may choose a threshold to optimise
    for a particular outcome. In the diabetes example, missing a positive result could
    potentially be life-threatening so we would want to minimise the false negatives.
    Changing the threshold for a classifier is one way to optimise this outcome, and
    the ROC curve is one way to visualise this trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: The code below uses Yellowbrick to construct a ROC curve.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/0284deff5900162eddc40e2e3a1695a1.png)'
  prefs: []
  type: TYPE_IMG
- en: ROC curve. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The ROC curve plots the true positive rate against the false-positive rate.
    Using this we can evaluate the impact of lowering or raising the classification
    threshold.
  prefs: []
  type: TYPE_NORMAL
- en: Precision-Recall Curves
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ROC curves are not always the best way to evaluate a classifier. If the class
    is imbalanced (one class has many more observations compared to another) the results
    of a ROC curve can be misleading.
  prefs: []
  type: TYPE_NORMAL
- en: The precision-recall curve is often a better choice in these situations.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s quickly recap what we mean by precision and recall.
  prefs: []
  type: TYPE_NORMAL
- en: '**Precision** measures how good the model is at correctly identifying the positive
    class. In other words out of all predictions for the positive class how many were
    actually correct?'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recall** tell us how good the model is at correctly predicting **all** the
    positive observations in the dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: There is often a trade-off between precision and recall. You may increase precision
    at the expense of decreasing recall for example.
  prefs: []
  type: TYPE_NORMAL
- en: A precision-recall curve displays this trade-off at different classification
    thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: The code below uses the Yellowbrick library to generate a precision-recall curve
    for the diabetes classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/a563822c4ad11c893f50bfe4d2f3d6e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Precision-recall curve. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: Intercluster Distance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Yellowbrick library also contains a set of visualisation tools for analysing
    clustering algorithms. A common way to evaluate the performance of clustering
    models is with an intercluster distance map.
  prefs: []
  type: TYPE_NORMAL
- en: The intercluster distance map plots an embedding of each cluster centre and
    visualises both the distance between the clusters and the relative size of each
    cluster based on membership.
  prefs: []
  type: TYPE_NORMAL
- en: We can turn the diabetes dataset into a clustering problem by only using the
    features (X).
  prefs: []
  type: TYPE_NORMAL
- en: Before we cluster the data we can use the popular elbow method to find the optimal
    number of clusters. Yellowbrick has a method for this.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/3b42e140a3ce6ffb0803f67d3061f1bc.png)'
  prefs: []
  type: TYPE_IMG
- en: Elbow method. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: The elbow curve suggests that two clusters are optimal.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s plot the inter-cluster map for the dataset, choosing two clusters.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/80473aa0345a1b9fe6584bd96b466349.png)'
  prefs: []
  type: TYPE_IMG
- en: Intercluster distance map. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: We can see from this that there is a lot of separation between the two clusters.
    The membership suggests that there is one cluster that has 165 observations and
    another with 603\. This is quite close to the balance of the two classes in the
    diabetes dataset which is 268 and 500 observations each.
  prefs: []
  type: TYPE_NORMAL
- en: Residuals Plot
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regression-based machine learning models have their own set of visualisations.
    Yellowbrick also provides support for these.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate the visualisations for regression problems we will use a variation
    on the diabetes dataset which can be obtained via the Scikit-learn API. This dataset
    has similar features to the one used earlier in this article, but the target is
    a quantitative measure of disease progression one year after baseline.
  prefs: []
  type: TYPE_NORMAL
- en: In regression, visualising the residuals is one method to analyse the performance
    of the model. The residuals are the difference between the observed value and
    the value predicted by the model. They are one way to quantify the error in a
    regression model.
  prefs: []
  type: TYPE_NORMAL
- en: The code below produces a residual plot for a simple regression model.
  prefs: []
  type: TYPE_NORMAL
- en: '![A Simple Guide to Machine Learning Visualisations](../Images/7784d09fedf565024201182e88143653.png)'
  prefs: []
  type: TYPE_IMG
- en: Residual plot. Image by Author.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other available visualisations for regression-based models from the Yellowbrick
    library include:'
  prefs: []
  type: TYPE_NORMAL
- en: Prediction error plot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alpha selection.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cook’s distance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Yellowbrick Python library offers a lightning-fast way to create machine
    learning visualisations for models developed using Scikit-learn. In addition to
    the visualisations for evaluating model performance, Yellowbrick also has [tools](https://www.scikit-yb.org/en/latest/api/model_selection/index.html) for
    visualising cross-validation, learning curves and feature importances. Additionally,
    it provides functionality for [text modelling](https://www.scikit-yb.org/en/latest/api/text/index.html) visualisations.
  prefs: []
  type: TYPE_NORMAL
- en: As described in the article single evaluation metrics models can be useful,
    and in some cases, if you have a simple problem and are comparing different models
    it might be sufficient. However, more often than not, creating a visualisation
    for model performance is an important additional step to obtaining a true understanding
    of how effective a machine learning model is.
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to read more about single evaluation metrics I have previously
    written an article covering evaluation metrics for classification and another
    for regression.
  prefs: []
  type: TYPE_NORMAL
- en: '***   [8 Metrics to Measure Classification Performance](https://towardsdatascience.com/8-metrics-to-measure-classification-performance-984d9d7fd7aa)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3 Evaluation Metrics for Regression](https://towardsdatascience.com/3-evaluation-metrics-for-regression-80cb34cee0e8)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**[Rebecca Vickery](https://www.linkedin.com/in/rebecca-vickery/)** is a Data
    Scientist with extensive experience of data analysis, machine learning and data
    engineering. 12 years experience SQL, 4+ years Python, R, Apache Airflow and Google
    Analytics.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/a-simple-guide-to-machine-learning-visualisations-6c808ac925dd).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Simple Salary Guide for Tech Experts 2022](https://www.kdnuggets.com/2022/07/simple-salary-guide-tech-experts-2022.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Personalized AI Made Simple: Your No-Code Guide to Adapting GPTs](https://www.kdnuggets.com/personalized-ai-made-simple-your-no-code-guide-to-adapting-gpts)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Simple Guide to Running LlaMA 2 Locally](https://www.kdnuggets.com/a-simple-guide-to-running-llama-2-locally)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Simple and Fast Data Streaming for Machine Learning Projects](https://www.kdnuggets.com/2022/11/simple-fast-data-streaming-machine-learning-projects.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Made Simple for Data Analysts with BigQuery ML](https://www.kdnuggets.com/machine-learning-made-simple-for-data-analysts-with-bigquery-ml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
