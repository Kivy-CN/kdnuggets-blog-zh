- en: 'Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique](https://www.kdnuggets.com/parallel-processing-in-prompt-engineering-the-skeleton-of-thought-technique)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Parallel Processing in Prompt Engineering: The Skeleton-of-Thought Technique](../Images/70a8efecb730ab3d06fda0aab1695595.png)'
  prefs: []
  type: TYPE_IMG
- en: Image created by Author with Midjourney
  prefs: []
  type: TYPE_NORMAL
- en: Key Takeaways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Skeleton-of-Thought (SoT) is an innovative prompt engineering technique that
    minimizes generation latency in Large Language Models (LLMs), enhancing their
    efficiency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By creating a skeleton of the answer and then parallelly elaborating on each
    point, SoT emulates human thinking, promoting more reliable and on-target AI responses
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing SoT in projects can significantly expedite problem-solving and
    answer generation, especially in scenarios demanding structured and efficient
    output from AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: SoT is an initial attempt at data-centric optimization for efficiency, and reveal
    the potential of pushing LLMs to think more like a human for answer quality.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prompt engineering is ground zero in the battle for leveraging the potential
    of generative AI. By devising effective prompts, and prompt-writing methodologies,
    we can guide AI in understanding the user's intentions and addressing these intentions
    effectively. One notable technique in this realm is the [Chain-of-Thought](https://www.kdnuggets.com/2023/07/power-chain-thought-prompting-large-language-models.html)
    (CoT) method, which instructs the generative AI model to elucidate its logic step-by-step
    while approaching a task or responding to a query. Building upon CoT, a new and
    promising technique called [Skeleton-of-Thought](https://arxiv.org/abs/2307.15337)
    (SoT) has emerged, which aims to refine the way AI processes and outputs information,
    in the hopes of consequently promoting more reliable and on-target responses.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Skeleton-of-Thought
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The genesis of Skeleton-of-Thought arises from the endeavor to minimize the
    generation latency inherent in large language models (LLMs). Unlike the sequential
    decoding approach, SoT emulates human thinking by first generating an answer's
    skeleton, then filling in the details in parallel, speeding up the inference process
    significantly​. When compared to CoT, SoT not only encourages a structured response
    but also efficiently organizes the generation process for enhanced performance
    in generative text systems.
  prefs: []
  type: TYPE_NORMAL
- en: '![SoT process depicted](../Images/307200c4823f5be0707a533f7e1b00ba.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1**: The Skeleton-of-Thought process (from [Skeleton-of-Thought: Large
    Language Models Can Do Parallel Decoding](https://arxiv.org/abs/2307.15337))'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing Skeleton-of-Thought
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As mentioned above, implementing SoT entails prompting the LLM to create a skeleton
    of the problem-solving or answer-generating process, followed by parallel elaboration
    on each point. This method can be particularly useful in scenarios requiring efficient
    and structured output from AI. For instance, when processing large datasets or
    answering complex queries, SoT can significantly expedite the response time, providing
    a streamlined workflow. By integrating SoT into existing prompt engineering strategies,
    prompt engineers can harness the potential of generative text more effectively,
    reliably, and quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the best way to demonstrate SoT is by example prompts.
  prefs: []
  type: TYPE_NORMAL
- en: Example 1
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Question**: Describe the process of photosynthesis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Skeleton**: Photosynthesis occurs in plants, involves converting light energy
    to chemical energy, creating glucose and oxygen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Point-expansion**: Elaborate on light absorption, chlorophyll''s role, the
    Calvin cycle, and oxygen release.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Example 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Question**: Explain the causes of the Great Depression.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Skeleton**: The Great Depression was caused by stock market crash, bank failures,
    and reduced consumer spending.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Point-expansion**: Delve into Black Tuesday, the banking crisis of 1933,
    and the impact of reduced purchasing power.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These examples demonstrate how SoT prompts facilitate a structured, step-by-step
    approach to answering complex questions. It also shows the workflow: pose a question
    or define a goal, give the LLM a broad or inclusive answer from which to elaborate
    supportive reasoning backward from, and then explicitly present those supportive
    reasoning issues and ask specifically prompt it to do so.'
  prefs: []
  type: TYPE_NORMAL
- en: '![XXX](../Images/4a81acb4e5bcaf7bdff079f5647fea03.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2**: The Skeleton-of-Though simplified process (Image by Author)'
  prefs: []
  type: TYPE_NORMAL
- en: While SoT offers a structured approach to problem-solving, it may not be suitable
    for all scenarios. Identifying the right use cases and understanding its implementation
    are important. Moreover, the transition from sequential to parallel processing
    might require a shift in system design or additional resources. However, overcoming
    these hurdles can unveil the potential of SoT in enhancing the efficiency and
    reliability of generative text tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The SoT technique, building on the CoT method, offers a new approach in prompt
    engineering. It not only expedites the generation process but also fosters a structured
    and reliable output. By exploring and integrating SoT in projects, practitioners
    can significantly enhance the performance and usability of generative text, driving
    towards more efficient and insightful solutions.
  prefs: []
  type: TYPE_NORMAL
- en: '[**Matthew Mayo**](https://www.linkedin.com/in/mattmayo13/) ([**@mattmayo13**](https://twitter.com/mattmayo13))
    holds a Master''s degree in computer science and a graduate diploma in data mining.
    As Editor-in-Chief of KDnuggets, Matthew aims to make complex data science concepts
    accessible. His professional interests include natural language processing, machine
    learning algorithms, and exploring emerging AI. He is driven by a mission to democratize
    knowledge in the data science community. Matthew has been coding since he was
    6 years old.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Parallel Processing Large File in Python](https://www.kdnuggets.com/2022/07/parallel-processing-large-file-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News, July 20: Machine Learning Algorithms Explained in…](https://www.kdnuggets.com/2022/n29.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Automating the Chain of Thought: How AI Can Prompt Itself to Reason](https://www.kdnuggets.com/2023/07/automating-chain-of-thought-ai-prompt-itself-reason.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Art of Prompt Engineering: Decoding ChatGPT](https://www.kdnuggets.com/2023/06/art-prompt-engineering-decoding-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Some Kick Ass Prompt Engineering Techniques to Boost our LLM Models](https://www.kdnuggets.com/some-kick-ass-prompt-engineering-techniques-to-boost-our-llm-models)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Prompt Engineering is a Fad](https://www.kdnuggets.com/why-prompt-engineering-is-a-fad)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
