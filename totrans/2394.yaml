- en: K-nearest Neighbors in Scikit-learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-learn中的K-最近邻
- en: 原文：[https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)
- en: '![K-nearest Neighbors in Scikit-learn](../Images/617f62294b09863e60149f470d2d8903.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Scikit-learn中的K-最近邻](../Images/617f62294b09863e60149f470d2d8903.png)'
- en: '[Nina Strehl](https://unsplash.com/@ninastrehl) via Unsplash'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nina Strehl](https://unsplash.com/@ninastrehl) via Unsplash'
- en: K-nearest neighbors (KNN) is a type of supervised learning machine learning
    algorithm and can be used for both regression and classification tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: K-最近邻（KNN）是一种监督学习的机器学习算法，可用于回归和分类任务。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速入门网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: A supervised machine learning algorithm is dependent on labeled input data which
    the algorithm learns on and uses its learnt knowledge to produce accurate outputs
    when unlabeled data is inputted.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一种监督式机器学习算法依赖于有标签的输入数据，算法在这些数据上进行学习，并利用学到的知识在输入未标记数据时生成准确的输出。
- en: The use of KNN is to make predictions on the test data set based on the characteristics
    (labeled data) of the training data. The method used to make these predictions
    is by calculating the distance between the test data and training data, assuming
    that similar characteristics or attributes of the data points exist within close
    proximity.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: KNN的使用是根据训练数据的特征（有标签的数据）对测试数据集进行预测。进行这些预测的方法是通过计算测试数据和训练数据之间的距离，假设数据点的相似特征或属性存在于接近的范围内。
- en: It allows us to identify and assign the category of the new data whilst taking
    into consideration its characteristics based on learned data points from the training
    data. These characteristics of the new data point will be learned by the KNN algorithm
    and based on its proximity to other data points, it will be categorized.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 它允许我们在考虑新数据点的特征的基础上，识别并分配新数据的类别，这些特征是基于训练数据中的学习数据点。这些新数据点的特征将被KNN算法学习，并根据其与其他数据点的接近程度进行分类。
- en: Why is KNN a Good Algorithm?
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么KNN是一个好的算法？
- en: KNN is a good algorithm to use, specifically for classification tasks. Classification
    is a typical task that a lot of Data Scientists and Machine Learning engineers
    come across. It solves a lot of real world problems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: KNN特别适用于分类任务。分类是许多数据科学家和机器学习工程师遇到的典型任务，它解决了许多现实世界的问题。
- en: Therefore, algorithms such as KNN are a good and accurate choice of algorithm
    to be used for pattern classification and regression models. KNN has been known
    not to make any assumptions about the data, leading to higher accuracy than other
    classification algorithms. The algorithm is also easy to implement and interpretable.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，像KNN这样的算法是用于模式分类和回归模型的好且准确的选择。KNN被认为不会对数据做任何假设，因此比其他分类算法具有更高的准确性。该算法也容易实现且易于解释。
- en: The ‘k’ in KNN
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: KNN中的“k”
- en: The ‘K’ in KNN is a parameter that refers to the number of nearest neighbors,
    where the K-value essentially creates an environment for the data points to understand
    its similarities based on proximity. Using the K-value, we compute the distance
    between the test data points and the trained labeled points to better categorize
    the new data points.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: KNN中的“K”是一个参数，指的是最近邻的数量，其中K值本质上创建了一个环境，使数据点根据接近程度理解其相似性。使用K值，我们计算测试数据点与已训练标签点之间的距离，以更好地对新数据点进行分类。
- en: The K-value is a positive integer which is typically small in value with a recommendation
    that it be an odd number. When the K-value is small, the error rate decreases,
    with a low bias but a high variance which leads to overfitting of the model.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: K值是一个正整数，通常值较小，推荐为奇数。当K值较小时，误差率下降，偏差较低但方差较高，这会导致模型过拟合。
- en: How do you Calculate the Distance Between the Data Points?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何计算数据点之间的距离？
- en: 'KNN is a distance-based algorithm, with the most common methods used being:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: KNN是一种基于距离的算法，最常用的方法包括：
- en: Euclidean and Manhattan for continuous data
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连续数据的欧氏距离和曼哈顿距离
- en: Hamming distance for categorical data
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类别数据的汉明距离
- en: Euclidean Distance is the mathematical distance between two points within Euclidean
    space using the length of a line between the two points. This is the most well
    known distance metric and a lot of people will remember it from school from Pythagoras
    Theorem.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 欧氏距离是欧几里得空间中两点之间的数学距离，使用两点之间的线段长度。这是最常见的距离度量，许多人会从学校的毕达哥拉斯定理中记住它。
- en: Manhattan Distance is the mathematical distance between two points, which is
    the sum of the absolute difference of their Cartesian coordinates. In simple terms,
    the movement of direction between the distance can only be top, bottom and sideways.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 曼哈顿距离是两点之间的数学距离，即其笛卡尔坐标的绝对差的总和。简单来说，距离的移动方向只能是上下和左右。
- en: Hamming distance compares two binary data strings and then compares these two
    string inputs to find the number of different characters in each position of the
    string.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 汉明距离比较两个二进制数据字符串，然后比较这两个字符串输入以找到每个位置字符的不同数量。
- en: Simple KNN Algorithm Steps
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单的KNN算法步骤
- en: These are the general steps you need to take for the KNN algorithm
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是KNN算法的一般步骤
- en: Load in your dataset
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载你的数据集
- en: Choose a k-value. You should choose an odd number to avoid a tie.
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个k值。你应该选择一个奇数，以避免出现平局。
- en: Find the distance between the new data point and the neighboring existing trained
    data points.
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算新数据点与邻近的已训练数据点之间的距离。
- en: Assign the new data point to its K nearest neighbor
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将新数据点分配给其K个最近邻
- en: Using sklearn for kNN
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用sklearn进行kNN
- en: neighbours is a package from the sklearn module which you use for nearest neighbor
    classification tasks. This can be used for both unsupervised and supervised learning.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`neighbours`是来自sklearn模块的一个包，用于最近邻分类任务。这可用于无监督学习和有监督学习。'
- en: 'First, you will need to import these libraries:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要导入这些库：
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This is the sklearn neighbors package:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这是sklearn的neighbors包：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'These are the parameters that can be used:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是可以使用的参数：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The distance metric used here in the example is minkowski, however as mentioned
    above there are different distance metrics you can use.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 示例中使用的距离度量是minkowski，但如上所述，你可以使用不同的距离度量。
- en: If you would like to know more about these parameters, click on this [link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于这些参数的信息，请点击这个[链接](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)。
- en: K-nearest Neighbors in Scikit-Learn on the Iris Dataset
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Scikit-Learn中的K近邻在鸢尾花数据集上的应用
- en: Load in the Iris Dataset
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载鸢尾花数据集
- en: 'Import these libraries:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 导入这些库：
- en: '[PRE3]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Import Iris dataset:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 导入鸢尾花数据集：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This is what the dataset should look like by executing df.head():'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 执行`df.head()`后数据集应呈现如下：
- en: '![Iris dataset](../Images/b25c0e8dcb031b95eee8a7dee71ed74f.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![鸢尾花数据集](../Images/b25c0e8dcb031b95eee8a7dee71ed74f.png)'
- en: Preprocessing of Dataset
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据集预处理
- en: The next step is to split the dataset based on attributes and labels. The class
    column is considered out labels and is referred to as y, where the first 4 columns
    are attributes and will be referred to as X
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是根据属性和标签拆分数据集。类别列被视为标签，称为y，而前4列是属性，称为X。
- en: '[PRE5]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Train/Test split
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练/测试划分
- en: Using a train/test split on our dataset will help us to better understand how
    well our algorithm performs on unseen data/testing phase. It also helps with reducing
    overfitting from occurring.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 对数据集进行训练/测试划分将帮助我们更好地了解算法在未见数据/测试阶段的表现。这也有助于减少过拟合的发生。
- en: '[PRE6]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Feature Scaling
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征缩放
- en: Feature scaling is an important step before executing your model to start making
    predictions. It involves rescaling the features in a common boundary so that no
    information about each of the data points is lost. Without this, your model could
    possibly make wrong predictions.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 特征缩放是在执行模型以开始进行预测之前的重要步骤。它涉及将特征重新缩放到一个共同的边界，以确保不丢失关于每个数据点的信息。否则，你的模型可能会做出错误的预测。
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Make Your Prediction
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进行预测
- en: This is where we will use the neighbors package from the sklearn module. As
    you can see, we have chosen our number of neighbors (K-value) as 5.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们将使用 sklearn 模块中的邻居包的地方。如你所见，我们已将邻居数量（K 值）选择为 5。
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now we want to make a prediction on the test dataset:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们想对测试数据集进行预测：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Evaluating Your Algorithm
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 评估你的算法
- en: The most typical metrics used for evaluating your algorithm are confusion matrix,
    precision, recall and f1 score.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 用于评估你算法的最典型指标是混淆矩阵、精确度、召回率和 F1 分数。
- en: '[PRE10]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is the output:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出：
- en: '![code output](../Images/4e1a093c224913a29143f850e70b107a.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![代码输出](../Images/4e1a093c224913a29143f850e70b107a.png)'
- en: Conclusion
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: So we’ve come to understand that KNN is a good algorithm to use for classification
    tasks and that the neighbors package in Scikit-learn can make it all so much easier.
    It is very simple and easy to implement with a flexibility to feature/distance
    choices. It has the ability to handle multi-class cases and it can effectively
    produce accurate outputs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们已经了解到 KNN 是一个适用于分类任务的良好算法，并且 Scikit-learn 中的邻居包可以使一切变得更加简单。它实现起来非常简单且容易，并且具有特征/距离选择的灵活性。它能够处理多类情况，并且可以有效地生成准确的输出。
- en: But there are some things you need to take into consideration when it comes
    to KNN. Determining the k-value can be difficult, because it can be the difference
    between causing overfitting or not. It can also be a matter of trial and error
    when determining which distance metric you should use.KNN also has a high computational
    cost as we compute the distances between the new data point and the training data
    points. With this being said, the KNN algorithm slows down as the number of examples
    and variables increases
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 但在使用 KNN 时，你需要考虑一些问题。确定 k 值可能很困难，因为这可能会导致过拟合或避免过拟合。确定应使用哪个距离度量也可能是一个反复试验的过程。KNN
    的计算成本也很高，因为我们要计算新数据点和训练数据点之间的距离。正因为如此，随着示例和变量数量的增加，KNN 算法会变慢。
- en: Although it is one of the oldest and well used classification algorithms out
    there, you need to consider the con as well.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是最古老且使用广泛的分类算法之一，但你仍然需要考虑其缺点。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一位数据科学家和自由技术作家。她特别关注提供数据科学职业建议或教程，以及围绕数据科学的理论知识。她还希望探索人工智能如何能够改善人类寿命。她是一个热衷学习的人，寻求扩展她的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[From Theory to Practice: Building a k-Nearest Neighbors Classifier](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从理论到实践：构建 k-最近邻分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)'
- en: '[Nearest Neighbors for Classification](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分类的最近邻](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)'
