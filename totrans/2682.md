# 处理机器学习中的不平衡数据

> 原文：[https://www.kdnuggets.com/2020/10/imbalanced-data-machine-learning.html](https://www.kdnuggets.com/2020/10/imbalanced-data-machine-learning.html)

[comments](#comments)

作为 ML 工程师或数据科学家，你有时不可避免地会发现自己处于这样一种情况：一个类标签有数百条记录，而另一个类标签有数千条记录。

在训练模型后，你的准确度超过 90%。然后你会发现模型预测一切都像是属于记录最多的那个类别。这在欺诈检测问题和流失预测问题中尤为明显，其中大多数记录都在负类中。在这种情况下你该怎么办？这将是本文的重点。

### 收集更多数据

最直接明显的做法是收集更多的数据，特别是少数类的数据点。这将显著改善模型的性能。然而，这并不总是可能的。除了需要花费的成本，有时收集更多的数据也是不可行的。例如，在流失预测和欺诈检测的情况下，你不能仅仅等待更多事件发生，以便收集更多数据。

### 考虑准确率以外的指标

精确度不是衡量类别标签不平衡模型性能的好方法。在这种情况下，考虑其他指标，如精确率、召回率、曲线下面积（AUC）——仅举几例。

**精确率** 衡量在所有被预测为正例的样本中，真正的正例与假正例的比例。例如，我们的模型预测会流失的用户中，有多少人实际上确实流失了？

![Image for post](../Images/8c8a6e75ec765f13c71b170a739268d0.png)

**召回率** 衡量真正正例与真正正例和假负例之和的比例。例如，我们的模型预测会流失的人中，实际流失的百分比。

![Image for post](../Images/d9823a244fcef9c52f95a711414e44ad.png)

AUC 是从接收者操作特征（ROC）曲线获得的。通过绘制真正正例率与假正例率的关系来获得该曲线。假正例率是通过将假正例除以假正例和真正负例之和来获得的。

AUC 越接近 1 越好，因为这表明模型能够找到真正的正例。

### 强调少数类

处理不平衡数据的另一种方法是让模型关注少数类。这可以通过计算类权重来实现。模型将关注权重更高的类。最终，模型将能够平等地从两个类中学习。可以借助 scikit-learn 计算这些权重。

[PRE0]

然后，你可以在训练模型时传递这些权重。例如，在逻辑回归的情况下：

[PRE1]

另外，你可以将类权重设置为`balanced`，权重将自动调整。

[PRE2]

这是调整权重之前的ROC曲线。

![Image for post](../Images/72c19a66abae792bd28fd187eb3cf048.png)

调整权重后的ROC曲线在这里。请注意AUC从0.69移动到了0.87。

![Image for post](../Images/4613bff2ccc6dc6c1ca9df6fcd6f086f.png)

### 尝试不同的算法

当你关注于不平衡数据的正确指标时，也可以尝试不同的算法。一般来说，基于树的算法在不平衡数据上表现更好。此外，一些算法如[LightGBM](https://heartbeat.fritz.ai/lightgbm-a-highly-efficient-gradient-boosting-decision-tree-53f62276de50)具有可调参数，以指示数据不平衡。

### 生成合成数据

你还可以生成[合成数据](https://heartbeat.fritz.ai/synthetic-data-a-bridge-over-the-data-moat-29f392a52f27)来增加少数类的记录数量——通常称为过采样。这通常在训练集上进行，经过训练测试分割后。在Python中，可以使用[Imblearn](https://github.com/scikit-learn-contrib/imbalanced-learn)包来完成。该包中可以实现的一种策略被称为[Synthetic Minority Over-sampling Technique (SMOTE)](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html)。该技术基于k-最近邻。

使用SMOTE时：

+   第一个参数是一个`float`，表示在重新采样后少数类样本数量与多数类样本数量的比例。

+   生成合成样本时使用的邻居数量可以通过`k_neighbors`参数来指定。

[PRE3]

然后你可以将你的重采样数据拟合到模型中。

[PRE4]

### 对多数类进行欠采样

你还可以尝试减少多数类中的样本数量。可以实现的一种策略是`[NearMiss](https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.under_sampling.NearMiss.html)`方法。你还可以像在SMOTE中一样指定比例，并通过`n_neighbors`***来指定邻居的数量。***

[PRE5]

### 最终思考

其他可以使用的技术包括使用建立[一个集成](https://heartbeat.fritz.ai/a-guide-to-ensemble-learning-390027fe38b8)的弱学习器来创建一个强分类器。当正类最重要时，精确率-召回率曲线和曲线下面积（PR, AUC）也是值得尝试的。

像往常一样，你应该尝试不同的技术，并选择那些在特定问题上给你最佳结果的技术。希望这篇文章能为你提供一些如何开始的见解。

**[代码在这里](https://github.com/mwitiderrick/imbalanced-data)**。

**个人简介：德里克·姆维蒂**是一位对分享知识充满热情的数据科学家。他通过Heartbeat、Towards Data Science、Datacamp、Neptune AI、KDnuggets等博客积极贡献于数据科学社区。他的内容在互联网的浏览量超过一百万次。德里克还是一位作者和在线讲师。他还与各种机构合作，实施数据科学解决方案，并提升员工技能。德里克在多媒体大学学习数学和计算机科学，还是Meltwater创业技术学校的校友。如果数据科学、机器学习和深度学习的世界吸引你，你可以查看他的[完整的数据科学与机器学习Python课程](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)。

[原文](https://heartbeat.fritz.ai/dealing-with-imbalanced-data-in-machine-learning-18e45fea7bb5)。已获许可转载。

**相关：**

+   [如何修复不平衡数据集](/2019/05/fix-unbalanced-dataset.html)

+   [处理不平衡数据集的5种最有用的技术](/2020/01/5-most-useful-techniques-handle-imbalanced-datasets.html)

+   [专家提示：如何处理类别不平衡和缺失标签](/2019/11/tips-class-imbalance-missing-labels.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT

* * *

### 更多相关话题

+   [处理文本数据中的噪声标签](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)

+   [处理推荐和搜索中的位置偏差](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)

+   [在类别不平衡数据集上进行无监督解缠表示学习…](https://www.kdnuggets.com/2023/01/unsupervised-disentangled-representation-learning-class-imbalanced-dataset-elastic-infogan.html)

+   [KDnuggets 新闻，8月31日：完整的数据科学学习路线图…](https://www.kdnuggets.com/2022/n35.html)

+   [处理不平衡数据的7种技术](https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html)

+   [克服现实世界中的不平衡数据挑战](https://www.kdnuggets.com/2023/07/overcoming-imbalanced-data-challenges-realworld-scenarios.html)
