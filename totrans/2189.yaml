- en: WTF is Regularization and What is it For?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/wtf-is-regularization-and-what-is-it-for](https://www.kdnuggets.com/wtf-is-regularization-and-what-is-it-for)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![WTF is Regularization and What is it For?](../Images/d39360463487f8003bd583da1523f5d9.png)'
  prefs: []
  type: TYPE_IMG
- en: “An ounce of prevention is worth a pound of cure" goes the old saying, reminding
    us that it's easier to stop something from happening in the first place than to
    repair the damage after it has happened.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In the era of artificial intelligence (AI), this proverb underscores the importance
    of avoiding potential pitfalls, such as overfitting, through techniques like regularization.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we will discover regularization by starting with its fundamental
    principles to its application using Sci-kit Learn(Machine Learning) and Tensorflow(Deep
    Learning) and witness its transformative power with real-world datasets by comparing
    these results. Let’s start!
  prefs: []
  type: TYPE_NORMAL
- en: What is regularization?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Regularization is a critical concept in machine learning and deep learning that
    aims to prevent models from overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting happens when a model learns the training data too well. The situation
    shows your model is too good to be true.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see what overfitting looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![WTF is Regularization and What is it For?](../Images/00ccaf0f05fa34b1cd5866ec402cda5c.png)'
  prefs: []
  type: TYPE_IMG
- en: Regularization techniques adjust the learning process to simplify the model,
    ensuring it performs well on training data and generalizes well to new data. We
    will explore two well-known ways of doing this.
  prefs: []
  type: TYPE_NORMAL
- en: Type of Regularization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In machine learning, regularization is often applied to linear models, such
    as linear and logistic regression. In this context, the most common forms of regularization
    are:'
  prefs: []
  type: TYPE_NORMAL
- en: L1 regularization (Lasso regression)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L2 regularization (Ridge regression)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Lasso Regularization** encourages the model to use only the most essential
    features by allowing some coefficient values to be exactly zero, which can be
    particularly useful for feature selection.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/8c5e1b738e7a4baa7bd1b0ad96b01bb5.png)'
  prefs: []
  type: TYPE_IMG
- en: '![WTF is Regularization and What is it For?](../Images/f00c7b9e37dfd3f73eae01feef99b5a1.png)'
  prefs: []
  type: TYPE_IMG
- en: On the other hand, **Ridge regularization** discourages significant coefficients
    by penalizing the square of their values.
  prefs: []
  type: TYPE_NORMAL
- en: '![Equation](../Images/921975c606833ee14811111d51b36028.png)'
  prefs: []
  type: TYPE_IMG
- en: '![WTF is Regularization and What is it For?](../Images/4a1d226d0650c5dd32dc770b8353f0e9.png)'
  prefs: []
  type: TYPE_IMG
- en: In short, they calculated differently.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s apply these to the cardiac patient data to see its power In deep learning
    and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Power of Regularization: Analyzing Cardiac Patient Data'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, we will apply regularization to analyze cardiac patient data to see the
    power of regularization. You can reach the dataset from [here](https://www.kaggle.com/datasets/arezaei81/heartcsv?resource=download).
  prefs: []
  type: TYPE_NORMAL
- en: To apply machine learning, we will use Scikit-learn; to apply deep learning,
    we will use TensorFlow. Let's start!
  prefs: []
  type: TYPE_NORMAL
- en: Regularization in Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scikit-learn is one of the most popular [Python libraries](https://www.stratascratch.com/blog/top-18-python-libraries-a-data-scientist-should-know/?utm_source=blog&utm_medium=click&utm_campaign=kdn+regularization)
    for machine learning that provides simple and efficient data analysis and modeling
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: It includes implementations of various regularization techniques, particularly
    for linear models.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we'll explore how to apply L1 (Lasso) and L2 (Ridge) regularization.
  prefs: []
  type: TYPE_NORMAL
- en: In the following code, we will train logistic regression using Ridge(L2) and
    Lasso regularization (L1) techniques. At the end, we will see the detailed report.
    Let’s see the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![WTF is Regularization and What is it For?](../Images/e9a18c84b34123f686942ea4dc3a6e64.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s evaluate the result.
  prefs: []
  type: TYPE_NORMAL
- en: L1 Regularization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At C=0.001, accuracy is notably low (48%). This shows that the model is underfitting.
    It shows too much regularization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As C increases to 0.01, accuracy remains unchanged for L1, suggesting that the
    model still suffers from underfitting or the regularization is too strong.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At C=0.1, accuracy improves significantly to 87%, showing that reducing the
    regularization strength allows the model to learn better from the data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: L2 Regularization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Across the board, L2 regularization performs consistently well, with accuracy
    at 87% for C=0.001 and slightly higher at 89% for C=0.01, then stabilizing at
    87% for C=0.1.
  prefs: []
  type: TYPE_NORMAL
- en: This suggests that L2 regularization is generally more forgiving and effective
    for this dataset in logistic regression models, potentially due to its nature.
  prefs: []
  type: TYPE_NORMAL
- en: Regularization in Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several regularization techniques are used in deep learning, including L1 (Lasso)
    and L2 (Ridge) regularization, dropout, and early stopping.
  prefs: []
  type: TYPE_NORMAL
- en: In this one, to repeat what we did in the machine learning example before, we
    will apply L1 and L2 regularization. Let’s define a list of L1 and L2 regularization
    values this time.
  prefs: []
  type: TYPE_NORMAL
- en: Then, for all of these values, we will train and evaluate our deep learning
    model, and at the end, we will assess the results.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see the code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Here is the output.
  prefs: []
  type: TYPE_NORMAL
- en: '![WTF is Regularization and What is it For?](../Images/aed9cbfb94be24b5c3de86e5d681d49d.png)'
  prefs: []
  type: TYPE_IMG
- en: The deep learning model performances vary more widely across different combinations
    of L1 and L2 regularization values.
  prefs: []
  type: TYPE_NORMAL
- en: The best performance is observed at L1=0.01 and L2=0.001, with an accuracy of
    88.5%, which indicates a balanced regularization that prevents overfitting while
    allowing the model to capture the underlying patterns in the data.
  prefs: []
  type: TYPE_NORMAL
- en: Higher regularization values, especially at L1=0.1 or L2=0.1, drastically reduce
    model accuracy to 52.5%, suggesting that too much regularization severely limits
    the model's learning capacity.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning & Deep Learning in Regularization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s compare the results between Machine Learning and Deep Learning.
  prefs: []
  type: TYPE_NORMAL
- en: '**Effectiveness of Regularization**: Both in machine learning and deep learning
    contexts, appropriate regularization helps mitigate overfitting, but excessive
    regularization leads to underfitting. The optimal regularization strength varies,
    with deep learning models potentially requiring a more nuanced balance due to
    their higher complexity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Performance:** The best-performing machine learning model (L2 with C=0.01,
    89% accuracy) and the best-performing deep learning model (L1=0.01, L2=0.001,
    88.5% accuracy) achieve comparable accuracies, demonstrating that both approaches
    can be effectively regularized to achieve high performance on this dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Regularization Strategy:** L2 regularization appears to be more effective
    and less sensitive to the choice of C in logistic regression models, while a combination
    of L1 and L2 regularization provides the best result in deep learning, offering
    a balance between feature selection and weight penalization.'
  prefs: []
  type: TYPE_NORMAL
- en: The choice and strength of regularization should be carefully tuned to balance
    learning complexity with the risk of overfitting or underfitting.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this exploration, we've demystified regularization, showing its role
    in preventing overfitting and ensuring our models generalize well to unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: Applying regularization techniques will bring you closer to proficiency in machine
    learning and deep learning, solidifying your data scientist toolset.
  prefs: []
  type: TYPE_NORMAL
- en: Go into the data projects and try regularizing your data in different scenarios,
    such as [Delivery Duration Prediction](https://platform.stratascratch.com/data-projects/delivery-duration-prediction?utm_source=blog&utm_medium=click&utm_campaign=kdn+regularization).
    We used both Machine Learning and Deep Learning models in this data project. However,
    in the end, we also mentioned that there might be room for improvement. So why
    don’t you try regularization over there and see if it helps?
  prefs: []
  type: TYPE_NORMAL
- en: '[](https://twitter.com/StrataScratch)****[Nate Rosidi](https://twitter.com/StrataScratch)****
    is a data scientist and in product strategy. He''s also an adjunct professor teaching
    analytics, and is the founder of StrataScratch, a platform helping data scientists
    prepare for their interviews with real interview questions from top companies.
    Nate writes on the latest trends in the career market, gives interview advice,
    shares data science projects, and covers everything SQL.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[WTF is the Difference Between GBM and XGBoost?](https://www.kdnuggets.com/wtf-is-the-difference-between-gbm-and-xgboost)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[WTF is a Tensor?!?](https://www.kdnuggets.com/2018/05/wtf-tensor.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Difference Between L1 and L2 Regularization](https://www.kdnuggets.com/2022/08/difference-l1-l2-regularization.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top AI and Data Science Tools and Techniques for 2022 and Beyond](https://www.kdnuggets.com/2022/03/nvidia-0317-top-ai-data-science-tools-techniques-2022-beyond.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Select Rows and Columns in Pandas Using [ ], .loc, iloc, .at…](https://www.kdnuggets.com/2019/06/select-rows-columns-pandas.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
