- en: 5 Different Ways to Load Data in Python
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0a347571eee0ed768118961a39020925.png)'
  prefs: []
  type: TYPE_IMG
- en: As a beginner, you might only know a single way to load data (normally in CSV)
    which is to read it using *p**andas.read_csv* function. It is one of the most
    mature and strong functions, but other ways are a lot helpful and will definitely
    come in handy sometimes.
  prefs: []
  type: TYPE_NORMAL
- en: 'The ways that I am going to discuss are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Manual **function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**loadtxt **function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**genfromtxt** function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**read_csv **function'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pickle**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset that we are going to use to load data can be found [**here**](http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/).
    It is named as 100-Sales-Records.
  prefs: []
  type: TYPE_NORMAL
- en: '**Imports**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will use Numpy, Pandas, and Pickle packages so import them.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 1\. Manual Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is the most difficult, as you have to design a custom function, which can
    load data for you. You have to deal with Python’s normal filing concepts and using
    that you have to read a *.csv* file.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s do that on 100 Sales Records file.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Hmmm, What is this????? Seems a bit complex code!!!! Let’s break it step by
    step so you know what is happening and you can apply similar logic to read a *.csv* file
    of your own.
  prefs: []
  type: TYPE_NORMAL
- en: Here, I have created a *load_csv* a function that takes in as an argument the
    path of the file you want to read.
  prefs: []
  type: TYPE_NORMAL
- en: I have a list named as *data *which is going to have my data of CSV file, and
    another list *col *which is going to have my column names. Now after inspecting
    the csv manually, I know that my column names are in the first row, so in my first
    iteration, I have to store the data of the first row in *col *and rest rows in *data*.
  prefs: []
  type: TYPE_NORMAL
- en: To check the first iteration, I have used a Boolean Variable named as *checkcol *which
    is False, and when it is false in the first iteration, it stores the data of first-line
    in *col *and then it sets *checkcol *to True, so we will deal with *data* list
    and store rest of values in *data* list.
  prefs: []
  type: TYPE_NORMAL
- en: Logic
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main logic here is that I have iterated in the file, using *readlines()* a
    function in Python. This function returns a list that contains all the lines inside
    a file.
  prefs: []
  type: TYPE_NORMAL
- en: When reading through headlines, it detects a new line as *\n* character, which
    is line terminating character, so in order to remove it, I have used *str.replace* function.
  prefs: []
  type: TYPE_NORMAL
- en: As it is a *.csv* file, so I have to separate things based on *commas *so I
    will split the string on a *,* using *string.split(',')*. For the first iteration,
    I will store the first row, which contains the column names in a list known as *col*.
    And then I will append all my data in my list known as *data*.
  prefs: []
  type: TYPE_NORMAL
- en: To read the data more beautifully, I have returned it as a dataframe format
    because it is easier to read a dataframe as compared to a numpy array or python’s
    list.
  prefs: []
  type: TYPE_NORMAL
- en: '**Output**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![XXXXX](../Images/f03b047096fbdb9279487fda55df4680.png)'
  prefs: []
  type: TYPE_IMG
- en: Data from Custom Function.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pros and Cons**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The important benefit is that you have all the flexibility and control over
    the file structure and you can read in whatever format and way you want and store
    it.
  prefs: []
  type: TYPE_NORMAL
- en: You can also read the files which do not have a standard structure using your
    own logic.
  prefs: []
  type: TYPE_NORMAL
- en: Important drawbacks of it are that it is complex to write especially for standard
    types of files because they can easily be read. You have to hard code the logic
    which requires trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: You should only use it when the file is not in a standard format or you want
    flexibility and reading the file in a way that is not available through libraries.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Numpy.loadtxt function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is a built-in function in Numpy, a famous numerical library in Python.
    It is a really simple function to load the data. It is very useful for reading
    data which is of the same datatype.
  prefs: []
  type: TYPE_NORMAL
- en: When data is more complex, it is hard to read using this function, but when
    files are easy and simple, this function is really powerful.
  prefs: []
  type: TYPE_NORMAL
- en: To get the data of a single type, you can download [this](https://docs.google.com/spreadsheets/d/16mgiYbNz-XaW_r6GXUy2cJ0hy2E-lxwFLaVXAYIAOj0/edit?usp=sharing) dummy
    dataset. Let’s jump to code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Here we simply used the *loadtxt *function as passed in *delimeter *as *','* because
    this is a CSV file.
  prefs: []
  type: TYPE_NORMAL
- en: Now if we print *df*, we will see our data in pretty decent numpy arrays that
    are ready to use.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/935fd87bb21b2d7076aaa36908b7c53a.png)'
  prefs: []
  type: TYPE_IMG
- en: We have just printed the first 5 rows due to the big size of data.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pros and Cons**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An important aspect of using this function is that you can quickly load in data
    from a file into numpy arrays.
  prefs: []
  type: TYPE_NORMAL
- en: Drawbacks of it are that you can not have different data types or missing rows
    in your data.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Numpy.genfromtxt()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will use the dataset, which is ‘100 Sales Records.csv’ which we used in our
    first example to demonstrate that we can have multiple data types in it.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s jump to code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: and to see it more clearly, we can just see it in a dataframe format, i.e.,
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/93ddc725447b2fa270c1266adf649ede.png)'
  prefs: []
  type: TYPE_IMG
- en: Wait? What is this? Oh, It has skipped all the columns with string data types.
    How to deal with it?
  prefs: []
  type: TYPE_NORMAL
- en: Just add another *dtype *parameter and set *dtype *to None which means that
    it has to take care of datatypes of each column itself. Not to convert whole data
    to single dtype.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'And then for output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/3247ba2a7d4a9375df900b0bbdd56566.png)'
  prefs: []
  type: TYPE_IMG
- en: Quite better than the first one, but here our Columns titles are Rows, to make
    them column titles, we have to add another parameter which is *names *and set
    it to *True *so it will take the first row as the Column Titles.
  prefs: []
  type: TYPE_NORMAL
- en: i.e.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'and we can print it as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/879d28bfba1322bb92bff7c200cdd2fe.png)'
  prefs: []
  type: TYPE_IMG
- en: And here we can see that It has successfully added the names of columns in the
    dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: Now the last problem is that the columns which are of string data types are
    not the actual strings, but they are in *bytes *format. You can see that before
    every string, we have a *b'* so to encounter them, we have to decode them in utf-8
    format.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This will return our dataframe in the desired form.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/7538bc624a1120c71dda7e8a2ea65797.png)'
  prefs: []
  type: TYPE_IMG
- en: 4\. Pandas.read_csv()
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Pandas is a very popular data manipulation library, and it is very commonly
    used. One of it’s very important and **mature **functions is *read_csv()* which
    can read any **.csv **file very easily and help us manipulate it. Let’s do it
    on our 100-Sales-Record dataset.
  prefs: []
  type: TYPE_NORMAL
- en: This function is very popular due to its ease of use. You can compare it with
    our previous codes, and you can check it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/a1f2478cfae283ced2691eff19112fe5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And guess what? We are done. This was actually so simple and easy to use. Pandas.read_csv
    definitely offers a lot of other parameters to tune in our data set, for example
    in our *convertcsv.csv* file, we had no column names so we can read it as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/36f53da09649fd35f12d2f84d3bf7dec.png)'
  prefs: []
  type: TYPE_IMG
- en: And we can see that it has read the *csv *file without the header. You can explore
    all other parameters in the official docs [here](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html#pandas.read_csv).
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Pickle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When your data is not in a good, human-readable format, you can use pickle to
    save it in a binary format. Then you can easily reload it using the pickle library.
  prefs: []
  type: TYPE_NORMAL
- en: We will take our 100-Sales-Record CSV file and first save it in a pickle format
    so we can read it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This will create a new file *test.pkl* which has inside it our *pdDf *from **Pandas** heading.
  prefs: []
  type: TYPE_NORMAL
- en: Now to open it using pickle, we just have to use *pickle.load* function.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![](../Images/196bc7ff09954d29f60e934e5f3dbc18.png)'
  prefs: []
  type: TYPE_IMG
- en: And here we have successfully loaded data from a pickle file in *pandas.DataFrame *format.
  prefs: []
  type: TYPE_NORMAL
- en: You are now aware of 5 different ways to load data files in Python, which can
    help you in different ways to load a data set when you are working in your day-to-day
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Automated Machine Learning with Python: A Comparison of Different…](https://www.kdnuggets.com/2023/03/automated-machine-learning-python-comparison-different-approaches.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How is Data Mining Different from Machine Learning?](https://www.kdnuggets.com/2022/06/data-mining-different-machine-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learn How Different Data Visualizations Work](https://www.kdnuggets.com/2022/09/datacamp-learn-different-data-visualizations-work.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Transition into Data Science from a Different Background?](https://www.kdnuggets.com/2023/05/transition-data-science-different-background.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interview Kickstart Data Science Interview Course — What Makes It…](https://www.kdnuggets.com/2022/10/interview-kickstart-data-science-interview-course-makes-different.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ultimate Guide To Different Word Embedding Techniques In NLP](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
