- en: 'Machine Learning & Artificial Intelligence: Main Developments in 2016 and Key
    Trends in 2017'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习与人工智能：2016年的主要发展与2017年的关键趋势
- en: 原文：[https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html](https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html](https://www.kdnuggets.com/2016/12/machine-learning-artificial-intelligence-main-developments-2016-key-trends-2017.html)
- en: At KDnuggets, we try to keep our finger on the pulse of main events and developments
    in industry, academia, and technology. We also do our best to look forward to
    key trends on the horizon.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KDnuggets，我们尽力保持对行业、学术界和技术领域主要事件和发展的关注。我们也尽力展望未来的关键趋势。
- en: We recently asked some of the leading experts in Big Data, Data Science, Artificial
    Intelligence, and Machine Learning for their opinion on the most important developments
    of 2016 and key trends they 2017.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最近询问了一些大数据、数据科学、人工智能和机器学习领域的领先专家，他们对2016年的重要发展和2017年的关键趋势发表了意见。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织的IT需求'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'To get up to speed on our first 2 posts published outlining expert opinions,
    see the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解我们发布的前两篇帖子中概述的专家意见，请参见以下内容：
- en: '**[Big Data: Main Developments in 2016 and Key Trends in 2017](/2016/12/big-data-main-developments-2016-key-trends-2017.html)**'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[大数据：2016年的主要发展与2017年的关键趋势](/2016/12/big-data-main-developments-2016-key-trends-2017.html)**'
- en: '**[Data Science & Predictive Analytics: Main Developments in 2016 and Key Trends
    in 2017](/2016/12/data-science-predictive-analytics-main-developments-trends.html)**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[数据科学与预测分析：2016年的主要发展与2017年的关键趋势](/2016/12/data-science-predictive-analytics-main-developments-trends.html)**'
- en: 'In the final post of the series, we bring you the collected responses to the
    question:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在系列文章的最后一篇中，我们带来对以下问题的汇总回应：
- en: '**"What were the main Artificial Intelligence/Machine Learning related events
    in 2016 and what key trends do you see in 2017?"**'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**“2016年主要的人工智能/机器学习相关事件是什么？您认为2017年的关键趋势是什么？”**'
- en: Common themes include the triumphs of deep neural networks, reinforcement learning's
    successes, AlphaGo as exemplar of the power of both of these phenomena in unison,
    the application of machine learning to the Internet of Things, self-driving vehicles,
    and automation, among others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的主题包括深度神经网络的成功、强化学习的成就、AlphaGo 作为这两种现象联合力量的典范、机器学习在物联网、自驾车辆和自动化等方面的应用。
- en: We generally asked participants to keep their responses to within 100 words
    or so, but were amenable to longer answers if the situation warranted. Without
    further delay, here is what we found.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常要求参与者将回答控制在100字左右，但如果情况需要，也乐于接受较长的回答。现在，来看看我们的发现吧。
- en: '![AI/ML experts](../Images/421d900ae8f712837a374838a8b89e49.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![AI/ML专家](../Images/421d900ae8f712837a374838a8b89e49.png)'
- en: '**[Yaser Abu-Mostafa](https://work.caltech.edu/)**, Caltech (in consultation
    with Professor Hsuan-Tien Lin and Professor Malik Magdon-Ismail)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Yaser Abu-Mostafa](https://work.caltech.edu/)**, 加州理工学院（与Hsuan-Tien Lin教授和Malik
    Magdon-Ismail教授协商）'
- en: 2016 and 2017 are an exciting time for [**Machine Learning**](/tag/machine-learning).
    There are two trends that have been accelerating. First, the showcases that prove
    ML to be an extraordinarily powerful technology. The recent successes of [AlphaGo](/tag/alphago)
    and [inhuman encryption](https://techcrunch.com/2016/10/28/googles-ai-creates-its-own-inhuman-encryption/)
    are compelling examples. Second, the expanding reach of ML applications. More
    complex tasks, more domains, and more acceptance of ML as the way to exploit data
    everywhere. The Google/Microsoft/Facebook/IBM AI partnerships are there for a
    reason.
  id: totrans-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年和2017年是[**机器学习**](/tag/machine-learning)的激动人心的时期。有两个趋势在加速发展。首先，展示了机器学习作为一种极其强大的技术的案例。最近，[AlphaGo](/tag/alphago)和[不人性化加密](https://techcrunch.com/2016/10/28/googles-ai-creates-its-own-inhuman-encryption/)的成功就是很有说服力的例子。其次，机器学习应用的扩展范围。更多复杂的任务，更多领域，以及对机器学习作为数据利用方式的更多接受。Google/Microsoft/Facebook/IBM
    的人工智能合作伙伴关系是有原因的。
- en: '**[Xavier Amatriain](https://www.quora.com/topic/Xavier-Amatriain-1)**, VP
    Engineering at Quora'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Xavier Amatriain](https://www.quora.com/topic/Xavier-Amatriain-1)**，Quora
    的工程副总裁'
- en: 2016 may very well go down in history as the year of “the Machine Learning [**hype**](/tag/hype)”.
    Everyone now seems to be doing machine learning, and if they are not, they are
    thinking of buying a startup to claim they do.
  id: totrans-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年可能会被载入历史，成为“机器学习[**炒作**](/tag/hype)”之年。现在似乎每个人都在做机器学习，如果他们没有在做，他们也在考虑收购一家初创公司来声称自己在做。
- en: ''
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Now, to be fair, there are reasons for much of that “hype”. Can you believe
    that it has been only a year since [Google announced](https://research.googleblog.com/2015/11/tensorflow-googles-latest-machine_9.html)
    they were open sourcing [**Tensor Flow**](/tag/tensorflow)? TF is already a very
    active project that is being used for anything ranging from drug discovery to
    [generating music](https://github.com/tensorflow/magenta). Google has not been
    the only company open sourcing their ML software though, many followed lead. [Microsoft
    open sourced CNTK](http://blogs.microsoft.com/next/2016/01/25/microsoft-releases-cntk-its-open-source-deep-learning-toolkit-on-github),
    [Baidu announced the release of PaddlePaddle](http://www.theverge.com/2016/9/1/12725804/baidu-machine-learning-open-source-paddle),
    and Amazon just recently announced that they [will back MXNet](http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html)
    in their new AWS ML platform. Facebook, on the other hand, are basically supporting
    the development of not one, but two Deep Learning frameworks: [Torch](http://torch.ch/)
    and [Caffe](http://caffe.berkeleyvision.org/). On the other hand, Google is also
    supporting the highly successful [Keras](https://github.com/fchollet/keras), so
    things are at least even between Facebook and Google on that front.'
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在，公平地说，这些“炒作”有其原因。你能相信吗，[Google 宣布](https://research.googleblog.com/2015/11/tensorflow-googles-latest-machine_9.html)开源[**Tensor
    Flow**](/tag/tensorflow)才过去了一年？Tensor Flow 已经是一个非常活跃的项目，用于从药物发现到[生成音乐](https://github.com/tensorflow/magenta)的各种应用。然而，Google
    并不是唯一一个开源其机器学习软件的公司，许多公司跟随了这个趋势。[Microsoft 开源了 CNTK](http://blogs.microsoft.com/next/2016/01/25/microsoft-releases-cntk-its-open-source-deep-learning-toolkit-on-github)，[百度宣布了
    PaddlePaddle 的发布](http://www.theverge.com/2016/9/1/12725804/baidu-machine-learning-open-source-paddle)，而
    Amazon 最近宣布他们[将支持 MXNet](http://www.allthingsdistributed.com/2016/11/mxnet-default-framework-deep-learning-aws.html)在其新的
    AWS 机器学习平台中。另一方面，Facebook 实际上支持了两个深度学习框架的开发：[Torch](http://torch.ch/)和[Caffe](http://caffe.berkeleyvision.org/)。另一方面，Google
    也支持了高度成功的[**Keras**](https://github.com/fchollet/keras)，所以在这一方面，Facebook 和 Google
    的情况至少是相当的。
- en: ''
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Besides the “hype” and the outpour of support from companies to machine learning
    open source projects, 2016 has also seen a great deal of applications of machine
    learning that were almost unimaginable a few months back. I was particularly impressed
    by the quality of [Wavenet](https://arxiv.org/pdf/1609.03499.pdf)’s audio generation.
    Having worked on similar problems in the past I can appreciate those results.
    I would also highlight some of the [recent results in lip reading](https://arxiv.org/pdf/1611.05358.pdf),
    a great application of video recognition that is likely to be very useful (and
    maybe scary) in the near future. I should also mention Google’s impressive [advances
    in machine translation](https://arxiv.org/pdf/1609.08144.pdf). It is amazing to
    see how much this area has improved in a year.
  id: totrans-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除了对机器学习开源项目的“炒作”和公司们的支持外，2016年也见证了许多几个月前几乎无法想象的机器学习应用。我特别对[Wavenet](https://arxiv.org/pdf/1609.03499.pdf)的音频生成质量感到印象深刻。由于我曾处理过类似的问题，因此我能够欣赏这些结果。我还想强调一些[近期的唇读结果](https://arxiv.org/pdf/1611.05358.pdf)，这是一项很好的视频识别应用，未来可能会非常有用（也许有些吓人）。我还应提及谷歌在[机器翻译方面的惊人进展](https://arxiv.org/pdf/1609.08144.pdf)。看到这一领域在一年内取得如此巨大的进步，令人惊叹。
- en: ''
  id: totrans-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'As a matter of fact, machine translation is not the only interesting advance
    we have seen in machine learning for language technologies this past year. I think
    it is very interesting to see some of the recent approaches to combine deep sequential
    networks with side-information in order to produce richer language models. In
    “[A Neural Knowledge Language Model](https://arxiv.org/pdf/1608.00318.pdf)”, Bengio’s
    team combines knowledge graphs with RNNs, and in “[Contextual LSTM models for
    Large scale NLP Tasks](https://arxiv.org/pdf/1602.06291.pdf)”, the DeepMind folks
    incorporate topics into the LSTM model. We have also seen a lot of interesting
    work in modeling attention and memory for language models. As an example, I would
    recommend “[Ask Me Anything: Dynamic Memory Networks for NLP](https://arxiv.org/pdf/1602.06291.pdf)”,
    presented in this year’s ICML.'
  id: totrans-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '实际上，机器翻译并不是我们在过去一年里在语言技术领域见到的唯一有趣的进展。我认为，看到一些将深度序列网络与侧信息结合以生成更丰富语言模型的最新方法非常有趣。在“[A
    Neural Knowledge Language Model](https://arxiv.org/pdf/1608.00318.pdf)”中，Bengio的团队将知识图谱与RNNs结合，而在“[Contextual
    LSTM models for Large scale NLP Tasks](https://arxiv.org/pdf/1602.06291.pdf)”中，DeepMind团队将话题融入LSTM模型。我们还看到许多关于语言模型中的注意力和记忆建模的有趣工作。例如，我推荐“[Ask
    Me Anything: Dynamic Memory Networks for NLP](https://arxiv.org/pdf/1602.06291.pdf)”，这是今年ICML会议上展示的内容。'
- en: ''
  id: totrans-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I could not finish this review of 2016 without some mention of advances in
    my main area of expertise: [**Recommender Systems**](/tag/recommender-systems).
    Of course Deep Learning has also impacted this area. While I would still not recommend
    DL as the default approach to recommender systems, it is interesting to see how
    it is already being used in practice, and in large scale, by products like [Youtube](http://dl.acm.org/citation.cfm?id=2959190).
    That said, there has been interesting research in the area that is not related
    to Deep Learning. The best paper award in this year’s ACM Recsys went to “[Local
    Item-Item Models For Top-N Recommendation](http://dl.acm.org/citation.cfm?id=2959185&CFID=672508488&CFTOKEN=91227145)”,
    an interesting extension to Sparse Linear Methods (i.e. [SLIM](https://www.researchgate.net/profile/George_Karypis/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems/links/549ee9ac0cf257a635fe7010.pdf))
    using an initial unsupervised clustering step. Also, “[Field-aware Factorization
    Machines for CTR Prediction](http://dl.acm.org/citation.cfm?id=2959134)”, which
    describes the winning approach to the [Criteo CTR Prediction Kaggle Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge/details/winners)
    is a good reminder that Factorization Machines are still a good tool to have in
    your ML toolkit.'
  id: totrans-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我不能结束这篇2016年的回顾而不提到我主要专业领域的进展：[**推荐系统**](/tag/recommender-systems)。当然，深度学习也对这一领域产生了影响。虽然我仍然不建议将深度学习作为推荐系统的默认方法，但有趣的是，它已经在实践中被广泛使用，例如在[Youtube](http://dl.acm.org/citation.cfm?id=2959190)中。话虽如此，在与深度学习无关的领域也有一些有趣的研究。今年ACM
    Recsys的最佳论文奖颁给了“[Local Item-Item Models For Top-N Recommendation](http://dl.acm.org/citation.cfm?id=2959185&CFID=672508488&CFTOKEN=91227145)”，这是对稀疏线性方法（即[SLIM](https://www.researchgate.net/profile/George_Karypis/publication/220765374_SLIM_Sparse_Linear_Methods_for_Top-N_Recommender_Systems/links/549ee9ac0cf257a635fe7010.pdf)）的一个有趣扩展，使用了初步的无监督聚类步骤。此外，“[Field-aware
    Factorization Machines for CTR Prediction](http://dl.acm.org/citation.cfm?id=2959134)”，描述了在[Criteo
    CTR Prediction Kaggle Challenge](https://www.kaggle.com/c/criteo-display-ad-challenge/details/winners)中获胜的方法，也很好地提醒我们因子分解机仍然是你机器学习工具箱中一个很好的工具。
- en: ''
  id: totrans-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I could probably go on for a couple of pages just listing impactful advances
    in machine learning in the last 12 months. Note that I haven’t even listed any
    of the breakthroughs related to image recognition or deep reinforcement learning,
    or obvious applications such as self-driving cars or game playing, which all saw
    huge advances in 2016\. Not to mention all the controversy around how machine
    learning is having or could have negative effects on society and the rise of discussions
    around [algorithmic bias and fairness](https://www.wired.com/2016/11/humans-can-force-machines-play-fair?mbid=social_twitter).
  id: totrans-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我可能可以列出几页内容，列举过去12个月中机器学习的重大进展。请注意，我甚至没有列出与图像识别或深度强化学习相关的突破，或诸如自动驾驶汽车或游戏玩法等明显的应用，所有这些在2016年都有巨大的进展。更不用说关于机器学习对社会产生或可能产生负面影响的争议，以及围绕[算法偏见和公平性](https://www.wired.com/2016/11/humans-can-force-machines-play-fair?mbid=social_twitter)的讨论。
- en: ''
  id: totrans-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'So, what should we expect for 2017? It is hard to say given how fast things
    are moving in the area. I am sure we will have a hard time just digesting what
    we will see in the [NIPS conference](https://nips.cc/Conferences/2016/Schedule)
    in a few days. I am definitely looking forward to many machine learning advances
    in the areas that I care the most about: personalization/recommendations, and
    natural language processing. I am sure, for example, that in the next few months
    we will see how ML can tackle the problem of fake news. But, of course, I also
    hope to see more self driving cars on the roads and machine learning being put
    to good use for health-related applications or for creating a better informed
    and more just society.'
  id: totrans-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 那么，我们应该对2017年抱有怎样的期待呢？鉴于这个领域变化如此之快，很难做出预测。我相信我们将难以消化在几天后的[NIPS会议](https://nips.cc/Conferences/2016/Schedule)上看到的内容。我肯定会期待在我最关注的领域——个性化/推荐系统和自然语言处理——中看到许多机器学习的进展。例如，我相信在接下来的几个月里，我们将看到机器学习如何应对假新闻问题。但当然，我也希望看到更多的自动驾驶汽车上路，以及机器学习在健康相关应用中或用于创建更好信息和更公正社会中的良好应用。
- en: '**[Yoshua Bengio](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html)**,
    Professor, Department of Computer Science and Operations Research, Université
    de Montréal‎, Canada Research Chair in Statistical Learning Algorithms, etc.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**[约书亚·本吉奥](http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html)**，蒙特利尔大学计算机科学与运筹学系教授，加拿大统计学习算法研究主席等。'
- en: The main events of 2016 from my point of view have been in the areas of deep
    [**reinforcement learning**](/tag/reinforcement-learning), [**generative models**](/tag/generative-models),
    and neural machine translation. First we had AlphaGo (DeepMind's network which
    beat the Go world champion using deep RL). Over the whole year we have seen a
    series of papers showing the success of generative adversarial networks (for unsupervised
    learning of generative models). Also in the area of unsupervised learning, we
    have seen the unexpected success of auto-correlation neural networks (like the
    WaveNet paper from DeepMind). Finally, just about a month ago we have seen the
    crowning of neural machine translation (which was initiated in part by my lab
    since 2014) with Google bringing this technology to the scale of Google Translate
    and obtaining really amazing results (approaching very significantly human-level
    performance).
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 从我的角度来看，2016年的主要事件集中在深度[**强化学习**](/tag/reinforcement-learning)、[**生成模型**](/tag/generative-models)和神经机器翻译领域。首先是AlphaGo（DeepMind的网络通过深度强化学习击败了围棋世界冠军）。整年我们看到了一系列论文展示生成对抗网络（用于生成模型的无监督学习）的成功。在无监督学习领域，我们也见证了自相关神经网络（如DeepMind的WaveNet论文）的意外成功。最后，就在一个月前，我们见证了神经机器翻译的巅峰（该技术部分由我的实验室自2014年起启动），Google将这项技术扩展到Google
    Translate的规模，并取得了非常惊人的结果（接近人类水平的表现）。
- en: ''
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I believe these are good indicators for the progress to be expected in 2017:
    more advances in [**unsupervised learning**](/tag/unsupervised-learning) (which
    remains a major challenge, we are very far from human abilities in that respect)
    and in the ability of computers to understand and generate natural language, probably
    first with chatbots and other dialogue systems. Another likely trend is the increase
    in research and results of applying deep learning in the healthcare domain, on
    a variety of types of data, including medical images, clinical data, genomic data,
    etc. Progress in computer vision will continue as we see more applications, including
    of course self-driving cars but I have the impression that in general the community
    is under-estimating the challenges ahead before reaching true autonomy.'
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我相信以下这些是对2017年期望进展的良好指标：在[**无监督学习**](/tag/unsupervised-learning)方面取得更多进展（这仍然是一个主要挑战，我们在这方面离人类能力还很远），以及计算机理解和生成自然语言的能力，可能首先体现在聊天机器人和其他对话系统上。另一个可能的趋势是深度学习在医疗领域应用的研究和成果增加，涵盖各种类型的数据，包括医学图像、临床数据、基因组数据等。计算机视觉的进展将继续，我们将看到更多应用，包括自动驾驶汽车，但我有一种感觉，整体社区对实现真正自主性面临的挑战估计不足。
- en: '![Self-driving car](../Images/72488205ebf5d06b9957e142c07a565a.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![自动驾驶汽车](../Images/72488205ebf5d06b9957e142c07a565a.png)'
- en: '**[Pedro Domingos](http://homes.cs.washington.edu/~pedrod/)**, Professor of
    computer science at UW and author of ''[The Master Algorithm](https://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708/)'''
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**[佩德罗·多明戈斯](http://homes.cs.washington.edu/~pedrod/)**，华盛顿大学计算机科学教授，《[大师算法](https://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708/)》的作者。'
- en: The main event of 2016 was AlphaGo's win. Two areas where we might see substantial
    progress in 2017 are [**chatbots**](/tag/chatbot) and [**self-driving cars**](/tag/self-driving-car),
    just because so many major companies are investing heavily in them. On the more
    fundamental side, one thing we'll probably see is increasing hybridization of
    deep learning with other ML/AI techniques, as is  typical for a maturing technology.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年的主要事件是AlphaGo的胜利。我们可能在2017年看到显著进展的两个领域是[**聊天机器人**](/tag/chatbot)和[**自动驾驶汽车**](/tag/self-driving-car)，仅仅因为许多主要公司在这些领域进行了大量投资。在更基础的方面，我们可能会看到深度学习与其他机器学习/人工智能技术的混合化增加，这对于成熟的技术来说是典型的。
- en: '[**Oren Etzioni**](http://allenai.org/team/orene/), CEO of the Allen Institute
    for Artificial Intelligence. He was a Professor at U. Washington, founder/co-founder
    of several companies including Farecast and Decide, and the author of over 100
    technical papers.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[**奥伦·艾齐奥尼**](http://allenai.org/team/orene/)，艾伦人工智能研究所的首席执行官。他曾是华盛顿大学的教授，也是包括Farecast和Decide在内的几家公司的创始人/联合创始人，并且发表了超过100篇技术论文。'
- en: The tremendous success of AlphaGo is the crowning achievement for an exciting
    2016\. In 2017, we will see more reinforcement learning in [**neural networks**](/tag/neural-networks),
    more research on neural networks in NLP & vision. However, the challenges of neural
    networks with limited labeled data, exemplified by systems like [Semantic Scholar](https://www.semanticscholar.org/),
    remain formidable and will occupy us for years to come. These are still early
    days for [**Deep Learning**](/tag/deep-learning) and more broadly for Machine
    Learning.
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AlphaGo的巨大成功是2016年的辉煌成就。2017年，我们将看到更多的强化学习在[**神经网络**](/tag/neural-networks)中的应用，更多关于神经网络在自然语言处理和计算机视觉中的研究。然而，神经网络在有限标注数据下面临的挑战，例如[Semantic
    Scholar](https://www.semanticscholar.org/)这样的系统，仍然是巨大的，并且将会占据我们多年的时间。这些对[**深度学习**](/tag/deep-learning)以及更广泛的机器学习领域来说仍然是早期阶段。
- en: '[**Ajit Jaokar**](https://twitter.com/AjitJaokar), #Datascience, #IoT, #MachineLearning,
    #BigData, Mobile,#Smartcities, #edtech (@feynlabs + @countdowncode) Teaching (@forumoxford
    + @citysciences)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Ajit Jaokar**](https://twitter.com/AjitJaokar)，#数据科学，#物联网，#机器学习，#大数据，移动，#智能城市，#教育科技（@feynlabs
    + @countdowncode）教学（@forumoxford + @citysciences）'
- en: 2017 will be a big year for both [**IoT**](/tag/IoT) and [**AI**](/tag/artificial-intelligence).
    As per my recent [KDnuggets post](/2016/11/continuous-improvement-iot-ai-learning.html),
    AI will be a core competency for Enterprises. For IoT, this would mean the ability
    to build and deploy models across platforms (Cloud, Edge, Streaming). This ties
    continuous learning to the vision of continuous improvement through AI. It also
    needs to new competencies as AI and devops converge.
  id: totrans-44
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2017年将是[**物联网**](/tag/IoT)和[**人工智能**](/tag/artificial-intelligence)的关键一年。根据我最近的[KDnuggets文章](/2016/11/continuous-improvement-iot-ai-learning.html)，人工智能将成为企业的核心能力。对于物联网来说，这意味着能够在各种平台（云端、边缘、流媒体）上构建和部署模型。这将持续学习与通过人工智能实现持续改进的愿景联系起来。它还需要在人工智能和DevOps融合时获得新的能力。
- en: '**[Neil Lawrence](http://inverseprobability.com/)**, Professor of Machine Learning
    at the University of Sheffield'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Neil Lawrence](http://inverseprobability.com/)**，谢菲尔德大学机器学习教授'
- en: I think things are progressing much as we might expect at the moment. [**Deep
    learning**](/tag/deep-learning) methods are being intelligently deployed on very
    large data sets. For smaller data sets I think we'll see some interesting directions
    on model repurposing, i.e the reuse of pre-trained deep learning models. There
    are some interesting open questions around how best to do this. A further trend
    has been the increasing press focus on the field. Including mainstream articles
    on papers placed on [**Arxiv**](/tag/arxiv) that have not yet been reviewed. This
    appetite for advance was also present last year but I think this year we've seen
    it accelerate. In response I think academics should probably become a lot more
    careful about how they choose to promote their work (for example on social media),
    particularly when it is unreviewed.
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我认为目前的进展与我们预期的情况差不多。**深度学习**方法正被智能地应用于非常大的数据集上。对于较小的数据集，我认为我们会看到一些有趣的模型再利用方向，即重用预训练的深度学习模型。关于如何最好地进行这些操作，还有一些有趣的未解问题。另一个趋势是对该领域的媒体关注度不断增加，包括关于尚未审阅的[**Arxiv**](/tag/arxiv)论文的主流文章。这种对前沿的兴趣去年也存在，但我认为今年这种趋势有所加速。对此，我认为学术界可能需要更加谨慎地选择如何推广他们的工作（例如在社交媒体上），尤其是当它尚未经过审阅时。
- en: '**[Randal Olson](http://www.randalolson.com/)**, Senior Data Scientist at the
    University of Pennsylvania Institute for Biomedical Informatics'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Randal Olson](http://www.randalolson.com/)**，宾夕法尼亚大学生物医学信息学研究所高级数据科学家'
- en: '[Automated Machine Learning (AutoML) systems](/2016/11/autoamted-machine-learning-interview-randy-olson-tpot.html)
    started becoming competitive with human machine learning experts in 2016\. Earlier
    this year, an MIT group created a [Data Science Machine](http://people.csail.mit.edu/kalyan/dsm/)
    that beat hundreds of teams in the popular KDD Cup and IJCAI machine learning
    competitions. Just this month, our in-house AutoML system, [TPOT](https://github.com/rhiever/tpot),
    started ranking in the 90th percentile on several [Kaggle](https://www.kaggle.com/)
    competitions. Needless to say, I am confident that AutoML systems will start replacing
    human experts for standard machine learning analyses in 2017.'
  id: totrans-48
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[自动化机器学习（AutoML）系统](/2016/11/autoamted-machine-learning-interview-randy-olson-tpot.html)在2016年开始与人类机器学习专家竞争。今年早些时候，麻省理工学院的一个团队创建了一个[数据科学机器](http://people.csail.mit.edu/kalyan/dsm/)，在流行的KDD
    Cup和IJCAI机器学习比赛中击败了数百个团队。就在这个月，我们的内部AutoML系统，[TPOT](https://github.com/rhiever/tpot)，开始在几个[Kaggle](https://www.kaggle.com/)比赛中排名90百分位。毫无疑问，我相信AutoML系统将在2017年开始取代人类专家进行标准机器学习分析。'
- en: '![Colorful neural networks](../Images/02b2b6e13a9bcc46c937d2817304b9f4.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![色彩斑斓的神经网络](../Images/02b2b6e13a9bcc46c937d2817304b9f4.png)'
- en: '**[Charles Martin](https://www.linkedin.com/in/charlesmartin14)**, Data Scientist
    & Machine Learning Expert'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Charles Martin](https://www.linkedin.com/in/charlesmartin14)**，数据科学家和机器学习专家'
- en: 2016 has been the watershed year for [**Deep learning**](/tag/deep-learning).
    We have had a year with [**Google Tensorflow**](/tag/tensorflow), and the applications
    keep pouring in. Combined with say Keras, Jupyter Notebooks, and GPU-enabled AWS
    nodes, [**Data Science teams**](/tag/data-science-team) have the infrastructure
    on-demand to start building truly innovative learning applications and start generating
    revenue fast. But they may not have the talent? It is not about coding. It is
    not an infrastructure play. It is very different from traditional analytics, and
    no one really understands Why Deep Learning Works. Still, let's face it, it is
    all Google and Facebook talk about! And the C-suite is listening. In 2017, companies
    will be looking to bring best-of-breed Deep Learning technologies in house to
    improve the bottom line.
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年是[**深度学习**](/tag/deep-learning)的分水岭年。我们经历了[**Google Tensorflow**](/tag/tensorflow)的一年，应用不断涌现。结合如Keras、Jupyter
    Notebooks和启用GPU的AWS节点，[**数据科学团队**](/tag/data-science-team)拥有按需的基础设施，可以开始构建真正创新的学习应用，并迅速产生收入。但他们可能没有足够的人才？这不仅仅是编码问题，也不是基础设施问题。它与传统分析大相径庭，没有人真正理解为什么深度学习有效。不过，面对现实吧，这正是谷歌和Facebook谈论的所有内容！而高层管理人员正在关注。2017年，公司将寻求引入最优秀的深度学习技术，以改善财务状况。
- en: '**[Matthew Mayo](/author/matt-mayo)**, Data Scientist, Deputy Editor of KDnuggets'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Matthew Mayo](/author/matt-mayo)**，数据科学家，KDnuggets副主编'
- en: The big story of 2016 has to be the accelerated returns we are seeing from deep
    learning. The (not solely) neural network-based "conquering" of Go is likely the
    most prominent example, but there are others. Looking forward to 2017, I would
    expect that the continued advancements in [**neural networks**](/tag/neural-networks)
    will remain the big story. However, [**automated machine learning**](/tag/automated-data-science)
    will quietly become an important event in its own right. Perhaps not as sexy to
    outsiders as deep neural networks, automated machine learning will begin to have
    far-reaching consequences in ML, AI, and data science, and 2017 will likely be
    the year this becomes apparent.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年的大事件必须是我们看到的深度学习的加速回报。基于（不仅仅是）神经网络的“征服”围棋可能是最突出的例子，但还有其他例子。展望2017年，我预计[**神经网络**](/tag/neural-networks)的持续进步将仍然是大新闻。然而，[**自动化机器学习**](/tag/automated-data-science)将悄然成为一个重要事件。虽然对外界来说不如深度神经网络那样引人注目，但自动化机器学习将开始在机器学习、人工智能和数据科学领域产生深远的影响，2017年可能会显现这一点。
- en: '**[Brandon Rohrer](https://www.linkedin.com/in/brohrer)**, Data Scientist at
    Facebook'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Brandon Rohrer](https://www.linkedin.com/in/brohrer)**，Facebook数据科学家'
- en: In 2016 machines read lips more accurately than humans ([arxiv.org/pdf/1611.05358.pdf](https://arxiv.org/pdf/1611.05358.pdf)),
    type from dictation faster than humans ([arxiv.org/abs/1608.07323](https://arxiv.org/abs/1608.07323))
    and create eerily realistic human speech ([arxiv.org/pdf/1609.03499.pdf](https://arxiv.org/pdf/1609.03499.pdf)).
    These are the results of exploring novel architectures and [**algorithms**](/tag/algorithms).
    [**Convolutional Neural Networks**](/tag/convolutional-neural-networks) are being
    modified beyond recognition and combined with reinforcement learners and time-aware
    methods to open up new application areas. In 2017 I expect a few more human level
    benchmarks to fall, particularly those that are vision-based and thus amenable
    to CNNs. I also expect (and hope!) that our community forays into the nearby territories
    of decision making, non-vision feature creation and time-aware methods will become
    more frequent and fruitful. Together these make intelligent robots possible. If
    we are really lucky, 2017 will bring us a machine that can beat humans at making
    a cup of coffee.
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在2016年，机器在读唇的准确度超过了人类（[arxiv.org/pdf/1611.05358.pdf](https://arxiv.org/pdf/1611.05358.pdf)），从听写中打字的速度超过了人类（[arxiv.org/abs/1608.07323](https://arxiv.org/abs/1608.07323)），并创造了逼真的人类语音（[arxiv.org/pdf/1609.03499.pdf](https://arxiv.org/pdf/1609.03499.pdf)）。这些都是探索新型架构和[**算法**](/tag/algorithms)的结果。[**卷积神经网络**](/tag/convolutional-neural-networks)正在被修改得面目全非，并与强化学习者和时间感知方法结合，以开辟新的应用领域。预计2017年会有更多人类水平的基准被打破，特别是那些基于视觉的，因此适合CNN。我还期待（并希望！）我们社区在决策制定、非视觉特征创建和时间感知方法等相关领域的探索会变得更加频繁和有成效。这些共同使得智能机器人成为可能。如果我们真的很幸运，2017年将会带来一种能在制作咖啡方面击败人类的机器。
- en: '**[Daniel Tunkelang](https://www.linkedin.com/in/dtunkelang)**, Data science,
    Engineering, and Leadership'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**[丹尼尔·腾克兰](https://www.linkedin.com/in/dtunkelang)**，数据科学、工程与领导力'
- en: The biggest story of 2016 was [**AlphaGo**](/tag/alphago) defeating Lee Sedol,
    the human world champion of Go. It was a surprise even to the AI community, and
    it will be remembered as the tipping point in the rise of deep learning. 2016
    was the year of deep learning and AI. Chatbots, self-driving cars, and computer-aided
    diagnosis have unlocked the possibilities of what we can do by throwing enough
    GPUs at the right training data. 2017 will bring us successes and disillusionments.
    Technologies like TensorFlow will commodify deep learning, and AI will be something
    we take for granted in consumer products. But we'll hit the limits of what we
    can model and optimize. We'll have to confront the biases in our data. And we'll
    grow up and realize that we're nowhere close to general AI or the [**singularity**](/tag/singularity).
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 2016年的最大新闻是[**AlphaGo**](/tag/alphago)战胜了围棋人类世界冠军李世石。这对AI社区来说也是个惊喜，它将被铭记为深度学习崛起的分水岭。2016年是深度学习和AI的年份。聊天机器人、自动驾驶汽车和计算机辅助诊断揭示了通过投入足够的GPU到合适的训练数据中，我们可以做什么。2017年将带来成功与失望。像TensorFlow这样的技术将使深度学习商品化，AI将在消费品中成为理所当然的存在。但我们将会遇到建模和优化的极限。我们必须面对数据中的偏见。我们会成长起来，意识到我们离通用AI或[**奇点**](/tag/singularity)还远得很。
- en: '**Related**:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**：'
- en: '[Big Data: Main Developments in 2016 and Key Trends in 2017](/2016/12/big-data-main-developments-2016-key-trends-2017.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[大数据：2016年的主要发展和2017年的关键趋势](/2016/12/big-data-main-developments-2016-key-trends-2017.html)'
- en: '[Data Science & Predictive Analytics: Main Developments in 2016 and Key Trends
    in 2017](/2016/12/data-science-predictive-analytics-main-developments-trends.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学与预测分析：2016年的主要发展和2017年的关键趋势](/2016/12/data-science-predictive-analytics-main-developments-trends.html)'
- en: '[Predictions for Deep Learning in 2017](/2016/12/ibm-predictions-deep-learning-2017.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2017年深度学习的预测](/2016/12/ibm-predictions-deep-learning-2017.html)'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[AI, Analytics, Machine Learning, Data Science, Deep Learning…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AI、分析、机器学习、数据科学、深度学习…](https://www.kdnuggets.com/2021/12/developments-predictions-ai-machine-learning-data-science-research.html)'
- en: '[Main 2021 Developments and Key 2022 Trends in AI, Data Science,…](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年主要发展和2022年AI、数据科学等关键趋势](https://www.kdnuggets.com/2021/12/trends-ai-data-science-ml-technology.html)'
- en: '[Data Science & Analytics Industry Main Developments in 2021 and Key…](https://www.kdnuggets.com/2021/12/developments-predictions-data-science-analytics-industry.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学与分析行业在2021年的主要发展和关键…](https://www.kdnuggets.com/2021/12/developments-predictions-data-science-analytics-industry.html)'
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为出色数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每位初学者数据科学家应掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
