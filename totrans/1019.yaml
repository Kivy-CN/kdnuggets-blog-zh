- en: Prepare Your Data for Effective Tableau & Power BI Dashboards
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/06/prepare-data-effective-tableau-power-bi-dashboards.html](https://www.kdnuggets.com/2022/06/prepare-data-effective-tableau-power-bi-dashboards.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Business Intelligence (BI) technologies like Power BI and Tableau collect, integrate,
    analyze, and present business information. These tools can help you analyze business
    data and visualize information to gain valuable insights.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a dashboard that provides some insights can be a quick process (especially
    once you gain some expertise with the BI tool of your choice). You might be even
    an expert, but still notice that things can get incredibly tricky and time consuming
    once you try to do one (or more) of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Connecting to multiple data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Playing with data types and data categorization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating data models that mix together your data sources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a visualization that plays with multiple levels of aggregation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating your dashboard refresh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: BI tools can be amazing for presenting your data, creating user views, even
    sometimes performing Row Level Security. Now, both PowerBI and Tableau offer their
    own features for more complex use cases like the above. These functionalities
    can be helpful to build a one-time quick analysis, but fall short when trying
    to build effective, scalable and stable visualizations with a wide, demanding
    audience. Most of the time, after an ad-hoc analysis is built, Data Analysts are
    required to turn it into stable reporting, facing challenges to automate the work
    done in a smart way.
  prefs: []
  type: TYPE_NORMAL
- en: '**The trick? **'
  prefs: []
  type: TYPE_NORMAL
- en: '**Decouple (separate) your data preparations from your analytics and stick
    to using BI tools for visualizations and formatting.** By simplifying the process
    as inputs and outputs, you will invest in your own future mental health and your
    customers’ satisfaction. Decoupling implies that each step is done in a tool that
    is most appropriate for it, then automated and then the pieces of the puzzle are
    simple and independent from each other.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Great, but how?**'
  prefs: []
  type: TYPE_NORMAL
- en: I’ve laid down the steps that are required to separate the stages of your data
    journey and make each of them simple to automate afterwards. **Note that you should
    be able to follow these steps no matter how technical your background is** (from
    basic excel files to complex Python flows). You can always adjust your approach
    to decouple your process and enable your future self (or your backup/replacement)
    to repeat it/update it/change. Nobody should have to dissect a file that became
    a black box each time they want to make a small change!
  prefs: []
  type: TYPE_NORMAL
- en: Understand the Ultimate Dashboarding Requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Start by carefully listening. Customers and end-users (or Product Owners) will
    come to you with wish lists and must-haves. They will be focused on the final
    look and formatting of what they want to see. What you keep in mind as the person
    behind the reporting, is that the purpose of reporting is to:'
  prefs: []
  type: TYPE_NORMAL
- en: Analyze the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Come to conclusions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make better decisions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Therefore, when they say “I need A and it should show B”, your next question
    shouldn’t be:'
  prefs: []
  type: TYPE_NORMAL
- en: What color?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What size?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What type of chart?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Instead, it is best to find out why your Product Owners want to see that metric.
    Ask yourself: What are they trying to accomplish? When you know their priorities,
    you can answer important questions before starting to analyze their data, such
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: Is this an ad-hoc analysis?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What question am I trying to answer?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who is my audience?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What level of detail are they used to?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will this reporting facilitate a recurring discussion?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the format of that discussion?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can I make sure these discussions revolve around solving problems?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ( instead of focusing on the origin of the numbers or what they mean for each
    participant? )
  prefs: []
  type: TYPE_NORMAL
- en: This is where trust comes in. If your customers know that you understand their
    needs and take the time to clean and optimize their data, they will trust that
    it reflects their reality. Ultimately, this is what every customer wants. Data
    that they can trust.
  prefs: []
  type: TYPE_NORMAL
- en: At this point of the process, after a couple of conversations, you should have
    a clearer scope of the work that is needed, the purpose of the dashboard and what
    they plan to do with it. So you can get to work and do it fast (you can be sure
    that the more time you spend on this stage, the more the wish list will grow with
    nice-to-haves)
  prefs: []
  type: TYPE_NORMAL
- en: Access the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This is the stage of the process where your multitasking skills are tested.
    Make sure that you come up with a list looking something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Data Source** | **Frequency needed** | **Purpose** | **Access by** | **Status**
    | **Temporary solution** |'
  prefs: []
  type: TYPE_TB
- en: '| Source A | Daily refresh | Needed for main pageKPIs:- A- B- C | Team/Person
    | Requested / Ticket open / Waiting for approval / Granted /… | Working with extract
    |'
  prefs: []
  type: TYPE_TB
- en: '| Source B | Weekly refresh | Needed for security layer (users and roles) |
    Team/Person |  | Working with data from test environment / Dummy data |'
  prefs: []
  type: TYPE_TB
- en: '| Source C | Monthly refresh | Needed for enabling actuals vs. Targets feature
    | Team/Person |  | Not available |'
  prefs: []
  type: TYPE_TB
- en: This will work wonders in  keeping track of what you want and what you don’t,
    while also protecting you from bottlenecks. The last thing anybody ever wants
    to hear in business is excuses, so give them the facts. This is what I have and
    what I don’t and this is what I’m using while I’m waiting for it. Your Product
    Owner will know exactly how to help you, as they want you to progress fast to
    a finished solution. They will also know which data has been given to you as a
    workaround (extract, test/dummy data…) allowing you to work on the solution, but
    without final numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, this shows resourcefulness (working with something while the
    final access is pending) and transparency (they know exactly why a certain part
    of the solution is not built yet or is working on non-production data). Keeping
    your partners engaged and building trust requires you to be resourceful and transparent..
    It will save you many headaches in the future stages of the process.
  prefs: []
  type: TYPE_NORMAL
- en: Ingesting (Fetching) the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Start with the quick wins, to secure a simple Demo early on in the process and
    focus on having some data already at your disposal. Take the data in the rawest
    of its forms, instead of processed data that nobody is accountable for. If taking
    the raw data makes it too large, then work with a subset of it. One of the typical
    mistakes is to aggregate the data too early in the process, you only realize you
    need more once it’s too late. Ingest a raw subset of each of the data sources
    you know you will need for a Demo.
  prefs: []
  type: TYPE_NORMAL
- en: At this point (and not later!), take notes and document what you have taken,
    and always inform your customers that you have acquired enough data to build the
    first demo. Some dashboards might require over twenty different sources of data,
    combined in multiple ways that are impossible to remember. Here, after ingestion,
    is where you start your ERD ([how to build an Entity Relationship Diagram](https://www.smartdraw.com/entity-relationship-diagram/)) 
    or for simpler use cases, [build your database diagram](https://www.smartdraw.com/entity-relationship-diagram/#ERDAutomated)
    to simply document what you have (or plan to have). No need to get fancy, you
    can do this manually using pen & paper, a whiteboard, a digital whiteboard tool
    (such as Excalidraw, Microsoft Whiteboard, Visio, Google Draw…), or markdown ([mermaid
    ERD](https://mermaid-js.github.io/mermaid/#/./entityRelationshipDiagram)), as
    long as you understand what data you have and how it will be merged into a final
    flat table.
  prefs: []
  type: TYPE_NORMAL
- en: Combine the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here is where you create the most value. By establishing strong relationships
    between your data, you build clean and complete operational datasets that make
    your end users’ lives easier. Ideally, they can connect to the product in a matter
    of seconds (using SQL, Python, Tableau, PowerBI…) and directly start analyzing.
    It is not an easy task and it depends on how good you were at step 1 (*Understand
    the ultimate requirements*). As with any tricky task, start by breaking it down
    into steps and using a [visual example:](https://wcs.smartdraw.com/entity-relationship-diagram/img/basic-database-erd-diagram.png?bn=15100111822)
  prefs: []
  type: TYPE_NORMAL
- en: '![In the current example, we have five datasets (UserAgent, Session, Event,
    EventType, EventData)](../Images/67a10cb1a9f414f7ba14ec03668c02fb.png)'
  prefs: []
  type: TYPE_IMG
- en: In the current example, we have five datasets (UserAgent, Session, Event, EventType,
    EventData)
  prefs: []
  type: TYPE_NORMAL
- en: Use your visuals (built on the previous step) and make sure each of your raw
    datasets has a unique key that can be used to create the connections with other
    datasets (this can be custom ids from data sources, auto-generated keys). You
    might need to clean up (careful with the data types!) certain fields and generate
    your  keys (e.g add a column with concatenation) to make sure the connections
    work.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that in this example, each UserAgent has an ID, each session has its own
    ID and also the UserAgentID that it relates to. During a session, an event happens
    (new ID). Take a moment to recognize which will be your core dataset(s), meaning
    those that are on the same level you will be reporting on ? this will help you
    build all the connections and join as needed. See here some scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: 'UserAgent level analysis: End-users want to have a dashboard that allows them
    to understand how many UserAgents are appearing and what is their engagement (number
    of sessions and events per session…). You will need to take the ‘UserAgent’ dataset
    as your core, then add the Sessions and the Events as complimentary info to help
    you answer questions about the user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Session analysis: End-users want to have a dashboard that allows them to understand
    how many sessions are taking place, maybe some characteristics of the users or
    the events related to those sessions. Here your core will be ‘Session’,  joining
    to ‘Event’, ‘EventType’, ‘EventData’...'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event analysis:  End-users want to have a dashboard that allows them to understand
    the most common events happening during user sessions. Here the core will be ‘Event’,
    joining to ‘Event Type’, ‘Sessions’, ‘EventData’...
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember**,** your dashboard might require all the above. You may have to focus
    on different datasets, so if you did the first step correctly you will know that
    you need more than one operational table as part of your product. Perform your
    joins (using SQL, Python, data crunching tools or even Excel in the earliest phase)
    and check the number of records regularly to prevent a generation of artificial
    rows when joining tables and create the first simplest versions of your operational
    tables.
  prefs: []
  type: TYPE_NORMAL
- en: Add all calculations that your end users requested directly on your model (and
    not on your visualization tool). Each time a user will need to use this calculated
    data, they will get it directly from the dataset instead of exporting it from
    your dashboard. This also scales better and avoids data discrepancies between
    different dashboards built by multiple users.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the first operational data, back to multitasking. You can
    build a quick demo for your visualization that your end users can use to give
    you feedback on the data accuracy, while you focus parallelly on the next step.
  prefs: []
  type: TYPE_NORMAL
- en: Cleanse & Format the Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, take a first glance at your data to be aware of what data you are using.
    Then take (e.g. first & last 10 rows) and pay attention to the small details.
    This includes:'
  prefs: []
  type: TYPE_NORMAL
- en: the data type (numeric, text, dates, boolean, array),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the data format (decimals, integers)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: whether the raw data format is similar for all columns with the same data type
    (e.g. if all columns with dates has the same date format)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: whether it is numerical (quantitative) and categorical (qualitative) data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if text data -> what is it? City names? Product codes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of this helps to understand relations between data, determine what preparation/processing
    the data requires and adjust visualization techniques. Remember to look for nulls,
    numeric / text, different formats between languages (for free text), and HTML
    tags cleanup.
  prefs: []
  type: TYPE_NORMAL
- en: Do this by filtering or through a quick summary. All of this will avoid tedious
    steps later on during visualization, if the data is clean and in the right format,
    preparing a visual can take only a few clicks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, go to the details. Depending on the data types, the approach to data
    cleansing differs, and different kinds of ''outliers'' may exist. A summary of
    what to look for in a particular data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dates**'
  prefs: []
  type: TYPE_NORMAL
- en: check the data type under which the data is stored. If the data is not related
    to dates, there is a risk that e.g. the date is processed as a numeric value,
    then the zeros at the beginning will be deleted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: maintain consistent formatting (e.g. 'YYYY-MM-DD')
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: dates should only be used if they make sense (e.g. birthdates shouldn't be future)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Text**'
  prefs: []
  type: TYPE_NORMAL
- en: if the text is long (e.g. tweets), use the tokenization method
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ensure Names are consistent (e.g. data might contain records with 'USA', 'United
    States of America' and 'U.S.A.' which relate to the same thing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Numeric**'
  prefs: []
  type: TYPE_NORMAL
- en: be consistent with formatting (e.g. decimals with two places, integers should
    look like integers, not decimals, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: detect outliers (e.g. via visualization, Z-score method, IQR method outliers
    can have a significant impact on metrics this is why it is important to think
    why they occurred and if to remove/fix them or they include significant and real
    information which might be key for business (e.g. frauds) -> outliers is huuuuge
    topic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: commas or periods -> be consistent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, if you have categorical data, make sure categories make sense and there
    are no two categories that apply to the same thing. Remember to document the categories
    you create/adjust, so that users of your data will know exactly what they mean
  prefs: []
  type: TYPE_NORMAL
- en: '**Third, provide column names.**'
  prefs: []
  type: TYPE_NORMAL
- en: during processing/modeling remember about simple, descriptive column names,
    avoid ' ' between words and special symbols to save yourself from unnecessary
    trouble
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: for final model for business use column names they want
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: try to stick to a [naming convention](https://www.sqlshack.com/learn-sql-naming-conventions/)
    (or create your own following guidelines), document it and familiarize your data
    users with it. Be consistent with it across datasets and you will slowly build
    a culture in your organization of clean data that everyone can understand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you understand your Product Owners' priorities, business intelligence technologies
    like Power BI and Tableau can optimize and prepare data for Tableau and PBI dashboards.
    Once you have access to the data, you can ingest, combine, cleanse, and format
    it.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you might be ready to jump to your BI tool (PowerBI, Tableau…)
    to do all these steps in one file connecting to a million raw extracts. **Resist
    that urge** and **trust the decoupled process**! Remember, simple is the keyword
    here
  prefs: []
  type: TYPE_NORMAL
- en: Listen, listen, listen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make lists that will work as a reference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Break things down into smaller separate steps (data ingestion, data validation,
    data cleaning…)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For data crunching, use tools that were built for automating data modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Python, SQL, visual SQL, even Excel if that's what you're comfortable with)
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Stick to visual tools for the final dashboarding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don’t forget to document your progress! You will move on to your next interesting
    project and most likely forget all the details. This was not covered in this article,
    but take a look at [how to build processes that speak for themselves](https://vertabelo.com/blog/data-modeling-documentation/)
    and save time at the end when your deadlines are approaching fast.
  prefs: []
  type: TYPE_NORMAL
- en: '*"Your future self will thank you later!"*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**[Valeria Perluzzo](https://www.linkedin.com/in/valeriaperluzzo/)** is head
    of analytics at [dyvenia](http://dyvenia.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[SQL for Data Visualization: How to Prepare Data for Charts and Graphs](https://www.kdnuggets.com/sql-for-data-visualization-how-to-prepare-data-for-charts-and-graphs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Cleaning in SQL: How To Prepare Messy Data for Analysis](https://www.kdnuggets.com/data-cleaning-in-sql-how-to-prepare-messy-data-for-analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Faster Way to Prepare Time-Series Data with the AI & Analytics Engine](https://www.kdnuggets.com/2021/12/piexchange-faster-way-prepare-timeseries-data-ai-analytics-engine.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Prepare for a Data Science Interview](https://www.kdnuggets.com/2022/12/prepare-data-science-interview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Create Efficient Combined Data Sources with Tableau](https://www.kdnuggets.com/2022/05/create-efficient-combined-data-sources-tableau.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Most Used Tableau Functions](https://www.kdnuggets.com/2022/08/10-used-tableau-functions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
