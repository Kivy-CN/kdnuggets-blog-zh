- en: 7 Essential Data Quality Checks with Pandas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas](https://www.kdnuggets.com/7-essential-data-quality-checks-with-pandas)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![7 Essential Data Quality Checks with Pandas](../Images/c9dfcc4434fa36f099ef3af225d45b7b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: As a data professional, you’re probably familiar with the cost of poor data
    quality. For all data projects—big or small—you should perform essential data
    quality checks.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: There are dedicated libraries and frameworks for data quality assessment. But
    if you are a beginner, you can run simple yet important data quality checks with
    pandas. And this tutorial will teach you how.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll use the [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html)
    from scikit-learn for this tutorial.
  prefs: []
  type: TYPE_NORMAL
- en: An Overview of the California Housing Dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ll use the California housing dataset from Scikit-learn’s [datasets module](https://scikit-learn.org/stable/datasets/real_world.html#real-world-datasets).
    The data set contains over 20,000 records of eight numeric features and a target
    median house value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s read the dataset into a pandas dataframe `df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'For a detailed description of the dataset, run `data.DESCR` as shown:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![7 Essential Data Quality Checks with Pandas](../Images/f75bc0f8c1f2fd389c4abd2454c2c71d.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of data.DESCR
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s get some basic information on the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we have numeric features, let us also get the summary starts using
    the `describe()` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![7 Essential Data Quality Checks with Pandas](../Images/116989112eb8a816cb5b4b701c5f246c.png)'
  prefs: []
  type: TYPE_IMG
- en: Output of df.describe()
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Check for Missing Values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Real-world datasets often have missing values. To analyze the data and build
    models, you need to handle these missing values.
  prefs: []
  type: TYPE_NORMAL
- en: To ensure data quality, you should check if the fraction of missing values is
    within a specific tolerance limit. You can then impute the missing values using
    suitable imputation strategies.
  prefs: []
  type: TYPE_NORMAL
- en: The first step, therefore, is to check for missing values across all features
    in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code checks for missing values in each column of the dataframe `df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is a pandas series that shows the count of missing values for each
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As seen, there are no missing values in this dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Identify Duplicate Records
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Duplicate records in the dataset can skew analysis. So you should check for
    and drop the duplicate records as needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code to identify and return duplicate rows in `df`. If there are
    any duplicate rows, they will be included in the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is an empty dataframe. Meaning there are no duplicate records in
    the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Check Data Types
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When analyzing a dataset, you’ll often have to transform or scale one or more
    features. To avoid unexpected errors when performing such operations, it is important
    to check if the columns are all of the expected data type.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code checks the data types of each column in the dataframe `df`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, all numeric features are of `float` data type as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Check for Outliers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Outliers are data points that are significantly different from other points
    in the dataset. If you remember, we ran the `describe()` method on the dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the quartile values and the maximum value, you could’ve identified
    that a subset of features contain outliers. Specifically, these features:'
  prefs: []
  type: TYPE_NORMAL
- en: MedInc
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AveRooms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AveBedrms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Population
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One approach to handling outliers is to use the [interquartile range](https://www.khanacademy.org/math/cc-sixth-grade-math/cc-6th-data-statistics/cc-6th/a/interquartile-range-review),
    the difference between the 75th and 25th quartiles. If Q1 is the 25th quartile
    and Q3 is the 75th quartile, then the interquartile range is given by: Q3 - Q1.'
  prefs: []
  type: TYPE_NORMAL
- en: We then use the quartiles and the IQR to define the interval `[Q1 - 1.5 * IQR,
    Q3 + 1.5 * IQR]`. And all points outside this range are outliers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '![7 Essential Data Quality Checks with Pandas](../Images/2c799aaf132686d2ac77a2b57ab6cb4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Outliers in 'AveRooms' Column | Truncated Output for Outliers Check
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Validate Numeric Ranges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An important check for numeric features is to validate the range. This ensures
    that all observations of a feature take on values in an expected range.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code validates that the ''MedInc'' value falls within an expected range
    and identifies data points that do not meet this criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'You can try for other numeric features of your choice. But we see that all
    values in the ''MedInc'' column lie in the expected range:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 6\. Check Cross-Column Dependency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Most data sets contain related features. So it's important to include checks
    based on logically relevant relationships between columns (or features).
  prefs: []
  type: TYPE_NORMAL
- en: While features—individually—may take on values in the expected range, the relationship
    between them may be inconsistent.
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example for our dataset. In a valid record, the ‘AveRooms’ should
    typically be greater than or equal to the ‘AveBedRms’.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the California housing dataset we’re working with, we see that there are
    no such invalid records:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 7\. Check for Inconsistent Data Entry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Inconsistent data entry is a common data quality issue in most datasets. Examples
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: Inconsistent formatting in datetime columns
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inconsistent logging of categorical variable values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording of reading in different units
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our dataset, we’ve verified the data types of columns and have identified
    outliers. But you can also run checks for inconsistent data entry.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s whip up a simple example to check if all the date entries have a consistent
    formatting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here we use regular expressions in conjunction with pandas `apply()` function
    to check if all date entries are in the `YYYY-MM-DD` format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'This returns the entries that do not follow the expected format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Wrapping up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this tutorial, we went over common data quality checks with pandas.
  prefs: []
  type: TYPE_NORMAL
- en: When you are working on smaller data analysis projects, these data quality checks
    with pandas are a good starting point. Depending on the problem and the dataset,
    you can include additional checks.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re interested in learning data analysis, check out the guide [7 Steps
    to Mastering Data Wrangling with Pandas and Python](/7-steps-to-mastering-data-wrangling-with-pandas-and-python).
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Quality Dimensions: Assuring Your Data Quality with Great Expectations](https://www.kdnuggets.com/2023/03/data-quality-dimensions-assuring-data-quality-great-expectations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning For Compliance Checks: What''s New?](https://www.kdnuggets.com/2022/05/deep-learning-compliance-checks-new.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Free 4 Week Data Science Course on AI Quality Management](https://www.kdnuggets.com/2022/02/truera-free-4-week-data-science-course-ai-quality-management.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Significance of Data Quality in Making a Successful Machine…](https://www.kdnuggets.com/2022/03/significance-data-quality-making-successful-machine-learning-model.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Quality: The Good, The Bad, and The Ugly](https://www.kdnuggets.com/2022/01/data-quality-good-bad-ugly.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
