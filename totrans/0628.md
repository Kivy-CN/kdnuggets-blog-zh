# 使用5行代码更改任何视频的背景

> 原文：[https://www.kdnuggets.com/2020/12/change-background-video-5-lines-code.html](https://www.kdnuggets.com/2020/12/change-background-video-5-lines-code.html)

[评论](#comments)

**由 [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/) 提供，独立AI研究员**

![图示](../Images/c90ef44af509ee9620dd55a0fd935595.png)

作者拍摄的照片

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT需求

* * *

PixelLib 是一个库，旨在简化现实应用中的对象分割实现。PixelLib 支持图像调节，即更改任何图像背景的能力。PixelLib 现在支持视频调节，即更改视频和摄像头画面背景的能力。PixelLib 使用对象分割技术来执行出色的前景和背景分离。PixelLib 利用在 pascalvoc 数据集上训练的 deeplabv3+ 模型，该数据集支持 20 个对象类别。

```py
person,bus,car,aeroplane, bicycle, ,motorbike,bird, boat, bottle,  cat, chair, cow, dinningtable, dog, horse pottedplant, sheep, sofa, train, tv
```

*支持的背景效果如下：*

**1** 使用图片更改图像的背景

**2** 给图像和视频的背景分配不同的颜色。

**3** 模糊图像和视频的背景。

**4** 将图像和视频的背景转换为灰度。

**5** 为视频创建虚拟背景。

安装 PixelLib 及其依赖项：

安装 Tensorflow 使用：（PixelLib 支持 tensorflow 2.0 及以上版本）

+   *pip3 install tensorflow*

安装 PixelLib 使用

+   pip3 install pixellib

如果已安装，请使用以下命令升级到最新版本：

+   pip3 install pixellib — 升级

### 目标对象的检测

在一些应用程序中，你可能希望对图像或视频中的特定对象进行检测。deeplab模型默认检测它支持的图像或视频中的所有对象。现在可以过滤掉未使用的检测并针对图像或视频中的特定对象进行检测。

*样例图片*

![图示](../Images/3844ccd3c79e2702e0710a8e6bb650ef.png)

来源：[Unsplash.com](https://unsplash.com/photos/D5mCL7Q_6Us) 由 Strvnge Films 提供

我们打算模糊上述图像的背景。

用于模糊图像背景的代码。

输出图像

![用于发布的图片](../Images/dd2a391896609ec6e19d2b2ecc8882b8.png)

我们的目标是完全模糊这张图像中人的背景，但对于其他物体的存在我们不满意。因此，需要修改代码以检测目标物体。

代码仍然相同，只是我们在*blur_bg*函数中引入了一个额外的参数***detect***。

```py
change_bg.blur_bg("sample.jpg", extreme = True, output_image_name="output_img.jpg", detect = "person")
```

**detect:** 这是确定要检测的目标物体的参数。detect的值设置为***person***。这意味着模型将仅检测图像中的人。

![Image for post](../Images/af4678c17099777cc6af3f59ac414219.png)

这是只有我们的目标物体的新的图像。

如果我们打算仅显示这张图像中的汽车，只需将**detect**的值从***person***更改为***car***。

```py
change_bg.blur_bg("sample.jpg", extreme = True, output_image_name="output_img.jpg", detect = "car")
```

![Image for post](../Images/c831882ee424554647b31976a41d2941.png)

我们将目标物体设置为***car***，图像中其他所有物体的背景都被模糊处理了。

***目标物体的背景颜色***

可以通过颜色效果进行目标检测。

```py
change_bg.color_bg("sample.jpg", colors = (0,128,0), output_image_name="output_img.jpg", detect = "person")
```

![Image for post](../Images/b849e912cc6dfe47cfae912cb1d5cbd9.png)

***用新图片改变目标物体的背景***

***背景图像***

![Figure](../Images/ccef7e7882379916a9c419cb6457e54e.png)

来源：[Unsplash.com by Dawid Zawila](https://unsplash.com/photos/9P2-bzjvIHk)

```py
change_bg.change_bg_img("sample.jpg", "background.jpg", output_image_name="output_img.jpg", detect = "person")
```

![Image for post](../Images/1602d3c22c22d9579a983ef93eeb1d1f.png)

***将目标物体的背景转换为灰度***

```py
change_bg.gray_bg("sample.jpg", output_image_name="output_img.jpg", detect = "person")
```

![Image for post](../Images/c08f9107b96b6938bb4eb9e9dfca052b.png)

阅读本文以深入了解使用PixelLib进行图像背景编辑的全面知识。

[**用5行代码改变任何图像的背景**](https://towardsdatascience.com/change-the-background-of-any-image-with-5-lines-of-code-23a0ef10ce9a)

### ***视频调整与PixelLib***

视频调整是改变任何视频背景的能力。

**模糊视频背景**

PixelLib使得使用仅五行代码模糊任何视频的背景变得方便。

**sample_video**

*模糊视频文件背景的代码*

```py
import pixellib                       
from pixellib.tune_bg import alter_bg  

change_bg = alter_bg(model_type = "pb")
change_bg.load_pascalvoc_model("xception_pascalvoc.pb")
```

我们导入了pixellib，并从pixellib中导入了*alter_bg*类。创建了该类的实例，并在类中添加了一个参数*model_type*并将其设置为***pb***。*最后我们调用了函数来加载模型。

**注意：** PixelLib支持两种类型的deeplabv3+模型，即keras和tensorflow模型。keras模型是从tensorflow模型的检查点提取的。tensorflow模型的性能优于从检查点提取的keras模型。我们将使用tensorflow模型。请从[这里](https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.1/xception_pascalvoc.pb)下载tensorflow模型。

有三个参数决定背景模糊的程度。

*低：* 当设置为true时，背景会稍微模糊。

*中等：* 当设置为true时，背景会中等程度地模糊。

*extreme:* 当设置为true时，背景会被深度模糊。

```py
change_bg.blur_video("sample_video.mp4", extreme = True, frames_per_second=10, output_video_name="blur_video.mp4", detect = "person")
```

这是模糊视频背景的代码行。此函数接受五个参数：

**video_path:** 这是我们想要模糊背景的视频文件的路径。

**extreme:** 设置为true时，视频的背景会被极度模糊。

**frames_per_second:** 这是设置输出视频文件每秒帧数的参数。在这种情况下，设置为10，即保存的视频文件将有10帧每秒。

**output_video_name:** 这是保存的视频。输出视频将保存在你当前的工作目录中。

**detect:** 这是选择视频中目标对象的参数。设置为***person***。

**输出视频**

**模糊摄像头画面的背景**

```py
import cv2capture = cv2.VideoCapture(0)
```

我们导入了cv2并包含了捕获摄像头画面的代码。

```py
change_bg.blur_camera(capture, extreme = True, frames_per_second= 5, output_video_name=”output_video.mp4", show_frames= True,frame_name= “frame”, detect = "person")
```

在模糊摄像头画面的代码中，我们将视频的文件路径替换为捕获，即我们将处理摄像头的画面流而不是视频文件。我们添加了额外的参数来显示摄像头的画面：

**show_frames:** 这是处理显示模糊摄像头画面的参数。

**frame_name:** 这是给摄像头显示的帧指定的名称。

**输出视频**

哇！PixelLib成功地模糊了视频中的背景。

### **为视频创建虚拟背景**

PixelLib使得为任何视频创建虚拟背景变得非常简单，你可以利用任何图像为视频创建虚拟背景。

**示例视频**

**用作视频背景的图像**

![图示](../Images/c5bdc32590fbb45357cd1a3591bdaa5f.png)

来源：[Unsplash.com](https://unsplash.com/photos/rCbdp8VCYhQ) [by Handy Holmes](https://unsplash.com/photos/rCbdp8VCYhQ)

```py
change_bg.change_video_bg(“sample_video.mp4”, “bg.jpg”, frames_per_second = 10, output_video_name=”output_video.mp4", detect = “person”)
```

代码还是一样，只是我们调用了函数*change_video_bg*来为视频创建虚拟背景。该函数接受我们想用作视频背景的图像路径。

**输出视频**

> 漂亮的演示！我们成功地为视频创建了一个虚拟空间背景。

**为摄像头的画面创建虚拟背景**

```py
change_bg.change_camera_bg(cap, “space.jpg”, frames_per_second = 5, show_frames=True, frame_name=”frame”, output_video_name=”output_video.mp4", detect = “person”)
```

这与我们用于模糊摄像头画面的代码类似。唯一的区别是我们调用了函数*change_camera_bg*。我们执行了相同的操作，替换了视频的文件路径为捕获，并添加了相同的参数。

**输出视频**

> 哇！PixelLib成功地为我的视频创建了虚拟背景。

**彩色视频背景**

PixelLib使得给视频背景指定任何颜色成为可能。

*给视频文件背景上色的代码*

```py
change_bg.color_video("sample_video.mp4", colors =  (0, 128, 0), frames_per_second=15, output_video_name="output_video.mp4", detect = "person")
```

代码还是一样，只是我们调用了函数*color_video*来给视频的背景添加独特的颜色。函数*color_bg*接受参数*colors*，并将颜色的RGB值设置为绿色。绿色的RGB值是（0，128，0）。

输出视频

```py
change_bg.color_video("sample_video.mp4", colors =  (0, 128, 0), frames_per_second=15, output_video_name="output_video.mp4", detect = "person")
```

同样的视频，背景为白色

**为摄像头的画面上色**

```py
change_bg.color_camera(capture, frames_per_second=10,colors = (0, 128, 0), show_frames = True, frame_name = “frame”, output_video_name=”output_video.mp4", detect = "person")
```

它类似于我们用来为摄像头的画面创建虚拟背景的代码。唯一的区别是我们调用了函数*color_camera*。我们执行了相同的程序，替换了视频的文件路径为捕捉，并添加了相同的参数。

**输出视频**

> 漂亮的演示！我的背景成功地用 PixelLib 被染成了绿色。

**灰度视频背景**

*将视频文件背景转换为灰度的代码*

```py
change_bg.gray_video("sample_video.mp4", frames_per_second=10, output_video_name="output_video.mp4", detect = "person")
```

输出视频

**注意：** 视频的背景会被改变，现有的对象会保持其原始质量。

**将摄像头视频的背景转换为灰度**

它类似于我们用来给摄像头的画面上色的代码。唯一的区别是我们调用了函数*gray_camera*。我们执行了相同的程序，替换了视频文件路径为捕捉，并添加了相同的参数。

> [访问 PixelLib 的官方 GitHub 仓库](https://github.com/ayoolaolafenwa/PixelLib)
> 
> [访问 PixelLib 的官方文档](https://pixellib.readthedocs.io/en/latest/)

通过以下方式联系我：

邮箱: [olafenwaayoola@gmail.com](https://mail.google.com/mail/u/0/#inbox)

Linkedin: [Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/)

Twitter: [@AyoolaOlafenwa](https://twitter.com/AyoolaOlafenwa)

Facebook: [Ayoola Olafenwa](https://web.facebook.com/ayofen)

查看这些关于如何使用 PixelLib 进行图像和视频中对象的语义分割和实例分割的文章。

[**用5行代码进行图像分割**](https://towardsdatascience.com/image-segmentation-with-six-lines-0f-code-acb870a462e8)

使用 PixelLib 进行语义分割和实例分割。

[**用5行代码进行视频分割**](https://towardsdatascience.com/video-segmentation-with-5-lines-of-code-87f798afb93)

视频的语义分割和实例分割。

[**用5行代码对150类对象进行语义分割**](https://towardsdatascience.com/semantic-segmentation-of-150-classes-of-objects-with-5-lines-of-code-7f244fa96b6c)

使用 PixelLib 对150类对象进行语义分割

[**用7行代码进行自定义实例分割训练**](https://towardsdatascience.com/custom-instance-segmentation-training-with-7-lines-of-code-ff340851e99b)

用7行代码训练你的数据集以实现实例分割和对象检测。

**简介：[Ayoola Olafenwa](https://www.linkedin.com/in/ayoola-olafenwa-003b901a9/)** 是一名独立的 AI 研究员，专注于计算机视觉领域。

[原文](https://towardsdatascience.com/change-the-background-of-any-video-with-5-lines-of-code-7cc847394f5d)。经许可转载。

**相关：**

+   [用5行代码更改任何图像的背景](/2020/11/change-background-image-5-lines-code.html)

+   [计算机视觉路线图](/2020/10/roadmap-computer-vision.html)

+   [使用深度学习自动旋转图像](/2020/07/auto-rotate-images-deep-learning.html)

### 更多相关话题

+   [NExT-GPT 介绍：任意对任意的多模态大型语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)

+   [少于 15 行代码的多模态深度学习](https://www.kdnuggets.com/2023/01/predibase-multi-modal-deep-learning-less-15-lines-code.html)

+   [如何从不同背景转行进入数据科学？](https://www.kdnuggets.com/2023/05/transition-data-science-different-background.html)

+   [SHAP：在 Python 中解释任何机器学习模型](https://www.kdnuggets.com/2022/11/shap-explain-machine-learning-model-python.html)

+   [如何在没有任何工作经验的情况下获得数据科学的第一份工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)

+   [在参加任何免费的数据科学课程之前请阅读此文](https://www.kdnuggets.com/read-this-before-you-take-any-free-data-science-course)
