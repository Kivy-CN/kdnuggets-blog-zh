# IT工程师需要学习多少数学才能进入数据科学领域？

> 原文：[https://www.kdnuggets.com/2017/12/mathematics-needed-learn-data-science-machine-learning.html](https://www.kdnuggets.com/2017/12/mathematics-needed-learn-data-science-machine-learning.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)

![Header image](../Images/b8d71fd7cbe65627c447344a2c108f50.png)

**免责声明和前言**

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速入门网络安全职业。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的IT

* * *

首先，免责声明，我不是IT工程师:-) 我在半导体领域工作，特别是高功率半导体，作为一名技术开发工程师，日常工作主要涉及半导体物理、硅制造过程的有限元仿真或电子电路理论。当然，这个过程里也涉及一些数学，但无论好坏，我都不需要涉及数据科学家所需的那种数学。

不过，我有很多朋友在IT行业，观察到许多传统的IT工程师对数据科学和机器学习/人工智能这一激动人心的领域充满热情。我自己也在这一领域摸索，以学习一些可以应用于半导体器件或工艺设计的行业技巧。但是，当我开始深入研究这些激动人心的主题（通过自学）时，我很快发现自己对一些基础数学知识了解甚少/仅有粗略的了解/大部分忘记了。我在[这篇LinkedIn文章中谈到这些](https://www.linkedin.com/pulse/whys-hows-studying-mathematics-mldata-science-preamble-sarkar)……

现在，我拥有美国一所著名大学的电气工程博士学位，但仍然觉得在没有一些基本数学复习的情况下，准备好掌握机器学习或数据科学技术是不够的。对IT工程师并无不敬，我必须说，他/她的工作性质和长期培训通常使他/她远离应用数学的世界。他/她可能每天处理大量数据和信息，但可能不会强调对这些数据的严格建模。通常，时间压力巨大，强调的是‘*利用数据满足你当前的需求然后继续前进*’，而不是对数据进行深入探究和科学探索。不幸的是，数据科学应该始终关注科学（*而非* 数据），遵循这一点，[某些工具和技术变得不可或缺](https://medium.freecodecamp.org/how-machines-learn-a-practical-guide-203aae23cafb)。

> 这些工具和技术——通过探究基础动态来建模一个过程（物理或信息），严格估计数据源的质量，培养从信息流中识别隐藏模式的能力，或者清楚理解模型的局限性——是健全科学过程的标志。

这些问题通常在应用科学/工程学科的高级研究生课程中教授。或者，通过类似领域的高质量研究生级别研究也可以掌握。不幸的是，即使在传统IT领域（如DevOps、数据库或QA/测试）工作了十年，也不足以严格提供这种培训。实际上，这并没有必要。

**时代在变**

直到现在。

你看，在大多数情况下，拥有完美的SQL查询知识，对总体业务需求有清晰的认识，以及对相应RDBMS的一般结构有了解，这就足以执行提取-转换-加载周期，从而为公司创造价值，对于任何有价值的IT工程师来说都够了。但是，如果有人过来开始问一些奇怪的问题，比如“*你的人工合成测试数据集足够随机吗*”或者“*你如何知道下一个数据点是否在数据分布的3σ范围内*”？或者，甚至是隔壁计算机科学毕业生/极客偶尔的调侃，提到*任何有意义的数学运算（即矩阵）的计算负荷随表格大小（即行数和列数）非线性增长*，这可能会让人感到烦恼和困惑。

> 这些类型的问题频率和紧迫性都在增加，因为数据是新的货币。

高管、技术经理、决策者们已经不再满足于传统ETL工具生成的仅仅是干巴巴的表格描述。他们希望看到隐藏的模式，渴望感受列之间微妙的互动，期望获取全面的描述性和推断性统计数据，以帮助预测建模并扩展数据集的预测能力，远远超出其所包含的即时值范围。

> 现在的数据必须讲述一个故事，或者，如果你愿意的话，就像唱首歌。然而，要听到它美妙的旋律，必须掌握音乐的基本音符，并且
> 
> 这些是数学真理。

言归正传，让我们来讨论问题的核心。一个普通的IT工程师如果想进入商业分析/数据科学/数据挖掘领域，必须学习/复习哪些数学的基本主题/子主题？我将在下图中展示我的想法。

![](../Images/a9a60b1042ea8e4d82c0af780f6a8172.png)

**基础代数、函数、集合论、绘图、几何**

![](../Images/4c82fabc3863599f615b8f2f8a0b0bf5.png)

总是从根本开始是个好主意。现代数学的构筑是基于一些关键基础——集合论、泛函分析、数论等。从应用数学的学习角度来看，我们可以通过一些简洁的模块（无特定顺序）来简化这些主题的学习：

![](../Images/95bee555cf3501cb1e11997fd7a00bef.png)

a) 集合论基础，b) 实数和复数及其基本性质，c) 多项式函数、指数、对数、三角函数恒等式，d) 线性和二次方程，e) 不等式、无穷级数、二项式定理，f) 排列和组合，g) 图形绘制、笛卡尔和极坐标系、圆锥曲线，h) 基本几何及定理、三角形性质。

**微积分**

**艾萨克·牛顿**想要解释天体的行为。但他当时没有足够好的数学工具来描述他的物理概念。因此，他在[逃避城市英格兰的瘟疫时躲在乡村农场上](https://en.wikipedia.org/wiki/Early_life_of_Isaac_Newton)发明了这一（或某种现代形式的）数学分支。从那时起，这被认为是任何分析研究的高级学习的入门——无论是纯科学还是应用科学、工程、社会科学、经济学等。

![](../Images/f7bd77eea2765b0dcdc18f233fffddcd.png)

因此，微积分的概念和应用在数据科学或机器学习领域中频繁出现也就不足为奇了。需要涵盖的最重要的主题如下——

a) 单变量函数、极限、连续性和可微性，b) 平均值定理、不确定形式和L’Hospital法则，c) 极大值和极小值，d) 乘积和链式法则，e) 泰勒级数，f) 积分学的基本定理和平均值定理，g) 定积分和不定积分的计算，h) 贝塔函数和伽马函数，i) 二变量函数、极限、连续性、偏导数，j) 常微分方程和偏微分方程的基础知识。

**线性代数**

在***Facebook***上收到了新的好友推荐？一个久未联系的职业联系人突然在***LinkedIn***上添加了你？***Amazon***突然为你的下一次假期阅读推荐了一本精彩的浪漫惊悚小说？还是***Netflix***挖掘出了一个小众却正好适合你口味和心情的纪录片？

![](../Images/8eb2ccd2d269ec86d3036db6fa7c3731.png)

知道如果你学习线性代数的基础知识，那么你就掌握了[科技行业中高层大佬们所有这些技术背后的基本数学对象](http://www.uh.edu/engines/epi2514.htm)的知识，不觉得很棒吗？

至少，你将了解控制你在***Target***上购物、如何使用***Google Map***驾驶、你在***Pandora***上听什么歌，或你在***Airbnb***上租哪个房间的数学结构的基本属性。

必须学习的核心主题有（绝不是一个按顺序或详尽的列表）：

a) 矩阵和向量的基本属性——标量乘法、线性变换、转置、共轭、秩、行列式，b) 内积和外积，c) 矩阵乘法规则及各种算法，d) 矩阵求逆，e) 特殊矩阵——方阵、单位矩阵、三角矩阵、稀疏矩阵和密集矩阵的概念、单位向量、对称矩阵、厄米矩阵、斜厄米矩阵和单位矩阵，f) 矩阵分解概念/LU分解、高斯/高斯-约旦消元法、解线性方程组Ax=b，g) 向量空间、基、跨度、正交性、正交规范性、线性最小二乘，h) 奇异值分解，i) 特征值、特征向量及对角化。

这里有一篇关于[你可以用线性代数完成什么的精彩Medium文章](https://medium.com/@jeremyjkun/here-s-just-a-fraction-of-what-you-can-do-with-linear-algebra-633383d4153f)。

**统计学与概率论**

> 唯有死亡和税收是确定的，其它一切均符合正态分布。

![](../Images/fdb2119353e6212d839543a0256109eb.png)

在讨论数据科学时，掌握统计学和概率论的基本概念的重要性无法被过分强调。许多领域内的从业者实际上将机器学习称为统计学习。我在进行第一次机器学习的MOOC时，遵循了广为人知的 “[统计学习简介](http://www-bcf.usc.edu/~gareth/ISL/)”，并立即意识到自己在该学科上存在的概念性差距。为了填补这些差距，我开始参加其他专注于基础统计学和概率论的MOOC，并阅读/观看相关主题的资料和视频。这个学科庞大而无穷，因此，聚焦的规划对于涵盖大部分基本概念至关重要。我尽力列出这些概念，但我担心这是我最可能不足的领域。

a) 数据总结和描述性统计，集中趋势，方差，协方差，相关性；b) 概率：基本概念，期望值，概率计算，贝叶斯定理，条件概率；c) 概率分布函数——均匀分布，正态分布，二项分布，卡方分布，学生t分布，中心极限定理；d) 抽样，测量，误差，随机数；e) 假设检验，A/B测试，置信区间，p值；f) 方差分析（ANOVA）；g) 线性回归；h) 功效，效应量，均值检验；i) 研究研究和实验设计。

这是一个关于 [数据科学家对统计知识的必要性](https://medium.com/towards-data-science/statistics-review-for-data-scientists-and-management-df8f94760221) 的很好的文章。

**专题：优化理论，算法分析**

这些主题与传统应用数学的讨论略有不同，因为它们大多与理论计算机科学、控制理论或运筹学等专业领域相关且广泛使用。然而，对这些强大技术的基本理解在机器学习实践中可以带来极大的好处，因此值得在这里提及。

![](../Images/03c5726e38083239c7c09fa7c065e7c3.png)

例如，几乎所有的机器学习算法/技术都旨在在各种约束条件下最小化某种估计误差。这本身就是一个优化问题，通常通过[线性规划](https://en.wikipedia.org/wiki/Linear_programming)或类似技术来解决。另一方面，理解计算机算法的时间复杂度总是令人深感满足和有洞察力的，因为当算法应用于大数据集时，它变得极其重要。在大数据时代，数据科学家通常需要提取、转换和分析数十亿条记录，他们必须非常小心地选择合适的算法，因为这可以决定表现的卓越与否。算法的一般理论和性质最好在正式的计算机科学课程中学习，但要理解它们的时间复杂度（即算法在处理给定数据规模时需要的时间）是如何分析和计算的，必须对[*动态规划*](https://medium.freecodecamp.org/demystifying-dynamic-programming-3efafb8d4296)或*递归方程*有基本的了解。对[*数学归纳法证明*](https://en.wikipedia.org/wiki/Mathematical_induction)技术的熟悉也可以非常有帮助。

**后记**

吓到了吗？觉得需要学习的主题令人头疼？别担心，你会在实际操作中和需要时逐渐学习。但目标是保持思维的窗户和大门敞开，并欢迎新知。

甚至有一个简明的[MOOC课程](https://www.coursera.org/learn/datasciencemathskills)来帮助你入门。请注意，这是一门用于刷新你高中或大学一年级知识的初学者级课程。还有一篇[关于数据科学的15个最佳数学课程的总结文章](/2015/09/15-math-mooc-data-science.html)在kdnuggets上。

但你可以放心，在复习这些主题后，无论是你可能在本科阶段学习过的，还是学习新的概念，你都会感到非常振奋，开始听到数据所唱的隐藏音乐。这就是成为数据科学家的一个重要进步……

**#数据科学, #机器学习, #信息, #技术, #数学**

如果你有任何问题或想法要分享，请通过[**tirthajyoti[AT]gmail.com**](mailto:tirthajyoti@gmail.com)联系作者。你还可以查看作者的[**GitHub仓库**](https://github.com/tirthajyoti)，获取其他有趣的Python、R或MATLAB代码片段以及机器学习资源。你还可以[在LinkedIn上关注我](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)。

**个人简介：[Tirthajyoti Sarkar](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)** 是一位半导体技术专家、机器学习/数据科学狂热者、电子工程博士、博客作者和作家。

[原文](https://towardsdatascience.com/how-much-maths-does-an-it-engineer-need-to-learn-to-get-into-data-science-machine-learning-7d6a42f79516)。经许可转载。

**相关：**

+   [为什么你应该忘记数据科学代码中的‘for-loop’，而拥抱向量化](/2017/11/forget-for-loop-data-science-code-vectorization.html)

+   [数据科学的15个数学MOOC课程](/2015/09/15-math-mooc-data-science.html)

+   [回归分析真的是机器学习吗？](/2017/06/regression-analysis-really-machine-learning.html)

### 更多相关内容

+   [成为伟大数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)

+   [2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)

+   [停止学习数据科学以寻找目标，并为…寻找目标](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [你在数据科学中需要多少数学知识？](https://www.kdnuggets.com/2020/06/math-data-science.html)

+   [学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)
