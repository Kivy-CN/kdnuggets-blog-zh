["```py\n\nimport numpy\nimport pickle\n\ndef sigmoid(inpt):\n  return 1.0 / (1 + numpy.exp(-1 * inpt))\n\nf = open(\"dataset_features.pkl\", \"rb\")\ndata_inputs2 = pickle.load(f)\nf.close()\n\nfeatures_STDs = numpy.std(a=data_inputs2, axis=0)\ndata_inputs = data_inputs2[:, features_STDs > 50]\n\nf = open(\"outputs.pkl\", \"rb\")\ndata_outputs = pickle.load(f)\nf.close()\n\nHL1_neurons = 150\ninput_HL1_weights = numpy.random.uniform(low=-0.1, high=0.1,\n    size=(data_inputs.shape[1], HL1_neurons))\n\nHL2_neurons = 60\nHL1_HL2_weights = numpy.random.uniform(low=-0.1, high=0.1,\n    size=(HL1_neurons, HL2_neurons))\n\noutput_neurons = 4\nHL2_output_weights = numpy.random.uniform(low=-0.1, high=0.1,\n    size=(HL2_neurons, output_neurons))\n\nH1_outputs = numpy.matmul(a=data_inputs[0, :], b=input_HL1_weights)\nH1_outputs = sigmoid(H1_outputs)\nH2_outputs = numpy.matmul(a=H1_outputs, b=HL1_HL2_weights)\nH2_outputs = sigmoid(H2_outputs)\nout_otuputs = numpy.matmul(a=H2_outputs, b=HL2_output_weights)\n\npredicted_label = numpy.where(out_otuputs == numpy.max(out_otuputs))[0][0]\nprint(\"Predicted class : \", predicted_label)\n\n```", "```py\n\nimport numpy\nimport pickle\n\ndef sigmoid(inpt):\n  return 1.0 / (1 + numpy.exp(-1 * inpt))\n\ndef relu(inpt):\n  result = inpt\n  result[inpt < 0] = 0\n  return result\n\ndef update_weights(weights, learning_rate):\n  new_weights = weights - learning_rate * weights\n  return new_weights\n\ndef train_network(num_iterations, weights, data_inputs, data_outputs, learning_rate, activation=\"relu\"):\n  for iteration in range(num_iterations):\n    print(\"Itreation \", iteration)\n    for sample_idx in range(data_inputs.shape[0]):\n      r1 = data_inputs[sample_idx, :]\n      for idx in range(len(weights) - 1):\n       curr_weights = weights[idx]\n       r1 = numpy.matmul(a=r1, b=curr_weights)\n       if activation == \"relu\":\n         r1 = relu(r1)\n       elif activation == \"sigmoid\":\n         r1 = sigmoid(r1)\n    curr_weights = weights[-1]\n    r1 = numpy.matmul(a=r1, b=curr_weights)\n    predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\n    desired_label = data_outputs[sample_idx]\n    if predicted_label != desired_label:\n      weights = update_weights(weights,\n        learning_rate=0.001)\n  return weights\n\ndef predict_outputs(weights, data_inputs, activation=\"relu\"):\n  predictions = numpy.zeros(shape=(data_inputs.shape[0]))\n  for sample_idx in range(data_inputs.shape[0]):\n    r1 = data_inputs[sample_idx, :]\n      for curr_weights in weights:\n        r1 = numpy.matmul(a=r1, b=curr_weights)\n      if activation == \"relu\":\n        r1 = relu(r1)\n      elif activation == \"sigmoid\":\n        r1 = sigmoid(r1)\n    predicted_label = numpy.where(r1 == numpy.max(r1))[0][0]\n    predictions[sample_idx] = predicted_label\n  return predictions\n\nf = open(\"dataset_features.pkl\", \"rb\")\ndata_inputs2 = pickle.load(f)\nf.close()\n\nfeatures_STDs = numpy.std(a=data_inputs2, axis=0)\ndata_inputs = data_inputs2[:, features_STDs > 50]\n\nf = open(\"outputs.pkl\", \"rb\")\ndata_outputs = pickle.load(f)\nf.close()\n\nHL1_neurons = 150\ninput_HL1_weights = numpy.random.uniform(low=-0.1, high=0.1,\nsize=(data_inputs.shape[1], HL1_neurons))\n\nHL2_neurons = 60\nHL1_HL2_weights = numpy.random.uniform(low=-0.1, high=0.1,\nsize=(HL1_neurons, HL2_neurons))\n\noutput_neurons = 4\nHL2_output_weights = numpy.random.uniform(low=-0.1, high=0.1,\nsize=(HL2_neurons, output_neurons))\n\nweights = numpy.array([input_HL1_weights,\n  HL1_HL2_weights,\n  HL2_output_weights])\n\nweights = train_network(num_iterations=10,\n  weights=weights,\n  data_inputs=data_inputs,\n  data_outputs=data_outputs,\n  learning_rate=0.01,\n  activation=\"relu\")\n\npredictions = predict_outputs(weights, data_inputs)\nnum_flase = numpy.where(predictions != data_outputs)[0]\nprint(\"num_flase \", num_flase.size)\n\n```"]