["```py\n# Installing Transformer\n\n!pip install -q transformers\n```", "```py\n# Import necessary library\n\n# For managing audio file\nimport librosa\n\n#Importing Pytorch\nimport torch\n\n#Importing Wav2Vec\nfrom transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n```", "```py\n# Loading the audio file\n\naudio, rate = librosa.load(\"taken_clip.wav\", sr = 16000)\n```", "```py\n# printing audio \nprint(audio)\n\narray([0., 0., 0., ..., 0., 0., 0.], dtype=float32)\n```", "```py\n# printing rate\nprint(rate)\n\n16000\n```", "```py\n# Importing Wav2Vec pretrained model\n\ntokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\nmodel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n```", "```py\n# Taking an input value\n\ninput_values = tokenizer(audio, return_tensors = \"pt\").input_values\n```", "```py\n# Storing logits (non-normalized prediction values)\nlogits = model(input_values).logits\n```", "```py\n# Storing predicted ids\nprediction = torch.argmax(logits, dim = -1)\n```", "```py\n# Passing the prediction to the tokenzer decode to get the transcription\ntranscription = tokenizer.batch_decode(prediction)[0]\n```", "```py\n# Printing the transcription\nprint(transcription)\n\n'I WILL LOOK FOR YOU I WILL FIND YOU  AND I WILL KILL YOU'\n```"]