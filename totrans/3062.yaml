- en: The Main Approaches to Natural Language Processing Tasks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/10/main-approaches-natural-language-processing-tasks.html](https://www.kdnuggets.com/2018/10/main-approaches-natural-language-processing-tasks.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)![](../Images/b499b10448af1c7b977d5420fb0113a5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Source: [Top 5 Semantic Technology Trends to Look for in 2017](https://ontotext.com/top-5-semantic-technology-trends-2017/)
    (ontotext).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have previously discussed a number of [introductory topics in natural language
    processing (NLP)](/2018/06/getting-started-natural-language-processing.html),
    and I had planned at this point to move forward with covering some some useful,
    practical applications. It then came to my attention that I had overlooked a couple
    of important introductory discussions which were likely needed prior to moving
    ahead. The first of those topics is will be covered here, more of a general discussion
    on the approaches to natural language processing tasks which are common today.
    This also brings up the question: specifically, what types of NLP tasks are there?'
  prefs: []
  type: TYPE_NORMAL
- en: The other fundamental topic which has been pointed out to me as being overlooked
    will be covered next week, and that will be address the common question of "how
    do we represent text for machine learning systems?"
  prefs: []
  type: TYPE_NORMAL
- en: But first, back to today's topic. Let's have a look at the main approaches to
    NLP tasks that we have at our disposal. We will then have a look at the concrete
    NLP tasks we can tackle with said approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Approaches to NLP Tasks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While not cut and dry, there are 3 main groups of approaches to solving NLP
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '![Image](../Images/06df8524acd26c1d5673e7fcf1602ad5.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig 1\. Dependency parse tree using [spaCy](https://spacy.io/).
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Rule-based**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule-based approaches are the oldest approaches to NLP. Why are they still
    used, you might ask? It''s because they are tried and true, and have been proven
    to work well. Rules applied to text can offer a lot of insight: think of what
    you can learn about arbitrary text by finding what words are nouns, or what verbs
    end in -ing, or whether a pattern recognizable as Python code can be identified.
    [Regular expressions](https://en.wikipedia.org/wiki/Regular_expression) and [context
    free grammars](https://en.wikipedia.org/wiki/Context-free_grammar) are textbook
    examples of rule-based approaches to NLP.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule-based approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: tend to focus on pattern-matching or parsing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: can often be thought of as "fill in the blanks" methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: are low precision, high recall, meaning they can have high performance in specific
    use cases, but often suffer performance degradation when generalized
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2\. "Traditional" Machine Learning**'
  prefs: []
  type: TYPE_NORMAL
- en: '"Traditional" machine learning approaches include probabilistic modeling, likelihood
    maximization, and linear classifiers. Notably, these are not neural network models
    (see those below).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional machine learning approaches are characterized by:'
  prefs: []
  type: TYPE_NORMAL
- en: training data - in this case, a corpus with markup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: feature engineering - word type, surrounding words, capitalized, plural, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: training a model on parameters, followed by fitting on test data (typical of
    machine learning systems in general)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: inference (applying model to test data) characterized by finding most probable
    words, next word, best category, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"semantic slot filling"'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3\. Neural Networks**'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is similar to "traditional" machine learning, but with a few differences:'
  prefs: []
  type: TYPE_NORMAL
- en: feature engineering is generally skipped, as networks will "learn" important
    features (this is generally one of the claimed big benefits of using neural networks
    for NLP)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: instead, streams of raw parameters ("words" -- actually vector representations
    of words) without engineered features, are fed into neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: very large training corpus
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specific neural networks of use in NLP include recurrent neural networks (RNNs)
    and convolutional neural networks (CNNs).
  prefs: []
  type: TYPE_NORMAL
- en: '**Why use "traditional" machine learning (or rule-based) approaches for NLP?**'
  prefs: []
  type: TYPE_NORMAL
- en: still good for sequence labeling (using probabilistic modeling)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: some ideas in neural networks are very similar to earlier methods (word2vec
    similar in concept to distributional semantic methods)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: use methods from traditional approaches to improve neural network approaches
    (for example, word alignments and attention mechanisms are similar)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Why deep learning over "traditional" machine learning?**'
  prefs: []
  type: TYPE_NORMAL
- en: SOTA in many applications (for example, machine translation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a lot of research (majority?) in NLP happening here now
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Importantly**, both neural network and non-neural network approaches can
    be useful for contemporary NLP in their own right; they can also can be used or
    studied in tandem for maximum potential benefit'
  prefs: []
  type: TYPE_NORMAL
- en: What are NLP Tasks?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have the approaches, but what about the tasks themselves?
  prefs: []
  type: TYPE_NORMAL
- en: There are no hard lines between these task types; however, many are fairly well-defined
    at this point. A given macro NLP task may include a variety of sub-tasks.
  prefs: []
  type: TYPE_NORMAL
- en: We first outlined the main approaches, since the technologies are often focused
    on for beginners, but it's good to have a concrete idea of what types of NLP tasks
    there are. Below are the main categories of NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**1\. Text Classification Tasks**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Representation: bag of words (does not preserve word order)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goal: predict tags, categories, sentiment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application: filtering spam emails, classifying documents based on dominant
    content'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2\. Word Sequence Tasks**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Representation: sequences (preserves word order)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goal: language modeling - predict next/previous word(s), text generation'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application: translation, chatbots, sequence tagging (predict POS tags for
    each word in sequence), named entity recognition'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3\. Text Meaning Tasks**'
  prefs: []
  type: TYPE_NORMAL
- en: 'Representation: word vectors, the mapping of words to vectors (*n*-dimensional
    numeric vectors) aka embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goal: how do we represent meaning?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application: finding similar words (similar vectors), sentence embeddings (as
    opposed to word embeddings), topic modeling, search, question answering'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Image](../Images/5b9fbdd9038ed540762215991c040a03.png)'
  prefs: []
  type: TYPE_IMG
- en: Fig 2\. Named entity recognition (NER) using spaCy (text excerpt taken from
    [here](https://www.nomadicmatt.com/travel-blogs/three-days-in-new-york-city/)).
  prefs: []
  type: TYPE_NORMAL
- en: '**4\. Sequence to Sequence Tasks**'
  prefs: []
  type: TYPE_NORMAL
- en: Many tasks in NLP can be framed as such
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples are machine translation, summarization, simplification, Q&A systems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Such systems are characterized by encoders and decoders, which work in complement
    to find a hidden representation of text, and to use that hidden representation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5\. Dialog Systems**'
  prefs: []
  type: TYPE_NORMAL
- en: 2 main categories of dialog systems, categorized by their scope of use
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goal-oriented dialog systems focus on being useful in a particular, restricted
    domain; more precision, less generalizable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversational dialog systems are concerned with being helpful or entertaining
    in a much more general context; less precision, more generalization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether it be in dialog systems or the practical difference between rule-based
    and more complex approaches to solving NLP tasks, note the trade-off between precision
    and generalizability; you generally sacrifice in one area for an increase in the
    other.
  prefs: []
  type: TYPE_NORMAL
- en: After covering text data representation in the next article, we will move on
    to some more advanced NLP topics, as well as some practical exploration of useful
    NLP tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[From Languages to Information](https://web.stanford.edu/class/cs124/), Stanford'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Natural Language Processing](https://www.coursera.org/learn/language-processing),
    National Research University Higher School of Economics (Coursera)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Neural Network Methods for Natural Language Processing](https://www.morganclaypool.com/doi/abs/10.2200/S00762ED1V01Y201703HLT037),
    Yoav Goldberg'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Related**:'
  prefs: []
  type: TYPE_NORMAL
- en: '[A General Approach to Preprocessing Text Data](/2017/12/general-approach-preprocessing-text-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Framework for Approaching Textual Data Science Tasks](/2017/11/framework-approaching-textual-data-tasks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Text Data Preprocessing: A Walkthrough in Python](/2018/03/text-data-preprocessing-walkthrough-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data Representation for Natural Language Processing Tasks](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[N-gram Language Modeling in Natural Language Processing](https://www.kdnuggets.com/2022/06/ngram-language-modeling-natural-language-processing.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
