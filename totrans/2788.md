# 使用示例介绍 K 最近邻算法

> 原文：[https://www.kdnuggets.com/2020/04/introduction-k-nearest-neighbour-algorithm-using-examples.html](https://www.kdnuggets.com/2020/04/introduction-k-nearest-neighbour-algorithm-using-examples.html)

[评论](#comments)

**由 [Ranvir Singh](https://ranvir.xyz/)，开源爱好者**

![KNN 算法 Python](../Images/9904c91821787cffd5c0365e7a03a07e.png)

* * *

## 我们的前三名课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT

* * *

`KNN`，也称为 K 最近邻，是一种 [监督式和模式分类学习算法](https://ranvir.xyz/blog/how-to-evaluate-your-machine-learning-model-like-a-pro-metrics/#supervised-learning-and-classification-problems)，帮助我们找到新输入（测试值）属于哪个类别，当选择`k`个最近邻并计算它们之间的距离时。

> 它试图估算在给定`X`的条件下`Y`的条件分布，并将给定的观察值（测试值）分类到具有最高估计概率的类别中。

它首先识别训练数据中与`测试值`最接近的`k`个点，并计算这些类别之间的距离。测试值将属于距离最小的类别。![KNN 算法距离](../Images/bab96a13fc6221a835a48218c68dacf3.png)

### KNN 中测试值分类的概率

它使用这个函数计算测试值属于类别`j`的概率

![图](../Images/94c277b5f05dafe4a4924438759b7895.png)

### 计算 KNN 中距离的方法

可以使用不同的方法来计算距离，包括这些方法，

+   欧几里得方法

+   曼哈顿方法

+   闵可夫斯基方法

+   等等…

有关可以使用的距离度量的更多信息，请阅读 [这篇关于 KNN 的文章](https://www.saedsayad.com/k_nearest_neighbors.htm)。你可以通过将`metric`参数传递给 KNN 对象来使用列表中的任何方法。这里有一个 [Stack Overflow 上的回答](https://stackoverflow.com/questions/21052509/sklearn-knn-usage-with-a-user-defined-metric) 可以帮助你。你甚至可以使用一些随机的距离度量。如果你想使用自己的距离计算方法，也 [阅读这个回答](https://stackoverflow.com/questions/34408027/how-to-allow-sklearn-k-nearest-neighbors-to-take-custom-distance-metric)。

### KNN 的过程与示例

假设我们有一个包含狗和马的身高和体重的标注数据集。我们将使用所有条目的体重和身高创建一个图表。现在每当有新条目时，我们将选择一个 `k` 值。为了本示例，假设我们选择 4 作为 `k` 值。我们将找到最近四个值的距离，距离最小的那个将具有更高的概率，被认为是赢家。![KNN 算法示例](../Images/d5ed5cee01cf2aad966a1e23d1318165.png)

### KneighborsClassifier：KNN Python 示例

GitHub 仓库：[KNN GitHub 仓库](https://github.com/singh1114/ml/blob/master/datascience/Machine%20learning/knn/knn.ipynb)使用的数据源：[数据源 GitHub](https://github.com/singh1114/ml/blob/master/datascience/Machine%20learning/knn/KNN_Project_Data)在 K 最近邻算法中，大多数时候你并不知道输入参数或分类类别的具体含义。在面试的情况下，这样做是为了隐藏真实的客户数据。

[PRE0]

![KNN 算法数据框头部](../Images/943f8d030780af21e4937ec3bf668a36.png)

数据的头部清楚地显示我们有一些变量和一个目标类别，该类别包含给定参数的不同类。

### 为什么需要对 KNN 变量进行标准化/归一化

正如我们已经看到的，数据框中的数据没有标准化，如果我们不对数据进行归一化，结果会大相径庭，我们将无法得到正确的结果。这是因为某些特征有很大的偏差（值范围从 1-1000）。这将导致图表效果很差，模型产生很多缺陷。有关归一化的更多信息，请查看 [stack exchange](https://stats.stackexchange.com/a/287439) 上的回答。Sklearn 提供了一种非常简单的方法来标准化数据。

[PRE1]

![KNN 算法归一化数据框](../Images/8e89f347796245cfc68040ed56805082.png)

### 使用 sklearn 进行测试/训练拆分

我们可以简单地 [使用 sklearn 拆分数据](https://ranvir.xyz/blog/how-to-evaluate-your-machine-learning-model-like-a-pro-metrics/#test-train-split-using-sklearn)。

[PRE2]

### 使用 KNN 和寻找最优的 k 值

选择一个好的 `k` 值可能是一个令人头疼的任务。我们将使用 Python 自动化这个任务。我们能够找到一个好的 `k` 值，这可以最小化模型中的错误率。

[PRE3]

![寻找最优的 k 值](../Images/df8207c791896b95d54c50ca55e2e4b5.png)从图表上看，我们可以看到 `k=30` 给出了一个非常理想的错误率值。

[PRE4]

### 评估 KNN 模型

阅读以下帖子以了解更多关于评估机器学习模型的信息。

[PRE5]

![混淆矩阵和分类报告](../Images/c6a18e3d0f4c354f208bcd472999ddcc.png)

### 使用 KNN 算法的好处

+   KNN 算法因其简单易用的特性被广泛应用于各种学习任务。

+   算法中仅有两个度量值：`k` 值和 `距离度量`。

+   可以处理任意数量的类别，而不仅仅是二分类器。

+   将新数据添加到算法中非常容易。

### KNN算法的缺点

+   预测`k`个最近邻的成本非常高。

+   当处理大量特征/参数时，效果不如预期。

+   处理分类特征时很困难。

一本很好的读物，[基准测试sklearn中Knn的各种选项](https://jakevdp.github.io/blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/)

希望你喜欢这篇文章。如有任何问题或疑问，请在下方评论中随时提出。

**简介：[Ranvir Singh](https://ranvir.xyz/)**（[**@ranvirsingh1114**](https://twitter.com/ranvirsingh1114)）是来自印度的网页开发人员。他是一个编码和Linux爱好者，想要学习尽可能多的东西。作为一名FOSS爱好者和开源贡献者，他还参与了2017年的Google Summer of Code项目，与AboutCode组织合作。他在2019年也担任了同一组织的GSoC导师。

[原文](https://ranvir.xyz/blog/k-nearest-neighbor-algorithm-using-sklearn-distance-metric/)。经许可转载。

**相关：**

+   [最新Scikit-learn版本中的5个新功能](/2019/12/5-features-scikit-learn-release-highlights.html)

+   [掌握中级机器学习的7个步骤——2019版](/2019/06/7-steps-mastering-intermediate-machine-learning-python.html)

+   [为你的数据集选择正确的聚类算法](/2019/10/right-clustering-algorithm.html)

### 更多相关内容

+   [从理论到实践：构建k-Nearest Neighbors分类器](https://www.kdnuggets.com/2023/06/theory-practice-building-knearest-neighbors-classifier.html)

+   [分类的最近邻](https://www.kdnuggets.com/2022/04/nearest-neighbors-classification.html)

+   [Scikit-learn中的K近邻算法](https://www.kdnuggets.com/2022/07/knearest-neighbors-scikitlearn.html)

+   [SQL LIKE运算符示例](https://www.kdnuggets.com/2022/09/sql-like-operator-examples.html)

+   [用示例了解集成学习](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)

+   [选择示例以理解机器学习模型](https://www.kdnuggets.com/2022/11/picking-examples-understand-machine-learning-model.html)
