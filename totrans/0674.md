# 快速而轻松地解决任何图像分类问题

> 原文：[https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2](https://www.kdnuggets.com/2018/12/solve-image-classification-problem-quickly-easily.html/2)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/12/solve-image-classification-problem-quickly-easily.html?page=2#comments)

### 6\. 示例

在这个示例中，我们将看到**如何在图像分类的迁移学习解决方案中实现这些分类器**。根据Rawat和Wang（2017）的说法，‘*在深度卷积神经网络基础上比较不同分类器的性能仍需要进一步研究，因此这是一个有趣的研究方向*’。因此，了解每个分类器在标准图像分类问题中的表现将很有趣。

你可以在[我的GitHub页面](https://github.com/pmarcelino/blog/blob/master/dogs_cats/dogs_cats.ipynb)找到这个示例的完整代码。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析水平

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织IT

* * *

**6.1\. 准备数据**

在这个示例中，我们将使用原始数据集的较小版本。这将使我们能够更快地运行模型，这对计算能力有限的人（比如我）来说是很有帮助的。

为了构建数据集的较小版本，我们可以根据代码1中显示的Chollet（2017）提供的代码进行调整。

代码1\. 创建一个较小的数据集用于狗与猫。

**6.2\. 从卷积基础中提取特征**

卷积基础将用于提取特征。这些特征将供我们要训练的分类器使用，以便识别图像中是否有狗或猫。

再次调整了Chollet（2017）提供的代码。代码2展示了使用的代码。

代码2\. 从卷积基础中提取特征。

**6.3\. 分类器**

**6.3.1\. 全连接层**

我们首先展示的解决方案基于全连接层。这个分类器添加了一堆全连接层，这些层由从卷积基础中提取的特征提供输入。

为了保持简单（且快速），我们将使用Chollet（2018）提出的解决方案，并做少量修改。特别是，我们将使用Adam优化器而不是RMSProp，因为[斯坦福大学说如此](http://cs231n.github.io/neural-networks-3/#adam)（多么美妙的*argumentum ad verecundiam*）。

代码3展示了使用的代码，而图5和图6展示了学习曲线。

代码 3\. 完全连接层解决方案。![](../Images/37a3b1336eb12b75a2b53aea7edf9958.png)

图 5\. 完全连接层解决方案的准确率。![](../Images/a624ba4e5278d22f95690936d9dab636.png)

图 6\. 完全连接层解决方案的损失。

**结果简要讨论：**

1.  验证准确率约为 0.85，考虑到数据集的大小，这是令人鼓舞的。

1.  模型严重过拟合。训练曲线与验证曲线之间存在较大差距。

1.  由于我们已经使用了 dropout，我们应该增加数据集的大小以改善结果。

**6.3.2\. 全局平均池化**

这个案例与前一个案例的区别在于，我们将添加一个全局平均池化层，并将其输出送入一个 sigmoid 激活层，而不是添加一堆完全连接的层。

注意我们讨论的是一个 sigmoid 激活层，而不是 Lin 等人（2013）推荐的 softmax 层。我们更改为 sigmoid 激活，因为在 Keras 中，要进行二分类，你应该使用 *sigmoid* 激活和 *binary_crossentropy* 作为损失（Chollet 2017）。因此，必须对 Lin 等人（2013）的原始方案进行这一小修改。

代码 4 显示了构建分类器的代码。图 7 和图 8 显示了结果的学习曲线。

代码 4\. 全局平均池化解决方案。![](../Images/10de3d9dcec03af404861a8879c0accb.png)

图 7\. 全局平均池化解决方案的准确率。![](../Images/a5d7d4e1dfd9f9804655064ae61f6cb7.png)

图 8\. 全局平均池化解决方案的损失。

**结果简要讨论：**

1.  验证准确率与完全连接层解决方案的结果相似。

1.  模型的过拟合情况没有前一个案例那么严重。

1.  当模型停止训练时，损失函数仍在下降。可能通过增加训练轮次可以改进模型。

**6.3.3 线性支持向量机**

在这种情况下，我们将训练一个线性支持向量机（SVM）分类器，使用卷积基提取的特征。

为了训练这个分类器，传统的机器学习方法更为合适。因此，我们将使用 k 折交叉验证来估计分类器的误差。由于将使用 k 折交叉验证，我们可以将训练集和验证集合并以扩大训练数据（我们保持测试集不变，正如之前的案例中所做的）。代码 5 显示了数据如何连接。

代码 5\. 数据连接。

最后，我们必须注意，SVM 分类器有一个超参数。这个超参数是误差项的惩罚参数 C。为了优化这个超参数的选择，我们将使用穷举网格搜索。代码 6 展示了构建这个分类器的代码，而图 9 说明了学习曲线。

代码 6\. 线性 SVM 解决方案。![](../Images/1636b5411bb359e6864f8a0c3784e7b9.png)

图 9\. 线性 SVM 解决方案的准确率。

**结果的简要讨论：**

1.  模型的准确率约为0.86，这与之前的解决方案的准确率相似。

1.  过拟合就在眼前。此外，训练准确率总是1.0，这不寻常，可以解释为过拟合的迹象。

1.  模型的准确率应该随着训练样本的增加而提高。然而，这似乎没有发生。这可能是由于过拟合。观察模型在数据集增加时的反应会很有趣。

### 7. 摘要

在这篇文章中，我们：

+   介绍了迁移学习、卷积神经网络和预训练模型的概念。

+   定义了基本的微调策略，以重新利用预训练模型。

+   描述了一种结构化的方法来决定应使用哪种微调策略，基于数据集的大小和相似性。

+   介绍了三种不同的分类器，这些分类器可以应用于从卷积基础提取的特征之上。

+   提供了这篇文章中介绍的每个分类器的图像分类端到端示例。

我希望你能感到有动力开始在计算机视觉领域开发你的深度学习项目。这是一个很棒的研究领域，每天都有新的令人兴奋的发现。

我很乐意帮助你，如果你有任何问题或改进建议，请告诉我！

### 8. 参考文献

1. Bengio, Y., 2009\. Learning deep architectures for AI. Foundations and trends in Machine Learning, 2(1), pp.1–127.

2. Canziani, A., Paszke, A. and Culurciello, E., 2016\. An analysis of deep neural network models for practical applications. arXiv preprint arXiv:1605.07678.

[3. Chollet, F., 2015\. Keras.](https://keras.io/)

4. [Chollet, F., 2017\. Deep learning with python. Manning Publications Co..](https://amzn.to/2CeEySF)

5. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K. and Fei-Fei, L., 2009, June. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009\. CVPR 2009\. IEEE Conference on (pp. 248–255). Ieee.

6. He, K., Zhang, X., Ren, S. and Sun, J., 2016\. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 770–778).

7. Krizhevsky, A., Sutskever, I. and Hinton, G.E., 2012\. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097–1105).

8. LeCun, Y., Bengio, Y. and Hinton, G., 2015\. Deep learning. nature, 521(7553), p.436.

9. Lin, M., Chen, Q. and Yan, S., 2013\. Network in network. arXiv preprint arXiv:1312.4400.

10. Pan, S.J. and Yang, Q., 2010\. A survey on transfer learning. IEEE Transactions on knowledge and data engineering, 22(10), pp.1345–1359.

11. Rawat, W. and Wang, Z., 2017\. Deep convolutional neural networks for image classification: A comprehensive review. Neural computation, 29(9), pp.2352–2449.

12\. Simonyan, K. 和 Zisserman, A., 2014\. 用于大规模图像识别的非常深度卷积网络。arXiv预印本 arXiv:1409.1556。

13\. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J. 和 Wojna, Z., 2016\. 重新思考计算机视觉的Inception架构。IEEE计算机视觉与模式识别会议论文集 (第2818–2826页)。

14\. Tang, Y., 2013\. 使用线性支持向量机的深度学习。arXiv预印本 arXiv:1306.0239。

15\. Voulodimos, A., Doulamis, N., Doulamis, A. 和 Protopapadakis, E., 2018\. 计算机视觉的深度学习：简要综述。计算智能与神经科学，2018。

16\. Yosinski, J., Clune, J., Bengio, Y. 和 Lipson, H., 2014\. 深度神经网络中的特征转移性如何？在神经信息处理系统进展 (第3320–3328页)。

17\. Zeiler, M.D. 和 Fergus, R., 2014年9月。可视化和理解卷积网络。在欧洲计算机视觉会议 (第818–833页)。Springer, Cham。

### 致谢

感谢[João Coelho](https://www.linkedin.com/in/joaopcoelho/)阅读这份草稿。

*你可以在*[*pmarcelino.com*](http://www.pmarcelino.com/) *找到更多关于我和我的项目的信息。同时，你也可以注册我的*[*newsletter*](http://pmarcelino.com/subscribe)*，以接收我关于人类、机器和科学的最新更新。*

**简介：[Pedro Marcelino](https://www.linkedin.com/in/pmarcelino/)** 对机器学习和数据分析的各个方面都感兴趣。他的重点是数据挖掘与质量、探索性分析与可视化，以及预测/处方分析，但也包括在实际问题上测试和基准不同的机器学习方法。

[原文](https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751)。已获授权转载。

**相关：**

+   [计算机视觉技术与应用的最新趋势](/2018/11/trends-computer-vision-technology-applications.html)

+   [构建一个在Raspberry Pi上运行的图像分类器](/2018/10/building-image-classifier-running-raspberry-pi.html)

+   [使用Tensorflow目标检测和OpenCV分析足球比赛](/2018/07/analyze-soccer-game-using-tensorflow-object-detection-opencv.html)

### 更多相关内容

+   [NExT-GPT介绍：任何到任何的多模态大语言模型](https://www.kdnuggets.com/introduction-to-nextgpt-anytoany-multimodal-large-language-model)

+   [机器学习不像你的大脑 第6部分：精确突触权重的重要性](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)

+   [以无代码方式轻松从网站抓取图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)

+   [在你的笔记本电脑上轻松探索LLMs，使用openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)

+   [使用 Scikit-LLM 将 LLMs 轻松集成到您的 Scikit-learn 工作流中](https://www.kdnuggets.com/easily-integrate-llms-into-your-scikit-learn-workflow-with-scikit-llm)

+   [卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)
