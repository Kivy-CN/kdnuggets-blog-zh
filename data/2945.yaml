- en: 'Building a Computer Vision Model: Approaches and datasets'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建计算机视觉模型：方法和数据集
- en: 原文：[https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html](https://www.kdnuggets.com/2019/05/computer-vision-model-approaches-datasets.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Javier Couto](https://twitter.com/JCoutoNLP), Tryolabs**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Javier Couto](https://twitter.com/JCoutoNLP)，Tryolabs**。'
- en: 'Computer vision is one of the hottest subfields of machine learning, given
    its [wide variety of applications](https://tryolabs.com/resources/introductory-guide-computer-vision/#industry-applications)
    and tremendous potential. Its goal: to replicate the powerful capacities of human
    vision. But how is this achieved with algorithms?'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是机器学习中最热门的子领域之一，鉴于其[广泛的应用](https://tryolabs.com/resources/introductory-guide-computer-vision/#industry-applications)和巨大的潜力。其目标是复制人类视觉的强大能力。但这如何通过算法实现呢？
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Let's have a loot at the most important datasets and approaches.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入了解最重要的数据集和方法。
- en: '**Existing datasets**'
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**现有数据集**'
- en: 'Computer vision algorithms are no magic. They need data to work, and they can
    only be as good as the data you feed in. These are different sources to collect
    the right data, depending on the task:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉算法并非魔法。它们需要数据才能工作，它们的效果仅能与输入的数据质量相匹配。以下是根据任务收集正确数据的不同来源：
- en: One of the most voluminous and well known dataset is **[ImageNet](http://www.image-net.org/)**,
    a readily-available dataset of 14 million images manually annotated using **[WordNet](https://wordnet.princeton.edu/)** concepts.
    Within the global dataset, 1 million images contain bounding box annotations.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个最大且最著名的数据集是**[ImageNet](http://www.image-net.org/)**，这是一个拥有 1400 万张图像的现成数据集，手动标注了使用**[WordNet](https://wordnet.princeton.edu/)**
    概念。在全球数据集中，100 万张图像包含边界框注释。
- en: '![](../Images/47bdf49b1e7bdf044830642dc62105e9.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/47bdf49b1e7bdf044830642dc62105e9.png)'
- en: '**ImageNet images with bounding boxes. [Image source](http://www.image-net.org/bbox_fig/kit_fox.JPG)**'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**带有边界框的 ImageNet 图像。[图片来源](http://www.image-net.org/bbox_fig/kit_fox.JPG)**'
- en: '![](../Images/1de2789c0f6f512afa807174edb804a3.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1de2789c0f6f512afa807174edb804a3.png)'
- en: '**ImageNet images with object attributes annotations. [Image source](http://www.image-net.org/attribute_fig/pullfigure.jpg)**'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**带有对象属性注释的 ImageNet 图像。[图片来源](http://www.image-net.org/attribute_fig/pullfigure.jpg)**'
- en: Another well-known one is the **[Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home)**,
    dataset, loaded with 328,000 images including 91 object types that would be easily
    recognizable by a 4 year old, with a total of 2.5 million labeled instances.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个著名的数据集是**[Microsoft Common Objects in Context (COCO)](http://cocodataset.org/#home)**，包含
    328,000 张图像，包括 91 种对象类型，这些类型对于 4 岁的孩子来说很容易识别，总共有 250 万个标注实例。
- en: '![](../Images/e60ccd5b9feab0cca16b8b7d9ebd07f8.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e60ccd5b9feab0cca16b8b7d9ebd07f8.png)'
- en: '**Examples of annotated images from the COCO dataset. [Image source](https://arxiv.org/abs/1405.0312)**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**来自 COCO 数据集的标注图像示例。[图片来源](https://arxiv.org/abs/1405.0312)**'
- en: While there isn’t a plethora of available datasets, there are several suitable
    for different tasks, such as the **[CelebFaces Attributes Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)** (CelebA,
    a face attributes dataset with more than 200K celebrity images); the **[Indoor
    Scene Recognition](http://web.mit.edu/torralba/www/indoor.html)** dataset (15,620
    images of indoor scenes); and the **[Plant Image Analysis](https://www.plant-image-analysis.org/dataset)** dataset
    (1 million images of plants from 11 different species).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可用的数据集不是很多，但有几个适合不同任务的，例如 **[CelebFaces 属性数据集](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)**（CelebA，包含超过
    20 万张名人图像的面部属性数据集）；**[室内场景识别](http://web.mit.edu/torralba/www/indoor.html)** 数据集（15,620
    张室内场景图像）；和 **[植物图像分析](https://www.plant-image-analysis.org/dataset)** 数据集（来自 11
    个不同物种的 100 万张植物图像）。
- en: '**A general strategy**'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**一般策略**'
- en: '**[Deep learning methods and techniques](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)** have
    profoundly transformed computer vision, along with other areas of artificial intelligence,
    to such an extent that for many tasks its use is considered standard. In particular, **[Convolutional
    Neural Networks](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)** (CNN)
    have achieved beyond state-of-the-art results utilizing traditional computer vision
    techniques.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**[深度学习方法和技术](https://tryolabs.com/blog/2018/12/19/major-advancements-deep-learning-2018/)**
    深刻地改变了计算机视觉以及人工智能的其他领域，以至于对于许多任务，其使用被认为是标准的。特别是，**[卷积神经网络](https://www.kdnuggets.com/2016/11/intuitive-explanation-convolutional-neural-networks.html)**（CNN）利用传统计算机视觉技术取得了超越现有技术水平的成果。'
- en: 'These four steps outline a general approach to building a computer vision model
    using CNNs:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个步骤概述了使用 CNN 构建计算机视觉模型的一般方法：
- en: Create a dataset comprised of annotated images or use an existing one. Annotations
    can be the image category (for a classification problem); pairs of bounding boxes
    and classes (for an object detection problem); or a pixel-wise segmentation of
    each object of interest present in an image (for an instance segmentation problem).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个由标注图像组成的数据集，或者使用现有的数据集。标注可以是图像类别（用于分类问题）；一对对的边界框和类别（用于物体检测问题）；或每个图像中感兴趣对象的逐像素分割（用于实例分割问题）。
- en: Extract, from each image, features pertinent to the task at hand. This is a
    key point in modeling the problem. For example, the features used to recognize
    faces, features based on facial criteria, are obviously not the same as those
    used to recognize tourist attractions or human organs.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从每张图像中提取与当前任务相关的特征。这是建模问题的关键点。例如，用于识别面孔的特征，与基于面部标准的特征显然不同于用于识别旅游景点或人体器官的特征。
- en: Train a deep learning model based on the features isolated. Training means feeding
    the machine learning model many images and it will learn, based on those features,
    how to solve the task at hand.
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于提取的特征训练深度学习模型。训练意味着向机器学习模型输入许多图像，模型将根据这些特征学习如何解决手头的任务。
- en: Evaluate the model using images that weren’t used in the training phase. By
    doing so, the accuracy of the training model can be tested.
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用未在训练阶段使用的图像评估模型。通过这样做，可以测试训练模型的准确性。
- en: This strategy is very basic but it serves the purpose well. Such an approach,
    known as **[supervised machine learning](https://www.kdnuggets.com/2017/11/3-different-types-machine-learning.html)**,
    requires a dataset that encompasses the phenomenon the model has to learn.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个策略非常基础，但能够很好地达到目的。这样的做法，被称为 **[监督式机器学习](https://www.kdnuggets.com/2017/11/3-different-types-machine-learning.html)**，需要一个涵盖模型需要学习的现象的数据集。
- en: '**Training an object detection model**'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**训练物体检测模型**'
- en: '**Viola and Jones approach**'
  id: totrans-32
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**维奥拉和琼斯方法**'
- en: There are many ways to address object detection challenges. For years, the prevalent
    approach was one proposed by Paul Viola and Michael Jones in the paper, **[Robust
    Real-time Object Detection](http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-2001-1.pdf)**.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多方法可以解决物体检测挑战。多年来，流行的方法是保罗·维奥拉和迈克尔·琼斯在论文中提出的 **[鲁棒实时物体检测](http://www.hpl.hp.com/techreports/Compaq-DEC/CRL-2001-1.pdf)**。
- en: Although it can be trained to detect a diverse range of object classes, the
    approach was first motivated by the objective of face detection. It is so fast
    and straightforward that it was the algorithm implemented in point-and-shoot cameras,
    which allows for real-time face detection with little processing power.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以训练以检测多种类别的对象，但这一方法最初是以面部检测为目标的。它速度快且简单，已被实现到傻瓜相机中，允许在实时面部检测中使用极少的处理能力。
- en: The central feature of the approach is to train with a potentially large set
    of binary classifiers based on **[Haar features](https://en.wikipedia.org/wiki/Haar-like_feature)**.
    These features represent edges and lines, and are extremely simple to compute
    when scanning an image.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法的核心特征是使用基于**[Haar特征](https://en.wikipedia.org/wiki/Haar-like_feature)**的大量二分类器进行训练。这些特征表示边缘和线条，在扫描图像时计算非常简单。
- en: '![](../Images/bc6c26478e97521e0942d50b5f5a4dce.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bc6c26478e97521e0942d50b5f5a4dce.png)'
- en: '**Haar features. [Image source](https://docs.opencv.org/3.4.3/haar_features.jpg)**'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**Haar特征。[图片来源](https://docs.opencv.org/3.4.3/haar_features.jpg)**'
- en: Although quite basic, in the specific case of faces these features allow for
    the capturing of important elements such as the nose, mouth, or the distance between
    the eyebrows. It is a supervised method that requires many positive and negative
    examples of the type of object to be discerned.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管相当基础，但在面部识别的具体情况下，这些特征可以捕捉到如鼻子、嘴巴或眉毛之间的距离等重要元素。这是一种监督方法，需要许多正例和负例的目标对象样本。
- en: '**Detecting the face of the Mona Lisa**'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**检测蒙娜丽莎的面部**'
- en: '**CNN-based approaches**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**基于CNN的方法**'
- en: Deep learning has been a real game changer in machine learning, especially in
    computer vision, where deep-learning-based approaches are now cutting edge for
    many of the usual tasks.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在机器学习领域带来了真正的变革，尤其是在计算机视觉领域，基于深度学习的方法现在在许多常见任务中处于最前沿。
- en: 'Among the different deep learning approaches proposed for accomplishing object
    detection, **[R-CNN](https://arxiv.org/abs/1311.2524)** (Regions with CNN features)
    is particularly simple to understand. The authors of this work propose a three
    stage process:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在为实现目标检测而提出的不同深度学习方法中，**[R-CNN](https://arxiv.org/abs/1311.2524)**（具有CNN特征的区域）特别容易理解。该工作的作者提出了一个三阶段的过程：
- en: Extract possible objects using a region proposal method.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用区域提案方法提取可能的对象。
- en: Identify features in each region using a CNN.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用CNN识别每个区域的特征。
- en: Classify each region utilizing **[SVMs](https://en.wikipedia.org/wiki/Support_vector_machine)**.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用**[支持向量机（SVMs）](https://en.wikipedia.org/wiki/Support_vector_machine)**对每个区域进行分类。
- en: '![](../Images/2be7c020983b89d8c01e3077de68f762.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2be7c020983b89d8c01e3077de68f762.png)'
- en: '**R-CNN Architecture. [Image source](https://arxiv.org/abs/1311.2524)**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**R-CNN架构。[图片来源](https://arxiv.org/abs/1311.2524)**'
- en: The region proposal method opted for in the original work was **[Selective Search](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)**,
    although the R-CNN algorithm is agnostic regarding the particular region proposal
    method adopted. Step 3 is very important as it decreases the number of object
    candidates, which makes the method less computationally expensive.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 原作中选择的区域提案方法是**[选择性搜索](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf)**，尽管R-CNN算法对于采用的具体区域提案方法没有偏好。第3步非常重要，因为它减少了对象候选数量，使得该方法计算开销较小。
- en: The features extracted here are less intuitive than the Haar features previously
    mentioned. To summarize, a CNN is used to extract a 4096-dimensional feature vector
    from each region proposal. Given the nature of the CNN, it is necessary that the
    input always have the same dimension. This is usually one of the CNN’s weak points
    and the various approaches address this in different ways. With respect to the
    R-CNN approach, the trained CNN architecture requires inputs of a fixed area of
    227 × 227 pixels. Since the proposed regions have sizes that differ from this,
    the authors’ approach simply warps the images so that they fit the required dimension.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这里提取的特征不如之前提到的Haar特征直观。总而言之，使用CNN从每个区域提案中提取一个4096维的特征向量。由于CNN的特性，输入必须始终具有相同的维度。这通常是CNN的一个弱点，各种方法以不同的方式解决这个问题。就R-CNN方法而言，训练好的CNN架构需要固定尺寸的227
    × 227像素的输入。由于提议的区域大小与此不同，作者的方法简单地将图像扭曲以适应所需的尺寸。
- en: '![](../Images/528b58be52eb7121ca6d994c8c7cbcd8.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/528b58be52eb7121ca6d994c8c7cbcd8.png)'
- en: '**Examples of warped images matching the input dimension required by the CNN.
    [Image source](https://arxiv.org/abs/1311.2524)**'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**与CNN所需输入维度匹配的扭曲图像示例。[图片来源](https://arxiv.org/abs/1311.2524)**'
- en: 'While it achieved great results, the training encountered several obstacles,
    and the approach was eventually outperformed by others. Some of those are reviewed
    in depth in the article, **[Object Detection with Deep Learning: The Definitive
    Guide](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)**.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管取得了优异的成果，但训练过程中遇到了一些障碍，最终该方法被其他方法超越。文章中详细回顾了一些这些内容，**[深度学习目标检测：终极指南](https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning/)**。
- en: This article is an extract of the *Introductory Guide to Computer Vision* by
    Tryolabs, originally published [here](https://tryolabs.com/resources/introductory-guide-computer-vision/).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '本文摘自*计算机视觉入门指南*，作者为Tryolabs，最初发布于[这里](https://tryolabs.com/resources/introductory-guide-computer-vision/)。 '
- en: '**Bio**: [Javier Couto](https://twitter.com/JCoutoNLP) is a freelance machine
    learning consultant and data scientist at Tryolabs, specialized in applying machine
    learning to solve business problems.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**：[Javier Couto](https://twitter.com/JCoutoNLP) 是Tryolabs的自由职业机器学习顾问和数据科学家，专注于应用机器学习解决商业问题。'
- en: '**Resources:**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于Web的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Think Like an Amateur, Do As an Expert: Lessons from a Career in Computer
    Vision](https://www.kdnuggets.com/2019/05/kanade-lessons-career-computer-vision.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[像业余爱好者一样思考，像专家一样行动：计算机视觉职业生涯的经验教训](https://www.kdnuggets.com/2019/05/kanade-lessons-career-computer-vision.html)'
- en: '[Predict Age and Gender Using Convolutional Neural Network and OpenCV](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络和OpenCV预测年龄和性别](https://www.kdnuggets.com/2019/04/predict-age-gender-using-convolutional-neural-network-opencv.html)'
- en: '[Pedestrian Detection in Aerial Images Using RetinaNet](https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用RetinaNet在航空图像中进行行人检测](https://www.kdnuggets.com/2019/03/pedestrian-detection-aerial-images-retinanet.html)'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据管理的6件事及其重要性…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[TensorFlow在计算机视觉中的应用 - 让迁移学习变得简单](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索计算机视觉的世界：介绍MLM的最新…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[计算机视觉的5个应用](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[DINOv2：Meta AI的自监督计算机视觉模型](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻 2022年3月9日：在5分钟内构建一个机器学习Web应用程序…](https://www.kdnuggets.com/2022/n10.html)'
