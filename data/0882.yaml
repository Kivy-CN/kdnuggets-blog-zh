- en: Exploring Data Cleaning Techniques With Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索使用 Python 的数据清理技术
- en: 原文：[https://www.kdnuggets.com/2023/04/exploring-data-cleaning-techniques-python.html](https://www.kdnuggets.com/2023/04/exploring-data-cleaning-techniques-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/04/exploring-data-cleaning-techniques-python.html](https://www.kdnuggets.com/2023/04/exploring-data-cleaning-techniques-python.html)
- en: '![Exploring Data Cleaning Techniques With Python](../Images/252e0add27f5fc4968f30d2c5734ac89.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Exploring Data Cleaning Techniques With Python](../Images/252e0add27f5fc4968f30d2c5734ac89.png)'
- en: Image by [freepik.com](https://www.freepik.com/free-vector/set-elements-chart-infographics-graphs-diagrams-chart-color_15573877.htm#query=graph&position=0&from_view=search&track=sph)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[freepik.com](https://www.freepik.com/free-vector/set-elements-chart-infographics-graphs-diagrams-chart-color_15573877.htm#query=graph&position=0&from_view=search&track=sph)
- en: In real-world data science projects, the data used for analysis may contain
    several imperfections such as the presence of missing data, redundant data, data
    entries having incorrect format, presence of outliers in the data, etc. Data cleaning
    refers to the process of preprocessing and transforming raw data to render it
    in a form that is suitable for further analysis such as for descriptive analysis
    (data visualization) or prescriptive analysis (model building). Clean, accurate,
    and reliable data must be utilized for post analysis because “*bad data leads
    to bad predictive models*”.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际的数据科学项目中，用于分析的数据可能包含多个缺陷，例如缺失数据、冗余数据、数据条目格式不正确、数据中的异常值等。数据清理指的是将原始数据进行预处理和转换，以便将其呈现为适合进一步分析的形式，例如描述性分析（数据可视化）或处方分析（模型构建）。必须使用干净、准确、可靠的数据进行后续分析，因为“*坏数据导致糟糕的预测模型*”。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的
    IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Several libraries in Python, including pandas and numpy, can be used for data
    cleaning and transformation. These libraries offer a wide range of methods and
    functions to carry out tasks including dealing with missing values, eliminating
    outliers, and translating data into a model-friendly format. Additionally, eliminating
    redundant features or combining groups of highly correlated features into a single
    feature could lead to dimensionality reduction. Training a model using a dataset
    with fewer features will improve the computational efficiency of the model. Furthermore,
    a model built using a dataset having fewer features is easier to interpret and
    has better predictive power.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python 中的多个库，包括 pandas 和 numpy，可用于数据清理和转换。这些库提供了广泛的方法和功能来执行任务，包括处理缺失值、消除异常值，以及将数据转换为模型友好的格式。此外，消除冗余特征或将高度相关的特征组合成一个特征可能会导致维度减少。使用特征较少的数据集训练模型将提高模型的计算效率。此外，使用特征较少的数据集构建的模型更容易解释，并且具有更好的预测能力。
- en: 'In this article, we will explore various tools and techniques that are available
    in Python for cleaning, processing, and transforming data. We will demonstrate
    data cleaning techniques using the ***data.cvs*** dataset shown below:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探索 Python 中用于清理、处理和转换数据的各种工具和技术。我们将使用下面展示的***data.cvs*** 数据集演示数据清理技术：
- en: '![Exploring Data Cleaning Techniques With Python](../Images/75d823feaeebf8241fe270b4adc2d980.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![Exploring Data Cleaning Techniques With Python](../Images/75d823feaeebf8241fe270b4adc2d980.png)'
- en: data.csv showing various imperfections such as duplicated data, NaN, etc. Data
    created by Author.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: data.csv 展示了多种缺陷，例如重复数据、NaN 等。数据由作者创建。
- en: Libraries For Data Cleaning in Python
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 数据清理库
- en: In Python, a range of libraries and tools, including pandas and NumPy, may be
    used to clean up data. For instance, the *dropna()*, *drop duplicates()*, and
    *fillna()* functions in pandas may be used to manage missing data, remove missing
    data, and remove duplicate rows, respectively. The scikit-learn toolkit offers
    tools for dealing with outliers (such as the *SimpleImputer* class) and transforming
    data into a format that can be utilized by a model, such as the *StandardScaler*
    class for standardizing normalizing numerical data, and the *MinMaxScalar* for
    normalizing data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，可以使用一系列库和工具，包括 pandas 和 NumPy，来清理数据。例如，pandas 中的 *dropna()*、*drop_duplicates()*
    和 *fillna()* 函数分别可用于处理缺失数据、删除缺失数据和删除重复行。scikit-learn 工具包提供了处理离群值的工具（例如 *SimpleImputer*
    类）和将数据转换为模型可以使用的格式的工具，例如用于标准化数值数据的 *StandardScaler* 类和用于归一化数据的 *MinMaxScaler*。
- en: In this article, we will explore various data cleaning techniques that can be
    used in Python to prepare and preprocess data for use in a machine learning model.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将探讨在 Python 中可以使用的各种数据清理技术，以便为机器学习模型准备和预处理数据。
- en: Processing Missing Data
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理缺失数据
- en: 'The processing of missing data is one of the most important imperfections in
    a dataset. Several methods for dealing with missing data are provided by the pandas
    package in Python, including **dropna()** and **fillna().** The **dropna()** method
    is used to eliminate any columns or rows that have missing values. For instance,
    the code below will eliminate all rows with at least one missing value:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 处理缺失数据是数据集中最重要的缺陷之一。Python 的 pandas 包提供了几种处理缺失数据的方法，包括**dropna()**和**fillna()**。**dropna()**
    方法用于消除任何具有缺失值的列或行。例如，下面的代码将消除所有至少有一个缺失值的行：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The **fillna()** function can be used to fill in missing values with a specific
    value or method. For example, the following code will fill in missing values in
    the ''age'' column with the mean age of the data:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**fillna()** 函数可用于用特定值或方法填充缺失值。例如，以下代码将用数据中的平均年龄填充 ''age'' 列中的缺失值：'
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Handling Outliers
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理离群值
- en: Handling outliers is a typical data cleaning activity. Values that diverge greatly
    from the rest of the data are considered outliers. These factors should be managed
    carefully since they have a significant influence on a model's performance. The
    *RobustScaler* class from the scikit-learn toolkit in Python is used to handle
    outliers. By deleting the median and scaling the data according to the interquartile
    range, this class may be used to scale the data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 处理离群值是典型的数据清理活动。那些与其余数据差异较大的值被视为离群值。这些因素需要小心处理，因为它们对模型的性能有显著影响。在 Python 的 scikit-learn
    工具包中，*RobustScaler* 类用于处理离群值。通过删除中位数并根据四分位范围来缩放数据，可以使用该类来对数据进行缩放。
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Encoding Categorical Variables
  id: totrans-26
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编码分类变量
- en: 'Another common data cleaning task is converting data into a format that can
    be used by a model. For instance, before categorical data can be employed in a
    model, it must be transformed into numerical data. The *get_dummies()* method
    in the pandas package allows one to transform category data into numerical data.
    In the example below, the categorical feature *‘Departmen*t’ is transformed into
    numerical data:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的数据清理任务是将数据转换为模型可以使用的格式。例如，在分类数据可以用于模型之前，必须将其转换为数值数据。pandas 包中的 *get_dummies()*
    方法允许将类别数据转换为数值数据。在下面的示例中，类别特征*‘Departmen*t’被转换为数值数据：
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Removing Duplicate Data
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 删除重复数据
- en: 'Duplicate data must also be eliminated during the data cleaning process. To
    delete duplicate rows from a Python DataFrame, the *drop_duplicates()* method
    provided by the pandas package can be used. For instance, the code below will
    eliminate any redundant rows from the data:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据清理过程中，还必须消除重复数据。要从 Python DataFrame 中删除重复的行，可以使用 pandas 包提供的*drop_duplicates()*
    方法。例如，下面的代码将消除数据中的所有冗余行：
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Feature Engineering
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: 'Feature selection and feature engineering are essential components of data
    cleaning. The process of choosing only the relevant features in a dataset is referred
    to as feature selection, whereas the process of building new features from already
    existing ones is known as feature engineering.  The code below is an illustration
    of feature engineering:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 特征选择和特征工程是数据清理的关键组成部分。选择数据集中仅相关特征的过程称为特征选择，而从现有特征中构建新特征的过程称为特征工程。下面的代码演示了特征工程的过程：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In the above code, we first create a feature matrix (X) by dropping the '*Employee
    ID*' and '*Date of Joining*' columns, and create a target vector (y) consisting
    of the '*Salary*' column. We then scale the numerical features '*Age*' and '*Experience*'
    using the StandardScaler() function from scikit-learn.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，我们首先通过删除'*员工编号*'和'*入职日期*'列来创建特征矩阵 (X)，然后创建一个包含'*薪资*'列的目标向量 (y)。接着，我们使用
    scikit-learn 的 StandardScaler() 函数对数值特征'*年龄*'和'*经验*'进行缩放。
- en: Next, we create dummy variables for the categorical '*Gender*' column and concatenate
    them with the scaled numerical features to create the final processed feature
    matrix (X_processed).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为分类列'*性别*'创建虚拟变量，并将其与缩放后的数值特征连接起来，创建最终处理后的特征矩阵 (X_processed)。
- en: Note that the specific feature extraction techniques used will depend on the
    data and the specific requirements of the analysis. Also, it's important to split
    the data into training and testing sets before applying any machine learning models
    to avoid overfitting.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，所使用的具体特征提取技术将取决于数据以及分析的具体要求。同时，在应用任何机器学习模型之前，重要的是将数据拆分为训练集和测试集，以避免过拟合。
- en: Conclusion
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: To conclude, data cleaning is an essential stage in the machine learning process
    since it guarantees the data used for analysis (descriptive or prescriptive) is
    of high quality. Important methods that may be used to prepare and preprocess
    data include converting data format, removing duplicate data, dealing with missing
    data, outlier detection, feature engineering, and feature selection. Pandas, NumPy,
    and scikit-learn are just a few of the many libraries and tools for feature engineering
    and data cleaning.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，数据清洗是机器学习过程中的一个重要阶段，因为它确保用于分析（描述性或规定性）的数据质量高。准备和预处理数据的重要方法包括转换数据格式、删除重复数据、处理缺失数据、异常值检测、特征工程和特征选择。Pandas、NumPy
    和 scikit-learn 只是特征工程和数据清洗众多库和工具中的一部分。
- en: '**[Benjamin O. Tayo](https://www.linkedin.com/in/benjamin-o-tayo-ph-d-a2717511/)**
    is a Physicist, Data Science Educator, and Writer, as well as the Owner of DataScienceHub.
    Previously, Benjamin was teaching Engineering and Physics at U. of Central Oklahoma,
    Grand Canyon U., and Pittsburgh State U.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**[本杰明·O·塔约](https://www.linkedin.com/in/benjamin-o-tayo-ph-d-a2717511/)**
    是一名物理学家、数据科学教育者和作家，同时也是 DataScienceHub 的创始人。此前，本杰明曾在中央俄克拉荷马大学、大峡谷大学和匹兹堡州立大学教授工程学和物理学。'
- en: More On This Topic
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清洗和预处理技术的 7 个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Exploring Infinite Iterators in Python''s itertools](https://www.kdnuggets.com/exploring-infinite-iterators-in-python-itertools)'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Python 的 itertools 中探索无限迭代器](https://www.kdnuggets.com/exploring-infinite-iterators-in-python-itertools)'
- en: '[Exploring the OpenAI API with Python](https://www.kdnuggets.com/exploring-the-openai-api-with-python)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 探索 OpenAI API](https://www.kdnuggets.com/exploring-the-openai-api-with-python)'
- en: '[Exploring Natural Sorting in Python](https://www.kdnuggets.com/exploring-natural-sorting-in-python)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[探索 Python 中的自然排序](https://www.kdnuggets.com/exploring-natural-sorting-in-python)'
- en: '[Navigating the Data Revolution: Exploring the Booming Trends in…](https://www.kdnuggets.com/navigating-the-data-revolution-exploring-the-booming-trends-in-data-science-and-machine-learning)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[导航数据革命：探索数据科学和机器学习中的蓬勃趋势](https://www.kdnuggets.com/navigating-the-data-revolution-exploring-the-booming-trends-in-data-science-and-machine-learning)'
- en: '[Optimizing Data Storage: Exploring Data Types and Normalization in SQL](https://www.kdnuggets.com/optimizing-data-storage-exploring-data-types-and-normalization-in-sql)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据存储：探索 SQL 中的数据类型和标准化](https://www.kdnuggets.com/optimizing-data-storage-exploring-data-types-and-normalization-in-sql)'
