- en: 'Machine Learning Model Development and Model Operations: Principles and Practices'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html](https://www.kdnuggets.com/2021/10/machine-learning-model-development-operations-principles-practice.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/), Principal Solution
    Architect, DXC Technology**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  id: totrans-4
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: The use of Machine Leaning (ML) has increased substantially in enterprise data
    analytics scenarios to extract valuable insights from the business data. Hence,
    it is very important to have an ecosystem to build, test, deploy, and maintain
    the enterprise grade machine learning models in production environments. The ML
    model development involves data acquisition from multiple trusted sources, data
    processing to make suitable for building the model, choose algorithm to build
    the model, build model, compute performance metrics and choose best performing
    model. The model maintenance plays critical role once the model is deployed into
    production. The maintenance of machine learning model includes keeping the model
    up to date and relevant in tune with the source data changes as there is a risk
    of model becoming outdated in course of time. Also, the configuration management
    of ML model play an important role in model management as the number of models
    grow. This article focuses on principles and industry standard practices, including
    the tools and technologies used for ML model development, deployment, and maintenance
    in an enterprise environment.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Model Development
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Machine Learning (ML) Model Lifecycle** refers to the process that covers
    right from source data identification to model development, model deployment and
    model maintenance. At high level, the entire activities fall under two broad categories,
    such as ML Model Development and ML Model Operations.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine Learning (ML) model development** includes a series of steps as mentioned
    in the Fig. 1.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/65ad4640976073749d0b838990e29200.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
- en: '**Fig 1:** Machine Learning (ML) Model Development Lifecyle'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: The ML model development lifecycle steps can be broadly classified as – data
    exploration, model building, model hyperparameters tuning and model selection
    with optimum performance.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**Exploratory data analysis** is an important step that starts once business
    hypothesis is ready. This step takes 40-50% of total project time as the model
    outcome depends on the quality of input data being fed to train the model. Exploratory
    data analysis involves data attributes identification, data preprocessing and
    feature engineering. Attributes’ identification involves identification of predictor/features
    variables (inputs) and target/class variable (output), along its data types (string
    or numeric or datetime) and classification of features into categorical and continuous
    variables that helps in applying appropriate treatment to be given to the variable
    by the algorithm while building the model. Data pre-processing involves identification
    of missing values and outliers and fill these gaps by computing mean or median
    for quantitative attributes and mode for qualitative attributes of data to improve
    the predictive power of model. The outliers cause increased mean and standard
    deviation, that can be eliminated by taking natural log value which reduces the
    variation caused by extreme values.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索性数据分析**是一个重要的步骤，一旦商业假设准备好后就开始进行。这个步骤占据了总项目时间的40-50%，因为模型结果依赖于输入数据的质量。探索性数据分析包括数据属性识别、数据预处理和特征工程。属性识别涉及识别预测变量/特征变量（输入）和目标/分类变量（输出），以及它们的数据类型（字符串、数值或日期时间），并将特征分类为类别变量和连续变量，这有助于在构建模型时算法对变量施加适当的处理。数据预处理涉及识别缺失值和异常值，通过计算定量属性的均值或中位数以及定性属性的众数来填补这些空白，以提高模型的预测能力。异常值会导致均值和标准差的增加，可以通过取自然对数来消除，这样可以减少极端值引起的变化。'
- en: '**Feature Engineering** is the next most important step in exploratory data
    analysis where the raw dataset is processed to convert data types of string or
    datetime or numeric ones to numeric vectors for an ML algorithm to understand
    and build efficient predictive model. Also, the labelled categorical data (e.g.,
    color red, green, blue; performance → poor, fair, good, very good, excellent;
    risk → low, medium, high; status → started, in-progress, on-hold, closed; gender
    → male/female; is_loan_approved/is_claim_fraudulent → yes/no) cannot be understood
    by an ML algorithm in its true context, hence it is required to be converted into
    numeric data. Feature Encoding is the widely used technique to transform the categorical
    data into continuous (numerical) values, e.g., Encode color as 1,2,3; performance
    as 1,2,3,4,5; risk as 1,2,3; status as 1,2,3,4; gender / is_loan_approved / is_claim_fraudulent
    as 0/1 etc. It is recommended to use label encoding in case categorical variables
    have no ordered relationship (e.g., color and status), ordinal encoding in case
    categorical variables have an ordered relationship (e.g., performance, risk) and
    one hot encoding in case categorical variable data is binary in nature (e.g.,
    gender, is_loan_approved, is_claim_fraudulent). A set of libraries are available
    in R or Python to implement these encoding methods. In some cases, a set of dummy
    variables or derived variables are created, especially in handling ‘date’ data
    types. Once the categorical text data is converted into numeric data, the data
    is ready to be fed to the model; As a last step, it is required to choose the
    appropriate features that help in improving the accuracy of model, by using the
    techniques such as Univariate Selection (statistical measure), Feature Importance
    (model property) and Correlation Matrix (identifies which features are most related
    to the target variable). These methods detect Collinearity between two variables
    where they are highly correlated and contain similar information about the variance
    within a given dataset. One may find the Variance Inflation Factor (VIF) useful
    to detect Multicollinearity where highly correlated three or more variables are
    included in the model. The key points in exploratory data analysis are represented
    in Fig.2, as shown below.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/d185e9dfbfb0d279fbe7c621987ac415.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: '**Fig 2:** Exploratory Data Analysis'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Building an ML Model** requires splitting of data into two sets, such as
    ‘training set’ and ‘testing set’ in the ratio of 80:20 or 70:30; A set of supervised
    (for labelled data) and unsupervised (for unlabeled data) algorithms are available
    to choose from depending on the nature of input data and business outcome to predict.
    In case of labelled data, it is recommended to choose logistic regression algorithm
    if the outcome to predict is of binary (0/1) in nature; choose decision tree classifier
    (or) Random Forest® classifier (or) KNN if the outcome to predict is of multi-class
    (1/2/3/...) in nature; and choose linear regression algorithm (e.g., decision
    tree regressor, random forest regressor) if the outcome to predict is continuous
    in nature. The clustering (Unsupervised) algorithm is preferred to analyze unlabeled
    / unstructured (text) data (e.g., k-means clustering). Artificial Neural Network
    (ANN) algorithms are suggested to analyze other unstructured (image/voice) data
    types, such as Convolutional Neural Networks (CNN) for image recognition and Recurrent
    Neural Networks (RNN) for voice recognition and Natural Language Processing (NLP).
    The model is built using training dataset and make prediction using test dataset.
    Use of deep learning (neural networks) models is preferred over regression models
    (ML models) for better performance as these models introduce extra layer of non-linearity
    with the introduction of Activation Function (AF). The algorithm selection under
    various scenarios has been represented in Fig.3, as shown below.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/fcbcb5d5eb3c35362f7a46ed449200f8.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: '**Fig 3:** Choose Right Algorithm'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '**Computation of Model Performance** is next logical step to choose the right
    model. The model performance metrics will decide on final model selection, that
    include computation of accuracy, precision, recall, F1 score (weighted average
    of precision and recall) , along with confusion matrix for classification models
    and co-efficient of determination for regression models. It is not recommended
    to use accuracy as a measure to determine the performance of classification models
    that are trained with imbalanced/skewed datasets, rather precision and recall
    are recommended to be computed to choose right classification model.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Hyperparameters Tuning** is highly recommended step in the process,
    continue till the model performance reach around 80%-85%. For example, the Random
    Forest algorithm takes maximum depth, maximum number of features, number of trees
    etc., as hyperparameters which can be intuitively tuned for improving model accuracy.
    Similarly, Neural Networks algorithm takes number of layers, batch size, number
    of epochs, number of samples etc. It is recommended to use Grid-search method
    to find the optimal hyperparameters of a model which results in the most ‘accurate’
    predictions. Besides this, it is also recommended to perform cross-validation
    as sometimes improvement in model accuracy may be due to overfitting (too sensitive
    model, unable to generalize) or underfitting (very generalized model) of model,
    using k-fold cross validation technique. To avoid overfitting, increase training
    data sample size that introduces more patterns or, reduce number of features that
    avoids complexity or, perform data regularization data using Ridge and Lasso regularization
    methods that reduces error/penalty. Similarly, to avoid underfitting, increase
    model complexity such as moving from linear to non-linear or adding more hidden
    layers (epochs) to neural network or add more features that introduce hidden patterns.
    However, adding more data volume does not solve the problem of underfitting, rather
    it hampers the model performance.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型超参数调优** 是过程中的重要步骤，建议继续调优直到模型性能达到约80%-85%。例如，随机森林算法采用最大深度、最大特征数、树的数量等超参数，这些超参数可以直观地调整以提高模型准确性。同样，神经网络算法包括层数、批量大小、训练轮数、样本数量等。建议使用网格搜索方法来找到模型的最佳超参数，从而获得最‘准确’的预测。此外，还推荐进行交叉验证，因为有时模型准确性的提升可能是由于过拟合（过于敏感的模型，无法泛化）或欠拟合（过于泛化的模型），可以使用k折交叉验证技术来验证。为避免过拟合，增加训练数据样本量以引入更多模式，或者减少特征数以避免复杂性，或使用岭回归和套索回归方法进行数据正则化以减少错误/惩罚。同样，为避免欠拟合，增加模型复杂性，如从线性模型转换为非线性模型，或在神经网络中增加更多隐藏层（轮次），或添加更多特征以引入隐藏模式。然而，增加更多数据量并不能解决欠拟合问题，反而会影响模型性能。'
- en: Finally. choose the model with optimum performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，选择性能最佳的模型。
- en: '**ML Model Development Best Practices:** The recommended ML Model Development
    Best Practices are (1) Perform clear hypothesis for the identified business problem
    before attributes identification itself; (2) Build the model using a basic algorithm
    first, like a logistic regression or decision tree and compile performance metrics,
    that gives enough confidence about relevance of data before going for a fancier
    algorithms, like neural networks; (3) Keep intermediate checkpoints in building
    the model to keep track of its model hyperparameters and its associated performance
    metrics that gives an ability to train the model incrementally and make good judgement
    when it comes to performance vs training time; (4) Use real-world production data
    for training the model to improve correctness of predictions.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习模型开发最佳实践：** 推荐的机器学习模型开发最佳实践包括（1）在属性识别之前，对识别出的业务问题进行明确的假设；（2）首先使用基本算法，如逻辑回归或决策树来构建模型，并编译性能指标，这样可以在使用更复杂的算法（如神经网络）之前，对数据的相关性有足够的信心；（3）在构建模型时保持中间检查点，以跟踪模型超参数及其相关性能指标，这样可以逐步训练模型，并在性能与训练时间方面做出合理判断；（4）使用真实的生产数据来训练模型，以提高预测的准确性。'
- en: Model Operations
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型操作
- en: '**Machine Leaning (ML) Model Operations** refers to implementation of processes
    to maintain the ML models in production environments. The common challenge encountered
    in a typical enterprise scenario is that the ML models worked in lab environment
    will remain stay at the proof-of-concept stage in many cases. If the model is
    rolled out into production, it becomes stale due to frequent source data changes
    that requires rebuilding of model. As the models are retrained multiple times,
    it is required to keep track for model performance and corresponding features
    and hyperparameters that are used for retraining the model. To perform all these
    operations, there should be a well-defined reproducible process in-place to implement
    the end-to-end machine learning operations (MLOps) that keeps the model current
    and accurate in production environment. The ML model operations lifecycle process
    is as shown in Fig. 4 that covers entire process of model development to model
    deployment to model performance monitoring in a seamless manner.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**机器学习（ML）模型操作** 指的是在生产环境中维护 ML 模型的过程实施。常见的挑战是在典型企业场景中，实验室环境中运行的 ML 模型在许多情况下会停留在概念验证阶段。如果将模型推向生产，它会因频繁的数据源变化而变得过时，需重建模型。由于模型需要多次重新训练，需要跟踪模型性能以及用于重新训练的相应特征和超参数。为执行所有这些操作，必须有一个定义明确、可重复的过程来实现端到端的机器学习操作（MLOps），以保持模型在生产环境中的当前性和准确性。ML
    模型操作生命周期过程如图 4 所示，涵盖了从模型开发到模型部署再到模型性能监控的整个过程。'
- en: '![Figure](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/bb4e45bca87cc0ad729aafbd8984fa5e.png)'
- en: '**Fig 4:** Machine Learning (ML) Model Operations Lifecyle'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 4:** 机器学习（ML）模型操作生命周期'
- en: The model retraining is very important at regular intervals, say fortnightly
    or monthly or quarterly or on-demand basis as it is very likely that the underlying
    source data will change over a period in the real-world scenario. A cron job is
    scheduled to retrain the model at the predefined intervals, or as and when the
    source data is changed, or as and when the model performance is degraded. There
    could be some changes to the model code due to hyperparameter tuning during model
    re-training.it is required to automate these model operations by having an automated
    model pipeline.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重新训练在定期时间间隔内非常重要，例如每两周、每月、每季度或按需进行，因为在实际场景中，基础数据可能会随时间变化。定时任务被安排在预定义的时间间隔内重新训练模型，或在数据源变化时，或在模型性能下降时进行重新训练。模型代码可能因超参数调整而发生变化，因此需要通过自动化模型管道来实现这些模型操作。
- en: The typical automated model pipeline in enterprise production environments include
    3 types of stores, such as **feature store****,** **metadata store and model registry**.
    The **feature store** contains data extracted from various source systems and
    transformed into the features as required by the model. The ML pipeline takes
    the data in batches from the feature store to train the model. The **metadata
    store** is a centralized model tracking (bookkeeping) system, maintained at the
    enterprise level, contains the model metadata at each stage of pipeline. The model
    metadata store facilitates the model stage transition, say from staging to production
    to archived. The model training is performed in one environment and deployment
    in other environments where the model inference will be performed just by specifying
    the remote model file path. The model metadata store is used for model experiments
    tracking and compare model experiments w.r.t. its performance. The model metadata
    includes training data set version, links to training runs and experiments. The
    **model registry** contains data of all trained models such as trained model version,
    model training date, model training metrics, hyperparameters used for training
    the model, predicted outcomes, and diagnostic charts (confusion matrix, ROC curves).
    The appropriate model will be picked from the model registry based on the intended
    target user’s requirement. The model metadata store & model registry can be implemented
    (custom) using a light-weight database, such as SQLite and a set of python functions;
    or a set of open-source/proprietary products, such as MLflow (community edition/managed
    service from Databricks). This tool provides an ability to manage models using
    a GUI or a set of APIs.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Deployment:** The models can be deployed in production environments
    to perform prediction either in batch inference mode or on-line inference mode.
    The batch inference can be achieved by scheduling as a job to run at a time interval
    and send the results via email to the intended users. The on-line inference can
    be achieved by exposing the model as a web service using frameworks such as python
    flask library or streamlit library to develop interactive web applications and
    invoke the model using its HTTP endpoint.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Packaging/Distribution:** The trained ML model is serialized into various
    formats to be able to distribute the model for deployment into TEST/PROD environments.
    The most common formats are pickle (for machine learning or deep learning models
    developed in python), ONNX (Open Neural Network Exchange format, for deep learning
    models), and PMML(Predictive Model Markup Language XML-based format, specifically
    for models developed using logistic regression and neural networks). The model
    can be packaged as a .jar file or as a docker container image and deployed as
    a prediction service into production.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Containerization** can be achieved by building a docker image, bundled
    with training and inference code, along with the necessary training and testing
    data and the model file for future predictions. Once the docker file is created
    bundled with necessary ML model, a CI/CD pipeline can be built using a tool, such
    as Jenkins. This docker container image can be exposed as a REST API, so that
    any external stakeholders can consume this ML model, either from on-premises or
    public cloud (in case of high compute requirements for building a deep learning
    model). In case of packaging and managing multiple docker containers, **Kubeflow**,
    the ML toolkit for Kubernetes can be used.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型容器化**可以通过构建一个包含训练和推理代码的 docker 镜像来实现，同时还需捆绑必要的训练和测试数据以及未来预测所需的模型文件。一旦创建了捆绑有必要机器学习模型的
    docker 文件，就可以使用像 Jenkins 这样的工具构建 CI/CD 管道。这个 docker 容器镜像可以暴露为 REST API，这样任何外部利益相关者都可以使用这个机器学习模型，无论是在本地还是在公共云上（如果构建深度学习模型需要高计算要求）。在打包和管理多个
    docker 容器的情况下，可以使用**Kubeflow**，这是 Kubernetes 的机器学习工具包。'
- en: '**Model Performance Monitoring** is an important activity where the predicted
    outcome (e.g., predicted sale price of an item) vs. actual value (actual sale
    price) is continuously monitored. And it is recommended to understand the end
    users’ reaction to the final predictions. In some scenarios, it is recommended
    to keep old model and new model running in-parallel to understand the variation
    in performance in both the models (model validation). It is mandatory to address
    performance degradation that arise due to ‘data drift’ (underlying source data
    pattern changes due to seasonality and trend, e.g., year-end sales data (or) addition
    of new categories (or) one particular attribute is not being generated by the
    upstream systems) and ‘model drift’ (statistical properties of target variable
    changes, e.g., definition of a fraudulent transaction itself changes). The most
    accurate way to measure the model drift is by measuring the F1 Score that combines
    the precision and the recall of a classifier into a single metric by taking their
    harmonic mean. The model will be retrained as an when the model drift (F1 Score)
    falls below certain threshold or at regular intervals (batch mode) or train the
    model as soon as the data is available (online training). It is very important
    to collect model logs and prediction logs by using popular logging tools such
    as elasticstack, and fluentd.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型性能监控**是一项重要的活动，其中预测结果（例如，某项商品的预测销售价格）与实际值（实际销售价格）会持续进行监控。建议了解最终预测对终端用户的反应。在一些情况下，建议让旧模型和新模型并行运行，以了解两个模型之间的性能变化（模型验证）。必须解决由于“数据漂移”（底层源数据模式由于季节性和趋势的变化，例如年终销售数据（或）新增类别（或）某个特定属性未由上游系统生成）和“模型漂移”（目标变量的统计属性变化，例如，欺诈交易的定义本身发生变化）引起的性能退化。测量模型漂移的最准确方法是通过测量
    F1 分数，该分数通过取分类器的精确度和召回率的调和平均值来结合这两个指标。当模型漂移（F1 分数）降到某个阈值以下时，或者在定期间隔（批处理模式）或数据一旦可用时（在线训练），将重新训练模型。使用像
    elasticstack 和 fluentd 这样的流行日志工具收集模型日志和预测日志是非常重要的。'
- en: '**Model version management** is a mandatory activity in ML model management
    as the model will be retrained at regular intervals due to changes in the underlying
    source data or as demanded by audit and compliance purposes. The source data,
    the model training scripts, model experiment, and the trained model are versioned
    together in the code repository. There are open-source tools available, such as
    Data Version Control (DVC) or AWS CodeCommit that uses Git as underlying code
    repository for model version management purposes.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**模型版本管理**是机器学习模型管理中一个必要的活动，因为模型会因为底层源数据的变化或审计和合规要求而定期重新训练。源数据、模型训练脚本、模型实验和训练后的模型会一起在代码库中进行版本控制。市面上有开源工具，例如
    Data Version Control (DVC) 或 AWS CodeCommit，这些工具使用 Git 作为底层代码库来进行模型版本管理。'
- en: '**ML Project Development Roles:** There are various roles involved in implementing
    ML model development and operations. Data Engineer analyzes the business data
    from various sources and ensures right and up-to-date data is accessible at the
    required granularity and quality in cost effective way. Data Scientists look at
    the data, performs data pre-processing and feature engineering, model building
    and choose right model that best fits the predictive/prescriptive requirements
    of business. Usually, Data Scientists take hypothesis-based approach to choose
    the model that fits the requirements. ML Engineer makes sure that the built model
    is giving the results reliably and assess the need for re-training the model by
    monitoring its outcome. Web App Developer builds the required presentation layer
    component to invoke and present the results to the intended stakeholders. The
    ML projects also require DevOps engineers to enable continuous delivery and data
    visualization experts to produce fancy dashboards.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: '**ML Model Deployment Best Practices:** The recommended model deployment best
    practices are (1) Automate the steps required for ML model development and deployment,
    by leveraging DevOps tools that gives some extra time for model retraining; (2)
    Perform continuous model testing, performance monitoring and retraining after
    its production deployment to keep the model relevant/current as the source data
    changes to predict the desired outcome(s); (3) Implement logging while exposing
    ML models as APIs, that includes capturing input features/model output (to track
    model drift), application context (for debugging production errors), model version
    (if multiple re-trained models are deployed in production); (4) Manage all the
    model metadata in a single repository.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Suresh Yaram](https://www.linkedin.com/in/sureshyaram/)** works with
    an IT company ([DXC Technology](https://dxc.com/us/en), erstwhile CSC India Limited))
    as Principal Solution Architect. Suresh comes with 20+ years of IT experience,
    focusing on Data Architecture, Big Data Analytics, Artificial Intelligence and
    Machine Learning. He has been involved in building Data & Analytics solutions
    to his customers across various domains such as Banking, Finance, and Insurance,
    including AI/ML for various insurance industry scenarios and presented them in
    various technology forums with in DXC. Suresh has also published a [paper](https://ieeexplore.ieee.org/document/7823950)
    in an IEEE Data Science conference conducted in India.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[Overview of Different Approaches to Deploying Machine Learning Models in Production](/2019/06/approaches-deploying-machine-learning-production.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Overview of MLOps](/2021/03/overview-mlops.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MLOps is an Engineering Discipline: A Beginner’s Overview](/2021/07/mlops-engineering-discipline.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并寻找目标…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
