- en: My favorite mind-blowing Machine Learning/AI breakthroughs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html](https://www.kdnuggets.com/2019/03/favorite-ml-ai-breakthroughs.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By [Jerry Chi](https://www.linkedin.com/in/jerrychi/), Data Science Manager
    at SmartNews**.'
  prefs: []
  type: TYPE_NORMAL
- en: Compared to other fields, machine learning / artificial intelligence seems to
    have a much higher frequency of super-interesting developments these days. Things
    that make you say “wow” or even “what a time to be alive!” (as the creator of [Two
    Minute Papers](https://www.youtube.com/channel/UCbfYPyITQ-7l4upoX8nvctg) always
    says)
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Disclaimer: I’m not using any rigorous definition of “mind-blowing” or “breakthrough”;
    it’s a casual list.. and I might use less rigorous terminology to make this post
    more accessible'
  prefs: []
  type: TYPE_NORMAL
- en: Amazingly accurate estimates from seemingly unusable information
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Through-wall human pose estimation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Website/video by MIT researchers, 2018](http://rfpose.csail.mit.edu/)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/fd784cc2060151479f7bba89b708f3ce.png)'
  prefs: []
  type: TYPE_IMG
- en: We can accurately estimate how a human on the other side of a wall is standing/sitting/walking
    just from perturbations in Wifi signals caused by that human.
  prefs: []
  type: TYPE_NORMAL
- en: Gauging materials’ physical properties from video
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Article/video by MIT researchers, 2015](http://news.mit.edu/2015/visual-microphone-identifies-structural-defects-0521)'
  prefs: []
  type: TYPE_NORMAL
- en: The researchers first [demonstrated in 2014 ](http://news.mit.edu/2014/algorithm-recovers-speech-from-vibrations-0804)that
    they can e.g. reproduce human speech from video (with no audio) of a potato chip
    bag based on the vibrations. This part was done without machine learning. In 2015,
    they used machine learning to show that you can estimate the stiffness, elasticity,
    weight per unit area, etc. of materials just from a video (in some cases just
    the vibrations caused by the ordinary circulation of air was sufficient).
  prefs: []
  type: TYPE_NORMAL
- en: Estimating keystrokes from a smartphone next to the keyboard
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Paper, 2015](https://www.sigmobile.org/mobicom/2015/papers/p142-liuA.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d8cd2c0a193be9d239ff8be4a92ecc22.png)'
  prefs: []
  type: TYPE_IMG
- en: Researchers showed that with the audio recorded by a single, off-the-shelf smartphone
    placed next to a keyboard, one can estimate with **94% accuracy** the individual
    keystrokes. Unlike previous approaches that used supervised deep learning with
    many microphones placed around the keyboard, this paper actually uses a relatively
    simple machine learning technique (K-means clustering) and **unsupervised** learning.
  prefs: []
  type: TYPE_NORMAL
- en: Generative models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Realistic face generation, style-mixing, and interpolation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Paper](https://arxiv.org/abs/1812.04948)/[video](https://www.youtube.com/watch?v=kSLJriaOumA) by
    NVIDIA researchers, 2018'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/d452d9c67d17a2d647fc49b9bd51e60d.png)'
  prefs: []
  type: TYPE_IMG
- en: The researchers combined a new architecture with tons of GPUs to create extremely
    photo-realistic artificial faces that are interpolations between other faces or
    applications of the “style” of one face to another face. The work builds upon
    past work on Generative Adversarial Networks (GANs). GANs were invented in 2014
    and have seen an explosion in research since then. The most basic concept of GANs
    is two neural networks dueling against each other (e.g. one that classifies images
    as “real” or “fake” and a second neural network that generates images in a way
    that attempts to “trick” the first neural network into wrongly classifying fake
    images as real…hence the second neural network is an “adversary” to the first).
  prefs: []
  type: TYPE_NORMAL
- en: In general, there is a lot of [awesome research](https://github.com/yenchenlin/awesome-adversarial-machine-learning) about
    adversarial machine learning, which has been around for more than a decade. There
    are many creepy implications for cybersecurity etc. But I digress.
  prefs: []
  type: TYPE_NORMAL
- en: Teaching machines to draw
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Blog post by Google Brain, 2017](https://ai.googleblog.com/2017/04/teaching-machines-to-draw.html)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/41d17838b9f6c454295e62d20784d32f.png)'
  prefs: []
  type: TYPE_IMG
- en: Interpolation between 2 drawings
  prefs: []
  type: TYPE_NORMAL
- en: My acquaintance [David Ha at Google Brain](https://twitter.com/hardmaru) used
    a generative recurrent neural network (RNN) to make drawings that are vector-based
    graphics (I think of this as Adobe Illustrator except automated).
  prefs: []
  type: TYPE_NORMAL
- en: Transferring great dance moves to poor dancers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Website](https://carolineec.github.io/everybody_dance_now/)/[video](https://www.youtube.com/watch?v=PCBTZh41Ris) from
    UC Berkeley researchers, 2018'
  prefs: []
  type: TYPE_NORMAL
- en: 'Think “Auto-Tune for dancing.” Using pose estimation and generative adversarial
    training, the researchers were able to make a fake video of any real person (the
    “target” person) dancing with great dance skills. The required input was only:'
  prefs: []
  type: TYPE_NORMAL
- en: a short video of someone with great dance skills dancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a few minutes of video of the target person dancing (typically poorly since
    most people suck at dancing)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I also saw Jensen Huang, the CEO of NVIDIA, show a video (made with this technique)
    of himself dancing like Michael Jackson. I’m glad I attended the GPU Tech Conference,
    haha.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: World models — AI learning inside its own dream
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Website by Google Brain, 2018](https://worldmodels.github.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/acf4711d39b9c3aadfc60f86717347c5.png)'
  prefs: []
  type: TYPE_IMG
- en: Humans do not actually know or think about all the details of the world we live
    in. We behave based on the abstraction of the world that is in our heads. For
    example, if I ride on a bike, I don’t think of the gears/nuts/bolts of the bike;
    I just have a rough sense of where the wheels, seat, and handle are and how to
    interact with them. Why not use a similar approach for AI?
  prefs: []
  type: TYPE_NORMAL
- en: This “world models” approach (again, created by David Ha et al) allows the “agent”
    (e.g. an AI that controls a car in a racing game) to create a generative model
    of the world/environment around it which is a simplification/abstraction of the
    actual environment. So, you can think of the world model as a dream that lives
    in the head of the AI. Then the AI can train via reinforcement learning in this
    “dream” to achieve better performance. So this approach is actually combining
    generative ML with reinforcement learning. By doing this, the researchers were
    able to achieve state-of-the-art performance on certain video game-playing tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[Update 2019/2/15] Building upon the above “world models” approach, Google
    just revealed [PlaNet: Deep Planning Network for Reinforcement Learning](http://ai.googleblog.com/2019/02/introducing-planet-deep-planning.html),
    which achieved 5000% better data efficiency than previous approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: AlphaStar — Starcraft II AI that beats the top pro players
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Blog post](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/), [e-sports-ish
    video](https://www.youtube.com/watch?v=cUTMhmVh1qs) by DeepMind (Google), 2019'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve come a long way from the [historic Go matches between Lee Sedol and DeepMind’s
    AlphaGo](https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol) that rocked the
    world, which was a mere 3 years ago in 2016 (check out the [NetFlix documentary](https://www.netflix.com/jp-en/title/80190844),
    which made some people cry). Then, it was even more amazing that AlphaZero in
    2017 became better than AlphaGo at Go (and better than any other algorithm at
    chess, shogi AKA Japanese chess, etc.) despite not using any training data from
    human matches. But AlphaStar in 2019 is even **more** amazing.
  prefs: []
  type: TYPE_NORMAL
- en: Being a StarCraft fan myself since 1998, I can appreciate how the “…need to
    balance short and long-term goals and adapt to unexpected situations… poses a
    huge challenge.” It’s truly a difficult and complex game which requires understanding
    at multiple levels to play well. Research on Starcraft-playing algorithms have
    been ongoing since 2009.
  prefs: []
  type: TYPE_NORMAL
- en: AlphaStar essentially used a combination of supervised learning (from human
    matches) and reinforcement learning (playing against itself) to achieve its results.
  prefs: []
  type: TYPE_NORMAL
- en: Humans training robots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Teaching tasks to machines with a single human demonstration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '[Article](https://news.developer.nvidia.com/new-ai-technique-helps-robots-work-alongside-humans/)/[video](https://www.youtube.com/watch?time_continue=1&v=B7ZT5oSnRys) by
    NVIDIA researchers, 2018'
  prefs: []
  type: TYPE_NORMAL
- en: 'I can think of 3 typical approaches to teaching robots to do something, but
    all take a lot of time/labor:'
  prefs: []
  type: TYPE_NORMAL
- en: Manually program the robot’s joint rotations etc. for each situation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let the robot try the task many, many times (reinforcement learning)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demonstrate a task to the robot many, many times
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Typically, one major criticism of deep learning is that it’s very costly to
    produce the millions of examples (data) that make the computer perform well. But
    increasingly, there are ways to not rely on such costly data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The researchers figured out a way for a robot arm to successfully perform a
    task (such as “pick up the blocks and stack them so that they are in the order:
    red block, blue block, orange block”) based on a **single **video of a **single **human
    demonstration (a physical real human hand moving the blocks), even if the video
    was shot from a different angle. The algorithm actually generates a human-readable
    description of the task it plans to do, which is great for troubleshooting. The
    algorithm relies on object detection with pose estimation, synthetic training
    data generation, and simulation-to-reality transfer.'
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised machine translation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Blog post by Facebook AI Research, 2018](https://code.fb.com/ai-research/unsupervised-machine-translation-a-novel-approach-to-provide-fast-accurate-translations-for-more-languages/)'
  prefs: []
  type: TYPE_NORMAL
- en: Typically, you would need a huge training dataset of translated documents (e.g.
    professional translations of United Nations proceedings) to do machine translation
    well (i.e. **supervised** learning). Of course, many topics and language pairs
    don’t have high-quality, plentiful training data. In this paper, researchers showed
    that it’s possible to use **unsupervised** learning (i.e. using no translation
    data and just using unrelated corpuses of text in each language), it’s possible
    to reach the translation quality of state-of-the-art **supervised** learning approaches.
    Wow.
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea is that, in any language, certain words/concepts will tend to
    appear in close proximity (e.g. “furry” and “cat”). They describe this as “embeddings
    of words in different languages share similar neighborhood structure.” I mean,
    OK, I get the idea, but it’s still mind-blowing that using this approach they
    can reach such high translation quality without training on translation datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Closing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I hope this post made you more excited about developments in ML/AI, if you weren’t
    already. Maybe I’ll write another similar post in a year from now. Please feel
    free to leave any thoughts/comments here or e-mail me at jerrychi123 [at] gmail.com.
  prefs: []
  type: TYPE_NORMAL
- en: What a time to be alive! =D
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio**: [Jerry Chi](https://www.linkedin.com/in/jerrychi/) has experience
    in data science, machine learning, data engineering, and strategy in digital industries.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://blog.usejournal.com/my-favorite-mind-blowing-ml-ai-breakthroughs-e7b4f3637e3d).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resources:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Acquiring Labeled Data to Train Your Models at Low Costs](https://www.kdnuggets.com/2019/02/labeled-data-train-models.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4 Reasons Why Your Machine Learning Code is Probably Bad](https://www.kdnuggets.com/2019/02/4-reasons-machine-learning-code-probably-bad.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Artificial Neural Network Implementation using NumPy and Image Classification](https://www.kdnuggets.com/2019/02/artificial-neural-network-implementation-using-numpy-and-image-classification.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
