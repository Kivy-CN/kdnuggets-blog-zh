- en: Open Source Toolkits for Speech Recognition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/03/open-source-toolkits-speech-recognition.html](https://www.kdnuggets.com/2017/03/open-source-toolkits-speech-recognition.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**By Cindi Thompson, [Silicon Valley Data Science](https://www.svds.com/).**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: As members of the [deep learning](http://svds.com/getting-started-deep-learning/)
    R&D team at SVDS, we are interested in comparing [Recurrent Neural Network](https://en.wikipedia.org/wiki/Recurrent_neural_network)
    (RNN) and other approaches to speech recognition. Until a few years ago, the state-of-the-art
    for speech recognition was a [phonetic](https://en.wikipedia.org/wiki/Phonetics)-based
    approach including separate components for pronunciation, [acoustic](https://en.wikipedia.org/wiki/Acoustic_model),
    and [language](https://en.wikipedia.org/wiki/Language_model) models. Typically,
    this consists of n-gram language models combined with [Hidden Markov models](https://en.wikipedia.org/wiki/Hidden_Markov_model)
    (HMM). We wanted to start with this as a baseline model, and then explore ways
    to combine it with newer approaches such as Baidu’s [Deep Speech](https://arxiv.org/abs/1412.5567).
    While summaries exist explaining these baseline phonetic models, there do not
    appear to be any easily-digestible blog posts or papers that compare the tradeoffs
    of the different freely available tools.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: This article reviews the main options for free speech recognition toolkits that
    use traditional HMM and n-gram language models. For operational, general, and
    customer-facing speech recognition it may be preferable to purchase a product
    such as [Dragon](http://www.nuance.com/dragon/index.htm) or [Cortana](https://www.microsoft.com/en-us/mobile/experiences/cortana/).
    But in an R&D context, a more flexible and focused solution is often required,
    and that is why we decided to develop our own speech recognition pipeline. Below
    we list the top contenders in the free or open source world, and rate them on
    several characteristics.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '![Comparison matrix](../Images/98e57bf6c7f584277f8b9c2b4f5ec19b.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
- en: Comparison of open source and free speech recognition toolkits.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: This analysis is based on our subjective experience and the information available
    from the repositories and toolkit websites. This is also not an exhaustive list
    of speech recognition software, most of which are listed [here](https://en.wikipedia.org/wiki/List_of_speech_recognition_software)
    (which goes beyond open source). A 2014 paper by Gaida et.al. evaluates the performance
    of [CMU Sphinx](http://cmusphinx.sourceforge.net/), [Kaldi](http://kaldi-asr.org/),
    and [HTK](http://htk.eng.cam.ac.uk/#). Note that HTK is not strictly open source
    in its usual interpretation, as the code cannot be redistributed or re-purposed
    for commercial use.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '**Programming Languages:** Depending on your familiarity with different languages,
    you may naturally prefer one toolkit over another. All of the listed options except
    for [ISIP](https://www.isip.piconepress.com/projects/speech/) have Python wrappers
    available either on the main site or found quickly with a web search. Of course,
    the Python wrappers may not expose the full functionality of the core code available
    in the toolkit. CMU Sphinx also has wrappers in several other programming languages.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**编程语言：** 根据你对不同语言的熟悉程度，你可能自然会偏好某个工具包。除 [ISIP](https://www.isip.piconepress.com/projects/speech/)
    外，所有列出的选项都有 Python 包装器，通常可以在主站点找到或通过网络搜索快速找到。当然，Python 包装器可能无法暴露工具包核心代码的全部功能。CMU
    Sphinx 也有多个其他编程语言的包装器。'
- en: '**Development activity:** All of the projects listed have their origins in
    academic research. CMU Sphinx, as may be obvious from its name, is a product of
    Carnegie Mellon University. It’s existed in some form for about 20 years, and
    is now available on both GitHub (with [C](https://github.com/cmusphinx/pocketsphinx)
    and [Java](https://github.com/cmusphinx/sphinx4) versions there) and [SourceForge](https://sourceforge.net/projects/cmusphinx/),
    with recent activity on both. Both the Java and C versions appear to have only
    one contributor on GitHub, but this doesn’t reflect the historical reality of
    the project (there are 9 administrator and more than a dozen developers on the
    SourceForge repo). Kaldi has its academic roots from a 2009 workshop, with its
    code now hosted on [GitHub](https://github.com/kaldi-asr/kaldi) with 121 contributors.
    HTK started its life at Cambridge University in 1989, was commercial for some
    time, but is now licenced back to Cambridge and is not available as open source
    software. While its latest version was updated in December of 2015, the prior
    release was in 2009\. [Julius](http://julius.osdn.jp/en_index.php) has been in
    development since 1997 and had its last major release in September of 2016 with
    a somewhat active [GitHub](https://github.com/julius-speech/julius) repo consisting
    of three contributors, which again is unlikely to reflect reality. ISIP was the
    first state-of-the-art open source speech recognition system, and originated from
    Mississippi State. It was developed mostly from 1996 to 1999, with its last release
    in 2011, but the project was mostly defunct before the emergence of GitHub.^([1](https://www.svds.com/open-source-toolkits-speech-recognition/#fn1))'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**开发活动：** 所列项目均源于学术研究。CMU Sphinx，如其名称所示，是卡内基梅隆大学的产物。它以某种形式存在了大约 20 年，现在可在 GitHub（包括[C](https://github.com/cmusphinx/pocketsphinx)
    和 [Java](https://github.com/cmusphinx/sphinx4) 版本）和 [SourceForge](https://sourceforge.net/projects/cmusphinx/)
    上找到，并且在两个平台上都有近期活动。Java 和 C 版本在 GitHub 上似乎只有一个贡献者，但这并不能反映项目的历史现实（在 SourceForge
    代码库上有 9 位管理员和十多位开发者）。Kaldi 的学术根源来自 2009 年的一个研讨会，其代码现在托管在 [GitHub](https://github.com/kaldi-asr/kaldi)
    上，拥有 121 位贡献者。HTK 于 1989 年在剑桥大学开始其生命历程，曾商业化一段时间，但现在许可回剑桥，并且不再作为开源软件提供。尽管其最新版本在
    2015 年 12 月更新，但之前的版本是在 2009 年。[Julius](http://julius.osdn.jp/en_index.php) 自 1997
    年起开发，并于 2016 年 9 月发布了最后一个重大版本，拥有一个稍微活跃的 [GitHub](https://github.com/julius-speech/julius)
    代码库，其中有三位贡献者，这可能仍未完全反映现实。ISIP 是第一个最先进的开源语音识别系统，源自密西西比州立大学。它主要在 1996 到 1999 年间开发，最后一次发布是在
    2011 年，但在 GitHub 出现之前，该项目基本上已停滞不前。^([1](https://www.svds.com/open-source-toolkits-speech-recognition/#fn1))'
- en: '![Github comparison](../Images/a863a2c6bcca436b4d4d6acc0f627238.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![GitHub 比较](../Images/a863a2c6bcca436b4d4d6acc0f627238.png)'
- en: '**Community:** Here we looked at both mailing and discussion lists and the
    community of developers involved. CMU Sphinx has online discussion forums and
    active interest in its repos. However, we wonder if the duplication of repos in
    both SourceForge and GitHub are blocking more widespread contribution. In comparison,
    Kaldi has both forums and mailing lists as well as an active GitHub repo. HTK
    has mailing lists but no open repository. The user forum link on the Julius web
    site is broken but there may be more information on the Japanese site. ISIP is
    primarily targeted for educational purposes and the mailing list archives are
    no longer functional.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**社区：** 在这里，我们考察了邮件列表和讨论列表以及相关的开发者社区。CMU Sphinx 有在线讨论论坛，并且在其代码库中有活跃的关注。然而，我们怀疑
    SourceForge 和 GitHub 上的代码库重复是否阻碍了更广泛的贡献。相比之下，Kaldi 拥有论坛和邮件列表以及一个活跃的 GitHub 代码库。HTK
    有邮件列表但没有开放的代码库。Julius 网站上的用户论坛链接已损坏，但在日本网站上可能会有更多信息。ISIP 主要面向教育用途，其邮件列表档案已不再有效。'
- en: '**Tutorials and Examples:** CMU Sphinx has very readable, thorough, and easy
    to follow documentation; Kaldi’s documentation is also comprehensive but a bit
    harder to follow in my opinion. However, Kaldi does cover both the phonetic and
    deep learning approaches to speech recognition. If you are not familiar with speech
    recognition, HTK’s tutorial documentation (available to registered users) gives
    a good overview to the field, in addition to documentation on actual design and
    use of the system. The Julius project is focused on Japanese, and the most current
    documentation is in Japanese^([2](https://www.svds.com/open-source-toolkits-speech-recognition/#fn2)),
    but they also are actively translating to English and provide that documentation
    as well; there are some examples of running speech recognition [here](https://github.com/julius-speech/dictation-kit).
    Finally, the ISIP project has some documentation, but is a little more difficult
    to navigate.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**教程和示例：** CMU Sphinx 拥有非常易读、详尽且易于跟随的文档；Kaldi 的文档也很全面，但在我看来稍显难以跟随。然而，Kaldi
    确实涵盖了语音识别的音素和深度学习方法。如果你对语音识别不熟悉，HTK 的教程文档（供注册用户使用）提供了该领域的良好概述，并包括系统的实际设计和使用文档。Julius
    项目专注于日语，最新的文档是日语的^([2](https://www.svds.com/open-source-toolkits-speech-recognition/#fn2))，但他们也在积极翻译成英语，并提供这些文档；这里有一些运行语音识别的示例[这里](https://github.com/julius-speech/dictation-kit)。最后，ISIP
    项目有一些文档，但导航起来有些困难。'
- en: '**Trained models:** Even though a main reason to use these open or free tools
    is because you want to train specialized recognition models, it is a big advantage
    when you can speak to the system out of the box. CMU Sphinx includes English and
    many [other models](https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/)
    ready to use, with the documentation for connecting to them with Python included
    right in the [GitHub readme](https://github.com/cmusphinx/pocketsphinx-python/blob/master/readme.md).
    Kaldi’s instructions for decoding with existing models is hidden deep in the documentation,
    but we eventually discovered a model trained on some part of an English VoxForge dataset
    in the `egs/voxforge` subdirectory of the repo, and recognition can be done by
    running the script in the `online-data` subdirectory. We didn’t dig as deeply
    into the other three packages, but they all come with at least simple models or
    appear to be compatible with the format provided on the [VoxForge](http://www.voxforge.org/home) site,
    a fairly active crowdsourced repository of speech recognition data and trained
    models.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练模型：** 尽管使用这些开源或免费工具的主要原因是因为你想训练专门的识别模型，但能够开箱即用地与系统对话是一个很大的优势。CMU Sphinx
    包含英语和许多[其他模型](https://sourceforge.net/projects/cmusphinx/files/Acoustic%20and%20Language%20Models/)可供使用，连接到这些模型的
    Python 文档直接包含在[GitHub readme](https://github.com/cmusphinx/pocketsphinx-python/blob/master/readme.md)中。Kaldi
    对现有模型解码的说明深藏在文档中，但我们最终发现了一个在 `egs/voxforge` 子目录中训练的英文 VoxForge 数据集的模型，并且可以通过运行
    `online-data` 子目录中的脚本进行识别。我们没有深入挖掘其他三个包，但它们都至少附带了简单的模型或似乎与[VoxForge](http://www.voxforge.org/home)网站提供的格式兼容，该网站是一个相当活跃的众包语音识别数据和训练模型的库。'
- en: In the future, we will discuss how to get started using CMU Sphinx. We also
    plan to follow up on our earlier deep learning post with one that applies neural
    networks to speech, and will compare the neural net’s recognition performance
    to that of CMU Sphinx. In the meantime, we always love feedback and questions
    on our blog posts, so let us know if you have additional perspective on these
    toolkits or others.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，我们将讨论如何开始使用 CMU Sphinx。我们还计划在之前的深度学习帖子基础上，进行一个将神经网络应用于语音的帖子，并将神经网络的识别性能与
    CMU Sphinx 进行比较。与此同时，我们始终欢迎对我们博客帖子的反馈和问题，因此如果你对这些工具包或其他工具包有更多看法，请告知我们。
- en: '**References**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献**'
- en: '[blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits](http://blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits/)'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits](http://blog.neospeech.com/2016/07/08/top-5-open-source-speech-recognition-toolkits/)'
- en: Gaida, Christian, et al. “Comparing open-source speech recognition toolkits.”
    Tech. Rep., DHBW Stuttgart (2014).
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gaida, Christian, 等。“比较开源语音识别工具包。”技术报告，DHBW 斯图加特（2014）。
- en: '**Bio: [Cindi Thompson](https://www.linkedin.com/in/cindithompson/)** is a
    naturally collaborative problem-solver able to bridge technical and business concerns
    using strong communication and facilitation skills. With a PhD in artificial intelligence,
    she brings a unique blend of academic and industry experience in machine learning,
    natural language understanding, and R&D.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[辛迪·汤普森](https://www.linkedin.com/in/cindithompson/)** 是一位具有自然合作精神的问题解决者，能够利用强大的沟通和协调技巧弥合技术和业务方面的关切。拥有人工智能博士学位，她带来了机器学习、自然语言理解和研发领域的独特学术与行业经验。'
- en: '[Original](https://www.svds.com/open-source-toolkits-speech-recognition/?utm_campaign=KDNuggets%20Blog&utm_source=KDNuggets).
    Reposted with permission.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://www.svds.com/open-source-toolkits-speech-recognition/?utm_campaign=KDNuggets%20Blog&utm_source=KDNuggets).
    经许可转载。'
- en: '**Related:**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Artificial Intelligence and Speech Recognition for Chatbots: A Primer](/2017/01/artificial-intelligence-speech-recognition-chatbots-primer.html)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能与聊天机器人语音识别入门](/2017/01/artificial-intelligence-speech-recognition-chatbots-primer.html)'
- en: '[Achieving Human Parity in Conversational Speech Recognition](/2016/12/achieving-human-parity-conversational-speech-recognition.html)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在对话语音识别中实现人类平衡](/2016/12/achieving-human-parity-conversational-speech-recognition.html)'
- en: '[Top 20 Python Machine Learning Open Source Projects, updated](/2016/11/top-20-python-machine-learning-open-source-updated.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前 20 个 Python 机器学习开源项目，已更新](/2016/11/top-20-python-machine-learning-open-source-updated.html)'
- en: '* * *'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 加速你的网络安全职业发展'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[The Evolution of Speech Recognition Metrics](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[语音识别指标的发展](https://www.kdnuggets.com/2022/10/evolution-speech-recognition-metrics.html)'
- en: '[Closed Source VS Open Source Image Annotation](https://www.kdnuggets.com/closed-source-vs-open-source-image-annotation)'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[闭源与开源图像注释](https://www.kdnuggets.com/closed-source-vs-open-source-image-annotation)'
- en: '[Build a Text-to-Speech Converter with Python in 5 Minutes](https://www.kdnuggets.com/2022/09/build-texttospeech-converter-python-5-minutes.html)'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 5 分钟内用 Python 构建文本转语音转换器](https://www.kdnuggets.com/2022/09/build-texttospeech-converter-python-5-minutes.html)'
- en: '[Transfer Learning for Image Recognition and Natural Language Processing](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[图像识别与自然语言处理的迁移学习](https://www.kdnuggets.com/2022/01/transfer-learning-image-recognition-natural-language-processing.html)'
- en: '[5 IT Jobs That Are High in Demand But Don’t Get Enough Recognition](https://www.kdnuggets.com/5-it-jobs-that-are-high-in-demand-but-dont-get-enough-recognition)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个需求高但不被重视的 IT 职业](https://www.kdnuggets.com/5-it-jobs-that-are-high-in-demand-but-dont-get-enough-recognition)'
- en: '[Introducing Objectiv: Open-source product analytics infrastructure](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 Objectiv：开源产品分析基础设施](https://www.kdnuggets.com/2022/06/objectiv-introducing-objectiv-opensource-product-analytics-infrastructure.html)'
