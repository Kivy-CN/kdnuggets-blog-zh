- en: Simple Derivatives with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 PyTorch 计算简单导数
- en: 原文：[https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html](https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html](https://www.kdnuggets.com/2018/05/simple-derivatives-pytorch.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: Derivatives are simple with PyTorch. Like many other neural network libraries,
    PyTorch includes an automatic differentiation package, `[autograd](https://pytorch.org/docs/master/autograd.html)`,
    which does the heavy lifting. But derivatives seem especially simple with PyTorch.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch 求导数很简单。像许多其他神经网络库一样，PyTorch 包含一个自动微分包 `[autograd](https://pytorch.org/docs/master/autograd.html)`，它完成了繁重的工作。但在
    PyTorch 中，导数的计算似乎尤其简单。
- en: One of the things I wish I had when first learning about how [derivatives and
    practical implementations of neural networks](https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html)
    fit together were concrete examples of using such neural network packages to find
    simple derivatives and perform calculations on them, separate from computation
    graphs in neural networks. PyTorch's architecture makes such pedagogical examples
    easy.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望在第一次学习如何将 [导数和神经网络的实际应用](https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html)结合起来时，有一些具体的例子，展示如何使用这样的神经网络包来找出简单的导数并进行计算，这些计算与神经网络中的计算图分开。PyTorch
    的架构使得这种教学示例变得容易。
- en: I can't really tell if this will be useful for people who want to see how PyTorch
    implements automatic differentiation, how to practically compute derivatives,
    or even learning what "finding the derivative" means, but let's give it a go anyways.
    There's a chance it isn't useful for any of these. :)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我不太确定这是否对那些想了解 PyTorch 如何实现自动微分、如何实际计算导数，甚至是学习“寻找导数”是什么意思的人有用，但我们还是试试看吧。也许这对这些人都没有帮助。
    :)
- en: '![PyTorch](../Images/05892c36023f36e716584053fc6b9e7a.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![PyTorch](../Images/05892c36023f36e716584053fc6b9e7a.png)'
- en: 'First we will need a function for which to find the derivative. Arbitrarily,
    let''s use this:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个函数来找出导数。我们随意使用这个：
- en: '![Equation](../Images/f63c40b9d1ac08484e874bdc8ba90142.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/f63c40b9d1ac08484e874bdc8ba90142.png)'
- en: We would do well to recall here that the derivative of a function can be interpreted
    as the slope of a tangent to the curve represented by our function, as well as
    the function's rate of change.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该记住，函数的导数可以被解释为切线的斜率，以及函数的变化率。
- en: 'Before we use PyTorch to find the derivative to this function, let''s work
    it out first by hand:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用 PyTorch 找出这个函数的导数之前，让我们先手动计算一下：
- en: '![Equation](../Images/63f2148d099a0885d5fcf5aeb0161e92.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/63f2148d099a0885d5fcf5aeb0161e92.png)'
- en: '![Equation](../Images/e9b358a522dc0f7f98dbb990318d9596.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/e9b358a522dc0f7f98dbb990318d9596.png)'
- en: The above is the *first order derivative* of our original function.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 上述是我们原始函数的 *一阶导数*。
- en: 'Now let''s find the value of our derivative function for a given value of *x*.
    Let''s arbitrarily use **2**:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们找出给定 *x* 值的导数函数值。我们随意使用 **2**：
- en: '![Equation](../Images/c85e3f5373a0fb763a2f27eed1eb8bee.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/c85e3f5373a0fb763a2f27eed1eb8bee.png)'
- en: '![Equation](../Images/f7e148a32128215ad6de52382a341e16.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/f7e148a32128215ad6de52382a341e16.png)'
- en: '![Equation](../Images/90de01b6c4561049c41a251cdf100dc7.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/90de01b6c4561049c41a251cdf100dc7.png)'
- en: '![Equation](../Images/69a4f46f44f8f44f74b2d1e673a6777b.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![公式](../Images/69a4f46f44f8f44f74b2d1e673a6777b.png)'
- en: Solving our derivative function for *x = 2* gives as **233**. This can be interpreted
    as the rate of change of *y* with respect to *x* in our formula is 233 when when
    *x = 2*.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对 *x = 2* 求导数函数的结果是 **233**。这可以解释为在公式中，当 *x = 2* 时，*y* 对 *x* 的变化率是 233。
- en: '**Using `autograd` to Find and Solve a Derivative**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用 `autograd` 查找并求解导数**'
- en: How can we do the same as above with PyTorch's `autograd` package?
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何使用 PyTorch 的 `autograd` 包做与上面相同的事情？
- en: 'First, it should be obvious that we have to represent our original function
    in Python as such:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要将原始函数在 Python 中表示为如下形式：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Line by line, the above code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码逐行解释：
- en: imports the torch library
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入 torch 库
- en: defines the function we want to compute the derivative of
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义我们想计算导数的函数
- en: defines the value (2) we want to compute the derivative with regard to as a
    PyTorch `Variable` object and specifies that it should be instantiated in such
    a way that it tracks where in the computation graph it connects to in order to
    perform differentiation by the chain rule (`requires_grad`)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将我们想要计算其导数的值（2）定义为PyTorch `Variable` 对象，并指定它应以能够跟踪计算图中连接位置的方式进行实例化，以便通过链式法则
    (`requires_grad`) 执行微分。
- en: uses `autograd`'s `[backward()](https://pytorch.org/docs/master/autograd.html#torch.autograd.backward)`
    to compute the sum of gradients, using the chain rule
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `autograd` 的 `[backward()](https://pytorch.org/docs/master/autograd.html#torch.autograd.backward)`
    计算梯度的总和，使用链式法则
- en: outputs the value stored in the *x* tensor's `grad` attribute, which, as shown
    below
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输出 *x* 张量的 `grad` 属性中存储的值，如下所示
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This value, 233, matches what we calculated by hand, above.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个值233与我们上面手动计算的结果一致。
- en: To take the next steps with using PyTorch, including using the `autograd` package
    and [`Tensor`](https://www.kdnuggets.com/2018/05/pytorch-tensor-basics.html) objects
    to build some basic neural networks, I suggest the official [PyTorch 60 Minute
    Blitz](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
    or [this tutorial](https://github.com/yunjey/pytorch-tutorial).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 若要进一步使用PyTorch，包括使用 `autograd` 包和 [`Tensor`](https://www.kdnuggets.com/2018/05/pytorch-tensor-basics.html)
    对象构建一些基础神经网络，我建议查看官方的 [PyTorch 60分钟快速教程](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)
    或 [这个教程](https://github.com/yunjey/pytorch-tutorial)。
- en: '**Related**:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**：'
- en: '[PyTorch Tensor Basics](/2018/05/pytorch-tensor-basics.html)'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch张量基础](/2018/05/pytorch-tensor-basics.html)'
- en: '[WTF is a Tensor?!?](/2018/05/wtf-tensor.html)'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么是张量?!?](/2018/05/wtf-tensor.html)'
- en: '[Boost your data science skills. Learn linear algebra.](/2018/05/boost-data-science-skills-learn-linear-algebra.html)'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升你的数据科学技能。学习线性代数。](/2018/05/boost-data-science-skills-learn-linear-algebra.html)'
- en: '* * *'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行IT管理'
- en: '* * *'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[5 Simple Steps Series: Master Python, SQL, Scikit-learn, PyTorch &…](https://www.kdnuggets.com/5-simple-steps-series-master-python-sql-scikit-learn-pytorch-google-cloud)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个简单步骤系列：掌握Python、SQL、Scikit-learn、PyTorch及其他](https://www.kdnuggets.com/5-simple-steps-series-master-python-sql-scikit-learn-pytorch-google-cloud)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释的PyTorch神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[The Complete Free PyTorch Course for Deep Learning](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[完整免费PyTorch深度学习课程](https://www.kdnuggets.com/2022/10/complete-free-pytorch-course-deep-learning.html)'
- en: '[Getting Started with PyTorch Lightning](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch Lightning入门](https://www.kdnuggets.com/2022/12/getting-started-pytorch-lightning.html)'
- en: '[Tuning Adam Optimizer Parameters in PyTorch](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[调优PyTorch中的Adam优化器参数](https://www.kdnuggets.com/2022/12/tuning-adam-optimizer-parameters-pytorch.html)'
- en: '[YOLOv5 PyTorch Tutorial](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[YOLOv5 PyTorch教程](https://www.kdnuggets.com/2022/12/yolov5-pytorch-tutorial.html)'
