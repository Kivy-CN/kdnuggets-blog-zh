- en: 6 areas of AI and Machine Learning to watch closely
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6个需要密切关注的AI和机器学习领域
- en: 原文：[https://www.kdnuggets.com/2017/01/6-areas-ai-machine-learning.html](https://www.kdnuggets.com/2017/01/6-areas-ai-machine-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2017/01/6-areas-ai-machine-learning.html](https://www.kdnuggets.com/2017/01/6-areas-ai-machine-learning.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Nathan Benaich](http://www.nathanbenaich.com/), investing in a future
    of technology.**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Nathan Benaich](http://www.nathanbenaich.com/) 提供，投资于未来技术。**'
- en: '![](../Images/71ab4e2fdf178256a081d486d31fbd0c.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/71ab4e2fdf178256a081d486d31fbd0c.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Distilling a generally-accepted definition of what qualifies as artificial intelligence
    (AI) has become a revived topic of debate in recent times. Some have rebranded
    AI as “cognitive computing” or “machine intelligence”, while others incorrectly
    interchange AI with “machine learning”. This is in part because AI is not *one*
    technology. It is in fact a broad field constituted of *many* disciplines, ranging
    from robotics to machine learning. The ultimate goal of AI, most of us affirm,
    is to build machines capable of performing tasks and cognitive functions that
    are otherwise only within the scope of human intelligence. In order to get there,
    machines must be able to learn these capabilities automatically instead of having
    each of them be explicitly programmed end-to-end.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 提炼出一个普遍接受的人工智能（AI）定义已成为近期重新讨论的话题。有些人将AI重新品牌化为“认知计算”或“机器智能”，而另一些人错误地将AI与“机器学习”混为一谈。这部分是因为AI不是*一种*技术。事实上，它是一个广泛的领域，由*许多*学科组成，从机器人技术到机器学习。大多数人认为，AI的最终目标是构建能够执行任务和认知功能的机器，而这些任务和功能通常仅限于人类智能的范围。为了实现这一目标，机器必须能够自动学习这些能力，而不是将每项能力逐步编程。
- en: It’s amazing how much progress the field of AI has achieved over the last 10
    years, ranging from self-driving cars to speech recognition and synthesis. Against
    this backdrop, AI has become a topic of conversation in more and more companies
    and households who have come to see AI as a technology that isn’t another 20 years
    away, but as something that is impacting their lives today. Indeed, the popular
    press reports on AI almost everyday and technology giants, one by one, articulate
    their significant long-term AI strategies. While several investors and incumbents
    are eager to understand how to capture value in this new world, the majority are
    still scratching their heads to figure out what this all means. Meanwhile, governments
    are grappling with the implications of automation in society (see Obama’s [farewell
    address](https://www.nytimes.com/2017/01/12/upshot/in-obamas-farewell-a-warning-on-automations-perils.html?_r=0)).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去10年中，AI领域取得了令人惊叹的进展，从自动驾驶汽车到语音识别和合成。背景下，AI已成为越来越多公司和家庭讨论的话题，他们开始将AI视为不再是20年后的技术，而是正在影响他们生活的事物。的确，主流媒体几乎每天都报道AI，科技巨头们也一个个阐明了他们的重要长期AI战略。尽管一些投资者和现有者渴望了解如何在这个新世界中获取价值，大多数人仍在摸索这意味着什么。与此同时，政府正在处理自动化对社会的影响（参见奥巴马的
    [告别演讲](https://www.nytimes.com/2017/01/12/upshot/in-obamas-farewell-a-warning-on-automations-perils.html?_r=0)）。
- en: Given that AI will impact the entire economy, actors in these conversations
    represent the entire distribution of intents, levels of understanding and degrees
    of experience with building or using AI systems. As such, it’s crucial for a discussion
    on AI — including the questions, conclusions and recommendations derived therefrom — to
    be grounded in data and reality, not conjecture. It’s far too easy (and sometimes
    exciting!) to wildly extrapolate the implications of results from published research
    or tech press announcements, speculative commentary and thought experiments.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于AI将影响整个经济体，参与这些对话的各方代表了意图、理解水平和构建或使用AI系统的经验程度的全面分布。因此，关于AI的讨论——包括从中得出的问题、结论和建议——必须以数据和现实为基础，而非推测。从已发布的研究结果或技术新闻公告、投机性评论和思想实验中对结果进行大胆的外推是极其容易（有时也令人兴奋）的。
- en: Here are six areas of AI that are particularly noteworthy in their ability to
    impact the future of digital products and services. I describe what they are,
    why they are important, how they are being used today and include a list (by no
    means exhaustive) of companies and researchers working on these technologies.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是六个在影响数字产品和服务未来方面特别值得关注的AI领域。我将描述它们是什么，为什么重要，它们的应用现状，并列出（绝非详尽）正在研究这些技术的公司和研究人员。
- en: '**![artificial-intelligence](../Images/fe5182fe4b645ad53ad3c5ab25b92b04.png)1\.
    Reinforcement learning (RL)**'
  id: totrans-15
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**![人工智能](../Images/fe5182fe4b645ad53ad3c5ab25b92b04.png)1\. 强化学习 (RL)**'
- en: RL is a paradigm for learning by trial-and-error inspired by the way humans
    learn new tasks. In a typical RL setup, an agent is tasked with observing its
    current state in a digital environment and taking actions that maximise accrual
    of a long-term reward it has been set. The agent receives feedback from the environment
    as a result of each action such that it knows whether the action promoted or hindered
    its progress. An RL agent must therefore balance the exploration of its environment
    to find optimal strategies of accruing reward with exploiting the best strategy
    it has found to achieve the desired goal. This approach was made popular by Google
    DeepMind in their work on [Atari games and Go](https://www.youtube.com/watch?v=Ih8EfvOzBOY).
    An example of RL working in the real world is the task of optimising energy efficiency
    for cooling Google data centers. Here, an RL system achieved a [40% reduction](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/)
    in cooling costs. An important native advantage of using RL agents in environments
    that can be simulated (e.g. video games) is that training data can be generated
    in troves and at very low cost. This is in stark contrast to supervised deep learning
    tasks that often require training data that is expensive and difficult to procure
    from the real world.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: RL 是一种通过试错学习新任务的范式，灵感来自于人类学习新任务的方式。在典型的RL设置中，代理被任务化为观察其在数字环境中的当前状态，并采取最大化长期奖励的行动。代理从环境中收到每个行动的反馈，以便知道该行动是促进还是阻碍了它的进展。因此，RL代理必须平衡对环境的探索，以找到获得奖励的最佳策略，同时利用其已发现的最佳策略来实现预期目标。这种方法在Google
    DeepMind关于[Atari游戏和围棋](https://www.youtube.com/watch?v=Ih8EfvOzBOY)的研究中变得流行。在现实世界中，RL的一个例子是优化Google数据中心的能效。在这里，RL系统实现了[40%的减少](https://deepmind.com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40%)。在可以模拟的环境（例如视频游戏）中使用RL代理的一个重要固有优势是可以以极低的成本生成大量训练数据。这与通常需要昂贵且难以从现实世界中获取的训练数据的监督深度学习任务形成了鲜明对比。
- en: '**Applications**: Multiple agents [learning in their own instance of an environment
    with a shared model](https://arxiv.org/abs/1602.01783) or by [interacting and
    learning from one another in the same environment](https://arxiv.org/abs/1605.06676),
    learning to [navigate 3D environments like mazes](https://arxiv.org/abs/1606.04671)
    or city streets for [autonomous driving](https://arxiv.org/abs/1610.03295), inverse
    reinforcement learning to recapitulate observed behaviours by learning the goal
    of a task (e.g. [learning to drive](https://arxiv.org/abs/1612.03653) or endowing
    non-player video game characters with human-like behaviours).'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：多个代理在[共享模型的环境实例中学习](https://arxiv.org/abs/1602.01783)或通过[在同一环境中互动和学习](https://arxiv.org/abs/1605.06676)，学习[在像迷宫这样的3D环境中导航](https://arxiv.org/abs/1606.04671)或城市街道以实现[自主驾驶](https://arxiv.org/abs/1610.03295)，逆向强化学习通过学习任务目标（例如[学习驾驶](https://arxiv.org/abs/1612.03653)）来重现观察到的行为，或者赋予非玩家视频游戏角色类似人类的行为。'
- en: '**Principal Researchers**: Pieter Abbeel (OpenAI), David Silver, Nando de Freitas,
    Raia Hadsell, Marc Bellemare (Google DeepMind), Carl Rasmussen (Cambridge), Rich
    Sutton (Alberta), John Shawe-Taylor (UCL) and [others](https://www.quora.com/Who-are-the-best-researchers-in-Deep-Learning-and-or-Reinforcement-Learning-who-mainly-work-in-a-university-not-in-the-industry).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要研究人员**：Pieter Abbeel（OpenAI），David Silver，Nando de Freitas，Raia Hadsell，Marc
    Bellemare（Google DeepMind），Carl Rasmussen（剑桥），Rich Sutton（阿尔伯塔），John Shawe-Taylor（UCL）及[其他](https://www.quora.com/Who-are-the-best-researchers-in-Deep-Learning-and-or-Reinforcement-Learning-who-mainly-work-in-a-university-not-in-the-industry)。'
- en: '**Companies**: Google DeepMind, Prowler.io, Osaro, MicroPSI, Maluuba/Microsoft,
    NVIDIA, Mobileye.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**：Google DeepMind，Prowler.io，Osaro，MicroPSI，Maluuba/Microsoft，NVIDIA，Mobileye。'
- en: '[2\. Generative models](https://openai.com/blog/generative-models/)'
  id: totrans-20
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '[2\. 生成模型](https://openai.com/blog/generative-models/)'
- en: 'In contrast to discriminative models that are used for classification or regression
    tasks, generative models learn a probability distribution over training examples.
    By sampling from this high-dimensional distribution, generative models output
    new examples that are similar to the training data. This means, for example, that
    a generative model trained on real images of faces can output new synthetic images
    of similar faces. For more details on how these models work, see Ian Goodfellow’s
    [awesome NIPS 2016 tutorial write up](https://arxiv.org/abs/1701.00160). The architecture
    he introduced, generative adversarial networks (GANs), are particularly hot right
    now in the research world because they [offer a path towards unsupervised learning](https://code.facebook.com/posts/1587249151575490/a-path-to-unsupervised-learning-through-adversarial-networks/).
    With GANs, there are two neural networks: a *generator*, which takes random noise
    as input and is tasked with synthesising content (e.g. an image), and a *discriminator*,
    which has learned what real images look like and is tasked with identifying whether
    images created by the generator are real or fake. Adversarial training can be
    thought of as a game where the generator must iteratively learn how to create
    images from noise such that the discriminator can no longer distinguish generated
    images from real ones. This framework is being extended to many data modalities
    and task.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 与用于分类或回归任务的判别模型相比，生成模型学习训练示例的概率分布。通过从这个高维分布中采样，生成模型输出的新示例与训练数据相似。例如，一个在真实面孔图像上训练的生成模型可以输出类似面孔的新合成图像。有关这些模型如何工作的更多细节，请参见Ian
    Goodfellow的[精彩NIPS 2016教程](https://arxiv.org/abs/1701.00160)。他介绍的架构，生成对抗网络（GANs），在研究界特别受关注，因为它们[提供了一条通向无监督学习的路径](https://code.facebook.com/posts/1587249151575490/a-path-to-unsupervised-learning-through-adversarial-networks/)。使用GANs时，有两个神经网络：一个*生成器*，以随机噪声作为输入，负责合成内容（例如图像），以及一个*判别器*，已学会真实图像的样子，负责识别生成器创建的图像是真实的还是伪造的。对抗训练可以被视为一种游戏，生成器必须迭代地学习如何从噪声中创建图像，以便判别器无法再区分生成的图像和真实图像。该框架正被扩展到许多数据模式和任务中。
- en: '**Applications**: Simulate possible futures of a time-series (e.g. for planning
    tasks in reinforcement learning);[super-resolution of images](https://arxiv.org/abs/1609.04802);
    recovering [3D structure from a 2D image](https://arxiv.org/abs/1607.00662); [generalising
    from small labeled datasets;](https://arxiv.org/abs/1406.5298) tasks where one
    input can yield multiple correct outputs (e.g. [predicting the next frame in a
    vide0](https://arxiv.org/abs/1511.06380); creating natural language in conversational
    interfaces (e.g. bots); [cryptography](https://arxiv.org/abs/1610.06918); semi-supervised
    learning when not all labels are available; [artistic style transfer](http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html);
    [synthesising music and voice](https://deepmind.com/blog/wavenet-generative-model-raw-audio/);
    image in-painting.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：模拟时间序列的可能未来（例如，用于强化学习中的任务规划）；[图像超分辨率](https://arxiv.org/abs/1609.04802)；从[2D图像恢复3D结构](https://arxiv.org/abs/1607.00662)；[从小型标记数据集中泛化](https://arxiv.org/abs/1406.5298)；一个输入可以产生多个正确输出的任务（例如，[预测视频中的下一帧](https://arxiv.org/abs/1511.06380)）；在对话接口中创建自然语言（例如，聊天机器人）；[密码学](https://arxiv.org/abs/1610.06918)；在标签不全时的半监督学习；[艺术风格迁移](http://dmlc.ml/mxnet/2016/06/20/end-to-end-neural-style.html)；[合成音乐和声音](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)；图像修复。'
- en: '**Companies**: Twitter Cortex, Adobe, Apple, Prisma, Jukedeck*, Creative.ai,
    Gluru*, Mapillary*, Unbabel.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**：Twitter Cortex，Adobe，Apple，Prisma，Jukedeck*，Creative.ai，Gluru*，Mapillary*，Unbabel。'
- en: '**Principal Researchers**: Ian Goodfellow (OpenAI), Yann LeCun and [Soumith
    Chintala](https://research.facebook.com/soumith-chintala) (Facebook AI Research),
    [Shakir Mohamed](http://shakirm.com/) and [Aäron van den Oord](https://twitter.com/avdnoord)
    (Google DeepMind), Alyosha Efros (Berkeley) and many[others](https://sites.google.com/site/nips2016adversarial/).'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要研究人员**：Ian Goodfellow（OpenAI），Yann LeCun 和 [Soumith Chintala](https://research.facebook.com/soumith-chintala)（Facebook
    AI Research），[Shakir Mohamed](http://shakirm.com/) 和 [Aäron van den Oord](https://twitter.com/avdnoord)（Google
    DeepMind），Alyosha Efros（伯克利）及其他[研究人员](https://sites.google.com/site/nips2016adversarial/)。'
- en: '![machine_learning](../Images/9d5f8d7a623362b0bd87dc4210b66be2.png)3\. Networks
    with memory'
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '![machine_learning](../Images/9d5f8d7a623362b0bd87dc4210b66be2.png)3\. 具有记忆的网络'
- en: In order for AI systems to generalise in diverse real-world environments just
    as we do, they must be able to continually learn new tasks and remember how to
    perform all of them into the future. However, traditional neural networks are
    typically incapable of such sequential task learning without forgetting. This
    shortcoming is termed *catastrophic forgetting.* It occurs because the weights
    in a network that are important to solve for task A are changed when the network
    is subsequently trained to solve for task B.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使 AI 系统能够像我们一样在多样化的现实环境中进行泛化，它们必须能够持续学习新任务并记住如何将所有任务执行到未来。然而，传统的神经网络通常无法在不遗忘的情况下进行这种顺序任务学习。这种缺陷被称为*灾难性遗忘*。它发生的原因是，当网络在之后被训练以解决任务
    B 时，解决任务 A 所需的重要权重发生了变化。
- en: There are, however, several powerful architectures that can endow neural networks
    with varying degrees of memory. These include [long-short term memory](https://en.wikipedia.org/wiki/Long_short-term_memory)
    networks (a recurrent neural network variant) that are capable of processing and
    predicting time series, DeepMind’s [differentiable neural computer](https://deepmind.com/blog/differentiable-neural-computers/)
    that combines neural networks and memory systems in order to learn from and navigate
    complex data structures on their own, the [*elastic weight consolidation*](https://arxiv.org/abs/1612.00796)
    algorithm that slows down learning on certain weights depending on how important
    they are to previously seen tasks, and[*progressive neural networks*](https://arxiv.org/abs/1606.04671)
    that learn lateral connections between task-specific models to extract useful
    features from previously learned networks for a new task.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，确实有几种强大的架构可以赋予神经网络不同程度的记忆。这些架构包括 [长短期记忆](https://en.wikipedia.org/wiki/Long_short-term_memory)
    网络（一种递归神经网络变体），它能够处理和预测时间序列；DeepMind 的 [可微神经计算机](https://deepmind.com/blog/differentiable-neural-computers/)，它结合了神经网络和记忆系统，以便从复杂的数据结构中自主学习和导航；[*弹性权重巩固*](https://arxiv.org/abs/1612.00796)
    算法，根据权重对先前任务的重要性来减缓特定权重的学习；以及[*渐进式神经网络*](https://arxiv.org/abs/1606.04671)，它学习任务特定模型之间的横向连接，从之前学习的网络中提取有用的特征以用于新任务。
- en: '**Applications**: Learning agents that can generalise to new environments;
    robotic arm control tasks; autonomous vehicles; time series prediction (e.g. financial
    markets, video, IoT); natural language understanding and next word prediction.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：能够泛化到新环境的学习代理；机器人臂控制任务；自动驾驶车辆；时间序列预测（例如金融市场、视频、物联网）；自然语言理解和下一个词预测。'
- en: '**Companies**: Google DeepMind, NNaisense (?), SwiftKey/Microsoft Research,
    Facebook AI Research.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**：Google DeepMind，NNaisense（？），SwiftKey/Microsoft Research，Facebook AI
    Research。'
- en: '**Principal Researchers**: Alex Graves, Raia Hadsell, Koray Kavukcuoglu (Google
    DeepMind), Jürgen Schmidhuber (IDSIA), Geoffrey Hinton (Google Brain/Toronto),
    James Weston, Sumit Chopra, Antoine Bordes (FAIR).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要研究人员**：Alex Graves，Raia Hadsell，Koray Kavukcuoglu（Google DeepMind），Jürgen
    Schmidhuber（IDSIA），Geoffrey Hinton（Google Brain/Toronto），James Weston，Sumit Chopra，Antoine
    Bordes（FAIR）。'
- en: 4\. Learning from less data and building smaller models
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4\. 从较少的数据中学习并构建更小的模型
- en: Deep learning models are notable for requiring enormous amounts of training
    data to reach state-of-the-art performance. For example, the [ImageNet Large Scale
    Visual Recognition Challenge](http://image-net.org/challenges/LSVRC/2016/) on
    which teams challenge their image recognition models, contains 1.2 million training
    images hand-labeled with 1000 object categories. Without large scale training
    data, deep learning models won’t converge on their optimal settings and won’t
    perform well on complex tasks such as speech recognition or machine translation.
    This data requirement only grows when a single neural network is used to solve
    a problem end-to-end; that is, taking raw audio recordings of speech as the input
    and outputting text transcriptions of the speech. This is in contrast to using
    multiple networks each providing intermediate representations (e.g. raw speech
    audio input → phonemes → words → text transcript output; or [raw pixels from a
    camera mapped directly to steering commands](https://arxiv.org/abs/1604.07316)).
    If we want AI systems to solve tasks where training data is particularly challenging,
    costly, sensitive, or time-consuming to procure, it’s important to develop models
    that can learn optimal solutions from less examples (i.e. one or zero-shot learning).
    When training on small data sets, challenges include overfitting, difficulties
    in handling outliers, differences in the data distribution between training and
    test. An alternative approach is to improve learning of a new task by transferring
    knowledge a machine learning model acquired from a previous task using processes
    collectively referred to as [*transfer learning*](http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型以需要大量训练数据才能达到最先进的性能而著称。例如，[ImageNet大规模视觉识别挑战赛](http://image-net.org/challenges/LSVRC/2016/)中，团队挑战其图像识别模型，包含120万张手动标记的训练图像，分为1000个物体类别。如果没有大规模的训练数据，深度学习模型将无法收敛到其最佳设置，也无法在语音识别或机器翻译等复杂任务中表现良好。这种数据需求在使用单一神经网络端到端解决问题时尤为突出；即，接受原始音频录音作为输入并输出语音的文本转录。这与使用多个网络每个提供中间表示（例如，原始语音音频输入→音素→单词→文本转录输出；或[从相机直接映射到转向命令的原始像素](https://arxiv.org/abs/1604.07316)）形成对比。如果我们希望人工智能系统解决那些训练数据特别具有挑战性、成本高昂、敏感或耗时的任务，那么开发能够从较少示例（即一-shot或零-shot学习）中学习最佳解决方案的模型是重要的。在小数据集上训练时，面临的挑战包括过拟合、处理异常值的困难、训练和测试数据分布之间的差异。另一种方法是通过转移知识来改善新任务的学习，这些知识是机器学习模型从先前任务中获得的，这些过程统称为[*迁移学习*](http://ftp.cs.wisc.edu/machine-learning/shavlik-group/torrey.handbook09.pdf)。
- en: A related problem is building smaller deep learning architectures with state-of-the-art
    performance using a similar number or significantly less parameters. [Advantages
    would include](https://arxiv.org/abs/1602.07360) more efficient distributed training
    because data needs to be communicated between servers, less bandwidth to export
    a new model from the cloud to an edge device, and improved feasibility in deploying
    to hardware with limited memory.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一个相关的问题是使用类似数量或显著更少的参数构建具有最先进性能的更小深度学习架构。[优势包括](https://arxiv.org/abs/1602.07360)更高效的分布式训练，因为数据需要在服务器之间传输，减少将新模型从云端导出到边缘设备的带宽，并提高在内存有限的硬件上部署的可行性。
- en: '**Applications**: Training shallow networks by learning to [mimic the performance
    of deep networks](https://arxiv.org/abs/1312.6184) originally trained on large
    labeled training data; architectures with fewer parameters but equivalent performance
    to deep models (e.g. [SqueezeNet](https://arxiv.org/abs/1602.07360)); [machine
    translation](https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html).'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：通过学习[模仿深度网络的表现](https://arxiv.org/abs/1312.6184)来训练浅层网络，这些深度网络最初是在大量标记数据上训练的；具有更少参数但性能等同于深度模型的架构（例如，[SqueezeNet](https://arxiv.org/abs/1602.07360)）；[机器翻译](https://research.googleblog.com/2016/11/zero-shot-translation-with-googles.html)。'
- en: '**Companies**: Geometric Intelligence/Uber, DeepScale.ai, Microsoft Research,
    Curious AI Company, Google, Bloomsbury AI.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**：Geometric Intelligence/Uber、DeepScale.ai、微软研究院、Curious AI Company、谷歌、Bloomsbury
    AI。'
- en: '**Principal Researchers**: Zoubin Ghahramani (Cambridge), Yoshua Bengio (Montreal),
    Josh Tenenbaum (MIT), Brendan Lake (NYU), Oriol Vinyals (Google DeepMind), Sebastian
    Riedel (UCL).'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要研究人员**：Zoubin Ghahramani（剑桥）、Yoshua Bengio（蒙特利尔）、Josh Tenenbaum（麻省理工学院）、Brendan
    Lake（纽约大学）、Oriol Vinyals（谷歌DeepMind）、Sebastian Riedel（伦敦大学学院）。'
- en: 5\. Hardware for training and inference
  id: totrans-37
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5\. 用于训练和推理的硬件
- en: A major catalyst for progress in AI is the repurposing of graphics processing
    units (GPUs) for training large neural network models. Unlike central processing
    unit (CPUs) that compute in a sequential fashion, GPUs offer a [massively parallel
    architecture](http://www.nvidia.com/object/what-is-gpu-computing.html) that can
    handle multiple tasks concurrently. Given that neural networks must process enormous
    amounts of (often high dimensional data), training on GPUs is much faster than
    with CPUs. This is why GPUs have veritably become the shovels to the gold rush
    ever since the [publication of AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
    in 2012 — the first neural network implemented on a GPU. NVIDIA continues to lead
    the charge into 2017, ahead of Intel, Qualcomm, AMD and more recently Google.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: AI 进步的一个主要催化剂是将图形处理单元（GPU）重新用于训练大型神经网络模型。与以顺序方式计算的中央处理单元（CPU）不同，GPU 提供了一个[大规模并行架构](http://www.nvidia.com/object/what-is-gpu-computing.html)，可以同时处理多个任务。鉴于神经网络必须处理大量（通常是高维）数据，在
    GPU 上训练比在 CPU 上要快得多。这就是为什么自从 [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)
    2012 年发布以来，GPU 实质上成为了淘金热中的铲子——第一个在 GPU 上实现的神经网络。NVIDIA 继续领先于 Intel、Qualcomm、AMD
    和最近的 Google。
- en: 'However, GPUs were not purpose-built for training or inference; they were created
    to render graphics for video games. GPUs have high computational precision that
    is not always needed and suffer memory bandwidth and data throughput issues. This
    has opened the playing field for a new breed of startups and projects within large
    companies like Google to design and produce silicon specifically for high dimensional
    machine learning applications. [Improvements promised by new chip designs](https://www.graphcore.ai/blog/5-reasons-why-we-need-new-machine-learning-hardware)
    include larger memory bandwidth, computation on graphs instead of vectors (GPUs)
    or scalars (CPUs), higher compute density, efficiency and performance per Watt.
    This is exciting because of the clear accelerating returns AI systems deliver
    to their owners and users: Faster and more efficient model training → better user
    experience → user engages with the product more → creates larger data set → improves
    model performance through optimisation. Thus, those who are able to train faster
    and deploy AI models that are computationally and energy efficient are at a significant
    advantage.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，GPU 并不是专门为训练或推断而设计的；它们是为了渲染视频游戏图形而创建的。GPU 拥有高计算精度，但这并不总是必要，并且存在内存带宽和数据吞吐量问题。这为新兴初创企业和大型公司如
    Google 内部的新项目提供了机会，以专门为高维机器学习应用设计和生产硅片。[新芯片设计承诺的改进](https://www.graphcore.ai/blog/5-reasons-why-we-need-new-machine-learning-hardware)包括更大的内存带宽、在图形而非向量（GPU）或标量（CPU）上进行计算、更高的计算密度、每瓦特效率和性能。这令人兴奋，因为
    AI 系统为其所有者和用户提供了明显的加速回报：更快、更高效的模型训练 → 更好的用户体验 → 用户更多地与产品互动 → 生成更大的数据集 → 通过优化提高模型性能。因此，那些能够更快训练和部署计算及能源高效
    AI 模型的人将占据显著优势。
- en: '**Applications**: Faster training of models (especially on graphs); energy
    and data efficiency when making predictions; running AI systems at the edge (IoT
    devices); always-listening IoT devices; cloud infrastructure as a service; autonomous
    vehicles, drones and robotics.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**: 更快的模型训练（尤其是在图形上）；预测时的能源和数据效率；边缘（IoT 设备）上运行 AI 系统；始终监听的 IoT 设备；云基础设施即服务；自动驾驶汽车、无人机和机器人。'
- en: '**Companies**: Graphcore, [Cerebras](http://cerebras.net/), Isocline Engineering,
    Google (TPU), NVIDIA (DGX-1), Nervana Systems (Intel), Movidius (Intel), Scortex'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**: Graphcore，[Cerebras](http://cerebras.net/)、Isocline Engineering、Google（TPU）、NVIDIA（DGX-1）、Nervana
    Systems（Intel）、Movidius（Intel）、Scortex'
- en: '**Principal Researchers**: ?'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**主要研究人员**: ？'
- en: 6\. Simulation environments
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6\. 仿真环境
- en: As discussed earlier, generating training data for AI systems is often challenging.
    What’s more, AI’s must generalise to many situations if they’re to be useful to
    us in the real world. As such, developing digital environments that simulate the
    physics and behaviour of the real world will provide us with test beds to measure
    and train an AI’s general intelligence. These environments present raw pixels
    to an AI, which then take actions in order to solve for the goals they have been
    set (or learned). Training in [these simulation environments](https://en.wikipedia.org/wiki/List_of_computer_simulation_software)
    can help us [understand how AI systems learn](http://www.ee.ic.ac.uk/gelenbe/index_files/Intellisim.pdf),
    how to improve them, but also provide us with models that can potentially transfer
    to real-world applications.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，为AI系统生成训练数据通常具有挑战性。此外，AI必须能够在多种情况下进行泛化，才能在现实世界中对我们有用。因此，开发能够模拟现实世界物理和行为的数字环境将为我们提供测试平台，以衡量和训练AI的通用智能。这些环境向AI展示原始像素，然后AI采取行动以实现设定（或学习）的目标。在[这些模拟环境](https://en.wikipedia.org/wiki/List_of_computer_simulation_software)中进行训练可以帮助我们[理解AI系统如何学习](http://www.ee.ic.ac.uk/gelenbe/index_files/Intellisim.pdf)，如何改进它们，还可以为我们提供可以潜在转移到现实世界应用的模型。
- en: '**Applications**: [Learning to drive](https://openai.com/blog/GTA-V-plus-Universe/);
    manufacturing; industrial design; game development; smart cities.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用**：[学习驾驶](https://openai.com/blog/GTA-V-plus-Universe/)；制造业；工业设计；游戏开发；智能城市。'
- en: '**Companies**: Improbable, Unity 3D, Microsoft (Minecraft), Google DeepMind/Blizzard,
    OpenAI, Comma.ai, Unreal Engine, Amazon Lumberyard'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**公司**：Improbable、Unity 3D、微软（Minecraft）、谷歌DeepMind/暴雪、OpenAI、Comma.ai、虚幻引擎、亚马逊Lumberyard'
- en: '**Researchers**: [Andrea Vedaldi](http://www.robots.ox.ac.uk/~vgg/research/researchdoom/)
    (Oxford)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究员**：[安德烈亚·维达尔迪](http://www.robots.ox.ac.uk/~vgg/research/researchdoom/)（牛津）'
- en: '[Original post](https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa).
    Reposted with permission.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[原创帖子](https://medium.com/@NathanBenaich/6-areas-of-artificial-intelligence-to-watch-closely-673d590aa8aa)。经许可转载。'
- en: '**Bio: [Nathan Benaich](https://medium.com/@NathanBenaich)** Invests in tech
    companies [@PlayfairCapital](https://twitter.com/PlayfairCapital). All things
    data, machine intelligence, user experiences. Former cancer researcher, photographer,
    perpetual foodie.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[内森·贝奈奇](https://medium.com/@NathanBenaich)** 投资于科技公司[@PlayfairCapital](https://twitter.com/PlayfairCapital)。涉及数据、机器智能、用户体验。前癌症研究员、摄影师、永恒的美食爱好者。'
- en: '**Related:**'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Continuous improvement for IoT through AI / Continuous learning](/2016/11/continuous-improvement-iot-ai-learning.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过AI/持续学习实现物联网的持续改进](/2016/11/continuous-improvement-iot-ai-learning.html)'
- en: '[Reinforcement Learning and the Internet of Things](/2016/08/reinforcement-learning-internet-things.html)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[强化学习与物联网](/2016/08/reinforcement-learning-internet-things.html)'
- en: '[Chatbots on Steroids: 10 Key Machine Learning Capabilities to Fuel Your Chatbot](/2017/01/chatbots-steroids-10-key-machine-learning-capabilities.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[增强版聊天机器人：推动聊天机器人的10项关键机器学习能力](/2017/01/chatbots-steroids-10-key-machine-learning-capabilities.html)'
- en: More On This Topic
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多
- en: '[5 Key Skills Needed To Become a Great Data Scientist](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成为出色数据科学家所需的5项关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)'
- en: '[6 Predictive Models Every Beginner Data Scientist Should Master](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个初学者数据科学家应该掌握的6种预测模型](https://www.kdnuggets.com/2021/12/6-predictive-models-every-beginner-data-scientist-master.html)'
- en: '[The Best ETL Tools in 2021](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2021年最佳ETL工具](https://www.kdnuggets.com/2021/12/mozart-best-etl-tools-2021.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并找到目标去…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
