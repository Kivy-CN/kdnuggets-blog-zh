- en: Computer Vision in Agriculture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/09/computer-vision-agriculture.html](https://www.kdnuggets.com/2021/09/computer-vision-agriculture.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Deep-Learning-in-the-Field.jpg](../Images/b346e8c53cfd9a026cfb49fb3d6fd630.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Deep Learning in the Field: Modern Computer Vision for Agriculture'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In today’s fast-paced world of city living and stressful work-life imbalances,
    especially on the (hopefully) tail-end of a year of pandemic quarantine measures,
    many young workers are yearning to get closer to nature and family. In the face
    of re-emerging commutes and the push-and-pull of back-to-the-office versus hybrid
    or fully-remote working, many young robots would rather ditch the status quo and
    return to the countryside to scratch a living from the land like their ancestors
    before them. And they’ll bring lasers, too.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, we’re not talking about the weary office drones being herded back
    to the office after a year of blissfully working at home, but of robots armed
    with deep learning computer vision systems and precision actuators for a new breed
    of farming automation. This new breed of automated agriculture promises to decrease
    inputs and the side-effects of modern agriculture, while helping farmers deal
    with everything from labor shortages to climate change.
  prefs: []
  type: TYPE_NORMAL
- en: '[Deep learning](https://www.exxactcorp.com/blog/Deep-Learning) isn’t just for
    placing ads or identifying cats anymore. Instead, a slew of young startups have
    started to incorporate the advances in computer vision made possible through larger
    and larger neural networks to real working robots in the fields.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For most of these nascent businesses, the initial product offering is similar:
    get rid of those pesky weeds (and those pesky human weeders). The weapon of choice
    may differ substantially between each robot, ranging from lasers to herbicide
    applicators, mechanical disruption or even fire, but the computer vision advances
    that make it possible are all of a lineage inheriting from modern machine learning
    and deep convolutional networks. Removing weeds may make a natural minimum viable
    product to showcase intelligent automation in agriculture, but it’s not the only
    game in town.'
  prefs: []
  type: TYPE_NORMAL
- en: Other projects are working on everything from harvesting delicate fruits to
    fully automated luxury greenhouses.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Fitting Solution to the Problem of Tractor Vision: Convolutional Neural Networks'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The key component of most of the agro-robotic systems described in this article
    is computer vision. Built on top of the deep learning frameworks and convolutional
    neural networks we’ve grown to know over the past decade, these models can handle
    classification, localization, and both semantic and instance segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: Old hands of deep learning can skip this next part, which will outline some
    of the characteristics of convolutional neural networks that make modern computer
    vision so effective.
  prefs: []
  type: TYPE_NORMAL
- en: Convolutional neural networks (CNNs) are built out of multiple convolutional
    layers, and convolution is an operation where a sliding window of weights is multiplied
    with an input matrix, the sum of the product of this multiplication at each point
    is the output of the convolution.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/c0ef57883df54939bbebfb35376d10fb.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Convolutional layers apply weights in a sliding window across an input matrix
    such as an image. Diagram in the public domain, *[*source.*](https://rivesunder.github.io/public_domain/2021/07/25/public_domain.html)'
  prefs: []
  type: TYPE_NORMAL
- en: A key characteristic of convolution, and what makes it an ideal component of
    vision systems, is the translation invariance (or equivariance more precisely)
    of the position of the inputs. Due to the sliding window (called a kernel in neural
    networks), it doesn’t matter if a tomato appears on the left center or the right
    bottom corner, the result of convolution at that position will be the same. Rotational
    invariance is another story, and something that convolutional models in general
    don’t possess. But this is unlikely to be a major issue for tractors taking a
    top-down view of crops and weeds, thanks to plenty of training data and the radial
    symmetry of many plants viewed from above.
  prefs: []
  type: TYPE_NORMAL
- en: Another appealing aspect of convolutional neural networks as vision systems
    is the close analogy to animal vision systems. The successive application of convolutional
    kernels in a deep convolutional network is reminiscent of the bundles of neurons
    in the retina (and further along the visual system) that activate together in
    response to stimuli following a specific pattern. These are called[ receptive
    fields](https://en.wikipedia.org/wiki/Receptive_field), and they closely resemble
    the edges, points, circles, and more abstracted features learned by convolutional
    kernels given a simple training objective.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/744a3ef231dc8d397e9377e64a697fbf.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Convolution has the valuable characteristic of being robust to objects appearing
    in different parts of an image; a tomato in the top left of an image is recognized
    the same as a tomato in the bottom right corner. Diagram in the public domain, *[*source.*](https://rivesunder.github.io/public_domain/2021/07/25/public_domain.html)'
  prefs: []
  type: TYPE_NORMAL
- en: Who's Working on the Agriculture Automation Problem?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are quite a few startups simultaneously pursuing the idea of enhanced
    agricultural automation augmented by deep learning. For many of them, the first
    product is something along the lines of an autonomous weeding tractor (or semi-autonomous
    tractor attachment) with a convolutional neural network vision system. Another
    popular approach is applied vision-guided automation to indoor gardening at a
    massive scale, at the extreme end this looks like a robot as large as an entire
    greenhouse.
  prefs: []
  type: TYPE_NORMAL
- en: We'll mostly focus on the case for robotic weeding and only make a brief mention
    of other applications being developed at the end.
  prefs: []
  type: TYPE_NORMAL
- en: '**Semi-Autonomous: The Pull-Behinds**'
  prefs: []
  type: TYPE_NORMAL
- en: There’s a midpoint between manually operating farm equipment with a human pilot
    at the helm, and arming 5 tons of agricultural industrial equipment with autonomous
    brains and 150-Watt lasers, and a few companies have chosen to take this route
    initially. What this looks like in the field is an attachment for a conventional
    tractor, equipped with camera sensors, actuators, and analysis software, that
    still relies on a human driver and supervisor.
  prefs: []
  type: TYPE_NORMAL
- en: This is the approach of Swiss company Ecorobotix’s[ Ara mounted sprayer](https://www.ecorobotix.com/en/ara_mounted_sprayer/).
    Ara uses computer vision to guide the application of herbicides, fungicides, or
    insecticides to plants targeted by the on-board cameras, and the company claims
    this can reduce pesticide inputs by 95%. This is also the approach taken by[ Blue
    River Technology](https://bluerivertechnology.com/ourmethods/), based in California,
    when they developed their[ “See & Spray” technology](https://www.youtube.com/watch?v=XH-EFtTa6IU).
    The company claim for “See & Spray” is an average of a 77% reduction in herbicide
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: One of the major incentives for targeted spraying of weeds, rather than spraying
    the whole field evenly (broadcast spraying) is that weeds and other plants can
    develop resistance to various pesticides over time. That leads to an increased
    tolerance for herbicide sprays like glyphosate (aka “RoundUp”) thanks to the selective
    pressure of being heavily exposed season after season.
  prefs: []
  type: TYPE_NORMAL
- en: This is a little like antibiotic resistance, which occurs rapidly after a new
    antibiotic enters use. Resistance to penicillin, the first modern antibiotic was[ noticed
    at least as early as 1940](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5369031/),
    concurrently with its development and before widespread use in human patients.
    In fact, glyphosate resistance was developed by directed evolution experiments[ long
    before](https://www.semanticscholar.org/paper/Selection-of-Glyphosate-Tolerant-Tobacco-Calli-and-Singer-McDaniel/6f19cf8f6dcf8fdaff540059a783bbc407608474) the
    famous “RoundUp Ready” transgenic crops were developed for market in the 1990s,
    so weeds developing resistance in response to increasing selective pressure is
    not surprising.
  prefs: []
  type: TYPE_NORMAL
- en: The primary advantage of targeted versus broadcast spraying is a decrease in
    this selective pressure on the field as a whole, complemented by a decrease in
    cost associated with lower inputs. It is only a partial solution however, and
    there are additional advantages to doing away with a chemical weeding solution
    entirely, if possible. Normally this might mean aggressive mechanical tilling
    or manual weeding requiring additional (and slow) human labor, but the startups
    in the next section are working on a cadre of robotic alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: '**Fully Autonomous Weeding Robots**'
  prefs: []
  type: TYPE_NORMAL
- en: '![laser-weeding.png](../Images/7c1ae2316065260a26e9f89b4b660ca9.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Autonomous weeding robots, [Source](https://youtu.be/0QzevFlKrkc)*'
  prefs: []
  type: TYPE_NORMAL
- en: The solutions described in this section take weeding automation one step further,
    from targeted to precision weeding. These autonomous agricultural robots range
    in size from a few hundred pounds to nearly 5 tons or more!
  prefs: []
  type: TYPE_NORMAL
- en: 'Each solution differs in the details, most noticeably in the choice of weeding
    implement, which range from lasers, mechanical disruption, herbicide, or even
    electric current. There are also many similarities: most of these robots use a
    deep learning computer vision solution to target weeds and leave crop plants alone,
    bringing a weeding implement to bear on their target with physical actuators or
    optical targeting.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Carbon robotics](https://carbonrobotics.com/) is an imposing example of a
    company tackling the autonomous weeding problem. That’s not least of all because
    of the imposing weeding platform they’ve developed: nearly five tons of laser-wielding
    heavy machinery, it uses a combination of cameras, GPS, and lidar sensors to operate
    in large fields. The makers claim that their robot reduces the need for herbicides
    and labor, reduces costs, and doesn’t disrupt the soil. On top of those advantages,
    the robotic method is certified for use on fully organic farms.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Carbon Robotics’ Deep Learning, Laser-Wielding, Farmbot'
  prefs: []
  type: TYPE_NORMAL
- en: 9,500 lb automated weed killing platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 12 cameras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Machine learning vision system powered by NVIDIA.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8 150W CO2 lasers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Front and rear drive cameras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPS navigation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lidar
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Organic
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'The [Small Robot Company](https://www.smallrobotcompany.com/) is a nascent
    company developing agrotech in Great Britain, and their robots offer a lightweight
    solution to field monitoring and weed management. They’ve split the functionality
    of their robotics out into three separate entities: Tom, which is a mobile sensor
    platform that handles field monitoring; Dick, a robotic weeding robot armed with
    a powerful electric shock; and Wilma, the suite of machine learning and analysis
    tools that orchestrates the endeavor. A third robot, Harry, is also in the works.
    Much like other robotic weeders in this article, the weeding robot Dick uses deep
    convolutional networks to target weeds in the midst of desirable crops. Unlike
    the others, it applies an electric current to weeds to burn out the core of unwanted
    plants.'
  prefs: []
  type: TYPE_NORMAL
- en: You’ll remember [Ecorobotix](https://www.ecorobotix.com/en/) from the description
    of their “Ara” mounted sprayer in the pull-behind section. They’ve also developed
    a standalone robot,[ Avo](https://www.ecorobotix.com/en/avo-autonomous-robot-weeder/),
    for fully autonomous operation. They cite the same 95% reduction in herbicide
    use as the Ara, and a cost savings of 50%. In addition to the vision system the
    Avo uses GPS, lidar, and ultrasound for navigation and obstacle detection. Compared
    to larger tractors, Avo weighs in at 750 kg and promises reduced soil compaction
    during operation.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the companies developed automated farm services offer robotic-tractors-as-a-service
    instead of selling or leasing the capital equipment directly. Businesses taking
    this approach include[ Farmwise](https://www.farmwise.io/services), which is trialing
    services with a massive automated weeding tractor in parts of California.
  prefs: []
  type: TYPE_NORMAL
- en: Robotic Greenhouses, Automated Mules, and Picker Robots
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another category of "agtech" currently experiencing a boom in interest is advanced
    greenhouse automation. Using a combination of sensory modalities including vision,
    soil moisture, temperature and humidity, these greenhouses can record vast troves
    of data and alert their operators when action is needed. Companies pursuing this
    automated greenhouse approach to agtech include[ Iron Ox](https://ironox.com/) and[ iUNU](https://iunu.com/).
    Of those two, iUNU seems to take a more ad-hoc approach to add automation and
    analytics to existing greenhouse systems, while Iron Ox’s website features a sleek
    medical-white machine that wouldn’t look out of place in a hospital or an animated
    film.
  prefs: []
  type: TYPE_NORMAL
- en: Another application area is automation for carting produce and plants from one
    area to another.[ Harvest Automation](https://www.public.harvestai.com/) offers
    the HV-100, a medium sized robot that is to the plant nursery what a warehouse
    robot is to a distribution center.[ Burro.ai](https://burro.ai/) offers a workhorse
    self-driving cart that works alongside human laborers to bring hand-picked produce
    from the field to nearby processing centers. Think of the eponymous Burro robot
    as a heavy-duty wheelbarrow that sports full self-driving capabilities, except
    unlike certain automobiles offering the feature this machine can and does operate
    without a human at the wheel.
  prefs: []
  type: TYPE_NORMAL
- en: Taking up the burden of transporting picked produce autonomously is a useful
    feature, but what about the actual harvest?[ Tevel](https://www.tevel-tech.com/) and[ Abundant
    Robotics](https://www.abundantrobotics.com/) are two early-stage companies working
    on robots for picking fruits. They’re both focusing on harvesting in orchards
    at first, but their approach couldn’t look more different. Tevel is developing
    a swarm of flying drones to zip through the rows of an orchard grabbing fruit
    with a forward facing gripper, while Abundant has built something that looks a
    little like a giant mechanical caterpillar, vacuuming up apples as it trundles
    through the rows. By all appearances it is a very hungry caterpillar. The one
    thing they undoubtedly have in common, though, is the use of deep convolutional
    neural networks to power the vision systems that allow them to zero in on their
    targets.
  prefs: []
  type: TYPE_NORMAL
- en: '![robot-picker.png](../Images/6881cba3e93c22ee525c718cb64c6da9.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Automated robots picking product, [Source](https://youtu.be/aijzVv6UeLQ)*'
  prefs: []
  type: TYPE_NORMAL
- en: Why Computer Vision Agriculture Innovations?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The plethora of early stage startups might lead one to believe that the idea
    of using autonomous robots for weeding and other labor-intensive (yet delicate)
    tasks in agriculture is a new idea. In fact it’s been more of a slow creep (followed
    by a mad rush) and there have been very similar projects building autonomous robots
    for the farm over a decade ago. Over 14 years ago in 2007 the “Hortibot” garnered
    mainstream,[ albeit not particularly reputable](https://www.theregister.com/2007/07/05/the_robo_peasantry_r_revolting/),
    news coverage for its inventors from Aarhus University. The Hortibot was an automated
    tractor, mainly for targeted spraying of herbicide for weed control.
  prefs: []
  type: TYPE_NORMAL
- en: Practically, its objective was a close cousin to the deep learning powered weeding
    robots described in this article. While it seems to be the case that nothing much
    remains of the Hortibot project (and the old website is a strange melange of defunct
    Danish spam), it was at least a realistic enough prospect to be covered again
    in a 2012[ New Scientist](https://archive.is/TdQ0Y) article on farming robots,
    mostly academic projects unlikely to scale to working agriculture.
  prefs: []
  type: TYPE_NORMAL
- en: Robotics projects like these are always on an ebb and flow as brittle implementations
    bump up against messy reality, and one might be tempted to conclude that this
    batch of eager farm startups will be no different than agro-robotics projects
    of the past. However, as Kevin Dunlap writes for[ Venture Beat](https://venturebeat.com/2021/07/17/farming-is-finally-ready-for-robots/),
    venture capitalists invested 60% more money into agricultural technology startups
    in 2020 as in the previous year, and nearly 20 times as much as in 2010\. Time
    will tell if these investments are as smart as the robots they are investing in.
  prefs: []
  type: TYPE_NORMAL
- en: Increasing farm automation set a trend of a slow and steady march over the past
    two decades, and the SARS-CoV-2 pandemic accelerated the pre-existing development
    of ag-tech as it did for so many other trends. Labor and supply chain disruptions
    associated with the virus[ might encourage farmers to reconsider](https://pitchbook.com/news/reports/q4-2020-emerging-tech-research-agtech) technological
    solutions that might have previously been too uncertain, too risky, or otherwise
    just not worth it.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Kevin Vu](https://www.kdnuggets.com/author/kevin-vu)** manages Exxact
    Corp blog and works with many of its talented authors who write about different
    aspects of Deep Learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://www.exxactcorp.com/blog/Deep-Learning/computer-vision-in-agriculture).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[3 Data Acquisition, Annotation, and Augmentation Tools](/2021/08/3-data-labeling-synthesizing-augmentation-tools.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Open Source Datasets for Computer Vision](/2021/08/open-source-datasets-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Extraction of Objects In Images and Videos Using 5 Lines of Code](/2021/03/extraction-objects-images-videos-5-lines-code.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[TensorFlow for Computer Vision - Transfer Learning Made Easy](https://www.kdnuggets.com/2022/01/tensorflow-computer-vision-transfer-learning-made-easy.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Discover the World of Computer Vision: Introducing MLM''s Latest…](https://www.kdnuggets.com/2024/01/mlm-discover-the-world-of-computer-vision-ebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Applications of Computer Vision](https://www.kdnuggets.com/2022/03/5-applications-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[KDnuggets News March 9, 2022: Build a Machine Learning Web App in 5…](https://www.kdnuggets.com/2022/n10.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DINOv2: Self-Supervised Computer Vision Models by Meta AI](https://www.kdnuggets.com/2023/05/dinov2-selfsupervised-computer-vision-models-meta-ai.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
