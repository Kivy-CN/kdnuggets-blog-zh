- en: Fast Gradient Boosting with CatBoost
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: In gradient boosting, predictions are made from an ensemble of weak learners.
    Unlike a random forest that creates a decision tree for each sample, in gradient
    boosting, trees are created one after the other. Previous trees in the model are
    not altered. Results from the previous tree are used to improve the next one.
    In this piece, we’ll take a closer look at a gradient boosting library called
    CatBoost.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: '[CatBoost](https://github.com/catboost) is a depth-wise gradient boosting library
    developed by [Yandex](https://yandex.com/company/). It uses oblivious decision
    trees to grow a balanced tree. The same features are used to make left and right
    splits for each level of the tree.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/22cec580000a5a651f8a7b907b81bca5.png)'
  prefs: []
  type: TYPE_IMG
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  prefs: []
  type: TYPE_NORMAL
- en: As compared to classic trees, the oblivious trees are more efficient to implement
    on CPU and are simple to fit.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with Categorical Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The common ways of handling categorical in machine learning are one-hot encoding
    and label encoding. CatBoost allows you to use categorical features without the
    need to pre-process them.
  prefs: []
  type: TYPE_NORMAL
- en: When using CatBoost, we shouldn’t use one-hot encoding, as this will affect
    the training speed, as well as the quality of predictions. Instead, we simply
    specify the categorical features using the `cat_features` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of using CatBoost
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here are a few reasons to consider using CatBoost:'
  prefs: []
  type: TYPE_NORMAL
- en: CatBoost allows for training of data on several GPUs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides great results with default parameters, hence reducing the time needed
    for parameter tuning.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Offers improved accuracy due to reduced overfitting.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use of CatBoost’s model applier for fast prediction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trained CatBoost models can be exported to Core ML for on-device inference (iOS).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can handle missing values internally.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can be used for regression and classification problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training Parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s look at the common parameters in CatBoost:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loss_function` alias as `objective` — Metric used for training. These are
    regression metrics such as root mean squared error for regression and logloss
    for classification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eval_metric` — Metric used for detecting overfitting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iterations` — The maximum number of trees to be built, defaults to 1000\.
    It aliases are `num_boost_round`, `n_estimators`, and `num_trees`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`learning_rate` alias `eta` — The learning rate that determines how fast or
    slow the model will learn. The default is usually 0.03.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`random_seed` alias `random_state` — The random seed used for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`l2_leaf_reg` alias `reg_lambda` — Coefficient at the L2 regularization term
    of the cost function. The default is 3.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bootstrap_type` — Determines the sampling method for the weights of the objects,
    e.g Bayesian, Bernoulli, MVS, and Poisson.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`depth` —The depth of the tree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grow_policy` — Determines how the greedy search algorithm will be applied.
    It can be either `SymmetricTree`, `Depthwise`, or `Lossguide`. `SymmetricTree` is
    the default. In `SymmetricTree`, the tree is built level-by-level until the depth
    is attained. In every step, leaves from the previous tree are split with the same
    condition. When `Depthwise` is chosen, a tree is built step-by-step until the
    specified depth is achieved. On each step, all non-terminal leaves from the last
    tree level are split. The leaves are split using the condition that leads to the
    best loss improvement. In `Lossguide`, the tree is built leaf-by-leaf until the
    specified number of leaves is attained. On each step, the non-terminal leaf with
    the best loss improvement is split'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_data_in_leaf` alias `min_child_samples` — This is the minimum number of
    training samples in a leaf. This parameter is only used with the `Lossguide` and `Depthwise` growing
    policies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`max_leaves` alias `num_leaves` — This parameter is used only with the `Lossguide` policy
    and determines the number of leaves in the tree.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ignored_features` — Indicates the features that should be ignored in the training
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nan_mode` — The method for dealing with missing values. The options are `Forbidden`, `Min`,
    and `Max`. The default is `Min`. When `Forbidden` is used, the presence of missing
    values leads to errors. With `Min`, the missing values are taken as the minimum
    values for that feature. In `Max`, the missing values are treated as the maximum
    value for the feature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`leaf_estimation_method` — The method used to calculate values in leaves. In
    classification, 10 `Newton` iterations are used. Regression problems using quantile
    or MAE loss use one `Exact` iteration. Multi classification uses one `Netwon` iteration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`leaf_estimation_backtracking` — The type of backtracking to be used during
    gradient descent. The default is `AnyImprovement`. `AnyImprovement` decreases
    the descent step, up to where the loss function value is smaller than it was in
    the last iteration. `Armijo` reduces the descent step until the [Armijo condition](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature) is
    met.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boosting_type` — The boosting scheme. It can be `plain` for the classic gradient
    boosting scheme, or `ordered`, which offers better quality on smaller datasets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`score_function` — The [score type](https://catboost.ai/docs/concepts/algorithm-score-functions.html) used
    to select the next split during tree construction. `Cosine` is the default option.
    The other available options are `L2`, `NewtonL2`, and `NewtonCosine`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`early_stopping_rounds` — When `True`, sets the overfitting detector type to `Iter` and
    stops the training when the optimal metric is achieved.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`classes_count` — The number of classes for multi-classification problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`task_type` — Whether you are using a CPU or GPU. CPU is the default.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`devices` — The IDs of the GPU devices to be used for training.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cat_features` — The array with the categorical columns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`text_features` —Used to declare text columns in classification problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression Example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CatBoost uses the scikit-learn standard in its implementation. Let’s see how
    we can use it for regression.
  prefs: []
  type: TYPE_NORMAL
- en: The first step — as always — is to import the regressor and instantiate it.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'When fitting the model, CatBoost also enables use to visualize it by setting `plot=true`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It also allows you to perform cross-validation and visualize the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, you can also perform grid search and visualize it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Image for post](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)'
  prefs: []
  type: TYPE_IMG
- en: We can also use CatBoost to plot a tree. Here’s the plot is for the first tree.
    As you can see from the tree, the leaves on every level are being split on the
    same condition—e.g 297, value >0.5.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/1bf072864f605a5db714f0a388c18dd4.png)'
  prefs: []
  type: TYPE_IMG
- en: CatBoost also gives us a dictionary with all the model parameters. We can print
    them by iterating through the dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Image for post](../Images/33f889fb3e9caa39f98841f2938006c5.png)'
  prefs: []
  type: TYPE_IMG
- en: Final Thoughts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this piece, we’ve explored the benefits and limitations of CatBoost, along
    with its primary training parameters. Then, we worked through a simple regression
    implementation with scikit-learn. Hopefully this gives you enough information
    on the library so that you can explore it further.
  prefs: []
  type: TYPE_NORMAL
- en: '[**CatBoost - state-of-the-art open-source gradient boosting library with categorical
    features support**](https://catboost.ai/)'
  prefs: []
  type: TYPE_NORMAL
- en: CatBoost is an algorithm for gradient boosting on decision trees. It is developed
    by Yandex researchers and engineers...
  prefs: []
  type: TYPE_NORMAL
- en: '[**The Data Science Bootcamp in Python**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)'
  prefs: []
  type: TYPE_NORMAL
- en: Learn Python for Data Science,NumPy,Pandas,Matplotlib,Seaborn,Scikit-learn,
    Dask,LightGBM,XGBoost,CatBoost and much...
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[LightGBM: A Highly-Efficient Gradient Boosting Decision Tree](/2020/06/lightgbm-gradient-boosting-decision-tree.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Understanding Gradient Boosting Machines](/2019/02/understanding-gradient-boosting-machines.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Mastering Fast Gradient Boosting on Google Colaboratory with free GPU](/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Top 5 Advantages That CatBoost ML Brings to Your Data to Make it Purr](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
