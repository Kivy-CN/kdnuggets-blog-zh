- en: 7 Python Libraries Every Data Engineer Should Know
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 每个数据工程师都应该知道的 7 个 Python 库
- en: 原文：[https://www.kdnuggets.com/7-python-libraries-every-data-engineer-should-know](https://www.kdnuggets.com/7-python-libraries-every-data-engineer-should-know)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/7-python-libraries-every-data-engineer-should-know](https://www.kdnuggets.com/7-python-libraries-every-data-engineer-should-know)
- en: '![7 Python Libraries Every Data Engineer Should Know](../Images/57686075a802394bd08409e9293398cc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![每个数据工程师都应该知道的 7 个 Python 库](../Images/57686075a802394bd08409e9293398cc.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: As a data engineer, the list of tools and frameworks you’re expected to know
    can often be daunting. But, at the least, you should be proficient in SQL, Python,
    and Bash scripting.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据工程师，你需要掌握的工具和框架列表可能会让人望而却步。但至少，你应该精通 SQL、Python 和 Bash 脚本。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT 工作'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'Beside being familiar with core Python features and built-in modules, you should
    also be comfortable working with Python libraries for tasks you’ll do all the
    time as a data engineer. Here, we’ll explore a few such libraries to help you
    with the following tasks:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 除了熟悉核心的 Python 特性和内置模块外，你还应该能够熟练使用 Python 库来完成你作为数据工程师经常要做的任务。在这里，我们将探讨一些这样的库，帮助你完成以下任务：
- en: Working with APIs
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 API
- en: Web scraping
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络爬取
- en: Connecting to databases
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接数据库
- en: Workflow orchestration
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流编排
- en: Batch and stream processing
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 批处理和流处理
- en: Let’s get started.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: 1\. Requests
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. Requests
- en: As a data engineer, you’ll often work with APIs to extract data. [Requests](https://requests.readthedocs.io/en/latest/)
    is a Python library that lets you make HTTP requests from within your Python script.
    With Requests, you can retrieve data from RESTful APIs, fetch web pages for scraping,
    send data to server endpoints, and more.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据工程师，你经常需要使用 API 来提取数据。[Requests](https://requests.readthedocs.io/en/latest/)
    是一个 Python 库，可以让你从 Python 脚本中发出 HTTP 请求。使用 Requests，你可以从 RESTful API 获取数据，抓取网页，向服务器端点发送数据，等等。
- en: 'Here’s why Requests is super popular among data professionals and developers
    alike:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是为什么 Requests 在数据专业人士和开发者中如此受欢迎的原因：
- en: Requests provides a simple and intuitive API for making HTTP requests, supporting
    various HTTP methods such as GET, POST, PUT, and DELETE.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Requests 提供了一个简单直观的 API，用于发出 HTTP 请求，支持 GET、POST、PUT 和 DELETE 等各种 HTTP 方法。
- en: It handles features like authentication, cookies, and sessions.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它处理诸如身份验证、cookies 和会话等功能。
- en: It also supports features like SSL verification, timeouts, and connection pooling
    for robust and efficient communication with web servers.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它还支持 SSL 验证、超时和连接池等功能，以实现与 web 服务器的稳健高效的通信。
- en: To get started with Requests, check out the [Quickstart](https://requests.readthedocs.io/en/latest/user/quickstart/)
    page and the [Advanced Usage](https://requests.readthedocs.io/en/latest/user/advanced/)
    guide in the official docs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 Requests，请查看 [快速入门](https://requests.readthedocs.io/en/latest/user/quickstart/)
    页面和官方文档中的 [高级用法](https://requests.readthedocs.io/en/latest/user/advanced/) 指南。
- en: 2\. BeautifulSoup
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. BeautifulSoup
- en: As a data professional (whether a data scientist or a data engineer), you should
    be comfortable with programmatically scraping the web to collect data. [BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)
    is one of the most widely used Python libraries for web scraping which you can
    use for parsing and navigating HTML and XML documents.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据专业人士（无论是数据科学家还是数据工程师），你应该能够通过编程方式爬取网页以收集数据。[BeautifulSoup](https://beautiful-soup-4.readthedocs.io/en/latest/)
    是最广泛使用的 Python 库之一，可用于解析和浏览 HTML 和 XML 文档。
- en: 'Let’s list some of the features of BeautifulSoup that make it a great choice
    for web scraping tasks:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们列出 BeautifulSoup 的一些特性，这些特性使它成为网络爬取任务的绝佳选择：
- en: BeautifulSoup provides a simple API for parsing HTML documents. You can search,
    filter, and extract data based on tags, attributes, and content.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It supports various parsers, including lxml and html5lib—offering performance
    and compatibility options for different use cases.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From navigating the parse tree to parsing only a part of the document, the [docs](https://beautiful-soup-4.readthedocs.io/en/latest/)
    provide detailed guidelines for all tasks you may need to perform when using BeautifulSoup.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: Once you’re comfortable with BeautifulSoup, you can also explore [Scrapy](https://scrapy.org/)
    for web scraping. For most web scraping tasks, you’ll often use Requests in conjunction
    with BeautifulSoup or Scrapy.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Pandas
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a data engineer, you’ll deal with data manipulation and transformation tasks
    regularly. [Pandas](https://pandas.pydata.org/) is a popular Python library for
    data manipulation and analysis. It provides data structures and a suite of functions
    necessary for cleaning, transforming, and analyzing data efficiently.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s why pandas is popular among data professionals:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: It supports reading and writing data in various formats such as CSV, Excel,
    SQL databases, and more
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As mentioned, pandas also offers functions for filtering, grouping, merging,
    and reshaping data.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The [Pandas Tutorial: Pandas Full Course](https://www.youtube.com/watch?v=PcvsOaixUh8)
    by Derek Banas on YouTube is a comprehensive tutorial to become comfortable with
    pandas. You can also check [7 Steps to Mastering Data Wrangling with Python and
    Pandas](/7-steps-to-mastering-data-wrangling-with-pandas-and-python) on tips for
    mastering data manipulation with pandas.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Once you’re comfortable with pandas, depending on the need to scale data processing
    tasks, you can explore [Dask](https://www.dask.org/). Which is a flexible parallel
    computing library in Python, enabling parallel computing on clusters.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: 4\. SQLAlchemy
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Working with databases is one of the most common tasks you’ll do in your workday
    as a data engineer. [SQLAlchemy](https://www.sqlalchemy.org/) is a SQL toolkit
    and an Object-Relational Mapping (ORM) library in Python which makes working with
    databases simple.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key features of SQLAlchemy that make it helpful include:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: A powerful ORM layer that allows defining database models as Python classes,
    with attributes mapping to database columns
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Allows writing and running SQL queries from Python
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for multiple database backends, including PostgreSQL, MySQL, and SQLite—providing
    a consistent API across different databases
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can check the SQLAlchemy docs for detailed reference guides on the [ORM](https://docs.sqlalchemy.org/en/20/orm/)
    and features like [connections and schema management](https://docs.sqlalchemy.org/en/20/core/).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: If, however, you work mostly with PostgreSQL databases, you may want to learn
    to use [Psycopg2](https://www.psycopg.org/docs/), the Postgres adapter for Python.
    Psycopg2 provides a low-level interface for working with PostgreSQL databases
    directly from Python code.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你主要使用 PostgreSQL 数据库，你可能想学习使用 [Psycopg2](https://www.psycopg.org/docs/)，这是
    Python 的 Postgres 适配器。Psycopg2 提供了一个低级接口，以便直接从 Python 代码中处理 PostgreSQL 数据库。
- en: 5\. Airflow
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. Airflow
- en: Data engineers frequently deal with workflow orchestration and automation tasks.
    With [Apache Airflow](https://airflow.apache.org/), you can author, schedule,
    and monitor workflows. So you can use it for coordinating batch processing jobs,
    orchestrating ETL workflows, or managing dependencies between tasks, and more.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程师经常处理工作流编排和自动化任务。使用 [Apache Airflow](https://airflow.apache.org/)，你可以创建、调度和监控工作流。因此，你可以用它来协调批处理作业、编排
    ETL 工作流或管理任务之间的依赖关系等。
- en: 'Let’s review some of Airflow''s features:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下 Airflow 的一些功能：
- en: With Airflow, you define workflows as DAGs, scheduling tasks, managing dependencies,
    and monitoring workflow execution.
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Airflow，你可以将工作流定义为 DAGs，调度任务，管理依赖关系，并监控工作流执行。
- en: It provides a set of operators for interacting with various systems and services,
    including databases, cloud platforms, and data processing frameworks.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一组用于与各种系统和服务（包括数据库、云平台和数据处理框架）交互的操作符。
- en: It is quite extensible; so you can define custom operators and hooks as needed.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它非常可扩展，因此你可以根据需要定义自定义操作符和钩子。
- en: '[Marc Lamberti’s tutorials](https://marclamberti.com/blog-list/) and courses
    are great resources to get started with Airflow. While Airflow is widely used,
    there are several alternatives such as Prefect and Mage that you can explore,
    too. To learn more about Airflow alternatives for orchestration, read [5 Airflow
    Alternatives for Data Orchestration](/5-airflow-alternatives-for-data-orchestration).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '[Marc Lamberti 的教程](https://marclamberti.com/blog-list/)和课程是开始学习 Airflow 的极好资源。虽然
    Airflow 被广泛使用，但也有一些替代品，如 Prefect 和 Mage，你也可以进行探索。要了解更多关于 Airflow 的编排替代品的信息，请阅读
    [5 Airflow Alternatives for Data Orchestration](/5-airflow-alternatives-for-data-orchestration)。'
- en: 6\. PySpark
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. PySpark
- en: As a data engineer, you’ll need to handle big data processing tasks that require
    distributed computing capabilities. [PySpark](https://spark.apache.org/docs/latest/api/python/index.html)
    is the Python API for Apache Spark, a distributed computing framework for processing
    large-scale data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据工程师，你需要处理需要分布式计算能力的大数据处理任务。[PySpark](https://spark.apache.org/docs/latest/api/python/index.html)
    是 Apache Spark 的 Python API，Apache Spark 是一个用于处理大规模数据的分布式计算框架。
- en: 'Some features of PySpark are as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: PySpark 的一些功能如下：
- en: It provides APIs for batch processing, machine learning, and graph processing
    amongst others.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了用于批处理、机器学习和图形处理等的 API。
- en: It offers high-level abstractions like DataFrame and Dataset for working with
    structured data, along with RDDs for lower-level data manipulation.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了像 DataFrame 和 Dataset 这样的高级抽象，用于处理结构化数据，以及 RDDs 进行更低级别的数据操作。
- en: The [PySpark Tutorial](https://youtu.be/_C8kWso4ne4?feature=shared) on freeCodeCamp’s
    community YouTube channel is a good resource to get started with PySpark.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '[PySpark 教程](https://youtu.be/_C8kWso4ne4?feature=shared) 在 freeCodeCamp 的社区
    YouTube 频道是开始学习 PySpark 的一个好资源。'
- en: 7\. Kafka-Python
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. Kafka-Python
- en: Kafka is a popular distributed streaming platform, and [Kafka-Python](https://kafka-python.readthedocs.io/en/master/)
    is a library for interacting with Kafka from Python. So you can use Kafka-Python
    when you need to work with real-time data processing and messaging systems.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka 是一个流行的分布式流平台，而 [Kafka-Python](https://kafka-python.readthedocs.io/en/master/)
    是一个用于从 Python 与 Kafka 交互的库。因此，当你需要处理实时数据处理和消息系统时，可以使用 Kafka-Python。
- en: 'Some features of Kafka-Python are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka-Python 的一些功能如下：
- en: Provides high-level Producer and Consumer APIs for publishing and consuming
    messages to and from Kafka topics
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供了高级的生产者和消费者 API 用于发布和消费 Kafka 主题中的消息。
- en: Supports features like message batching, compression, and partitioning
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持诸如消息批处理、压缩和分区等功能。
- en: You may not always use Kafka for all projects you work on. But if you want to
    learn more, the [docs](https://kafka-python.readthedocs.io/en/master/) page has
    helpful usage examples.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能不会在所有项目中都使用 Kafka。但如果你想了解更多，[docs](https://kafka-python.readthedocs.io/en/master/)
    页面有有用的使用示例。
- en: Wrapping Up
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: And that's a wrap! We’ve gone over some of the most commonly used Python libraries
    for data engineering. If you want to explore data engineering, you can try building
    end-to-end data engineering projects to see how these libraries actually work.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 到此为止！我们已经涵盖了一些最常用的 Python 库用于数据工程。如果你想探索数据工程，可以尝试构建端到端的数据工程项目，看看这些库实际是如何工作的。
- en: 'Here are a couple of resources to get you started:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个资源可以帮助你入门：
- en: '[A Beginner’s Guide to Data Engineering](/2023/07/beginner-guide-data-engineering.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据工程初学者指南](/2023/07/beginner-guide-data-engineering.html)'
- en: '[Free Data Engineering Course for Beginners](/free-data-engineering-course-for-beginners)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[初学者免费数据工程课程](/free-data-engineering-course-for-beginners)'
- en: Happy learning!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 祝学习愉快！
- en: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    is a developer and technical writer from India. She likes working at the intersection
    of math, programming, data science, and content creation. Her areas of interest
    and expertise include DevOps, data science, and natural language processing. She
    enjoys reading, writing, coding, and coffee! Currently, she''s working on learning
    and sharing her knowledge with the developer community by authoring tutorials,
    how-to guides, opinion pieces, and more. Bala also creates engaging resource overviews
    and coding tutorials.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://twitter.com/balawc27)**[Bala Priya C](https://www.kdnuggets.com/wp-content/uploads/bala-priya-author-image-update-230821.jpg)****
    是一位来自印度的开发者和技术作家。她喜欢在数学、编程、数据科学和内容创作的交汇点工作。她的兴趣和专长领域包括 DevOps、数据科学和自然语言处理。她喜欢阅读、写作、编程和喝咖啡！目前，她正致力于通过编写教程、操作指南、观点文章等方式学习和分享知识。Bala
    还创建了引人入胜的资源概述和编程教程。'
- en: More On This Topic
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[10 Python Libraries Every Data Scientist Should Know](https://www.kdnuggets.com/10-python-libraries-every-data-scientist-should-know)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的 10 个 Python 库](https://www.kdnuggets.com/10-python-libraries-every-data-scientist-should-know)'
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets 新闻，4月13日：数据科学家应了解的 Python 库…](https://www.kdnuggets.com/2022/n15.html)'
- en: '[5 Machine Learning Skills Every Machine Learning Engineer Should…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个机器学习工程师都应该掌握的 5 个机器学习技能…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
- en: '[Tools Every AI Engineer Should Know: A Practical Guide](https://www.kdnuggets.com/tools-every-ai-engineer-should-know-a-practical-guide)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个 AI 工程师都应该知道的工具：实用指南](https://www.kdnuggets.com/tools-every-ai-engineer-should-know-a-practical-guide)'
- en: '[Python Libraries Data Scientists Should Know in 2022](https://www.kdnuggets.com/2022/04/python-libraries-data-scientists-know-2022.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2022 年数据科学家应该知道的 Python 库](https://www.kdnuggets.com/2022/04/python-libraries-data-scientists-know-2022.html)'
