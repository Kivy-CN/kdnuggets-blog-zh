- en: 20 AI, Data Science, Machine Learning Terms You Need to Know in 2020 (Part 2)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html](https://www.kdnuggets.com/2020/03/ai-data-science-machine-learning-key-terms-part2.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: This is the 2nd part of our list of 20 AI, Data Science, Machine Learning terms
    to know for 2020.  Here is [**20 AI, Data Science, Machine Learning Terms You
    Need to Know in 2020 (Part 1)**](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Those definitions were compiled by KDnuggets Editors [Matthew Dearing](/author/matthew-dearing),
    [Matthew Mayo](/author/matt-mayo), [Asel Mendis](/author/asel-mendis), and [Gregory
    Piatetsky](/author/gregory-piatetsky).
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: In this installment, we explain
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Double Descent
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethics in AI
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explainability (Explainable AI)
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full Stack Data Science
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geospatial
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPT-2
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NLG (Natural Language Generation)
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PyTorch
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reinforcement Learning
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transformer Architecture
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Double Descent
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a really interesting concept, which [Pedro Domingos](https://en.wikipedia.org/wiki/Pedro_Domingos),
    a leading AI researcher, called one of the most significant advances in ML theory
    in 2019.  The phenomenon is shown in Figure 1.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '![OpenAI Double Descent graph](../Images/74f2dd93c859947a79b736628f930f7f.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
- en: '**Fig. 1:  Test/Train Error vs Model Size (Source OpenAI** [**blog**](https://openai.com/blog/deep-double-descent/)**)**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: The error first declines as the model gets larger, then the error increases
    as the model begins to overfit, but then the error declines again with the increasing
    model size, data size, or training time.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: The classical statistical theory says that the bigger model will be worse because
    of overfitting.  However, the modern ML practice shows that a very big Deep Learning
    model is usually better than a smaller one.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI [blog](https://openai.com/blog/deep-double-descent/) notes that this
    occurs in CNNs, ResNets, and transformers. OpenAI researchers observed that when
    model is not large enough to fit the training set, larger models had higher test
    error. However, after passing this threshold, larger models with more data started
    performing better.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Read the original OpenAI blog and a longer [explanation](https://towardsdatascience.com/deep-double-descent-when-more-data-and-bigger-models-are-a-bad-thing-3a3f108d5538)
    by Rui Aguiar.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '*Written by [Gregory Piatetsky](/author/gregory-piatetsky)*.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '*由[格雷戈里·皮亚捷茨基](/author/gregory-piatetsky)撰写*。'
- en: '[Ethics](/tag/ethics/) in AI'
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[人工智能中的伦理](/tag/ethics/)'
- en: Ethics in AI is concerned with the ethics of practical artificial intelligence
    technology.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能伦理关注的是实际人工智能技术的伦理。
- en: AI ethics is a very broad field, and encompasses a wide variety of seemingly
    very different aspects of ethical concern. Concerns over the use of AI, and of
    all types of technology, more generally, have existed for as long as these technologies
    were first conceived of. Yet given the recent explosion of AI, machine learning,
    and related technologies, and their increasingly quick adoption and integration
    into society at large, these ethical concerns have risen to the forefront of many
    minds both within and outside of the AI community.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能伦理是一个非常广泛的领域，涵盖了各种看似非常不同的伦理关切方面。关于人工智能及所有技术类型的使用的担忧，自这些技术首次被构想到现在就一直存在。然而，鉴于人工智能、机器学习及相关技术的近期爆炸式增长，以及它们在整个社会中的日益快速的采纳和整合，这些伦理关切已成为许多人，既包括人工智能社区内的人，也包括外界人士，关注的重点。
- en: While esoteric and currently abstract ethical concerns such as the potential
    future rights of sentient robots can also be included under the umbrella of AI
    ethics, more pressing contemporary concerns such as AI system transparency, the
    potential biases of these systems, and the representative inclusion of all categories
    of society participants in the engineering of said systems are likely of much
    greater and immediate concern to most people. How are decisions being made in
    AI systems? What assumptions are these systems making about the world and the
    people in it? Are these systems crafted by a single dominant majority class, gender,
    and race of society at large?
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然像有感知的机器人未来可能的权利这样的深奥和目前抽象的伦理问题也可以被纳入人工智能伦理的范畴，但更紧迫的当代问题，如人工智能系统的透明度、这些系统可能存在的偏见，以及在这些系统工程中社会参与者的代表性包容，可能更令大多数人关注。人工智能系统中的决策是如何做出的？这些系统对世界和其中的人有什么假设？这些系统是否由单一主导的多数群体、性别和种族制造？
- en: 'Rachel Thomas, Director of the USF Center for Applied Data Ethics, [has stated](https://www.fast.ai/2018/09/24/ai-ethics-resources/)
    the following about what constitutes working on AI ethics, which goes beyond concerns
    related directly and solely to the lower-level creation of AI systems, and takes
    into account the proverbial bigger picture:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 美国旧金山大学应用数据伦理中心主任瑞秋·托马斯[Rachel Thomas](https://www.fast.ai/2018/09/24/ai-ethics-resources/)对从事人工智能伦理工作的定义进行了说明，这超越了直接涉及人工智能系统低层次创建的关注点，并考虑了所谓的更广泛的背景：
- en: '**founding tech companies and building products in ethical ways;'
  id: totrans-36
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**创建科技公司并以伦理方式开发产品；'
- en: advocating and working for more just laws and policies;
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 提倡和推动更公正的法律和政策；
- en: attempting to hold bad actors accountable;
  id: totrans-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尝试追究不良行为者的责任；
- en: and research, writing, and teaching in the field.**
  id: totrans-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以及在这一领域的研究、写作和教学。**
- en: The dawn of autonomous vehicles has presented additional specific challenges
    related to AI ethics, as have the potential weaponization of AI systems, and a
    growing international AI arms race. Contrary to what some would have us believe,
    these aren't problems predestined for a dystopian future, yet they are problems
    which will require some critical thought, proper preparation, and extensive cooperation.
    Even with what we may believe to be adequate consideration, AI systems might still
    prove to be uniquely and endemically problematic, and the unintended consequences
    of AI systems, another aspect of AI ethics, will need to be considered. *Written
    by [Matthew Mayo](/author/matt-mayo)*
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 自动驾驶汽车的出现带来了与人工智能伦理相关的额外特定挑战，人工智能系统的潜在武器化以及日益增长的国际人工智能军备竞赛也是如此。与某些人想让我们相信的情况相反，这些问题并不是注定会发生在反乌托邦未来的难题，然而这些问题确实需要经过一些深思熟虑、适当的准备和广泛的合作。即便我们认为已经进行了充分的考虑，人工智能系统仍可能被证明是独特且内生性的问题，人工智能系统的意外后果，作为人工智能伦理的另一个方面，也需要被考虑。*由[马修·梅奥](/author/matt-mayo)撰写*
- en: '[Explainability](/tag/explainability) ([Explainable AI](/tag/explainable-ai))'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[可解释性](/tag/explainability) ([可解释人工智能](/tag/explainable-ai))'
- en: As AI and Machine Learning become a larger part of our lives, with smartphones,
    medical diagnostics, self-driving cars, intelligent search, automated credit decisions,
    etc. having decisions made by AI, one important aspect this decision making comes
    to the forefront - explainability. Humans can usually explain their knowledge-based
    decisions  (whether such explanations are accurate is a separate question) and
    that contributes to trust by other humans for such decisions.  Can AI and ML algorithms
    explain their decisions?  This is important for
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: improving understanding and trust in the decision
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: deciding accountability or liability in case something goes wrong.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: avoiding discrimination and societal bias in decisions
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We note that some form of explainability is required by [GDPR](https://www.kdnuggets.com/2018/03/gdpr-machine-learning-illegal.html).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: Explainable AI ([XAI](/tag/xai)) is becoming a major field, with DARPA launching
    [XAI program](https://www.darpa.mil/program/explainable-artificial-intelligence)
    in 2018.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![Explainable AI Venn Diagram](../Images/9e36474a8c22f1ad3a399824608f7a1a.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: '**Fig. 2: Explainable AI Venn Diagram.** ([Source](https://www.kdnuggets.com/2019/01/explainable-ai.html)).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Explainability is a multifaceted topic. It encompasses both individual models
    and the larger systems that incorporate them. It refers not only to whether the
    decisions a model outputs are interpretable, but also whether or not the whole
    process and intention surrounding the model can be properly accounted for. The
    goal is to have an efficient trade-off between accuracy and explainability along
    with a great human-computer interface which can help translate the model to understandable
    representation for the end users.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Some of the more popular methods for Explainable AI include [LIME](/tag/lime)
    and [SHAP](https://www.kdnuggets.com/2020/01/explaining-black-box-models-ensemble-deep-learning-lime-shap.html).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Explainability tools are now offered by Google ([Explainable AI service](https://www.kdnuggets.com/2019/12/googles-new-explainable-ai-service.html)),
    [IBM AIX 360](https://github.com/IBM/AIX360) and other vendors.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: 'See also a  KDnuggets blog on [Explainable AI](https://www.kdnuggets.com/2019/01/explainable-ai.html)
    by Preet Gandhi and [Explainable Artificial Intelligence (XAI): Concepts, Taxonomies,
    Opportunities and Challenges toward Responsible AI](https://arxiv.org/abs/1910.10045)
    (arxiv 1910.10045). *Written by [Gregory Piatetsky](/author/gregory-piatetsky)*.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: Full Stack Data Science
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Full Stack Data Scientist is the epitome of the Data Science Unicorn. Someone
    who possesses the skills of a Statistician that can model a real life scenario,
    a Computer Scientist that can manage databases and deploy model to the web, and
    a businessman that translates the insights and the models to actionable insights
    to the end users who are typically senior management that does not care about
    the backend work.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Below are two great talks that can give you an idea about the different nuances
    of an End-to-End Data Science product.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是两个很棒的演讲，可以让你了解端到端数据科学产品的不同细微差别。
- en: '1\. Going Full Stack with Data Science: Using Technical Readiness, by Emily
    Gorcenski'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 通过数据科学全面发展：使用技术准备，由Emily Gorcenski
- en: '2\. [Video: #42 Full Stack Data Science (with Vicki Boykis) - DataCamp](https://www.youtube.com/watch?v=EICvvS6MUt8).'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. [视频：#42 完整数据科学（与Vicki Boykis一起）- DataCamp](https://www.youtube.com/watch?v=EICvvS6MUt8)。
- en: Read [#42 Full Stack Data Science (with Vicki Boykis) - Transcript](https://www.r-bloggers.com/full-stack-data-science-transcript/).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读 [#42 完整数据科学（与Vicki Boykis一起）- 文本记录](https://www.r-bloggers.com/full-stack-data-science-transcript/)。
- en: '*Written by [Asel Mendis](/author/asel-mendis)*.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '*作者：[Asel Mendis](/author/asel-mendis)*。'
- en: '[Geospatial](/tag/geospatial)'
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[地理空间](/tag/geospatial)'
- en: Geospatial is a term for any data that has a spatial/location/geographical component
    to it. Geospatial analysis has been gaining in popularity due to the onset of
    technology that tracks user movements and creates geospatial data as a by-product.
    The most famous technologies (Geographic Information Systems – GIS) used for spatial
    analysis are [ArcGIS](https://www.arcgis.com/index.html), [QGIS](https://www.qgis.org/en/site/),
    [CARTO](https://carto.com/) and [MapInfo](https://www.pitneybowes.com/us/location-intelligence/geographic-information-systems/mapinfo-pro.html).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 地理空间是指具有空间/位置/地理成分的任何数据。由于跟踪用户移动并生成地理空间数据的技术出现，地理空间分析的受欢迎程度逐渐上升。用于空间分析的最著名技术（地理信息系统
    – GIS）包括 [ArcGIS](https://www.arcgis.com/index.html)、[QGIS](https://www.qgis.org/en/site/)、[CARTO](https://carto.com/)
    和 [MapInfo](https://www.pitneybowes.com/us/location-intelligence/geographic-information-systems/mapinfo-pro.html)。
- en: The current epidemic of Coronavirus is tracked by [ARCGIS dashboard](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6),
    developed by Johns Hopkins U. Center for Systems Science and Engineering.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的冠状病毒疫情由 [ARCGIS仪表板](https://www.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6)
    追踪，由约翰斯·霍普金斯大学系统科学与工程中心开发。
- en: '![Coronavirus 2020 Mar 2 Johns Hopkins](../Images/2d9fa602b92c76f86079aed611f721f6.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![2020年3月2日的冠状病毒，约翰斯·霍普金斯](../Images/2d9fa602b92c76f86079aed611f721f6.png)'
- en: '**Fig. 3: Coronavirus stats as of March 2, 2020, according to Johns Hopkins
    CSSE dashboard.**'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**图3：根据约翰斯·霍普金斯CSSE仪表板，截至2020年3月2日的冠状病毒统计数据。**'
- en: Geospatial data can be used in applications from sales prediction modelling
    to assessing government funding initiative. Because the data is in reference to
    a specific location, there are many insights we can gather. Different countries
    record and measure their spatial data differently and to varying degrees. The
    geographic boundaries of a country are different and must be treated as unique
    to each country.  *Written by [Asel Mendis](/author/asel-mendis)*.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 地理空间数据可以用于从销售预测建模到评估政府资助计划等各种应用。由于数据参考了特定位置，因此我们可以获得许多见解。不同国家记录和测量其空间数据的方式不同，并且程度各异。一个国家的地理边界不同，必须视为每个国家的独特特征。
    *作者：[Asel Mendis](/author/asel-mendis)*。
- en: '[GPT-2](/tag/gpt-2)'
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[GPT-2](/tag/gpt-2)'
- en: '[GPT-2](https://openai.com/blog/better-language-models/) is a transformer-based
    language model created by [OpenAI](/tag/openai). GPT-2 is a generative language
    model, meaning that it generates text by predicting word by word which word comes
    next in a sequence, based on what the model has previously learned. In practice,
    a user-supplied prompt is presented to the model, following which subsequent words
    are generated.  GPT-2 was trained to predict the next word on a massive amount
    (40 GB) of internet text, and is built solely using transformer decoder blocks
    (contrast this with BERT, which uses encoder blocks). For more information on
    transformers see below.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[GPT-2](https://openai.com/blog/better-language-models/) 是由 [OpenAI](/tag/openai)
    创建的基于变换器的语言模型。GPT-2 是一个生成语言模型，这意味着它通过逐词预测序列中下一个词来生成文本，基于模型之前学到的内容。在实践中，用户提供的提示会呈现给模型，然后生成随后的词。GPT-2
    被训练用于预测在大量（40 GB）互联网文本中的下一个词，并且完全使用变换器解码块构建（与使用编码块的BERT相比）。有关变换器的更多信息，请参见下文。'
- en: GPT-2 isn't a particularly novel undertaking; what sets it apart from similar
    models, however, is the number of its trainable parameters, and the storage size
    required for these trained parameters. While OpenAI initially released a scaled
    down version of the trained model — out of concerns that there could be malicious
    uses for it — the full model contains 1.5 billion parameters. This 1.5 billion
    trainable parameter model requires 6.5 GB of trained parameter (synonymous to
    "trained model") storage.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2并不是一个特别新颖的项目；然而，它与类似模型不同之处在于其可训练参数的数量以及这些训练参数所需的存储大小。虽然OpenAI最初发布了一个缩小版的训练模型——出于对可能出现恶意用途的担忧——但完整模型包含15亿个参数。这15亿个可训练参数模型需要6.5
    GB的训练参数（等同于“训练模型”）存储。
- en: Upon release, GPT-2 generated a lot of hype and attention in large part due
    to the selected examples which accompanied it, the most famous of which — a news
    report documenting the discovery of English speaking unicorns in the Andes — [can
    be read here](https://pbs.twimg.com/media/DzYpsJOU0AA1PO9.png:large). A unique
    application of the GPT-2 model has surfaced in form of the AI Dungeon, an online
    text adventure game which treats user-supplied text as prompts for input into
    the model, and generated output is used to advance the game and user experience.
    You can [try out AI Dungeon here](https://aidungeon.io/).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2发布时引起了大量的关注和热议，这在很大程度上是由于随之而来的示例，其中最著名的一个——记录安第斯山脉发现说英语的独角兽的新闻报道——[可以在这里阅读](https://pbs.twimg.com/media/DzYpsJOU0AA1PO9.png:large)。GPT-2模型的一个独特应用是AI
    Dungeon，这是一款在线文字冒险游戏，将用户提供的文本视为对模型的输入提示，并使用生成的输出推动游戏进程和用户体验。你可以[在这里试用AI Dungeon](https://aidungeon.io/)。
- en: While text generation via next word prediction is the bread and butter (and
    pizzazz) of GPT-2 and decoder block transformers more generally, they have shown
    promise in additional related areas, such as language translation, text summarization,
    music generation, and more. For technical details on the GPT-2 model and additional
    information, see Jay Alammar's fantastic [Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2).
    *Written by [Matthew Mayo](/author/matt-mayo)*.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通过下一个词预测生成文本是GPT-2及解码器块变换器的主要功能（以及亮点），它们在语言翻译、文本摘要、音乐生成等其他相关领域也展现了潜力。有关GPT-2模型的技术细节和更多信息，请参见Jay
    Alammar的精彩[Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2)。*作者：[Matthew
    Mayo](/author/matt-mayo)*。
- en: NLG ([Natural Language Generation](/tag/natural-language-generation))
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NLG ([自然语言生成](/tag/natural-language-generation))
- en: Significant progress has been made in natural language understanding – getting
    a computer to interpret human input and provide a meaningful response. Many people
    enjoy this technology every day through personal devices, such as Amazon Alexa
    and Google Home. Not unexpectedly, kids really like asking for jokes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言理解方面取得了重大进展——使计算机能够解释人类输入并提供有意义的回应。许多人通过个人设备，如亚马逊Alexa和Google Home，每天都在享受这一技术。毫不意外，孩子们特别喜欢要求讲笑话。
- en: The tech here is that the machine learning backend is trained on a wide variety
    of inputs, such as “please tell me a joke,’ to which it can select one from a
    prescribed list of available responses. What if Alexa or Google Home could tell
    an *original* joke, one that was created on the fly based on training from a large
    set of human authored jokes. That’s [natural language *generation*](https://www.kdnuggets.com/2020/01/guide-natural-language-generation.html).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的技术是机器学习后端经过各种输入的训练，例如“请告诉我一个笑话”，机器可以从预定的响应列表中选择一个。如果Alexa或Google Home能够讲一个*原创*笑话，即基于大量人类创作的笑话进行即时创作，那就是[自然语言*生成*](https://www.kdnuggets.com/2020/01/guide-natural-language-generation.html)。
- en: Original jokes are only the beginning (can a trained [machine learning model
    even be funny](http://joking.abdn.ac.uk/webversion/welcome.php)?), as powerful
    applications of NLG are being developed for analytics that generate human-understandable
    summaries of data sets. The creative side of a computer can also be explored through
    NLG techniques that output [original movie scripts](https://www.youtube.com/watch?v=LY7x2Ihqjmc),
    even ones that star [David Hasselhoff](https://www.youtube.com/watch?v=5qPgG98_CQ8),
    as well as text-based stories, similar to [a tutorial you can follow](https://www.kdnuggets.com/2019/07/training-neural-network-write-like-lovecraft.html)
    that leverages long short-term memory, the recurrent neural network architecture
    with feedback, that is another hot research topic today.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 原创笑话只是个开始（一个训练好的[机器学习模型甚至能搞笑](http://joking.abdn.ac.uk/webversion/welcome.php)吗？），强大的NLG应用正被开发用于生成能够被人类理解的数据集摘要。计算机的创造性方面也可以通过NLG技术进行探索，这些技术能够输出[原创电影剧本](https://www.youtube.com/watch?v=LY7x2Ihqjmc)，甚至有[David
    Hasselhoff](https://www.youtube.com/watch?v=5qPgG98_CQ8)主演的剧本，以及类似于[你可以跟随的教程](https://www.kdnuggets.com/2019/07/training-neural-network-write-like-lovecraft.html)的基于文本的故事，利用长短期记忆（LSTM）这种反馈的递归神经网络架构，这是当前的热门研究话题之一。
- en: While business analysis and entertainment applications of computer-generated
    language might be appealing and culture-altering, ethical concerns are already
    boiling over. NLG's capability to deliver “fake news” that is autonomously generated
    and dispersed is causing distress, even if its intentions were not programmed
    to be evil. For example, OpenAI has been [carefully releasing](https://www.kdnuggets.com/2019/03/openai-gpt-2-model-hype-controversy.html)
    their GPT-2 language model for which studies have shown can generate text output
    that is convincing to humans, difficult to detect as synthetic, and can be fine-tuned
    for misuse. Now, they are using this research on the development of AI that can
    be troublesome for humanity as a way to understand better how to control these
    worrisome biases and potentials for malicious use of text generators.  *Written
    by [Matthew Dearing](/author/matthew-dearing)*.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管计算机生成语言在商业分析和娱乐应用方面可能颇具吸引力并能改变文化，但伦理问题已经引发了大量关注。自然语言生成（NLG）能够自主生成并传播“假新闻”的能力令人不安，即使其意图并非被编程为恶意。例如，OpenAI
    [小心发布](https://www.kdnuggets.com/2019/03/openai-gpt-2-model-hype-controversy.html)了他们的GPT-2语言模型，研究表明该模型可以生成令人信服的文本输出，难以被检测为合成内容，并且可以被微调以进行不当使用。他们现在利用这项研究来开发可能对人类带来麻烦的AI，以更好地理解如何控制这些令人担忧的偏见和恶意使用文本生成器的潜力。
    *作者：[Matthew Dearing](/author/matthew-dearing)*。
- en: '[PyTorch](/tag/pytorch)'
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[PyTorch](/tag/pytorch)'
- en: First released in 2002 and implemented in C, the [Torch package](https://github.com/torch/torch7)
    is a tensor library developed with a range of algorithms to support deep learning.
    [Facebook's AI Research](https://research.fb.com/) lab took a liking to Torch
    and open sourced the library in early 2015 that also incorporated many of its
    machine learning tools. The following year, they released a Python implementation
    of the framework, called PyTorch, optimized for GPU-acceleration.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[Torch包](https://github.com/torch/torch7)最早于2002年发布，使用C语言实现，是一个包含多种算法的张量库，支持深度学习。
    [Facebook AI研究](https://research.fb.com/)实验室对Torch产生了兴趣，并在2015年初将该库开源，同时也融入了许多机器学习工具。次年，他们发布了一个Python实现的框架，名为PyTorch，经过优化以支持GPU加速。'
- en: With the powerful Torch tools now accessible to Python developers, many major
    players integrated PyTorch into their development stack. Today, this once Facebook-internal
    machine learning framework is now one of the [most used deep learning libraries](https://www.kdnuggets.com/2020/01/openai-pytorch-adoption.html)
    with OpenAI being the latest to join a growing slate of corporations and researchers
    leveraging PyTorch. The competing package released by Google in 2017, TensorFlow,
    has dominated the deep learning community since its inception and is now clearly
    trending toward being outpaced by PyTorch later in 2020.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 随着强大的Torch工具现在对Python开发者开放，许多主要企业将PyTorch整合到他们的开发堆栈中。如今，这个曾经是Facebook内部的机器学习框架已成为[最受欢迎的深度学习库](https://www.kdnuggets.com/2020/01/openai-pytorch-adoption.html)之一，OpenAI是最新加入使用PyTorch的公司和研究人员中的一员。Google在2017年发布的竞争软件包TensorFlow，自诞生以来一直主导深度学习社区，并且现在明显趋势是PyTorch将在2020年晚些时候超越TensorFlow。
- en: If you are looking for your first machine learning package to study or are a
    seasoned TensorFlow user, you can [get started](https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html)
    with PyTorch to find out for yourself which is the best framework for your development
    needs. *Written by [Matthew Dearing](/author/matthew-dearing)*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在寻找第一个机器学习包进行学习，或者是一个经验丰富的TensorFlow用户，你可以[开始使用](https://www.kdnuggets.com/2019/09/gentle-introduction-pytorch-12.html)PyTorch，亲自找出哪个框架最适合你的开发需求。*作者：[Matthew
    Dearing](/author/matthew-dearing)*。
- en: '[Reinforcement Learning](/tag/reinforcement-learning)'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[强化学习](/tag/reinforcement-learning)'
- en: Along with supervised and unsupervised learning, [reinforcement learning](https://www.kdnuggets.com/2017/12/interview-rich-sutton-reinforcement-learning.html)
    (RL) is a fundamental approach in machine learning. The essential idea is a training
    algorithm that provides a reward feedback to a trial-and-error decision-making
    “agent” that attempts to perform some computational task. In other words, if you
    toss a stick across the yard for Rover to fetch, and your new puppy decides to
    return it to you for a treat, then it will repeat the same decision faster and
    more efficiently next time. The exciting feature of this approach is that labeled
    data is not necessary – the model can explore known and unknown data with guidance
    toward an optimal solution through an encoded reward.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 除了监督学习和无监督学习，[强化学习](https://www.kdnuggets.com/2017/12/interview-rich-sutton-reinforcement-learning.html)（RL）是机器学习中的一种基本方法。其核心思想是一个训练算法，它为一个试错决策“代理”提供奖励反馈，该代理尝试执行某些计算任务。换句话说，如果你将一根棍子扔到院子里让Rover去取，而你的新小狗决定把棍子还给你以获得奖励，那么它下次将更快、更有效地重复相同的决策。这种方法的一个令人兴奋的特点是无需标记数据——模型可以通过编码的奖励在已知和未知数据中探索，朝着最佳解决方案前进。
- en: RL is the foundation of the incredible, record-breaking, and human-defeating
    competitions in chess, video games, and [AlphaGo’s crushing blow](https://www.kdnuggets.com/2017/10/alphago-zero-biggest-ai-advance.html)
    that learned the game of Go without any instructions hardcoded into its algorithms.
    However, while these developments in AI’s superhuman capabilities are significant,
    they perform within well-defined computer representations, such as games with
    unchanging rules. RL is [not directly generalizable to the messiness of the real
    world](https://www.kdnuggets.com/2020/01/modern-ai-from-neurips-2019.html), as
    seen with [OpenAI’s Rubik’s Cube model](https://openai.com/blog/solving-rubiks-cube/)
    that could solve the puzzle in simulation, but took years to see much-less-than-perfect
    results when translated through robotic arms.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习是那些令人惊叹的、打破纪录的、战胜人类的国际象棋、视频游戏以及[AlphaGo的致命一击](https://www.kdnuggets.com/2017/10/alphago-zero-biggest-ai-advance.html)的基础。AlphaGo在没有任何硬编码到算法中的指令下学会了围棋。然而，虽然这些人工智能超人能力的发展是显著的，它们是在规则不变的游戏这样的明确定义的计算机表征内进行的。强化学习[并不能直接推广到现实世界的复杂性](https://www.kdnuggets.com/2020/01/modern-ai-from-neurips-2019.html)，正如[OpenAI的魔方模型](https://openai.com/blog/solving-rubiks-cube/)所示，该模型在模拟中能够解出难题，但在通过机器人手臂转化时却需要多年才能看到远不完美的结果。
- en: So, a great deal is yet to be developed and improved in the area of reinforcement
    learning, and 2019 witnessed that a [potential renaissance is underway](https://www.kdnuggets.com/2019/12/review-what-happened-ai.html).
    Expanding RL to real-world applications will be a hot topic in 2020, with [important
    implementations](https://www.kdnuggets.com/2020/01/created-lazy-ai.html) already
    underway. *Written by [Matthew Dearing](https://www.kdnuggets.com/author/matthew-dearing)*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在强化学习领域还有大量的开发和改进工作需要进行，2019年见证了[潜在的复兴正在进行中](https://www.kdnuggets.com/2019/12/review-what-happened-ai.html)。将强化学习扩展到实际应用将是2020年的一个热门话题，[重要的实施工作](https://www.kdnuggets.com/2020/01/created-lazy-ai.html)已经在进行中。*作者：[Matthew
    Dearing](https://www.kdnuggets.com/author/matthew-dearing)*。
- en: '[Transformer](/tag/transformer)'
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[变压器](/tag/transformer)'
- en: The Transformer is a novel neural network architecture based on self-attention
    mechanism that is especially well-suited to NLP and Natural Language Understanding.
    It was proposed in [Attention Is All You Need](https://goo.gl/dwSBxB), 2017 paper
    by Google AI researchers. The Transformer is an architecture for "transforming"
    one sequence to another with the help of Encoder and Decoder, but it does not
    use recurrent networks or LSTM. Instead it uses the attention mechanism which
    allows it to look at other positions in the input sequence to help improve encoding.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Here is an example, well-explained by Jay Alammar. Suppose we want to translate
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '"The animal didn''t cross the street because it was too tired"'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: What does "it" refer to?  Humans understand that "it" refers to the animal,
    not the street, but this question is hard for computers.  When encoding the word
    "it", the self-attention mechanism focuses on "The Animal" and associates these
    words with "it".
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![Transformer Self-Attention Mechanism](../Images/90f5c8c65f8f3dc6a706383cc8c4d0ab.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
- en: '**Fig. 4: As transformer is encoding the word "it", part of the attention mechanism
    was focusing on "The Animal", and connected its representation into the encoding
    of "it".** ([Source](https://jalammar.github.io/illustrated-transformer/).)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Google reports that Transformer has significantly outperformed other approaches
    on translation tasks. Transformer architecture was used in many NLP frameworks,
    such as BERT (**B**idirectional **E**ncoder **R**epresentations from **T**ransformers)
    and its descendants.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: For a great visual illustration, see [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/),
    by Jay Alammar. *Written by [Gregory Piatetsky](/author/gregory-piatetsky)*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[20 AI, Data Science, Machine Learning Terms You Need to Know in 2020 (Part
    1)](https://www.kdnuggets.com/2020/02/ai-data-science-machine-learning-key-terms-2020.html)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277 Data Science Key Terms, Explained](https://www.kdnuggets.com/2017/09/data-science-key-terms-explained.html)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What is Data Science?](https://www.kdnuggets.com/2019/11/what-is-data-science.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Building a solid data team](https://www.kdnuggets.com/2021/12/build-solid-data-team.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Write Clean Python Code Using Pipes](https://www.kdnuggets.com/2021/12/write-clean-python-code-pipes.html)'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
