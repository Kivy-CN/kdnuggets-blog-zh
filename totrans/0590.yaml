- en: An Overview of Hugging Face Diffusers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Hugging Face Diffusers 概览
- en: 原文：[https://www.kdnuggets.com/an-overview-of-hugging-face-diffusers](https://www.kdnuggets.com/an-overview-of-hugging-face-diffusers)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/an-overview-of-hugging-face-diffusers](https://www.kdnuggets.com/an-overview-of-hugging-face-diffusers)
- en: '![An Overview of Hugging Face Diffusers](../Images/f6108832a80f1123ece521a4c494e821.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![Hugging Face Diffusers 概览](../Images/f6108832a80f1123ece521a4c494e821.png)'
- en: Image by Author
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - 支持您的组织的
    IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Diffusers is a Python library developed and maintained by HuggingFace. It simplifies
    the development and inference of Diffusion models for generating images from user-defined
    prompts. The code is openly available on [GitHub](https://github.com/huggingface/diffusers)
    with 22.4k stars on the repository. HuggingFace also maintains a wide variety
    of Stable DIffusion and various other diffusion models can be easily used with
    their library.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Diffusers 是一个由 HuggingFace 开发和维护的 Python 库。它简化了从用户定义的提示生成图像的扩散模型的开发和推理。代码在 [GitHub](https://github.com/huggingface/diffusers)
    上公开提供，仓库有 22.4k 星标。HuggingFace 还维护了多种 Stable Diffusion 和其他扩散模型，可以轻松地与其库一起使用。
- en: Installation and Setup
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装和设置
- en: It is good to start with a fresh Python environment to avoid clashes between
    library versions and dependencies.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 从一个新的 Python 环境开始是很好的，以避免库版本和依赖之间的冲突。
- en: 'To set up a fresh Python environment, run the following commands:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置一个新的 Python 环境，请运行以下命令：
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Installing the Diffusers library is straightforward. It is provided as an official
    pip package and internally uses the PyTorch library. In addition, a lot of diffusion
    models are based on the Transformers architecture so loading a model will require
    the transformers pip package as well.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Diffusers 库非常简单。它作为一个官方 pip 包提供，并内部使用 PyTorch 库。此外，许多扩散模型基于 Transformers
    架构，因此加载模型也需要 transformers pip 包。
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Using Diffusers for AI-Generated Images
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Diffusers 生成 AI 图像
- en: The diffuser library makes it extremely easy to generate images from a prompt
    using stable diffusion models. Here, we will go through a simple code line by
    line to see different parts of the Diffusers library.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Diffuser 库使得通过稳定扩散模型从提示生成图像变得非常简单。这里，我们将逐行探讨一个简单的代码，了解 Diffusers 库的不同部分。
- en: Imports
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 导入
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The torch package will be required for the general setup and configuration of
    the diffuser pipeline. The AutoPipelineForText2Image is a class that automatically
    identifies the model that is being loaded, for example, StableDiffusion1-5, StableDiffusion2.1,
    or SDXL, and loads the appropriate classes and modules internally. This saves
    us from the hassle of changing the pipeline whenever we want to load a new model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: torch 包将用于 diffuser 管道的一般设置和配置。AutoPipelineForText2Image 是一个自动识别正在加载的模型的类，例如
    StableDiffusion1-5、StableDiffusion2.1 或 SDXL，并内部加载适当的类和模块。这让我们避免了每次想加载新模型时都需要更改管道的麻烦。
- en: Loading the Models
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 加载模型
- en: A diffusion model is composed of multiple components, including but not limited
    to Text Encoder, UNet, Schedulers, and Variational AutoEncoder. We can separately
    load the modules but the diffusers library provides a builder method that can
    load a pre-trained model given a structured checkpoint directory. For a beginner,
    it may be difficult to know which pipeline to use, so AutoPipeline makes it easier
    to load a model for a specific task.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型由多个组件组成，包括但不限于文本编码器、UNet、调度器和变分自编码器。我们可以单独加载这些模块，但 diffusers 库提供了一个构建方法，可以加载给定结构化检查点目录的预训练模型。对于初学者来说，可能很难知道使用哪个管道，因此
    AutoPipeline 使得为特定任务加载模型变得更容易。
- en: 'In this example, we will load an SDXL model that is openly available on [HuggingFace](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0),
    trained by Stability AI. The files in the directory are structured according to
    their names and each directory has its own safetensors file. The directory structure
    for the SDXL model looks as below:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将加载一个由Stability AI训练的、在[HuggingFace](https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0)上公开提供的SDXL模型。目录中的文件根据其名称进行结构化，每个目录都有自己的safetensors文件。SDXL模型的目录结构如下所示：
- en: '![directory structure for the SDXL model](../Images/13b6b0b3589de3e35e8729d6e8c7f19c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![SDXL模型的目录结构](../Images/13b6b0b3589de3e35e8729d6e8c7f19c.png)'
- en: To load the model in our code, we use the AutoPipelineForText2Image class and
    call the from_pretrained function.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要在我们的代码中加载模型，我们使用AutoPipelineForText2Image类并调用from_pretrained函数。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We provide the model path as the first argument. It can be the HuggingFace model
    card name as above or a local directory where you have the model downloaded beforehand.
    Moreover, we define the model weights precisions as a keyword argument. We normally
    use 32-bit floating-point precision when we have to run the model on a CPU. However,
    running a diffusion model is computationally expensive, and running an inference
    on a CPU device will take hours! For GPU, we either use 16-bit or 32-bit data
    types but 16-bit is preferable as it utilizes lower GPU memory.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将模型路径作为第一个参数提供。它可以是上述的HuggingFace模型卡名称，也可以是您提前下载模型的本地目录。此外，我们将模型权重精度定义为关键字参数。当我们在CPU上运行模型时，通常使用32位浮点精度。然而，运行扩散模型计算成本高昂，且在CPU设备上运行推理将需要几个小时！对于GPU，我们可以使用16位或32位数据类型，但16位更优，因为它利用了较低的GPU内存。
- en: The above command will download the model from HuggingFace and it can take time
    depending on your internet connection. Model sizes can vary from 1GB to over 10GBs.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将从HuggingFace下载模型，下载时间可能会根据您的互联网连接而有所不同。模型的大小可以从1GB到超过10GB不等。
- en: Once a model is loaded, we will need to move the model to the appropriate hardware
    device. Use the following code to move the model to CPU or GPU. Note, for Apple
    Silicon chips, move the model to an MPS device to leverage the GPU on MacOS devices.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦模型加载完成，我们需要将模型移动到合适的硬件设备上。使用以下代码将模型移动到CPU或GPU。请注意，对于Apple Silicon芯片，将模型移动到MPS设备以利用MacOS设备上的GPU。
- en: '[PRE4]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Inference
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推理
- en: 'Now, we are ready to generate images from textual prompts using the loaded
    diffusion model. We can run an inference using the below code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好使用加载的扩散模型从文本提示中生成图像。我们可以使用以下代码进行推理：
- en: '[PRE5]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We can use the pipeline object and call it with multiple keyword arguments to
    control the generated images. We define a prompt as a string parameter describing
    the image we want to generate. Also, we can define the height and width of the
    generated image but it should be in multiples of 8 or 16 due to the underlying
    transformer architecture. In addition, the total inference steps can be tuned
    to control the final image quality. More denoising steps result in higher-quality
    images but take longer to generate.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用管道对象，并通过多个关键字参数调用它以控制生成的图像。我们将提示定义为描述我们希望生成的图像的字符串参数。此外，我们可以定义生成图像的高度和宽度，但应为8或16的倍数，因为底层的变压器架构要求如此。此外，总的推理步骤可以调整以控制最终图像的质量。更多的去噪步骤会生成更高质量的图像，但需要更长时间生成。
- en: Finally, the pipeline returns a list of generated images. We can access the
    first image from the array and can manipulate it as a Pillow image to either save
    or show the image.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，管道返回一个生成的图像列表。我们可以从数组中访问第一个图像，并将其作为Pillow图像进行操作，以便保存或显示图像。
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '![Generated Image](../Images/d66a9e1aa7d812723bc97cbab89a52d4.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![生成的图像](../Images/d66a9e1aa7d812723bc97cbab89a52d4.png)'
- en: Generated Image
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像
- en: Advance Uses
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级用法
- en: The text-2-image example is just a basic tutorial to highlight the underlying
    usage of the Diffusers library. It also provides multiple other functionalities
    including Image-2-image generation, inpainting, outpainting, and control-nets.
    In addition, they provide fine control over each module in the diffusion model.
    They can be used as small building blocks that can be seamlessly integrated to
    create your custom diffusion pipelines. Moreover, they also provide additional
    functionality to train diffusion models on your own datasets and use cases.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到图像的示例只是一个基础教程，旨在突出 Diffusers 库的基本用法。它还提供了多种其他功能，包括图像到图像生成、修复、扩展以及控制网络。此外，它们还提供了对扩散模型中每个模块的精细控制。它们可以作为小型构建块，无缝集成以创建自定义扩散管道。此外，它们还提供了在自己的数据集和用例上训练扩散模型的额外功能。
- en: Wrapping Up
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this article, we went over the basics of the Diffusers library and how to
    make a simple inference using a Diffusion model. It is one of the most used Generative
    AI pipelines in which features and modifications are made every day. There are
    a lot of different use cases and features you can try and the [HuggingFace documentation](https://huggingface.co/docs/diffusers/en/index)
    and [GitHub code](https://github.com/huggingface/diffusers) is the best place
    for you to get started.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们介绍了 Diffusers 库的基础知识以及如何使用扩散模型进行简单的推理。这是最常用的生成 AI 管道之一，每天都有功能和修改。你可以尝试很多不同的用例和功能，而
    [HuggingFace 文档](https://huggingface.co/docs/diffusers/en/index) 和 [GitHub 代码](https://github.com/huggingface/diffusers)
    是你入门的最佳地方。
- en: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal is a machine learning engineer and a technical writer with a profound passion
    for data science and the intersection of AI with medicine. She co-authored the
    ebook "Maximizing Productivity with ChatGPT". As a Google Generation Scholar 2022
    for APAC, she champions diversity and academic excellence. She''s also recognized
    as a Teradata Diversity in Tech Scholar, Mitacs Globalink Research Scholar, and
    Harvard WeCode Scholar. Kanwal is an ardent advocate for change, having founded
    FEMCodes to empower women in STEM fields.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**[](https://www.linkedin.com/in/kanwal-mehreen1/)**[Kanwal Mehreen](https://www.linkedin.com/in/kanwal-mehreen1/)****
    Kanwal 是一位机器学习工程师和技术作家，对数据科学以及 AI 与医学的交叉领域充满热情。她共同撰写了电子书《用 ChatGPT 最大化生产力》。作为
    2022 年 APAC 地区的 Google Generation 学者，她倡导多样性和学术卓越。她还被认可为 Teradata 技术多样性学者、Mitacs
    Globalink 研究学者和哈佛 WeCode 学者。Kanwal 是变革的积极倡导者，创立了 FEMCodes，旨在赋能 STEM 领域的女性。'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Top 10 Machine Learning Demos: Hugging Face Spaces Edition](https://www.kdnuggets.com/2022/05/top-10-machine-learning-demos-hugging-face-spaces-edition.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[前 10 名机器学习演示：Hugging Face Spaces 版](https://www.kdnuggets.com/2022/05/top-10-machine-learning-demos-hugging-face-spaces-edition.html)'
- en: '[A community developing a Hugging Face for customer data modeling](https://www.kdnuggets.com/2022/08/objectiv-community-developing-hugging-face-customer-data-modeling.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个社区正在为客户数据建模开发 Hugging Face](https://www.kdnuggets.com/2022/08/objectiv-community-developing-hugging-face-customer-data-modeling.html)'
- en: '[Build AI Chatbot in 5 Minutes with Hugging Face and Gradio](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用 Hugging Face 和 Gradio 在 5 分钟内构建 AI 聊天机器人](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
- en: '[How to Use Hugging Face AutoTrain to Fine-tune LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face AutoTrain 对 LLM 进行微调](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
- en: '[How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain](https://www.kdnuggets.com/how-to-finetune-mistral-ai-7b-llm-with-hugging-face-autotrain)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Hugging Face AutoTrain 微调 Mistral AI 7B LLM](https://www.kdnuggets.com/how-to-finetune-mistral-ai-7b-llm-with-hugging-face-autotrain)'
- en: '[Mistral 7B-V0.2: Fine-Tuning Mistral’s New Open-Source LLM with…](https://www.kdnuggets.com/mistral-7b-v02-fine-tuning-mistral-new-open-source-llm-with-hugging-face)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mistral 7B-V0.2：使用 Hugging Face 微调 Mistral 的新开源 LLM](https://www.kdnuggets.com/mistral-7b-v02-fine-tuning-mistral-new-open-source-llm-with-hugging-face)'
