- en: Fast Gradient Boosting with CatBoost
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CatBoost 进行快速梯度提升
- en: 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html](https://www.kdnuggets.com/2020/10/fast-gradient-boosting-catboost.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: In gradient boosting, predictions are made from an ensemble of weak learners.
    Unlike a random forest that creates a decision tree for each sample, in gradient
    boosting, trees are created one after the other. Previous trees in the model are
    not altered. Results from the previous tree are used to improve the next one.
    In this piece, we’ll take a closer look at a gradient boosting library called
    CatBoost.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在梯度提升中，预测是通过一组弱学习器进行的。与为每个样本创建决策树的随机森林不同，梯度提升中树是一个接一个地创建的。模型中的前一棵树不会被更改。前一棵树的结果用于改进下一棵树。在本文中，我们将更详细地了解一种称为
    CatBoost 的梯度提升库。
- en: '![Figure](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/94e889b5133e25e115ddeb1ea1e6afd7.png)'
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
- en: '* * *'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业道路。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '[CatBoost](https://github.com/catboost) is a depth-wise gradient boosting library
    developed by [Yandex](https://yandex.com/company/). It uses oblivious decision
    trees to grow a balanced tree. The same features are used to make left and right
    splits for each level of the tree.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[CatBoost](https://github.com/catboost) 是由 [Yandex](https://yandex.com/company/)
    开发的深度梯度提升库。它使用无感知决策树来生成平衡树。在树的每一层中，使用相同的特征来进行左右分裂。'
- en: '![Figure](../Images/22cec580000a5a651f8a7b907b81bca5.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/22cec580000a5a651f8a7b907b81bca5.png)'
- en: '[source](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[来源](https://catboost.ai/news/catboost-enables-fast-gradient-boosting-on-decision-trees-using-gpus)'
- en: As compared to classic trees, the oblivious trees are more efficient to implement
    on CPU and are simple to fit.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 与经典树相比，无感知树在 CPU 上的实现更高效，且更容易拟合。
- en: Dealing with Categorical Features
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理分类特征
- en: The common ways of handling categorical in machine learning are one-hot encoding
    and label encoding. CatBoost allows you to use categorical features without the
    need to pre-process them.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中处理分类变量的常见方法是独热编码和标签编码。CatBoost 允许你使用分类特征而无需预处理。
- en: When using CatBoost, we shouldn’t use one-hot encoding, as this will affect
    the training speed, as well as the quality of predictions. Instead, we simply
    specify the categorical features using the `cat_features` parameter.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 CatBoost 时，我们不应使用独热编码，因为这会影响训练速度以及预测质量。相反，我们只需使用 `cat_features` 参数来指定分类特征。
- en: Advantages of using CatBoost
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 CatBoost 的优点
- en: 'Here are a few reasons to consider using CatBoost:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是考虑使用 CatBoost 的几个理由：
- en: CatBoost allows for training of data on several GPUs.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CatBoost 允许在多个 GPU 上进行数据训练。
- en: It provides great results with default parameters, hence reducing the time needed
    for parameter tuning.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用默认参数可以获得很好的结果，从而减少了参数调整所需的时间。
- en: Offers improved accuracy due to reduced overfitting.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于过拟合减少，精度得到提高。
- en: Use of CatBoost’s model applier for fast prediction.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CatBoost 的模型应用程序进行快速预测。
- en: Trained CatBoost models can be exported to Core ML for on-device inference (iOS).
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练好的 CatBoost 模型可以导出到 Core ML 以进行设备端推断（iOS）。
- en: Can handle missing values internally.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以内部处理缺失值。
- en: Can be used for regression and classification problems.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以用于回归和分类问题。
- en: Training Parameters
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练参数
- en: 'Let’s look at the common parameters in CatBoost:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 CatBoost 中的常见参数：
- en: '`loss_function` alias as `objective` — Metric used for training. These are
    regression metrics such as root mean squared error for regression and logloss
    for classification.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`loss_function` 别名 `objective` — 用于训练的指标。这些是回归指标，例如回归的均方根误差和分类的对数损失。'
- en: '`eval_metric` — Metric used for detecting overfitting.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`eval_metric` — 用于检测过拟合的指标。'
- en: '`iterations` — The maximum number of trees to be built, defaults to 1000\.
    It aliases are `num_boost_round`, `n_estimators`, and `num_trees`.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iterations` — 要构建的最大树数量，默认为1000。别名有 `num_boost_round`、`n_estimators` 和 `num_trees`。'
- en: '`learning_rate` alias `eta` — The learning rate that determines how fast or
    slow the model will learn. The default is usually 0.03.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`learning_rate` 别名 `eta` — 确定模型学习速度的学习率。默认值通常为0.03。'
- en: '`random_seed` alias `random_state` — The random seed used for training.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`random_seed` 别名 `random_state` — 用于训练的随机种子。'
- en: '`l2_leaf_reg` alias `reg_lambda` — Coefficient at the L2 regularization term
    of the cost function. The default is 3.0.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`l2_leaf_reg` 别名 `reg_lambda` — 成本函数L2正则化项的系数。默认值为3.0。'
- en: '`bootstrap_type` — Determines the sampling method for the weights of the objects,
    e.g Bayesian, Bernoulli, MVS, and Poisson.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap_type` — 确定对象权重的抽样方法，例如贝叶斯（Bayesian）、伯努利（Bernoulli）、MVS和泊松（Poisson）。'
- en: '`depth` —The depth of the tree.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`depth` — 树的深度。'
- en: '`grow_policy` — Determines how the greedy search algorithm will be applied.
    It can be either `SymmetricTree`, `Depthwise`, or `Lossguide`. `SymmetricTree` is
    the default. In `SymmetricTree`, the tree is built level-by-level until the depth
    is attained. In every step, leaves from the previous tree are split with the same
    condition. When `Depthwise` is chosen, a tree is built step-by-step until the
    specified depth is achieved. On each step, all non-terminal leaves from the last
    tree level are split. The leaves are split using the condition that leads to the
    best loss improvement. In `Lossguide`, the tree is built leaf-by-leaf until the
    specified number of leaves is attained. On each step, the non-terminal leaf with
    the best loss improvement is split'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grow_policy` — 决定贪婪搜索算法的应用方式。可以是 `SymmetricTree`、`Depthwise` 或 `Lossguide`。`SymmetricTree`
    是默认值。在 `SymmetricTree` 中，树按层构建，直到达到指定深度。在每一步中，上一棵树的叶子按照相同条件进行分裂。选择 `Depthwise`
    时，树一步步构建，直到达到指定深度。在每一步中，最后一棵树层的所有非终端叶子都进行分裂。叶子按照最优损失改进条件进行分裂。在 `Lossguide` 中，树逐步构建叶子，直到达到指定数量。在每一步中，最佳损失改进的非终端叶子被分裂。'
- en: '`min_data_in_leaf` alias `min_child_samples` — This is the minimum number of
    training samples in a leaf. This parameter is only used with the `Lossguide` and `Depthwise` growing
    policies.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_data_in_leaf` 别名 `min_child_samples` — 叶子中最小的训练样本数。该参数仅与 `Lossguide` 和
    `Depthwise` 增长策略一起使用。'
- en: '`max_leaves` alias `num_leaves` — This parameter is used only with the `Lossguide` policy
    and determines the number of leaves in the tree.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_leaves` 别名 `num_leaves` — 该参数仅与 `Lossguide` 策略一起使用，决定树中的叶子数量。'
- en: '`ignored_features` — Indicates the features that should be ignored in the training
    process.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ignored_features` — 指示在训练过程中应忽略的特征。'
- en: '`nan_mode` — The method for dealing with missing values. The options are `Forbidden`, `Min`,
    and `Max`. The default is `Min`. When `Forbidden` is used, the presence of missing
    values leads to errors. With `Min`, the missing values are taken as the minimum
    values for that feature. In `Max`, the missing values are treated as the maximum
    value for the feature.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nan_mode` — 处理缺失值的方法。选项有 `Forbidden`、`Min` 和 `Max`。默认值为 `Min`。使用 `Forbidden`
    时，缺失值的存在会导致错误。使用 `Min` 时，缺失值被视为该特征的最小值。在 `Max` 中，缺失值被视为该特征的最大值。'
- en: '`leaf_estimation_method` — The method used to calculate values in leaves. In
    classification, 10 `Newton` iterations are used. Regression problems using quantile
    or MAE loss use one `Exact` iteration. Multi classification uses one `Netwon` iteration.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaf_estimation_method` — 用于计算叶子值的方法。在分类中，使用10次 `Newton` 迭代。回归问题使用分位数或MAE损失则使用一次
    `Exact` 迭代。多分类使用一次 `Newton` 迭代。'
- en: '`leaf_estimation_backtracking` — The type of backtracking to be used during
    gradient descent. The default is `AnyImprovement`. `AnyImprovement` decreases
    the descent step, up to where the loss function value is smaller than it was in
    the last iteration. `Armijo` reduces the descent step until the [Armijo condition](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature) is
    met.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`leaf_estimation_backtracking` — 在梯度下降过程中使用的回溯类型。默认值是 `AnyImprovement`。`AnyImprovement`
    减少下降步长，直到损失函数值小于上次迭代中的值。`Armijo` 减少下降步长，直到满足 [Armijo 条件](https://en.wikipedia.org/wiki/Wolfe_conditions#Armijo_rule_and_curvature)。'
- en: '`boosting_type` — The boosting scheme. It can be `plain` for the classic gradient
    boosting scheme, or `ordered`, which offers better quality on smaller datasets.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`boosting_type` — 提升方案。可以是 `plain`，用于经典的梯度提升方案，或者 `ordered`，它在较小的数据集上提供更好的质量。'
- en: '`score_function` — The [score type](https://catboost.ai/docs/concepts/algorithm-score-functions.html) used
    to select the next split during tree construction. `Cosine` is the default option.
    The other available options are `L2`, `NewtonL2`, and `NewtonCosine`.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`score_function` — 用于选择树构建过程中下一个分裂的 [评分类型](https://catboost.ai/docs/concepts/algorithm-score-functions.html)。`Cosine`
    是默认选项。其他可用选项包括 `L2`、`NewtonL2` 和 `NewtonCosine`。'
- en: '`early_stopping_rounds` — When `True`, sets the overfitting detector type to `Iter` and
    stops the training when the optimal metric is achieved.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`early_stopping_rounds` — 当设置为 `True` 时，将过拟合检测器类型设置为 `Iter` 并在达到最佳指标时停止训练。'
- en: '`classes_count` — The number of classes for multi-classification problems.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`classes_count` — 多分类问题中的类别数。'
- en: '`task_type` — Whether you are using a CPU or GPU. CPU is the default.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`task_type` — 指示你是使用 CPU 还是 GPU。CPU 是默认选项。'
- en: '`devices` — The IDs of the GPU devices to be used for training.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`devices` — 用于训练的 GPU 设备的 ID。'
- en: '`cat_features` — The array with the categorical columns.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cat_features` — 包含分类列的数组。'
- en: '`text_features` —Used to declare text columns in classification problems.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`text_features` — 用于声明分类问题中的文本列。'
- en: Regression Example
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 回归示例
- en: CatBoost uses the scikit-learn standard in its implementation. Let’s see how
    we can use it for regression.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 在实现中使用了 scikit-learn 标准。让我们看看如何使用它进行回归分析。
- en: The first step — as always — is to import the regressor and instantiate it.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步——像往常一样——是导入回归器并实例化它。
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'When fitting the model, CatBoost also enables use to visualize it by setting `plot=true`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型时，CatBoost 还允许我们通过设置 `plot=true` 进行可视化：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '![Image for post](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![发布图像](../Images/b7a07bcc879003b93fae2c1c40b964b5.png)'
- en: 'It also allows you to perform cross-validation and visualize the process:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它还允许你执行交叉验证并可视化过程：
- en: '![Image for post](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![发布图像](../Images/cc4a7d964a02c88e7ad3997232ab4d69.png)'
- en: 'Similarly, you can also perform grid search and visualize it:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，你也可以执行网格搜索并进行可视化：
- en: '![Image for post](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![发布图像](../Images/2abad5ea87a4baf9e06c9f175d29840a.png)'
- en: We can also use CatBoost to plot a tree. Here’s the plot is for the first tree.
    As you can see from the tree, the leaves on every level are being split on the
    same condition—e.g 297, value >0.5.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用 CatBoost 绘制树。这里的图是第一棵树的绘图。正如你从树中看到的，每一层的叶子都在相同条件下进行分裂——例如 297，值 >0.5。
- en: '[PRE2]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '![Image for post](../Images/1bf072864f605a5db714f0a388c18dd4.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![发布图像](../Images/1bf072864f605a5db714f0a388c18dd4.png)'
- en: CatBoost also gives us a dictionary with all the model parameters. We can print
    them by iterating through the dictionary.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 还为我们提供了一个包含所有模型参数的字典。我们可以通过遍历字典来打印它们。
- en: '[PRE3]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Image for post](../Images/33f889fb3e9caa39f98841f2938006c5.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![发布图像](../Images/33f889fb3e9caa39f98841f2938006c5.png)'
- en: Final Thoughts
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最终想法
- en: In this piece, we’ve explored the benefits and limitations of CatBoost, along
    with its primary training parameters. Then, we worked through a simple regression
    implementation with scikit-learn. Hopefully this gives you enough information
    on the library so that you can explore it further.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们探讨了 CatBoost 的优缺点及其主要训练参数。然后，我们通过 scikit-learn 完成了一个简单的回归实现。希望这能为你提供足够的信息，以便你可以进一步探索该库。
- en: '[**CatBoost - state-of-the-art open-source gradient boosting library with categorical
    features support**](https://catboost.ai/)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[**CatBoost - 最先进的开源梯度提升库，支持类别特征**](https://catboost.ai/)'
- en: CatBoost is an algorithm for gradient boosting on decision trees. It is developed
    by Yandex researchers and engineers...
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: CatBoost 是一种决策树上的梯度提升算法。它由 Yandex 的研究人员和工程师开发...
- en: '[**The Data Science Bootcamp in Python**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[**Python 数据科学训练营**](https://www.udemy.com/course/data-science-bootcamp-in-python/?referralCode=9F6DFBC3F92C44E8C7F4)'
- en: Learn Python for Data Science,NumPy,Pandas,Matplotlib,Seaborn,Scikit-learn,
    Dask,LightGBM,XGBoost,CatBoost and much...
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 学习 Python 数据科学、NumPy、Pandas、Matplotlib、Seaborn、Scikit-learn、Dask、LightGBM、XGBoost、CatBoost
    等等…
- en: '**Bio: [Derrick Mwiti](https://derrickmwiti.com/)** is a data analyst, a writer,
    and a mentor. He is driven by delivering great results in every task, and is a
    mentor at Lapid Leaders Africa.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介：[Derrick Mwiti](https://derrickmwiti.com/)** 是数据分析师、作家和导师。他致力于在每个任务中提供出色的成果，并且是
    Lapid Leaders Africa 的导师。'
- en: '[Original](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a).
    Reposted with permission.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://heartbeat.fritz.ai/fast-gradient-boosting-with-catboost-38779b0d5d9a)。经许可转载。'
- en: '**Related:**'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[LightGBM: A Highly-Efficient Gradient Boosting Decision Tree](/2020/06/lightgbm-gradient-boosting-decision-tree.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[LightGBM：高效的梯度提升决策树](/2020/06/lightgbm-gradient-boosting-decision-tree.html)'
- en: '[Understanding Gradient Boosting Machines](/2019/02/understanding-gradient-boosting-machines.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[理解梯度提升机](/2019/02/understanding-gradient-boosting-machines.html)'
- en: '[Mastering Fast Gradient Boosting on Google Colaboratory with free GPU](/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Google Colaboratory 上使用免费 GPU 掌握快速梯度提升](/2019/03/mastering-fast-gradient-boosting-google-colaboratory-free-gpu.html)'
- en: More On This Topic
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Top 5 Advantages That CatBoost ML Brings to Your Data to Make it Purr](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[CatBoost ML 为您的数据带来的 5 大优势，让数据更“喵”](https://www.kdnuggets.com/2023/02/top-5-advantages-catboost-ml-brings-data-make-purr.html)'
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**掌握季节性和提升商业结果的终极指南**](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[How Fast Can BERT Go With Sparsity?](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[BERT 在稀疏性下能有多快？](https://www.kdnuggets.com/2022/04/fast-bert-go-sparsity.html)'
- en: '[Speed up Machine Learning with Fast Kriging (FKR)](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过快速克里金（FKR）加速机器学习](https://www.kdnuggets.com/2022/06/vmc-speed-machine-learning-fast-kriging.html)'
- en: '[How to Make Python Code Run Incredibly Fast](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何让 Python 代码运行得非常快](https://www.kdnuggets.com/2021/06/make-python-code-run-incredibly-fast.html)'
