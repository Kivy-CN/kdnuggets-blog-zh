# 初学者的 Python 线性回归指南，使用 Scikit-Learn

> 原文：[https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html/2](https://www.kdnuggets.com/2019/03/beginners-guide-linear-regression-python-scikit-learn.html/2)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2019/03/beginners-guide-linear-regression-python-scikit-learn.html?page=2#comments)

### 多元线性回归

![图](../Images/4f15f7ec4a039d35457676f74b14112c.png)

[来源](https://hackernoon.com/an-intuitive-perspective-to-linear-regression-7dc566b2c14c)

我们刚刚在上面的部分中进行了涉及两个变量的线性回归。几乎所有你将遇到的现实世界问题都将涉及多个变量。涉及多个变量的线性回归称为“多元线性回归”或多变量线性回归。执行多元线性回归的步骤几乎与简单线性回归相似。区别在于评估。你可以使用它来找出哪个因素对预测输出影响最大，以及不同变量之间的关系。

在这一部分，我下载了红酒质量数据集。数据集与葡萄牙的红酒变种“[Vinho Verde](https://en.wikipedia.org/wiki/Vinho_Verde)”相关。由于隐私和物流问题，只有物理化学（输入）和感官（输出）变量可用（例如，没有关于葡萄类型、酒品牌、酒售价等的数据）。

你可以从[这里](https://drive.google.com/open?id=195gkZ5cTZL11L308MHc7EyBbAoiB4xqf)下载数据集。

我们将考虑各种输入特征，如固定酸度、挥发酸度、柠檬酸、残余糖、氯化物、游离二氧化硫、总二氧化硫、密度、pH 值、硫酸盐、酒精。基于这些特征，我们将预测葡萄酒的质量。

现在，让我们开始编码：

导入所有所需的库：

```py
import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
import seaborn as seabornInstance 
from sklearn.model_selection import train_test_split 
from sklearn.linear_model import LinearRegression
from sklearn import metrics
%matplotlib inline
```

以下命令从你通过上面的链接下载的文件中导入数据集：

```py
dataset = pd.read_csv('/Users/nageshsinghchauhan/Documents/projects/ML/ML_BLOG_LInearRegression/winequality.csv')
```

让我们通过检查数据中的行数和列数来探索一下数据。

```py
dataset.shape
```

它将输出 (1599, 12)，这意味着我们的数据集有 1599 行和 12 列。

要查看数据集的统计细节，我们可以使用`describe()`：

```py
dataset.describe()
```

![](../Images/a825b7f56a565fe80e2b6edb8e822331.png)

让我们稍微清理一下数据，所以首先检查哪些列包含 NaN 值：

```py
dataset.isnull().any()
```

执行上述代码后，所有列应该都返回 False。如果某列返回 True，则使用下面的代码从该列中删除所有空值。

```py
dataset = dataset.fillna(method='ffill')
```

我们的下一步是将数据分成“特征”和“标签”。X 变量包含所有特征/属性，y 变量包含标签。

```py
X = dataset[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates','alcohol']].values

y = dataset['quality'].values
```

让我们检查“质量”列的平均值。

```py
plt.figure(figsize=(15,10))
plt.tight_layout()
seabornInstance.distplot(dataset['quality'])
```

![图](../Images/d2a4e1ae90c77b97c853af7273e45f39.png)

葡萄酒质量的平均值。

正如我们所观察到的，大多数时候值要么是5，要么是6。

接下来，我们将80%的数据拆分为训练集，20%的数据拆分为测试集，使用下面的代码。

```py
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

现在让我们训练我们的模型。

```py
regressor = LinearRegression()  
regressor.fit(X_train, y_train)
```

正如之前所述，在多变量线性回归的情况下，回归模型必须为所有属性找到最优系数。要查看我们的回归模型选择了哪些系数，请执行以下脚本：

```py
coeff_df = pd.DataFrame(regressor.coef_, X.columns, columns=['Coefficient'])  
coeff_df
```

它应该会给出类似这样的输出：

![](../Images/11216eb6645322e26e5e34683b070353.png)

*这意味着“密度”每增加一个单位，酒的质量就会减少31.51单位。类似地，“氯化物”每减少一个单位，酒的质量就会增加1.87单位。我们可以看到，其余的特征对酒的质量影响很小。*

现在让我们对测试数据进行预测。

```py
y_pred = regressor.predict(X_test)
```

检查实际值与预测值之间的差异。

```py
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

df1 = df.head(25)
```

![图示](../Images/9e88cabf6460129f7099a75310035b09.png)

实际值与预测值的比较

现在让我们绘制实际值与预测值的比较图

```py
df1.plot(kind='bar',figsize=(10,8))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()
```

![图示](../Images/77e0fc97f77526698c8b0b2ce15a0cff.png)

条形图显示实际值与预测值之间的差异

正如我们在这里观察到的，我们的模型返回了相当好的预测结果。

最后一步是评估算法的性能。我们将通过计算[MAE](https://en.wikipedia.org/wiki/Mean_absolute_error)、[MSE](https://en.wikipedia.org/wiki/Mean_squared_error)和[RMSE](https://en.wikipedia.org/wiki/Root-mean-square_deviation)的值来实现。请执行以下脚本：

```py
print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  
print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  
print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
```

输出如下：

```py
('Mean Absolute Error:', 0.46963309286611077)
('Mean Squared Error:', 0.38447119782012446)
('Root Mean Squared Error:', 0.6200574149384268)
```

你可以看到根均方误差的值为0.62，这比所有州的平均气体消耗值5.63的10%略大。这意味着我们的算法不是很准确，但仍能做出相当好的预测。

可能导致这种不准确性的因素有很多，例如：

+   **需要更多数据**：我们需要大量数据才能获得最佳预测结果。

+   **错误的假设**：我们假设这些数据具有线性关系，但情况可能并非如此。可视化数据可能会帮助你确定这一点。

+   **糟糕的特征**：我们使用的特征可能与我们试图预测的值的相关性不够高。

### **结论**

在这篇文章中，我们研究了最基础的机器学习算法，即线性回归。我们在Scikit-Learn机器学习库的帮助下实现了简单线性回归和多重线性回归。

希望大家喜欢这篇文章。如果有任何疑问或建议，请在评论区告知我。

感谢阅读。

你也可以通过[**LinkedIn**](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)联系我。

快乐学习!!!

**简介：[纳戈什·辛格·乔汉](https://www.linkedin.com/in/nagesh-singh-chauhan-6936bb13b/)** 是一位数据科学爱好者，对大数据、Python 和机器学习感兴趣。

[原文](https://towardsdatascience.com/a-beginners-guide-to-linear-regression-in-python-with-scikit-learn-83a8f7ae2b4f)。经许可转载。

**相关内容：**

+   [针对绝对初学者的 Numpy 神经网络——第2部分：线性回归](/2019/03/neural-networks-numpy-absolute-beginners-part-2-linear-regression.html)

+   [Scikit Learn 介绍：Python 机器学习的黄金标准](/2019/02/introduction-scikit-learn-gold-standard-python-machine-learning.html)

+   [Python 数据科学入门](/2019/02/python-data-science-beginners.html)

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速开启网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的IT工作

* * *

### 更多相关话题

+   [预测：Python 中线性回归的初学者指南](https://www.kdnuggets.com/2023/06/making-predictions-beginner-guide-linear-regression-python.html)

+   [线性回归与逻辑回归的比较](https://www.kdnuggets.com/2022/11/comparing-linear-logistic-regression.html)

+   [使用线性回归模型而非……的3个理由](https://www.kdnuggets.com/2021/08/3-reasons-linear-regression-instead-neural-networks.html)

+   [线性回归与逻辑回归：简明解释](https://www.kdnuggets.com/2022/03/linear-logistic-regression-succinct-explanation.html)

+   [KDnuggets 新闻 22:n12, 3月23日：最佳数据科学书籍……](https://www.kdnuggets.com/2022/n12.html)

+   [数据科学中的线性回归](https://www.kdnuggets.com/2022/07/linear-regression-data-science.html)
