- en: 5 Ways to Get Started with Reinforcement Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2017/09/5-ways-get-started-reinforcement-learning.html](https://www.kdnuggets.com/2017/09/5-ways-get-started-reinforcement-learning.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/b1f1892f4476b0d4d7ff79f1901c2b3a.png)'
  prefs: []
  type: TYPE_IMG
- en: Artwork by [Robert Aguilera](http://robertaguileradesign.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning algorithms, and neural networks in particular, are considered
    to be the cause of a new AI ‘revolution’. In this article I will introduce the
    concept of reinforcement learning but with limited technical details so that readers
    with a variety of backgrounds can understand the essence of the technique, its
    capabilities and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: '*At the end of the article, I will provide* ***links*** *to a few* ***resources***
    *for implementing RL.*'
  prefs: []
  type: TYPE_NORMAL
- en: What is Reinforcement Learning?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Broadly speaking, data-driven algorithms can be categorized into three types:
    **Supervised**, **Unsupervised**, and **Reinforcement** learning.'
  prefs: []
  type: TYPE_NORMAL
- en: The first two are generally used to perform tasks such as image classification,
    detection, etc. While their accuracy is remarkable, these tasks differ from those
    that we would expect from an ‘intelligent’ being.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where reinforcement learning comes in. The concept itself is very simple,
    and much like our evolutionary process: the environment rewards the agent for
    things that it gets right and penalizes it for things that it gets wrong. The
    main challenge is developing the capacity to learn several million possible ways
    of doing things.'
  prefs: []
  type: TYPE_NORMAL
- en: Q Learning & Deep Q Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Q learning is a widely used reinforcement learning algorithm. Without going
    into the detailed math, the given quality of an action is determined by what state
    the agent is in. The agent usually performs the action which gives it the maximum
    reward. The detailed math can be found [**here**](https://en.wikipedia.org/wiki/Q-learning).
  prefs: []
  type: TYPE_NORMAL
- en: In this algorithm, the agent learns the quality(Q value) of each action (action
    is also called policy) based on how much reward the environment gave it. The value
    of each environment’s state, along with the Q value is usually stored in a table.
    As the agent interacts with the environment, the Q values get updated from random
    values to values that actually help maximize reward.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Q Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The problem with using Q learning with tables is that it doesn’t scale well.
    If the number of states is too high, the table will not fit in memory. This is
    where Deep Q learning could be applied. Deep learning is basically just a universal
    approximation machine which can understand and come up with abstract representations.
    Deep learning can be used to approximate Q values, and it can also easily learn
    optimal Q values by using gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: '*Fun Fact:*'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Google has a patent on some elements of Deep Q learning: [US20150100530](https://www.google.com/patents/US20150100530)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Exploration vs Exploitation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is often the case that the agent memorizes one path and will never try to
    explore any other paths. In general, we would like an agent to not only exploit
    good paths, but also sometimes explore new paths that it can perform actions in.
    Therefore, a hyper-parameter, named *ε,* is used to govern how much to explore
    new paths vs how much to exploit old paths.
  prefs: []
  type: TYPE_NORMAL
- en: Experience Replay
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When training a neural network, data imbalance plays a very important role.
    If a model is trained as the agent interacts with the environment, there will
    be imbalances. The most recent play will obviously have more bearing than older
    plays.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, all the states, along with related data, is stored in the memory,
    and the neural network can randomly pick a batch of some interactions and learn
    (this makes it very similar to supervised learning).
  prefs: []
  type: TYPE_NORMAL
- en: The Training Framework
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is what the whole framework for deep Q learning looks like. Note the *γ*.
    This represents the discounted reward. It is a hyperparameter that controls how
    much weight the future reward will have. The symbol***´*** denotes next. e.g.
    s´ denotes next state.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bec61ce4815420ff287ea8593a29a62e.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 1.0** Deep Q Learning training framework. Credit: [Robert Aguilera](http://robertaguileradesign.com/)'
  prefs: []
  type: TYPE_NORMAL
- en: Extending Reinforcement Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reinforcement learning works well with many things (such as [**AlphaGo**](https://deepmind.com/research/alphago/)),
    but it often fails in places where the feedback is sparse. The agent will not
    explore behaviors that are actually beneficial in the long term. Sometimes, exploring
    some actions is needed for its own sake (intrinsic motivation) instead of directly
    trying to solve problems.
  prefs: []
  type: TYPE_NORMAL
- en: Doing this allows the agent to perform complicated actions and essentially allows
    the agent to ‘plan’ things. [**Hierarchical Learning**](https://arxiv.org/pdf/1604.06057.pdf)
    allows for such kinds of abstract learning.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/df0237426aeb85f512c80ad4af86a8de.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 2.0 Hierarchical Deep Q learning**'
  prefs: []
  type: TYPE_NORMAL
- en: In this kind of a setup, there are two Q networks. They are represented as the
    controller and meta-controller. The meta controller looks at the raw states and
    calculates which ‘goal’ to follow. The controller takes in the states along with
    the goal and outputs a policy to solve the goal. The critic checks if the goal
    is reached and gives some reward to the controller. The controller stops when
    the episode ends, or when the goal is reached. The meta controller then chooses
    a new goal, and this repeats.
  prefs: []
  type: TYPE_NORMAL
- en: The ‘goal’ is something that will eventually help the agent get to the final
    reward. This is better because it’s possible to have Q learning on top of Q learning
    in a hierarchical fashion.
  prefs: []
  type: TYPE_NORMAL
- en: Introductory Resources for Reinforcement Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This list will be helpful for those who are looking to get started with Reinforcement
    Learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[**The Basics of Deep Q Learning**](https://www.intelnervana.com/demystifying-deep-reinforcement-learning/).
    Very helpful for understanding the math and processes of Reinforcement Learning.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**The Hierarchical Learning paper**](https://arxiv.org/pdf/1604.06057.pdf),
    for those who want to understand Hierarchical Learning in detail.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Hierarchical Learning paper explanation**](https://www.youtube.com/watch?v=tyRUql_ZR7Q)
    video from the authors.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Deep RL: An Overview**](https://arxiv.org/abs/1701.07274) What I would consider
    the Reinforcement Learning handbook. It covers nearly every aspect of RL that
    is required to understand the current level of research. It delves deep into the
    math, but also provides high-level overviews.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[**Implementing Deep Q learning with a single python script.**](https://gist.github.com/EderSantana/c7222daa328f0e885093#file-qlearn-py-L157)
    Perhaps the simplest deep Q learning implementation. This is very easy to read
    and a great starting point.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](../Images/3373f1c2c0122aa4b193371fc9365e4d.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Figure 3.0 Deep Q Learning in action.** Output of python script in Point
    5'
  prefs: []
  type: TYPE_NORMAL
- en: Call to Action
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you have comments or questions, feel free to respond to this article below.
  prefs: []
  type: TYPE_NORMAL
- en: '***Big thanks to*** [***Robert Aguilera***](http://robertaguileradesign.com/)
    ***for making the Artwork and the flowchart.***'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://buzzrobot.com/5-ways-to-get-started-with-reinforcement-learning-b96d1989c575).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Transforming from Autonomous to Smart: Reinforcement Learning Basics](/2017/08/transforming-autonomous-smart-reinforcement-learning-basics.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Learning Zero to One: 5 Awe-Inspiring Demos with Code for Beginners](/2017/06/deep-learning-demos-code-beginners.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Next Challenges for Reinforcement Learning](/2017/03/next-challenges-reinforcement-learning.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[3 Possible Ways to Get into Data Science](https://www.kdnuggets.com/2022/03/3-possible-ways-get-data-science.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Federated Learning: Collaborative Machine Learning with a Tutorial…](https://www.kdnuggets.com/2021/12/federated-learning-collaborative-machine-learning-tutorial-get-started.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7 Beginner-Friendly Projects to Get You Started with ChatGPT](https://www.kdnuggets.com/2023/08/7-beginnerfriendly-projects-get-started-chatgpt.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Free Must-Take Data Science Courses to Get Started](https://www.kdnuggets.com/10-free-must-take-data-science-courses-to-get-started)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why Upskilling in Data Vis Matters (& How to Get Started)](https://www.kdnuggets.com/2022/07/sphere-upskilling-data-vis-matters.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3 Benefits to A/B Testing (+ Where to Get Started)](https://www.kdnuggets.com/2022/08/sphere-3-benefits-ab-testing-get-started.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
