- en: Resurgence of AI During 1983-2010
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1983-2010年间的人工智能复兴
- en: 原文：[https://www.kdnuggets.com/2018/02/resurgence-ai-1983-2010.html](https://www.kdnuggets.com/2018/02/resurgence-ai-1983-2010.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/02/resurgence-ai-1983-2010.html](https://www.kdnuggets.com/2018/02/resurgence-ai-1983-2010.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: Prologue
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 序言
- en: 'Every decade seems to have its technological buzzwords: we had personal computers
    in 1980s; Internet and worldwide web in 1990s; smart phones and social media in
    2000s; and Artificial Intelligence (AI) and Machine Learning in this decade. However,
    the field of AI is 67 years old and this is the second of a series of five articles
    wherein:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 每个十年似乎都有其技术流行词：1980年代有个人计算机；1990年代有互联网和万维网；2000年代有智能手机和社交媒体；而这个十年则是人工智能（AI）和机器学习。尽管如此，AI领域已经有67年的历史，这是五篇系列文章中的第二篇，其中：
- en: The [first article discusses the genesis of AI and the first hype cycle during
    1950 and 1982](/2018/02/birth-ai-first-hype-cycle.html)
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[第一篇文章讨论了人工智能的起源以及1950年至1982年的首次炒作周期](/2018/02/birth-ai-first-hype-cycle.html)'
- en: This article discusses a resurgence of AI and its achievements during 1983-2010
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 本文讨论了人工智能的复兴及其在1983-2010年间的成就
- en: The [third article discusses the domains in which AI systems are already rivaling
    humans](https://www.kdnuggets.com/2018/02/domains-ai-rivaling-humans.html)
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[第三篇文章讨论了人工智能系统已经与人类竞争的领域](https://www.kdnuggets.com/2018/02/domains-ai-rivaling-humans.html)'
- en: The [fourth article discusses the current hype cycle in Artificial Intelligence](https://www.kdnuggets.com/2018/02/current-hype-cycle-artificial-intelligence.html)
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[第四篇文章讨论了人工智能当前的炒作周期](https://www.kdnuggets.com/2018/02/current-hype-cycle-artificial-intelligence.html)'
- en: The fifth article discusses as to what 2018-2035 may portend for brains, minds
    and machines
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第五篇文章讨论了2018-2035年可能对大脑、思想和机器的预示
- en: '![](../Images/07c9eecdc53dbcbb299083b89dbcb15a.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/07c9eecdc53dbcbb299083b89dbcb15a.png)'
- en: Resurgence of Artificial Intelligence
  id: totrans-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能的复兴
- en: '* * *'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您组织中的IT工作'
- en: '* * *'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: The 1950-82 era saw a new field of Artificial Intelligence (AI) being born,
    lot of pioneering research being done, massive hype being created, and AI going
    into hibernation when this hype did not materialize, and the research funding
    dried up [56]. During 1983 and 2010, research funding ebbed and flowed, and research
    in AI continued to gather steam although "some computer scientists and software
    engineers would avoid the term artificial intelligence for fear of being viewed
    as wild-eyed dreamers" [43].
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 1950-82年间，人工智能（AI）作为一个新领域诞生，进行了大量开创性的研究，产生了巨大的炒作，但当这种炒作没有实现时，AI进入了休眠状态，研究资金也枯竭了[56]。在1983年至2010年期间，研究资金起伏不定，虽然“有些计算机科学家和软件工程师会避免使用‘人工智能’这一术语，以免被视为异想天开的人”[43]，但AI研究依然持续升温。
- en: During 1980s and 90s, researchers realized that many AI solutions could be improved
    by using techniques from mathematics and economics such as game theory, stochastic
    modeling, classical numerical methods, operations research and optimization. Better
    mathematical descriptions were developed for deep neural networks as well as evolutionary
    and genetic algorithms, which matured during this period. All of this led to new
    sub-domains and commercial products in AI being created.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在1980年代和1990年代，研究人员意识到许多AI解决方案可以通过使用数学和经济学中的技术如博弈论、随机建模、经典数值方法、运筹学和优化来改进。更好的数学描述被开发出来用于深度神经网络以及进化和遗传算法，这些在此期间得到了成熟。所有这些都导致了AI中新子领域和商业产品的诞生。
- en: In this article, we first briefly discuss supervised learning, unsupervised
    learning and reinforcement learning, as well as shallow and deep neural networks,
    which became quite popular during this period. Next, we will discuss the following
    six reasons that helped AI research and development in gaining steam – hardware
    and network connectivity became cheaper and faster; parallel and distributed became
    practical, and lots of data ("Big Data") became available for training AI systems.
    Finally, we will discuss a few AI applications that were commercialized during
    this era.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们首先简要讨论了监督学习、无监督学习和强化学习，以及在这一时期变得相当流行的浅层和深层神经网络。接下来，我们将讨论以下六个促使人工智能研究和发展加速的原因——硬件和网络连接变得更便宜和更快；并行和分布式计算变得实际可行，且大量数据（“大数据”）变得可用于训练人工智能系统。最后，我们将讨论一些在这一时期商业化的人工智能应用。
- en: Machine Learning Techniques Improve Substantially
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习技术显著改进
- en: Supervised Machine Learning
  id: totrans-22
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监督机器学习
- en: These techniques require to be trained by humans by using labeled data [58].
    Suppose we are given several thousand pictures of faces of dogs and cats and we
    would like to partition them into two groups – one containing dogs and the other
    cats. Rather than doing it manually, a machine learning expert writes a computer
    program by including the attributes that differentiate dog-faces from cat-faces
    (e.g., length of whiskers, droopy ears, angular faces, round eyes). After enough
    attributes have been included and the program checked for accuracy, the first
    picture is given to this "black box" program. If its output is not the same as
    that provided by a "human trainer" (who may be training in person or has provided
    a pre-labeled picture), this program modifies some of its internal code to ensure
    that its answer becomes the same as that of the trainer (or the pre-labeled picture).
    After going through several thousand such pictures and modifying itself accordingly,
    this black box learns to differentiate the faces of dogs from cats. By 2010, researchers
    had developed many algorithms that could be used inside the black box, most of
    which are mentioned in the Appendix, and today, some applications that commonly
    use these techniques include object recognition, speaker recognition and speech
    to text conversion.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术需要通过使用标记数据进行人工训练[58]。假设我们有几千张狗和猫的面部照片，我们希望将它们分成两组——一组包含狗，另一组包含猫。与其手动完成，不如由机器学习专家编写一个程序，程序中包括区分狗脸和猫脸的属性（例如，胡须长度、垂耳、角脸、圆眼）。在包含足够多的属性并检查程序的准确性后，将第一张图片提供给这个“黑箱”程序。如果其输出与“人类训练者”（可能是现场培训或提供了预标记图片）的输出不相同，程序会修改其内部代码，以确保其答案与训练者（或预标记图片）的答案相同。在经过几千张这样的图片并相应修改后，这个黑箱学会了区分狗脸和猫脸。到2010年，研究人员开发了许多可以在黑箱内部使用的算法，其中大多数在附录中提到，今天，一些常用这些技术的应用包括物体识别、说话人识别和语音转文本转换。
- en: '![](../Images/e60f6aff7ac8000d39b6bcef23fb1faa.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e60f6aff7ac8000d39b6bcef23fb1faa.png)'
- en: Unsupervised learning algorithms
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无监督学习算法
- en: 'These techniques do not require any pre-labeled data and they try to determine
    hidden structure from "unlabeled" data [59]. One important use case of unsupervised
    learning is computing the hidden probability distribution with respect to the
    key attributes and explaining them, e.g., understanding the data by using its
    attributes and then clustering and partitioning it in "similar" groups. There
    are several techniques in unsupervised learning most of which are mentioned in
    the Appendix. Since the data points given to these algorithms are unlabeled, their
    accuracy is usually hard to define. Applications that use unsupervised learning
    include recommender systems (e.g., if a person bought x then will the person by
    y), creating cohorts of groups for marketing purposes (e.g., clustering by gender,
    spending habits, education, zip code), and creating cohorts of patients for improving
    disease management. Since k-means is one of the most common technique, it is briefly
    described below:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术不需要任何预标记的数据，它们尝试从“未标记”的数据中确定隐藏的结构[59]。无监督学习的一个重要应用案例是计算相对于关键属性的隐藏概率分布并进行解释，例如，通过使用数据的属性来理解数据，然后将其分成“相似”的组。无监督学习中有几种技术，其中大多数在附录中提到。由于这些算法所处理的数据点是未标记的，它们的准确性通常很难定义。使用无监督学习的应用包括推荐系统（例如，如果某人购买了x，那么此人是否会购买y）、为营销目的创建群体（例如，按性别、消费习惯、教育程度、邮政编码进行聚类）和为改善疾病管理创建患者群体。由于k-means是最常用的技术之一，因此下面简要描述了它：
- en: 'Suppose we are given a lot of data points each having n attributes (which can
    be labelled as n coordinates) and we want to partition them into k groups. Since
    each group has n coordinates, we can imagine these data points as being in an
    n-dimensional space. To begin with, the algorithm partitions these data points
    arbitrarily into k groups. Now, for each group the algorithm computes its centroid,
    which is an imaginary point with each of its coordinates being the average of
    the same coordinates of all the points in that group, i.e., this imaginary point''s
    first coordinate is the average of all first coordinates of the points in this
    group, second coordinate is the average of all second coordinates, and so on.
    Next, for each data point, it finds the centroid that is the closest to that point
    and achieves a new partition of these data points into k new groups. This algorithm
    again finds the centroids of these groups and repeats these steps until it either
    converges or has gone through a specified number of iterations. An example in
    a two-dimensional space with k=2 is shown in the picture below:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有很多数据点，每个数据点有n个属性（可以标记为n个坐标），我们想将它们划分为k个组。由于每个组有n个坐标，我们可以将这些数据点想象成在n维空间中。首先，算法将这些数据点任意划分为k个组。现在，对于每个组，算法计算其质心，这是一个虚拟点，每个坐标是该组中所有点相同坐标的平均值，即，这个虚拟点的第一个坐标是该组中所有点第一个坐标的平均值，第二个坐标是所有第二个坐标的平均值，以此类推。接下来，对于每个数据点，算法找到最接近该点的质心，并实现这些数据点的新k个组的划分。该算法再次找到这些组的质心，并重复这些步骤，直到它收敛或经过了指定次数的迭代。下图展示了k=2的二维空间示例：
- en: '![](../Images/8ef54f94e52549d484655311070b57a3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8ef54f94e52549d484655311070b57a3.png)'
- en: Another technique, hierarchical clustering creates hierarchical groups, which
    at the top level would have 'super groups' each containing sub-groups, which may
    contain sub-sub groups and so on. K-means clustering is often used for creating
    hierarchical groups as well.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种技术，层次聚类创建层次性组，在顶层会有‘超级组’，每个超级组包含子组，这些子组可能包含子子组，依此类推。k-means聚类通常也用于创建层次性组。
- en: Reinforcement Learning
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强化学习
- en: 'Reinforcement Learning (RL) algorithms learn from the consequences of their
    actions, rather than from being taught by humans or by using pre-labeled data
    [60]; it is analogous to Pavlov’s conditioning, when Pavlov noticed that his dogs
    would begin to salivate whenever he entered the room, even when he was not bringing
    them food [61]. The rules that such algorithms should obey are given upfront and
    they select their actions on basis of their past experiences and by considering
    new choices. Hence, they learn by trial and error in a simulated environment.
    At the end of each "learning session," the RL algorithm provides itself a "score"
    that characterizes its level of success or failure, and over time, the algorithm
    tries to perform those actions that maximize this score. Although IBM’s Deep Blue,
    which won the chess match against Kasparov, did not use Reinforcement Learning,
    as an example, we describe a potential RL algorithm for playing chess:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习（RL）算法通过其行动的后果来学习，而不是通过人类教授或使用预标记的数据[60]；这类似于巴甫洛夫的条件反射，当巴甫洛夫发现他的狗在他进入房间时会开始流口水，即使他没有带食物[61]。这些算法应遵守的规则事先给出，它们根据过去的经验和新选择来选择行动。因此，它们在模拟环境中通过试错学习。在每次“学习会话”结束时，RL
    算法为自己提供一个“分数”，以表征其成功或失败的程度，随着时间的推移，算法尝试执行那些最大化该分数的行动。尽管IBM的深蓝没有使用强化学习作为例子，我们描述了一个潜在的用于下棋的RL算法：
- en: As input, the RL algorithm is given the rules of playing chess, e.g., 8*8 board,
    initial location of pieces, what each chess piece can do in one step, a score
    of zero if the player’s king has a check-mate, a score of one if the opponent's
    king has a check-mate, and 0.5 if only two kings are left on the board. In this
    embodiment, the RL algorithm creates two identical solutions, A and B, which start
    playing chess against each other. After each game is over, the RL algorithm assigns
    the appropriate scores to A and B but also keeps complete history of the moves
    and countermoves made by A and B that can be used to train A and B (individually)
    for playing better. After playing several thousand such games in the first round,
    the RL algorithm uses the "self-generated" labelled data with outcomes of 0, 0.5,
    and 1 for each game and of all the moves played in that game and by using learning
    techniques, determines the patterns of moves that led A (and similarly B) to getting
    a poor score. Hence for the next round, it refines these solutions for A and for
    B and optimizes the play of such "poor moves," thereby, improving them for the
    second round, and then for the third round, and so on, until the improvements
    from one round to another become miniscule, in which case A and B end up being
    reasonably well-trained solutions.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 作为输入，RL算法提供了下棋的规则，例如，8*8棋盘，棋子的初始位置，每个棋子在一步中可以做什么，玩家的王被将死时的分数为零，对方的王被将死时的分数为一，如果棋盘上只剩下两个王，则分数为0.5。在这个实施方案中，RL算法创建了两个相同的解决方案A和B，它们开始相互下棋。在每局游戏结束后，RL算法将适当的分数分配给A和B，并且还保留了A和B所做的所有移动和反移动的完整历史，这些可以用于训练A和B（各自）以更好地玩游戏。在第一轮中玩了几千局这样的游戏后，RL算法使用“自生成”的标记数据（每局游戏的结果为0、0.5和1以及该游戏中所有的移动）并通过学习技术，确定了导致A（以及类似地B）获得较差分数的移动模式。因此，在下一轮中，它为A和B改进这些解决方案，并优化这些“差劲的移动”，从而在第二轮中改进它们，然后是第三轮，依此类推，直到一轮到另一轮的改进变得微不足道，此时A和B最终成为经过合理训练的解决方案。
- en: '![](../Images/28f19ccc77d7278d15702cd2343ec2a1.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28f19ccc77d7278d15702cd2343ec2a1.png)'
- en: In 1951, Minsky and Edmonds built the first neural network machine, SNARC (Stochastic
    Neural Analogy Reinforcement Computer); it successfully modeled the behavior of
    a rat in a maze searching for food, and as it made its way through the maze, the
    strength of some synaptic connections would increase, thereby reinforcing the
    underlying behavior, which seemed to mimic the functioning of living neurons [5].
    In general, Reinforcement Learning algorithms perform well while solving optimization
    problems, in game theoretic situations (e.g., in playing Backgammon [62] or GO
    [94]) and in problems where the business rules are well defined (e.g., autonomous
    car driving) since they can self-learn by playing against humans or against each
    other.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 1951年，Minsky和Edmonds建造了第一个神经网络机器SNARC（随机神经类比强化计算机）；它成功模拟了老鼠在迷宫中寻找食物的行为，当它在迷宫中移动时，一些突触连接的强度会增加，从而强化了基础行为，这似乎模拟了活体神经元的功能[5]。一般而言，强化学习算法在解决优化问题、游戏理论情境（例如，在玩掼蛋[62]或围棋[94]）以及在商业规则明确的问题（例如，自动驾驶）中表现良好，因为它们可以通过与人类或彼此对抗进行自我学习。
- en: Mixed learning
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 混合学习
- en: Mixed learning techniques use a combination of one or more of supervised, unsupervised
    and reinforcement learning techniques. Semi-supervised learning is particularly
    useful in cases where it is expensive or time consuming to label a large dataset.
    ", e.g., while differentiating dog-faces from cat-faces, if the database contains
    some images that are labeled but most of them are not. Some of their broad uses
    include classification, pattern recognition, anomaly detection, and clustering/grouping..
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 混合学习技术使用一种或多种监督学习、无监督学习和强化学习技术的组合。半监督学习在标记大数据集代价高或耗时的情况下特别有用，例如，在区分狗脸和猫脸时，如果数据库包含一些已标记的图像但大多数未标记的图像。它们的一些广泛用途包括分类、模式识别、异常检测和聚类/分组。
- en: '![](../Images/28e2e937832ab8324d98146904812121.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/28e2e937832ab8324d98146904812121.png)'
- en: Resurgence of Neural Networks – Both Shallow and Deep
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 神经网络的复兴——浅层和深层
- en: 'As discussed in the previous article [56], a one-layer perceptron network consists
    of an input layer, connected to one hidden layer of perceptrons, which is in turn
    connected to an output layer of perceptrons [17]. A signal coming via a connection
    is recalibrated by the "weight" of that connection, and this weight is assigned
    to a connection during the "learning process". Like a human neuron, a perceptron
    "fires" if all the incoming signals together exceed a specified potential but
    unlike humans, in most such networks, signals only move from one layer to that
    in front of it. The term, Artificial Neural Networks (ANNs) was coined by Igor
    Aizenberg and colleagues in 2000 for Boolean threshold neurons but is used for
    perceptrons and other "neurons" of the same ilk [63]. Examples of one hidden layer
    and eight-hidden layer networks are given below:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一篇文章[56]中讨论的，一个单层感知器网络由一个输入层组成，连接到一个感知器的隐藏层，然后再连接到一个感知器的输出层[17]。通过连接传递的信号由该连接的“权重”重新校准，这个权重在“学习过程中”分配给连接。像人类神经元一样，如果所有的输入信号总和超过指定的潜在值，感知器就会“发射”，但与人类不同，在大多数此类网络中，信号只在一层与前面的层之间移动。术语“人工神经网络（ANNs）”由Igor
    Aizenberg及其同事于2000年创造，用于布尔阈值神经元，但也用于感知器和其他同类“神经元”[63]。下面给出了一个隐藏层和八个隐藏层网络的示例：
- en: '![](../Images/61dab6c4f50cb0b7905ca6e1061cee5b.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61dab6c4f50cb0b7905ca6e1061cee5b.png)'
- en: Although multi-layer perceptrons were invented in 1965 and an algorithm for
    training an 8-layer network was provided in 1971 [18, 19, 20], the term, Deep
    Learning, was introduced by Rina Dechter in 1986 [64]. For our purposes, a deep
    learning network has more than one hidden layer.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管多层感知器于1965年发明，并且在1971年提供了一个训练8层网络的算法[18, 19, 20]，但“深度学习”这一术语由Rina Dechter在1986年引入[64]。就我们的目的而言，深度学习网络有超过一个隐藏层。
- en: Although multi-layer perceptrons were invented in 1965 and an algorithm for
    training an 8-layer network was provided in 1971, the term, Deep Learning, was
    introduced by Rina Dechter in 1986
  id: totrans-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尽管多层感知器于1965年发明，并且在1971年提供了一个训练8层网络的算法，但“深度学习”这一术语由Rina Dechter在1986年引入
- en: 'Given below are important deep learning networks that were developed during
    1975 and 2006 and are frequently used today; their description is out of scope
    of this article:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 下面给出了在1975年到2006年期间开发的重要深度学习网络，并且今天仍然被频繁使用；它们的描述超出了本文的范围：
- en: In 1979, Fukushima provided the first "convolutional neural network" (CNN) when
    he developed Neocognitron in which he used a hierarchical, multilayered design
    [65]. CNNs are widely used for image processing, speech to text conversion, document
    processing and Bioactivity Prediction in Structure based Drug Discovery [97].
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1979年，Fukushima 提供了第一个“卷积神经网络”（CNN），他开发了 Neocognitron，并使用了分层的多层设计 [65]。CNN 广泛用于图像处理、语音到文本转换、文档处理以及基于结构的药物发现中的生物活性预测
    [97]。
- en: In 1983, Hopfield popularized Recurrent Neural Networks (RNNs), which were originally
    introduced by Little in 1974 [51,52,55]. RNNs are analogous to Rosenblatt’s perceptron
    networks but are not feedforward because they allow connections to go towards
    both the input and output layers; this allows RNNs to exhibit temporal behavior.
    Unlike feedforward neural networks, RNNs use their internal memory to process
    arbitrary sequences of incoming data. RNNs have since been used for speech to
    text conversion, natural language processing and for early detection of heart
    failure onset [98].
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1983年，Hopfield 推广了递归神经网络（RNN），这些网络最初由 Little 于1974年引入 [51,52,55]。RNN 类似于 Rosenblatt
    的感知机网络，但由于允许连接既向输入层也向输出层延伸，因此不是前馈的，这使得 RNN 能够表现出时间行为。与前馈神经网络不同，RNN 使用其内部记忆处理任意序列的输入数据。RNN
    此后被用于语音到文本转换、自然语言处理和心力衰竭早期检测 [98]。
- en: In 1997, Hochreiter and Schmidhuber developed a specific kind of deep learning
    recurrent neural network, called LSTM (long short-term memory) [66]. LSTMs mitigate
    some problems that occur while training RNNs and they are well suited for predictions
    related to time-series. Applications of such networks include those in robotics,
    time series prediction, speech recognition, grammar learning, handwriting recognition,
    protein homology detection, and prediction in medical care pathways [99].
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1997年，Hochreiter 和 Schmidhuber 开发了一种特定类型的深度学习递归神经网络，称为 LSTM（长短期记忆）[66]。LSTM
    解决了训练 RNN 时出现的一些问题，非常适合与时间序列相关的预测。这些网络的应用包括机器人技术、时间序列预测、语音识别、语法学习、手写识别、蛋白质同源性检测以及医疗护理路径预测
    [99]。
- en: In 2006, Hinton, Osindero and Teh invented Deep Belief Networks and showed that
    in many situations, multi-layer feedforward neural networks could be pre-trained
    one layer at a time by treating each layer as an unsupervised machine and then
    fine-tuning it using supervised backpropagation [67]. Applications of such networks
    include those in image recognition, handwriting recognition, and identifying of
    onset of diseases such as liver cancer and schizophrenia [100, 109].
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2006年，Hinton、Osindero 和 Teh 发明了深度置信网络，并展示了在许多情况下，多层前馈神经网络可以通过将每一层视为无监督机器来逐层进行预训练，然后使用有监督的反向传播进行微调
    [67]。这些网络的应用包括图像识别、手写识别以及识别肝癌和精神分裂症等疾病的发生 [100, 109]。
- en: Parallel and Distributed Computing Improve AI Capabilities
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 并行和分布式计算提高了 AI 能力
- en: 'During 1983 and 2010, hardware became much cheaper and more than 500,000 times
    faster; however, for many problems, one computer was still not enough to execute
    many machine learning algorithms in a reasonable amount of time. At a theoretical
    level, computer science research during 1950-2000 had shown that such problems
    could be solved much faster by using many computers simultaneously and in a distributed
    manner. However, the following fundamental problems related to distributed computing
    remained resolved until 2003: (a) how to parallelize computation, (b) how to distribute
    data "equitably" among computers and do automatic load balancing, and (b) how
    to handle computer failures and interrupt them if they go into infinite loops.
    In 2003, Google published Google File Systems paper and then followed it up by
    publishing MapReduce in 2004, which was a framework and an associated implementation
    for processing and generating big data sets with a parallel, distributed algorithm
    on a cluster [68]. Since MapReduce was proprietary to Google, in 2006, Cutting
    and Carafella (from University of Washington but working at Yahoo) created an
    open source and free version of this framework called Hadoop [69]. Also, in 2012,
    Spark and its resilient distributed datasets were invented, which reduced the
    latency of many applications when compared to MapReduce and Hadoop implementations
    [70]. Today a Hadoop-Spark based infrastructure can handle 100,000 or more computers
    and several hundred million Gigabytes of storage.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在1983到2010年间，硬件变得便宜了很多，速度提高了超过50万倍；然而，对于许多问题来说，一台计算机仍然不足以在合理的时间内执行许多机器学习算法。从理论上讲，1950-2000年的计算机科学研究表明，通过同时使用许多计算机并以分布式方式处理，这些问题可以更快地解决。然而，以下与分布式计算相关的基本问题直到2003年才得到解决：（a）如何并行计算，（b）如何在计算机之间“公平”地分配数据并进行自动负载均衡，（c）如何处理计算机故障以及在计算机陷入无限循环时中断它们。2003年，谷歌发布了Google
    File Systems论文，并在2004年发布了MapReduce，这是一个用于在集群上处理和生成大数据集的并行分布式算法的框架及其相关实现[68]。由于MapReduce是谷歌专有的，2006年，Cutting和Carafella（来自华盛顿大学，但在Yahoo工作）创建了一个开源的免费版本，称为Hadoop[69]。此外，2012年，Spark及其弹性分布式数据集被发明，这相比于MapReduce和Hadoop实现降低了许多应用的延迟[70]。如今，基于Hadoop-Spark的基础设施可以处理10万台或更多计算机以及数亿千兆字节的存储。
- en: Big Data begins to help AI systems
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 大数据开始帮助人工智能系统
- en: In 1998, John Mashey (at Silicon Graphics) seemingly first coined the term,
    "Big Data," that referred to large volume, variety and velocity at which data
    is being generated and communicated [71]. Since most learning techniques require
    lots of data (especially labelled data), the data stored in organizations’ repositories
    and on the World Wide Web, became vital for AI. By early 2000, social media websites
    such as Facebook, Twitter, Pinterest, Yelp, and Youtube as well as weblogs and
    a plethora of electronic devices started generating Big Data, which set the stage
    for creating several "open databases" with labeled and unlabeled data (for researchers
    to experiment with) [72,73]. By 2010, humans had already created almost a quadrillion
    Gigabytes (i.e., one zetta bytes) of data, most of which was either structured
    (e.g., spreadsheets, relational databases) or unstructured (e.g., text, images,
    audio and video files) [74].
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在1998年，John Mashey（在Silicon Graphics）似乎首次创造了“Big Data”（大数据）这一术语，指的是数据生成和传输的巨大体量、多样性和速度[71]。由于大多数学习技术需要大量数据（尤其是标记数据），组织的存储库和万维网上存储的数据变得对人工智能至关重要。到2000年初，社交媒体网站如Facebook、Twitter、Pinterest、Yelp和YouTube以及博客和大量电子设备开始生成大数据，这为创建多个“开放数据库”提供了基础，这些数据库包含标记和未标记的数据（供研究人员实验使用）[72,73]。到2010年，人类已经创建了近一千万亿千兆字节（即一个zettabyte）的数据，其中大多数是结构化的（例如，电子表格、关系数据库）或非结构化的（例如，文本、图像、音频和视频文件）[74]。
- en: '![](../Images/8d03a5de8c7e8155a8faeb9c581a0887.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8d03a5de8c7e8155a8faeb9c581a0887.png)'
- en: Progress in Sub-fields of AI and Commercial Applications
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能子领域的进展与商业应用
- en: Reinforcement Learning Algorithms play Backgammon
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强化学习算法玩西洋双陆棋
- en: In 1992, IBM’s Gerald Tesauro built TD-Gammon, which was a reinforcement learning
    program to play backgammon; its level was slightly below that of the top human
    backgammon players at that time [62].
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在1992年，IBM的Gerald Tesauro开发了TD-Gammon，这是一个用来玩西洋双陆棋的强化学习程序；当时它的水平略低于顶尖的人类西洋双陆棋玩家[62]。
- en: Machines beat humans in Chess
  id: totrans-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器在国际象棋中战胜了人类
- en: Alan Turing was the first to design a computer chess program in 1953 although
    he "ran the program by flipping through the pages of the algorithm and carrying
    out its instructions on a chessboard" [75]. In 1989, chess playing programs, HiTech
    and Deep Thought developed at Carnegie Mellon University, defeated a few chess
    masters [76]. In 1997, IBM’s Deep Blue became the first computer chess-playing
    system to beat world’s champion, Garry Kasparov. Deep Blue’s success was essentially
    due to considerably better engineering and processing 200 million moves per second
    [77].
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 艾伦·图灵是1953年首次设计计算机象棋程序的人，尽管他是“通过翻阅算法的页面并在棋盘上执行指令来运行程序”[75]。1989年，在卡内基梅隆大学开发的象棋程序HiTech和Deep
    Thought战胜了几位象棋大师[76]。1997年，IBM的Deep Blue成为第一个击败世界冠军加里·卡斯帕罗夫的计算机象棋系统。Deep Blue的成功主要归功于其显著更好的工程设计和每秒处理200百万个棋步的能力[77]。
- en: Robotics
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 机器人技术
- en: In 1994, Adler and his colleagues at Stanford University invented, a stereotactic
    radiosurgery-performing robot, Cyberknife, which could surgically remove tumors;
    it is almost as accurate as human doctors, and during the last 20 years, it has
    treated over 100,000 patients [78]. In 1997, NASA built Sojourner, a small robot
    that could perform semi-autonomous operations on the surface of Mars [79].
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 1994年，Adler及其斯坦福大学的同事们发明了一种立体定向放射外科手术机器人——Cyberknife，它能够手术切除肿瘤；它的准确性几乎与人类医生一样，在过去20年中，它已经治疗了超过100,000名患者[78]。1997年，NASA制造了Sojourner，一种能够在火星表面执行半自主操作的小型机器人[79]。
- en: Better Chat-bots
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 更好的聊天机器人
- en: In 1995, Wallce create A.L.I.C.E., which was based on pattern matching but had
    no reasoning capabilities [80]. Thereafter, Jabberwacky (renamed Cleverbot in
    2008) was created, which had web-searching and gameplaying abilities [81] but
    was still limited in nature. Both chatbots used improved NLP algorithms for communicating
    with humans.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 1995年，Wallce创建了基于模式匹配的A.L.I.C.E.，但没有推理能力[80]。随后，Jabberwacky（在2008年更名为Cleverbot）被创造出来，具有网络搜索和游戏能力[81]，但本质上仍然有限。这两款聊天机器人都使用了改进的自然语言处理算法来与人类交流。
- en: Improved Natural Language Processing (NLP)
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 改进的自然语言处理（NLP）
- en: Until the 1980s, most NLP systems were based on complex sets of hand-written
    rules. In the late 1980s, researchers started using machine learning algorithms
    for language processing. This was due to the faster and cheaper hardware as well
    as the reduced dominance of Chomsky-based theories of linguistics. Instead researchers
    created statistical models that made probabilistic decisions based on assigning
    weights to appropriate input features, and they also started using supervised
    and semi-supervised learning techniques and partially labeled data [82,83].
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 直到1980年代，大多数自然语言处理系统都基于复杂的手工编写规则。1980年代末，研究人员开始使用机器学习算法进行语言处理。这是由于硬件的速度和成本的降低以及对乔姆斯基语言学理论的主导地位的削弱。于是，研究人员创建了统计模型，通过为适当的输入特征分配权重来做出概率决策，他们还开始使用监督学习和半监督学习技术以及部分标记的数据[82,83]。
- en: Speech and Speaker Recognition
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语音和说话者识别
- en: During late 1990s, SRI researchers used deep neural networks for speaker recognition
    and they achieved significant success [84]. In 2009, Hinton and Deng collaborated
    with several colleagues from University of Toronto, Microsoft, Google and IBM,
    and showed substantial progress in speech recognition using LSTM-based deep networks
    [85,86].
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在1990年代末，SRI研究人员使用深度神经网络进行说话者识别，并取得了显著的成功[84]。2009年，Hinton和Deng与多位来自多伦多大学、微软、谷歌和IBM的同事合作，展示了使用基于LSTM的深度网络在语音识别方面的显著进展[85,86]。
- en: Recommender Systems
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推荐系统
- en: By 2010, several companies (e.g., TiVo, Netflix, Facebook, Pandora) built recommendation
    engines using AI and started using them for marketing and sales purposes, thereby,
    improving their revenue and profit margins [87].
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 到2010年，几家公司（如TiVo、Netflix、Facebook、Pandora）利用AI构建了推荐引擎，并开始将其用于营销和销售，从而提高了他们的收入和利润率[87]。
- en: Recognizing hand-written digits
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 识别手写数字
- en: In 1989, LeCun and colleagues provided the first practical demonstration of
    backpropagation; they combined convolutional neural networks (CNNs) with back
    propagation in order to read "handwritten" digits. This system was eventually
    used to read the numbers in handwritten checks; in 1998, and by the early 2000s,
    such networks processed an estimated 10% to 20% of all the checks written in the
    United States [88].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 1989年，LeCun及其同事首次展示了反向传播的实际应用；他们将卷积神经网络（CNN）与反向传播结合起来，以识别“手写”数字。这个系统最终被用于读取手写支票上的数字；到1998年及2000年代初，这些网络处理了美国约10%到20%的支票[88]。
- en: During 1983 and 2010, exemplary research done by Hinton, Schmidhuber, Bengio,
    LeCun, Hochreiter, and others ensured rapid progress in deep learning and some
    networks were also used in commercial applications
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在1983年至2010年期间，Hinton、Schmidhuber、Bengio、LeCun、Hochreiter等人所做的杰出研究确保了深度学习的快速进展，并且一些网络也开始被用于商业应用。
- en: Conclusion
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: The year 2000 had come and gone but Alan Turing’s prediction of humans creating
    an AI computer remained unfulfilled [3,4] and Loebner prize was initiated in 1990
    with the aim of developing such a computer [89]. Nevertheless, substantial progress
    was made in AI, especially with respect to deep neural networks, which were invented
    in 1965 with the first algorithm for training them given in 1971 [18,19,20]; during
    1983 and 2010, exemplary research done by Hinton, Schmidhuber, Bengio, LeCun,
    Hochreiter, and others ensured rapid progress in deep learning techniques [90,91,92,93]
    and some of these networks began to be used in commercial applications. Because
    of these techniques and the availability of inexpensive hardware and data, which
    made them practical, the pace of research and development picked up substantially
    during 2005 and 2010, which in turn, led to a substantial growth in AI solutions
    that started rivaling humans during 2011 and 2017; we will discuss such solutions
    in the next article, "Domains in Which AI Systems are Rivaling Humans" [151].
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 2000年已过去，但艾伦·图灵关于人类创造AI计算机的预言仍未实现[3,4]，而Loebner奖于1990年发起，旨在开发这样的计算机[89]。尽管如此，在AI方面取得了重大进展，特别是在深度神经网络方面，深度神经网络于1965年被发明，1971年提出了训练它们的第一个算法[18,19,20]；在1983年至2010年期间，Hinton、Schmidhuber、Bengio、LeCun、Hochreiter等人所做的杰出研究确保了深度学习技术的快速进展[90,91,92,93]，这些网络中的一些开始被用于商业应用。由于这些技术以及便宜的硬件和数据的可用性使其变得实际，研究和开发的步伐在2005年至2010年期间显著加快，这反过来又导致了AI解决方案的显著增长，这些解决方案在2011年至2017年期间开始与人类相抗衡；我们将在下一篇文章“AI系统与人类竞争的领域”[151]中讨论这些解决方案。
- en: References for all articles in this series can be found at [www.scryanalytics.com/bibliography](https://scryanalytics.ai/bibliography)
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 本系列所有文章的参考文献可以在[www.scryanalytics.com/bibliography](https://scryanalytics.ai/bibliography)找到。
- en: '**Bio: [Dr. Alok Aggarwal](https://scryanalytics.ai/about-us/)**, is CEO and
    Chief Data Scientist at [Scry Analytics, Inc](https://scryanalytics.ai/). He previously
    was at IBM Research Yorktown Heights, founded IBM India Research Lab, and was
    founder and CEO Evalueserve which employed over 3,000 people worldwide. In 2014
    he started Scry Analytics.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [阿洛克·阿加瓦尔博士](https://scryanalytics.ai/about-us/)**，是[Scry Analytics,
    Inc](https://scryanalytics.ai/)的首席执行官和首席数据科学家。他曾在IBM研究院约克镇工作，创立了IBM印度研究实验室，并且是Evalueserve的创始人和首席执行官，Evalueserve在全球雇佣了3000多名员工。2014年，他创办了Scry
    Analytics。'
- en: '[Original](https://scryanalytics.ai/resurgence-of-artificial-intelligence-during-1983-2010/).
    Reposted with permission.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://scryanalytics.ai/resurgence-of-artificial-intelligence-during-1983-2010/)。转载已获许可。'
- en: '**Related**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关**'
- en: '[**The Birth of AI and The First AI Hype Cycle**](https://www.kdnuggets.com/2018/02/birth-ai-first-hype-cycle.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**AI的诞生和第一次AI炒作周期**](https://www.kdnuggets.com/2018/02/birth-ai-first-hype-cycle.html)'
- en: '[**Which Machine Learning Algorithm be used in year 2118?**](https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**2118年将使用哪些机器学习算法？**](https://www.kdnuggets.com/2018/02/machine-learning-algorithm-2118.html)'
- en: '[**3 principles for solving AI Dilemma: Optimization vs Explanation**](https://www.kdnuggets.com/2018/02/3-principles-ai-dilemma-optimization-explanation.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**解决AI困境的3个原则: 优化与解释**](https://www.kdnuggets.com/2018/02/3-principles-ai-dilemma-optimization-explanation.html)'
