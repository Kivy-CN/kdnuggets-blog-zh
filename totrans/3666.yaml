- en: 'RedPajama Project: An Open-Source Initiative to Democratizing LLMs'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RedPajama项目：一个开源倡议，旨在普及LLMs
- en: 原文：[https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html](https://www.kdnuggets.com/2023/06/redpajama-project-opensource-initiative-democratizing-llms.html)
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/5d082ed99816c02306cba227165e9598.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![RedPajama项目：一个开源倡议，旨在普及LLMs](../Images/5d082ed99816c02306cba227165e9598.png)'
- en: Image by Author (Generated via [Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1))
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供（通过[Stable Diffusion 2.1](https://huggingface.co/stabilityai/stable-diffusion-2-1)生成）
- en: In recent times, Large Language Models or LLM have dominated the world. With
    the introduction of ChatGPT, everyone could now benefit from the text generation
    model. But, many powerful models are only available commercially, leaving much
    great research and customization behind.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，大型语言模型或LLM主导了世界。随着ChatGPT的推出，每个人都可以受益于文本生成模型。但是，许多强大的模型仅在商业上提供，留下了许多优秀的研究和定制工作。
- en: There are, of course, many projects now trying to open-source many of the LLMs
    fully. Projects such as [Pythia](https://github.com/EleutherAI/pythia), [Dolly](https://github.com/databrickslabs/dolly),
    [DLite](https://huggingface.co/aisquared/dlite-v2-1_5b), and many others are some
    of examples. But why try to make LLMs open-source? It’s a sentiment of the community
    that moved all these projects to bridge the limitation that the closed model brings.
    However, are the open-source models inferior compared to the closed ones? Of course
    not. Many models could rival commercial models and show promising results in many
    areas.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，现在有很多项目尝试完全开源许多LLMs。[Pythia](https://github.com/EleutherAI/pythia)、[Dolly](https://github.com/databrickslabs/dolly)、[DLite](https://huggingface.co/aisquared/dlite-v2-1_5b)等项目就是一些例子。但为什么要尝试使LLMs开源？这是社区的共识，促使所有这些项目填补封闭模型带来的限制。然而，开源模型是否比封闭模型差？当然不是。许多模型可以与商业模型竞争，并在许多领域展现出有前景的结果。
- en: To follow up with this movement, one of the open-source projects to democratize
    LLM is the RedPajama. What is this project, and how could it benefit the community?
    Let’s explore this further.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了跟进这一运动，RedPajama是一个开源项目，旨在普及LLM。这个项目是什么，它如何能够使社区受益？让我们进一步探讨一下。
- en: RedPajama
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RedPajama
- en: '[RedPajama](https://github.com/togethercomputer/RedPajama-Data) is a collaboration
    project between [Ontocord.ai](https://www.ontocord.ai/), [ETH DS3Lab](https://ds3lab.inf.ethz.ch/),
    [Stanford CRFM](https://crfm.stanford.edu/), and [Hazy Research](https://hazyresearch.stanford.edu/)
    to develop reproducible open-source LLMs. The RedPajama project contains three
    milestones, including:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[RedPajama](https://github.com/togethercomputer/RedPajama-Data)是[Ontocord.ai](https://www.ontocord.ai/)、[ETH
    DS3Lab](https://ds3lab.inf.ethz.ch/)、[Stanford CRFM](https://crfm.stanford.edu/)和[Hazy
    Research](https://hazyresearch.stanford.edu/)之间的合作项目，旨在开发可重复的开源LLMs。RedPajama项目包含三个里程碑，包括：'
- en: Pre-training data
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预训练数据
- en: Base models
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基础模型
- en: Instruction tuning data and models
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指令调整数据和模型
- en: When this article was written, the RedPajama project had developed the pre-training
    data and the models, including the base, instructed, and chat versions.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，RedPajama项目已经开发了预训练数据和模型，包括基础版、指令版和聊天版。
- en: RedPajama Pre-Trained Data
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RedPajama预训练数据
- en: In the first step, RedPajama tries replicating the semi-open model's [LLaMa](https://arxiv.org/abs/2302.13971)
    dataset. This means RedPajama tries to build pre-trained data with 1.2 trillion
    tokens and fully open-source it for the community. Currently, the full data and
    the sample data can be downloaded on the [HuggingFace](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一步中，RedPajama尝试复制半开源模型的[LLaMa](https://arxiv.org/abs/2302.13971)数据集。这意味着RedPajama尝试构建具有1.2万亿标记的预训练数据，并将其完全开源以供社区使用。目前，可以在[HuggingFace](https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T)下载完整数据和样本数据。
- en: The data sources for the RedPajama dataset are summarized in the table below.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: RedPajama数据集的数据来源总结如下表所示。
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/bdb1b7145b1d25649e2386a7b59546cd.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![RedPajama项目：一个开源倡议，旨在普及LLMs](../Images/bdb1b7145b1d25649e2386a7b59546cd.png)'
- en: Where each data slice is pre-processed and filtered carefully, the number of
    tokens also roughly matches the number reported in the LLaMa paper.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个数据片段经过仔细预处理和过滤后，标记的数量大致与LLaMa论文中报告的数量相符。
- en: The next step after the dataset creation is to development of the base models.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集创建后的下一步是开发基础模型。
- en: RedPajama Models
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RedPajama模型
- en: 'In the following weeks after the creation of the RedPajama dataset, the first
    model trained on the dataset was released. The base models have two versions:
    a 3 billion and a 7 Billion parameters model. The RedPajama project also releases
    two variations of each base model: instruction-tuned and chat models.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在RedPajama数据集创建后的几周内，第一个基于该数据集训练的模型发布了。基础模型有两个版本：一个是30亿参数，另一个是70亿参数。RedPajama项目还发布了每个基础模型的两种变体：指令调优模型和对话模型。
- en: The summary of each model can be seen in the table below.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型的总结可以在下表中查看。
- en: '![RedPajama Project: An Open-Source Initiative to Democratizing LLMs](../Images/5f68338f56df1e5603ee24e0c53f30c4.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![RedPajama项目：一个开放源代码的倡议，旨在民主化LLMs](../Images/5f68338f56df1e5603ee24e0c53f30c4.png)'
- en: Image by Author (Adapted from [together.xyz](https://www.together.xyz/blog/redpajama-models-v1))
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者提供（改编自 [together.xyz](https://www.together.xyz/blog/redpajama-models-v1)）
- en: 'You can access the models above using the following links:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下链接访问上述模型：
- en: '[RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Base-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1)'
- en: '[RedPajama-INCITE-Chat-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Chat-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-3B-v1)'
- en: '[RedPajama-INCITE-Instruct-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Instruct-3B-v1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-3B-v1)'
- en: '[RedPajama-INCITE-Base-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1)'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Base-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-7B-v0.1)'
- en: '[RedPajama-INCITE-Chat-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-7B-v0.1)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Chat-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Chat-7B-v0.1)'
- en: '[RedPajama-INCITE-Instruct-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1)'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[RedPajama-INCITE-Instruct-7B-v0.1](https://huggingface.co/togethercomputer/RedPajama-INCITE-Instruct-7B-v0.1)'
- en: Let’s try out the RedPajama Base model. For example, we will try the RedPajama
    3B base model with the code adapted from [HuggingFace](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试RedPajama基础模型。例如，我们将使用来自[HuggingFace](https://huggingface.co/togethercomputer/RedPajama-INCITE-Base-3B-v1)的代码尝试RedPajama
    3B基础模型。
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The 3B Base model's result is promising, and it might be better if we use the
    7B Base model. As the development is still ongoing, the project might have an
    even better model in the future.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 3B基础模型的结果很有希望，如果使用7B基础模型可能会更好。由于开发仍在进行中，项目未来可能会有更好的模型。
- en: Conclusion
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Generative AI is rising, but sadly many great models are still locked under
    the company's archive. RedPajama is one of the leading projects that try to replicate
    the semi-open LLaMA model to democratize the LLMs. By developing a similar dataset
    to the LLama, RedPajama manages to create an open-source 1.2 trillion tokens dataset
    that many open-source projects have used.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性AI正在兴起，但遗憾的是许多优秀模型仍被锁定在公司的档案中。RedPajama是领先的项目之一，试图复制半开放的LLaMA模型以民主化LLMs。通过开发类似于LLaMA的数据集，RedPajama成功创建了一个开源的1.2万亿标记数据集，许多开源项目已经使用了该数据集。
- en: RedPajama also releases two kinds of models; 3B and 7B parameter base models,
    where each base model contains instruction-tuned and chat models.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: RedPajama还发布了两种类型的模型；3B和7B参数基础模型，每个基础模型包括指令调优和对话模型。
- en: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    is a data science assistant manager and data writer. While working full-time at
    Allianz Indonesia, he loves to share Python and Data tips via social media and
    writing media.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Cornellius Yudha Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**
    是一位数据科学助理经理和数据撰写者。在全职工作于Allianz Indonesia期间，他喜欢通过社交媒体和写作媒体分享Python和数据技巧。'
- en: '* * *'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织在 IT 方面'
- en: '* * *'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[水印如何帮助减轻 LLM 的潜在风险？](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html)'
- en: '[Explore LLMs Easily on Your Laptop with openplayground](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过 openplayground 轻松在你的笔记本电脑上探索 LLM](https://www.kdnuggets.com/2023/04/explore-llms-easily-laptop-openplayground.html)'
- en: '[Falcon LLM: The New King of Open-Source LLMs](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Falcon LLM：开源 LLM 的新王者](https://www.kdnuggets.com/2023/06/falcon-llm-new-king-llms.html)'
- en: '[Ensuring Reliable Few-Shot Prompt Selection for LLMs](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[确保 LLM 的可靠少样本提示选择](https://www.kdnuggets.com/2023/07/ensuring-reliable-fewshot-prompt-selection-llms.html)'
- en: '[Introducing OpenLLM: Open Source Library for LLMs](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 OpenLLM：LLM 的开源库](https://www.kdnuggets.com/2023/07/introducing-openllm-open-source-library-llms.html)'
- en: '[8 Free AI and LLMs Playgrounds](https://www.kdnuggets.com/2023/05/8-free-ai-llms-playgrounds.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8 个免费的 AI 和 LLM 游乐场](https://www.kdnuggets.com/2023/05/8-free-ai-llms-playgrounds.html)'
