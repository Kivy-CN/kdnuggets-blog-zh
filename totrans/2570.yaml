- en: An introduction to Explainable AI (XAI) and Explainable Boosting Machines (EBM)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可解释人工智能（XAI）和可解释增强机器（EBM）介绍
- en: 原文：[https://www.kdnuggets.com/2021/06/explainable-ai-xai-explainable-boosting-machines-ebm.html](https://www.kdnuggets.com/2021/06/explainable-ai-xai-explainable-boosting-machines-ebm.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/06/explainable-ai-xai-explainable-boosting-machines-ebm.html](https://www.kdnuggets.com/2021/06/explainable-ai-xai-explainable-boosting-machines-ebm.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Chaitanya Krishna Kasaraneni](https://chaitanya-kasaraneni.medium.com/),
    Data Science Intern at Predmatic AI**.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Chaitanya Krishna Kasaraneni](https://chaitanya-kasaraneni.medium.com/)，Predmatic
    AI 的数据科学实习生**。'
- en: '![Robot](../Images/92c068288f90d97b1434d25654c75827.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![机器人](../Images/92c068288f90d97b1434d25654c75827.png)'
- en: '*Photo by [Rock’n Roll Monkey](https://unsplash.com/@rocknrollmonkey?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) on [Unsplash](https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText).*'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*照片由 [Rock’n Roll Monkey](https://unsplash.com/@rocknrollmonkey?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText) 提供，来源于 [Unsplash](https://unsplash.com/s/photos/artificial-intelligence?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText)。*'
- en: In recent times, machine learning has become the core of developments in many
    fields such as sports, medicine, science, and technology. Machines (computers)
    have become so intelligent that they even [defeated professionals in games like
    Go](https://deepmind.com/research/case-studies/alphago-the-story-so-far). Such
    developments raise questions if machines would also make for better drivers (autonomous
    vehicles) or even better doctors.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，机器学习已成为许多领域如体育、医学、科学和技术发展的核心。机器（计算机）变得如此智能，甚至 [击败了围棋等游戏中的专业人士](https://deepmind.com/research/case-studies/alphago-the-story-so-far)。这些发展引发了关于机器是否也能成为更好的司机（自动驾驶车辆）甚至更好的医生的问题。
- en: In many machine learning applications, the users rely on the model to make decisions.
    But, a doctor certainly cannot operate on a patient simply because “the model
    said so.” Even in low-risk situations, such as when choosing a movie to watch
    from a streaming platform, a certain measure of trust is required before we surrender
    hours of our time based on a model.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多机器学习应用中，用户依赖模型来做出决策。但是，医生显然不能仅仅因为“模型这么说”就对病人进行手术。即使在低风险情况下，例如从流媒体平台选择一部电影，我们也需要一定的信任度，然后才能根据模型的推荐投入几个小时的时间。
- en: Despite the fact that many machine learning models are black boxes, understanding
    the rationale behind the model’s predictions would certainly help users decide
    when to trust or not to trust their predictions. This “understanding the rationale”
    leads to the concept called Explainable AI (XAI).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多机器学习模型是黑箱，但理解模型预测背后的理由肯定会帮助用户决定何时信任或不信任其预测。这种“理解理由”的需求引出了一个概念，称为可解释人工智能（XAI）。
- en: What is Explainable AI (XAI)?
  id: totrans-9
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 什么是可解释人工智能（XAI）？
- en: '*Explainable AI refers to methods and techniques in the application of artificial
    intelligence technology (AI) such that the results of the solution can be understood
    by human experts. [[Wikipedia](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)]*'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*可解释人工智能指的是应用人工智能技术（AI）中的方法和技术，使得解决方案的结果可以被人类专家理解。[[维基百科](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence)]*'
- en: '**How is Explainable AI different from Artificial Intelligence?**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**可解释人工智能如何不同于人工智能？**'
- en: '![Ai Process 5 questions](../Images/6eb762743cef3ed7230454c3c62cfa56.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![AI 过程 5 个问题](../Images/6eb762743cef3ed7230454c3c62cfa56.png)'
- en: '![XAI Process 5 statements](../Images/023db49bccdcea5df635cf0e503d679d.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![XAI 过程 5 个陈述](../Images/023db49bccdcea5df635cf0e503d679d.png)'
- en: '*Difference Between AI and XAI.*'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI 和 XAI 之间的区别。*'
- en: In general, AI arrives at a result using an ML algorithm, but the architects
    of the AI systems do not fully understand how the algorithm reached that result.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，AI 使用机器学习算法得出结果，但 AI 系统的设计者并未完全理解算法是如何得出该结果的。
- en: On the other hand, XAI is a set of processes and methods that allows users to
    understand and trust the results/output created by a machine learning model/algorithm.
    XAI is used to describe an AI model, its expected impact, and potential biases.
    It helps characterize model accuracy, fairness, transparency, and outcomes in
    AI-powered decision-making. Explainable AI is crucial for an organization in building
    trust and confidence when putting AI models into production. AI explainability
    also helps an organization adopt a responsible approach to AI development.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，XAI 是一组过程和方法，允许用户理解和信任机器学习模型/算法产生的结果/输出。XAI 用于描述 AI 模型、其预期影响和潜在偏差。它帮助描述模型的准确性、公平性、透明度以及
    AI 驱动决策的结果。可解释的 AI 对于组织在将 AI 模型投入生产时建立信任和信心至关重要。AI 解释性还帮助组织采用负责任的 AI 开发方法。
- en: Famous examples of such explainers are **Local Interpretable Model-agnostic
    Explanations** ([LIME](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)) and **SHapley
    Additive exPlanations** ([SHAP](https://shap.readthedocs.io/en/latest/)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这种解释器的著名例子包括**局部可解释模型无关解释**（[LIME](https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/)）和**Shapley
    加性解释**（[SHAP](https://shap.readthedocs.io/en/latest/)）。
- en: LIME explains the predictions of any classifier in an interpretable and faithful
    manner by learning an interpretable model locally around the prediction.
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LIME 通过在预测周围局部学习一个可解释的模型，以可解释和忠实的方式解释任何分类器的预测。
- en: SHAP is a game theoretic approach to explain the output of any machine learning
    model.
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SHAP 是一种博弈论方法，用于解释任何机器学习模型的输出。
- en: Explaining Predictions using SHAP
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 SHAP 解释预测
- en: SHAP is a novel approach to XAI developed by Scott Lundberg here at Microsoft
    and eventually opened sourced.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 是由 Scott Lundberg 在微软开发的一种新颖的 XAI 方法，并最终开源。
- en: SHAP has a strong mathematical foundation. It connects optimal credit allocation
    with local explanations using the classic Shapley values from game theory and
    their related extensions (see [papers](https://github.com/slundberg/shap#citations) for
    details).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 具有强大的数学基础。它将最优的信用分配与使用经典的博弈论 Shapley 值及其相关扩展的局部解释联系起来（详细信息见[papers](https://github.com/slundberg/shap#citations)）。
- en: '**Shapley values**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**Shapley 值**'
- en: With Shapley values, each prediction can be broken down into individual contributions
    for every feature.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Shapley 值，每个预测可以被分解为每个特征的单独贡献。
- en: For example, consider your input data has 4 features (x1, x2, x3, x4) and the
    output of a model is 75, using Shapley values, you can say that feature x1 contributed
    30, feature x2 contributed 20, feature x3 contributed -15, and feature x4 contributed
    40\. The sum of these 4 Shapley values is 30+20–15+40=75, i.e., the output of
    your model. This feels great, but sadly, these values are extremely hard to calculate.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，假设你的输入数据有 4 个特征（x1, x2, x3, x4），模型的输出是 75，使用 Shapley 值，你可以说特征 x1 贡献了 30，特征
    x2 贡献了 20，特征 x3 贡献了 -15，特征 x4 贡献了 40。这 4 个 Shapley 值的总和是 30+20–15+40=75，即模型的输出。这听起来不错，但遗憾的是，这些值极其难以计算。
- en: For a general model, the time taken to compute Shapley values is **exponential
    to the number of features**. If your data has 10 features, this might still be
    okay. But if the data has more features, say 20, depending on your hardware, it
    might be impossible already. To be fair, if your model consists of trees, there
    are faster approximations to compute Shapley values, but it can still be slow.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一般模型，计算 Shapley 值所需的时间是**与特征数量的指数关系**。如果你的数据有 10 个特征，这可能还算可以。但如果数据有更多特征，比如
    20 个，根据你的硬件条件，可能已经是不可能的。公平地说，如果你的模型由树结构组成，有更快的近似方法来计算 Shapley 值，但仍然可能会很慢。
- en: SHAP using Python
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Python 的 SHAP
- en: In this article, we’ll be using [red wine quality data](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) to
    understand SHAP. The target value of this dataset is the quality rating from low
    to high (0–10). The input variables are the content of each wine sample, including
    fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free
    sulfur dioxide, total sulfur dioxide, density, pH, sulfates, and alcohol. There
    are 1,599 wine samples. The code can be found via this [GitHub link](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将使用 [红酒质量数据](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) 来理解
    SHAP。此数据集的目标值为从低到高（0–10）的质量评分。输入变量是每个酒样的成分，包括固定酸度、挥发酸度、柠檬酸、残留糖、氯化物、游离二氧化硫、总二氧化硫、密度、pH
    值、硫酸盐和酒精。有 1,599 个酒样。代码可以通过此 [GitHub 链接](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples)找到。
- en: In this post, we will build a random forest regression model and will use the
    TreeExplainer in SHAP. There is a SHAP Explainer for any ML algorithm — either
    tree-based or non-tree-based algorithms. It is called the *KernelExplainer. *If
    your model is a tree-based machine learning model, you should use the tree explainer *TreeExplainer()* that
    has been optimized to render fast results. If your model is a deep learning model,
    use the deep learning explainer *DeepExplainer()*. For all other types of algorithms
    (such as KNNs), use *KernelExplainer()*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们将构建一个随机森林回归模型，并使用 SHAP 的 TreeExplainer。SHAP 为任何机器学习算法提供了解释器——无论是基于树的还是非基于树的算法。它被称为
    *KernelExplainer*。如果你的模型是基于树的机器学习模型，你应使用已优化的树解释器 *TreeExplainer()*，以便快速渲染结果。如果你的模型是深度学习模型，请使用深度学习解释器
    *DeepExplainer()*。对于所有其他类型的算法（如 KNN），使用 *KernelExplainer()*。
- en: The SHAP value works for either the case of a continuous or binary target variable.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 值适用于连续或二元目标变量的情况。
- en: '**Variable Importance Plot — Global Interpretability**'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**变量重要性图 — 全球解释性**'
- en: A variable importance plot lists the most significant variables in descending
    order. The top variables contribute more to the model than the bottom ones and
    thus have high predictive power. Please refer to this [notebook](https://nbviewer.jupyter.org/github/chaitanyakasaraneni/SHAP_EBM_Examples/blob/main/SHAP%20Example.ipynb) for
    code.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 变量重要性图按降序列出最重要的变量。排名靠前的变量对模型的贡献大于排名靠后的变量，因此具有较高的预测能力。有关代码，请参阅此 [笔记本](https://nbviewer.jupyter.org/github/chaitanyakasaraneni/SHAP_EBM_Examples/blob/main/SHAP%20Example.ipynb)。
- en: '![](../Images/a24a19e60535025b430d3bd0c44228eb.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a24a19e60535025b430d3bd0c44228eb.png)'
- en: '*Variable Importance Plot using SHAP.*'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用 SHAP 的变量重要性图。*'
- en: '**Summary Plot**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**总结图**'
- en: Although the SHAP does not have built-in functions, you can output the plot
    using the matplotlib library.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 SHAP 没有内置函数，但你可以使用 matplotlib 库输出图表。
- en: The SHAP value plot can further show the positive and negative relationships
    of the predictors with the target variable.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: SHAP 值图进一步展示了预测变量与目标变量之间的正负关系。
- en: '![](../Images/358189896a588348df58aba92b190874.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/358189896a588348df58aba92b190874.png)'
- en: '*Summary Plot.*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '*总结图。*'
- en: 'This plot is made of all the dots in the train data. It demonstrates the following
    information:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 该图由训练数据中的所有点组成。它展示了以下信息：
- en: Variables are ranked in descending order.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 变量按降序排列。
- en: The horizontal location shows whether the effect of that value *is associated
    with a higher or lower prediction*.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 水平位置显示该值的效应是否*与更高或更低的预测相关*。
- en: The color shows whether that variable is high (in red) or low (in blue) for
    that observation.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 颜色显示该变量在观察值中是高（红色）还是低（蓝色）。
- en: Using SHAP, we can generate partial dependence plots. The partial dependence
    plot shows the marginal effect one or two features have on the predicted outcome
    of a machine learning model ([J. H. Friedman 2001](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)).
    It tells whether the relationship between the target and a feature is linear,
    monotonic, or more complex.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 SHAP，我们可以生成部分依赖图。部分依赖图展示了一个或两个特征对机器学习模型预测结果的边际影响（[J. H. Friedman 2001](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)）。它可以说明目标与特征之间的关系是线性的、单调的还是更复杂的。
- en: Black-box explanations are much better than no explanation at all. However,
    as we have seen, both LIME and SHAP have some shortcomings. It would be better
    if the model is performing well *and* is interpretable at the same time—**Explainable
    Boosting Machine** (EBM) is a representative of such a method.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 黑箱解释远胜于没有解释。然而，正如我们所见，LIME 和 SHAP 都有一些不足。如果模型能同时表现良好*并且*具有可解释性，那就更好了——**解释性提升机器**（EBM）就是这样一种方法的代表。
- en: Explainable Boosting Machine (EBM)
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解释性提升机器（EBM）
- en: EBM is a glassbox model designed to have accuracy comparable to state-of-the-art
    machine learning methods like Random Forest and BoostedTrees, while being highly
    intelligible and explainable.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: EBM 是一种玻璃盒模型，旨在具有与先进的机器学习方法（如随机森林和提升树）相当的准确性，同时保持高度的可理解性和可解释性。
- en: The EBM Algorithm is a fast implementation of the GA²M algorithm. In turn, the
    GA²M algorithm is an extension of the GAM algorithm. Therefore, let’s start with
    what the GAM algorithm is.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: EBM 算法是 GA²M 算法的快速实现。反过来，GA²M 算法是 GAM 算法的扩展。因此，让我们从 GAM 算法开始讲起。
- en: '**GAM Algorithm**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**GAM 算法**'
- en: 'GAM stands for Generalized Additive Model. It is more flexible than logistic
    regression but still interpretable. The hypothesis function for GAM is as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: GAM 代表广义加法模型。它比逻辑回归更灵活，但仍然具有可解释性。GAM 的假设函数如下所示：
- en: '![](../Images/bd07a8265307454aaf50fba70ef87f5e.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bd07a8265307454aaf50fba70ef87f5e.png)'
- en: The key part to notice is that instead of a linear term ????ixi for a feature,
    now we have a function fi(xi). We will come back later to how this function is
    computed in EBM.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的关键部分是，特征的线性项 ????ixi 现在被替换为函数 fi(xi)。稍后我们会回到如何在 EBM 中计算这个函数。
- en: One limitation of GAM is that each feature function is learned independently.
    This prevents the model from capturing interactions between features and pushes
    the accuracy down.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: GAM 的一个限制是每个特征函数是独立学习的。这阻碍了模型捕捉特征之间的交互，并降低了准确性。
- en: '**GA²M algorithm**'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**GA²M 算法**'
- en: GA²M seeks to improve this. To do so, it also considers some pairwise interaction
    terms in addition to the function learned for each feature. This is not an easy
    problem to solve because there are a larger number of interaction pairs to consider,
    which increases compute time drastically. In GA²M, they use the FAST algorithm
    to pick up useful interactions efficiently. This is the hypothesis function for
    GA²M. Note the extra pairwise interaction terms.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: GA²M 旨在改善这一点。为此，它除了考虑每个特征学习到的函数外，还考虑了一些成对交互项。这不是一个容易解决的问题，因为需要考虑的交互对的数量更多，这会大幅增加计算时间。在
    GA²M 中，他们使用 FAST 算法高效地选择有用的交互项。这是 GA²M 的假设函数。注意额外的成对交互项。
- en: '![](../Images/4cd867d7302fdbfeb77ee56eeafa4edb.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4cd867d7302fdbfeb77ee56eeafa4edb.png)'
- en: By adding pairwise interaction terms, we get a stronger model while still being
    interpretable. This is because one can use a heatmap and visualize two features
    in 2D and their effect on the output clearly.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 通过添加成对交互项，我们得到了一个更强的模型，同时仍然保持可解释性。这是因为可以使用热图清晰地可视化两个特征在二维空间中的影响及其对输出的作用。
- en: '**EBM Algorithm**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**EBM 算法**'
- en: Finally, let us talk about the EBM algorithm. In EBM, we learn each feature
    function fi(xi) using methods such as bagging and gradient boosting. To make the
    learning independent of the order of features, the authors use a very low learning
    rate and cycle through the features in a round robin fashion. The feature function
    fi for each feature represents how much each feature contributes to the model’s
    prediction for the problem and is hence directly interpretable. One can plot the
    individual function for each feature to visualize how it affects the prediction.
    The pairwise interaction terms can also be visualized on a heatmap as described
    earlier.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们讨论一下 EBM 算法。在 EBM 中，我们使用诸如袋装法和梯度提升等方法来学习每个特征函数 fi(xi)。为了使学习过程独立于特征的顺序，作者使用了非常低的学习率，并以循环的方式遍历特征。每个特征的特征函数
    fi 代表了每个特征对模型在该问题上的预测贡献程度，因此具有直接的可解释性。可以绘制每个特征的单独函数，以可视化其对预测的影响。成对交互项也可以在之前描述的热图上进行可视化。
- en: This implementation of EBM is also parallelizable, which is invaluable in large-scale
    systems. It also has the added advantage of having an extremely fast inference
    time.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这种 EBM 的实现也是可并行化的，这在大规模系统中是非常宝贵的。它还有一个极快的推理时间的额外优势。
- en: '**Training the EBM**'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练 EBM**'
- en: The EBM training part uses a combination of boosted trees and bagging. A good
    definition would probably be *bagged boosted bagged shallow trees*.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: EBM训练部分使用了增强树和袋装的组合。一个好的定义可能是*袋装的增强袋装浅层树*。
- en: 'Shallow trees are trained in a boosted way. These are tiny trees (with a maximum
    of 3 leaves by default). Also, the boosting process is specific: Each tree is
    trained on only one feature. During each boosting round, trees are trained for
    each feature one after another. It ensures that:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 浅层树以增强的方式进行训练。这些是微小的树（默认最多有3片叶子）。此外，增强过程是特定的：每棵树仅在一个特征上进行训练。在每次增强轮次中，树会逐个对每个特征进行训练。这确保了：
- en: The model is additive.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型是可加的。
- en: Each shape function uses only one feature.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个形状函数仅使用一个特征。
- en: 'This is the base of the algorithm, but other techniques further improve the
    performance:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是算法的基础，但其他技术进一步提高了性能：
- en: Bagging, on top of this base model.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在这个基础模型上进行袋装。
- en: Optional bagging, for each boosting step. This step is disabled by default because
    it increases the training time.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个增强步骤的可选袋装。此步骤默认情况下被禁用，因为它会增加训练时间。
- en: Pairwise interactions.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成对交互作用。
- en: Depending on the task, the third technique can dramatically boost performance.
    Once a model is trained with individual features, a second pass is done (using
    the same training procedure) but with pairs of features. The pair selection uses
    a dedicated algorithm that avoids trying all possible combinations (which would
    be infeasible when there are many features).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任务，第三种技术可以显著提升性能。一旦使用单个特征训练了模型，就会进行第二次训练（使用相同的训练过程），但使用特征对。对的选择使用了一个专门的算法，避免了尝试所有可能的组合（当特征很多时，这将不可行）。
- en: Finally, after all these steps, we have a tree ensemble. These trees are discretized
    simply by running them with all the possible values of the input features. This
    is easy since all features are discretized. So the maximum number of values to
    predict is the number of bins for each feature. In the end, these thousands of
    trees are simplified to binning and scoring vectors for each feature.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，在所有这些步骤之后，我们得到了一个树的集成。这些树通过使用输入特征的所有可能值来进行离散化。这很简单，因为所有特征都被离散化。因此，预测的最大值数量是每个特征的箱数。最后，这些成千上万的树被简化为每个特征的分箱和评分向量。
- en: EBM using Python
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Python 的 EBM
- en: We will use the same [red wine quality data](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009) to
    understand InterpretML. The code can be found via this [GitHub Link](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用相同的[红酒质量数据](https://www.kaggle.com/uciml/red-wine-quality-cortez-et-al-2009)来理解InterpretML。代码可以通过这个[GitHub
    链接](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples)找到。
- en: '**Exploring Data**'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索数据**'
- en: The “summary” of training data displays a histogram of the target variable.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: “总结”中的训练数据显示了目标变量的直方图。
- en: '![](../Images/dcd538236c0981bc12596139a1cc4112.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dcd538236c0981bc12596139a1cc4112.png)'
- en: '*Summary displaying a histogram of Target.*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '*总结显示目标的直方图。*'
- en: When an individual feature (here fixed acidity) is selected, the graph shows
    the Pearson Correlation of that feature with the target. Also, a histogram of
    the selected feature is shown in blue color against the histogram of the target
    variable in red color.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当选择单个特征（这里是固定酸度）时，图表显示了该特征与目标的皮尔逊相关性。同时，所选特征的直方图以蓝色显示，相对于目标变量的直方图以红色显示。
- en: '![](../Images/19ea16427ab8add173778630dcc08f8b.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/19ea16427ab8add173778630dcc08f8b.png)'
- en: '*Individual Feature against Target.*'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '*单个特征与目标对比。*'
- en: '**Training the Explainable Boosting Machine (EBM)**'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练解释性提升机（EBM）**'
- en: The *ExplainableBoostingRegressor() *model of the InterpretML library with the
    default hyper-parameters is used here. *RegressionTree()* and *LinearRegression()*
    are also trained for comparison.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这里使用的是InterpretML库中的*ExplainableBoostingRegressor()*模型，采用默认超参数。*RegressionTree()*和*LinearRegression()*也被训练用于对比。
- en: '![](../Images/6b6a60ef8a3cdee9dc55d372abd4f873.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6b6a60ef8a3cdee9dc55d372abd4f873.png)'
- en: '*ExplainableBoostingRegressor Model.*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*解释性提升回归模型。*'
- en: '**Explaining EBM Performance**'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**解释EBM性能**'
- en: '*RegressionPerf()* is used to assess the performance of each model on the test
    data. The R-squared value of EBM is 0.37, which outperforms the R-squared error
    of linear regression and regression tree models.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '*RegressionPerf()*用于评估每个模型在测试数据上的表现。EBM的R平方值为0.37，优于线性回归和回归树模型的R平方误差。'
- en: '![](../Images/9e06bd3c3bac680be5d10be4bd7bfc98.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9e06bd3c3bac680be5d10be4bd7bfc98.png)'
- en: '![](../Images/7b2b346deddab8e053b3a79928cedf19.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7b2b346deddab8e053b3a79928cedf19.png)'
- en: '![](../Images/772a3475eb7a159a7909d1a3861b43a3.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/772a3475eb7a159a7909d1a3861b43a3.png)'
- en: '*Performance of (a) EBM, (b) Linear Regression, and (c) Regression Tree.*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*（a）EBM，（b）线性回归，以及（c）回归树的性能。*'
- en: The global and local interpretability of each model can also be generated using
    the *model.explain_global()* and *model.explain_local()*methods, respectively.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 每个模型的全局和局部可解释性也可以分别使用*model.explain_global()*和*model.explain_local()*方法生成。
- en: InterpretML also provides a feature to combine everything and generate an interactive
    dashboard. Please refer to the [notebook](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples/blob/main/InterpretML_Example.ipynb) for
    graphs and a dashboard.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: InterpretML 还提供了一个功能，可以将所有内容结合起来并生成一个互动仪表板。请参考[笔记本](https://github.com/chaitanyakasaraneni/SHAP_EBM_Examples/blob/main/InterpretML_Example.ipynb)以查看图表和仪表板。
- en: Conclusion
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: With the increasing growth of requirements for explainability and existing shortcomings
    of the XAI models, the times when one had to choose between accuracy and explainability
    are long gone. EBMs can be as efficient as boosted trees while being as easily
    explainable as logistic regression.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 随着对可解释性要求的增加以及现有XAI模型的不足，选择准确性和可解释性之间的时代早已过去。EBM可以像提升树一样高效，同时又像逻辑回归一样容易解释。
- en: '[Original](https://chaitanya-kasaraneni.medium.com/understanding-xai-and-ebm-5482da5cb1d0).
    Reposted with permission.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://chaitanya-kasaraneni.medium.com/understanding-xai-and-ebm-5482da5cb1d0).
    经授权转载。'
- en: '**Related:**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Machine Learning Model Interpretation](https://www.kdnuggets.com/2021/06/machine-learning-model-interpretation.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型解释](https://www.kdnuggets.com/2021/06/machine-learning-model-interpretation.html)'
- en: '[The Explainable Boosting Machine](https://www.kdnuggets.com/2021/05/explainable-boosting-machine.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[可解释提升机器](https://www.kdnuggets.com/2021/05/explainable-boosting-machine.html)'
- en: '[Introduction to the White-Box AI: the Concept of Interpretability](https://www.kdnuggets.com/2021/03/introduction-white-box-ai-interpretability.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[白盒人工智能简介：可解释性的概念](https://www.kdnuggets.com/2021/03/introduction-white-box-ai-interpretability.html)'
- en: '* * *'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大推荐课程
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT需求'
- en: '* * *'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[A Gentle Introduction to Support Vector Machines](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机简明介绍](https://www.kdnuggets.com/2023/07/gentle-introduction-support-vector-machines.html)'
- en: '[The Ultimate Guide to Mastering Seasonality and Boosting Business Results](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握季节性和提升业务结果的终极指南](https://www.kdnuggets.com/2023/08/media-mix-modeling-ultimate-guide-mastering-seasonality-boosting-business-results.html)'
- en: '[Boosting Machine Learning Algorithms: An Overview](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[提升机器学习算法：概述](https://www.kdnuggets.com/2022/07/boosting-machine-learning-algorithms-overview.html)'
- en: '[Support Vector Machines: An Intuitive Approach](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[支持向量机：一种直观的方法](https://www.kdnuggets.com/2022/08/support-vector-machines-intuitive-approach.html)'
- en: '[The Ethics of AI: Navigating the Future of Intelligent Machines](https://www.kdnuggets.com/2023/04/ethics-ai-navigating-future-intelligent-machines.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工智能伦理：引导智能机器的未来](https://www.kdnuggets.com/2023/04/ethics-ai-navigating-future-intelligent-machines.html)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[最先进深度学习的可解释预测与现在预测](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
