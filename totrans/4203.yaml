- en: Teaching AI to Classify Time-series Patterns with Synthetic Data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用合成数据训练 AI 进行时间序列模式分类
- en: 原文：[https://www.kdnuggets.com/2021/10/teaching-ai-classify-time-series-patterns-synthetic-data.html](https://www.kdnuggets.com/2021/10/teaching-ai-classify-time-series-patterns-synthetic-data.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/10/teaching-ai-classify-time-series-patterns-synthetic-data.html](https://www.kdnuggets.com/2021/10/teaching-ai-classify-time-series-patterns-synthetic-data.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: What do we want to achieve?
  id: totrans-3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们想要实现什么目标？
- en: We want to train an AI agent or model that can do something like this,
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想训练一个可以做类似事情的 AI 代理或模型，
- en: '![Teaching AI to Classify Time-series Patterns with Synthetic Data](../Images/09a0bbf71a73d15eca77d3c0da527966.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![使用合成数据训练 AI 进行时间序列模式分类](../Images/09a0bbf71a73d15eca77d3c0da527966.png)'
- en: '**Image source**: Prepared by the author using this [Pixabay image](https://pixabay.com/illustrations/alien-robot-android-antennae-blue-1905155/) (Free
    to use)'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**图片来源**：作者使用[Pixabay 图片](https://pixabay.com/illustrations/alien-robot-android-antennae-blue-1905155/)（免费使用）准备的'
- en: Variances, anomalies, shifts
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方差、异常、变化
- en: Little more specifically, we want to train an AI agent (or model) to identify/classify
    time-series data for,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 更具体地说，我们想训练一个 AI 代理（或模型）来识别/分类时间序列数据，
- en: low/medium/high variance
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低/中/高方差
- en: anomaly frequencies (*little or high fraction of anomalies*)
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常频率（*异常比例很小或很高*）
- en: anomaly scales (*are the anomalies too far from the normal or close*)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常尺度（*异常是否远离正常值或接近正常值*）
- en: a positive or negative shift in the time-series data (in the presence of some
    anomalies)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列数据中的正向或负向变化（在存在一些异常的情况下）
- en: But, we don’t want to complicate things
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 但我们不想复杂化问题
- en: However, we don’t want to do a ton of feature engineering or learn complicated
    time-series algorithms (e.g. ARIMA) and properties (e.g. seasonality, stationarity)
    for this.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们不想进行大量的特征工程或学习复杂的时间序列算法（例如 ARIMA）和特性（例如季节性、平稳性）。
- en: We just want to feed our time-series data (with proper labels) into some kind
    of supervised ‘learning’ machine that can *learn these categories* (high or low
    variance, too few or too many anomalies, etc.) *from the raw data*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只想将我们的时间序列数据（带有正确标签）输入到某种监督‘学习’机器中，这样它就可以从原始数据中*学习这些类别*（高或低方差、异常太少或太多等）。
- en: A helpful Python library
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个有用的 Python 库
- en: Why don’t we take advantage of a Python library which can do this kind of classification
    for us automatically and all we have to do is to throw the data into it using
    standard Numpy/Pandas format?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么不利用一个 Python 库，它可以自动为我们完成这种分类工作，而我们只需将数据以标准的 Numpy/Pandas 格式输入其中？
- en: Even better if that library has the looks and feels of our favorite Scikit-learn
    package!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个库具有我们最喜欢的 Scikit-learn 包的外观和感觉，那就更好了！
- en: We find such features in the beautiful library — [**tslearn**](https://tslearn.readthedocs.io/en/stable/index.html).
    Put it simply, it is a Python package that provides machine learning tools for
    the analysis of time series. This package builds on (and hence depends on) `scikit-learn`, `numpy` and `scipy` libraries.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在美丽的库中找到了这样的功能 —— [**tslearn**](https://tslearn.readthedocs.io/en/stable/index.html)。简单来说，它是一个提供时间序列分析的机器学习工具的
    Python 包。该包构建在（因此依赖于）`scikit-learn`、`numpy` 和 `scipy` 库之上。
- en: '![](../Images/b38a62759752c6e95a2e978c6e14b4cb.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b38a62759752c6e95a2e978c6e14b4cb.png)'
- en: Image source:[ tslearn documentation](https://tslearn.readthedocs.io/en/stable/index.html)
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[tslearn 文档](https://tslearn.readthedocs.io/en/stable/index.html)
- en: Why (and how) Synthetic Data?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么（以及如何）使用合成数据？
- en: As I wrote in this article — “ *a synthetic dataset is a repository of data
    that is generated programmatically. So, it is not collected by any real-life survey
    or experiment. Its main purpose, therefore, is to be flexible and rich enough
    to help an ML practitioner conduct fascinating experiments with various classification,
    regression, and clustering algorithms*.”
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在这篇文章中所写的 —— “*合成数据集是通过程序生成的数据仓库。因此，它不是通过任何现实生活中的调查或实验收集的。它的主要目的是灵活且足够丰富，以帮助机器学习从业者进行各种分类、回归和聚类算法的有趣实验*。”
- en: '[**Synthetic data generation — a must-have skill for new data scientists**](https://towardsdatascience.com/synthetic-data-generation-a-must-have-skill-for-new-data-scientists-915896c0c1ae)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[**合成数据生成——新数据科学家的必备技能**](https://towardsdatascience.com/synthetic-data-generation-a-must-have-skill-for-new-data-scientists-915896c0c1ae)'
- en: …and then extended the argument in this article — “*Synthetic time-series is
    no exception — it helps a data scientist to experiment with various algorithmic
    methods and to prepare for real-life deployment in ways that could not have been
    possible with only real datasets.*”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '[**Create synthetic time-series with anomaly signatures in Python**](https://towardsdatascience.com/create-synthetic-time-series-with-anomaly-signatures-in-python-c0b80a6c093c)'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Basically, we want to **synthesize time-series data with anomalies and other
    patterns**, automatically label them, and feed them to the `tslearn` algorithms
    for teaching our AI agent about these patterns.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: In particular, if we want to use deep-learning-based classifiers (as offered
    by `tslearn`), then we may need a significant amount of data covering all possible
    variations, which may not be available readily in real-life situations. This is
    where synthetic data comes in handy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Off to the adventure then!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Teaching the AI agent about time-series patterns
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The demo notebook can be [**found here in my Github repo**](https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/Anomaly-training-tslearn.ipynb).
    The process of converting time-series data to a format suitable for training by
    a `tslearn` model is rather simple and is illustrated in the notebook. Here, we
    mainly focus on the various types of classification results as illustrations.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: High or low variance in the data?
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I deal with a lot of industrial data i.e. where an army of sensors are creating
    a never-ending stream of digital data from machines, factories, operators, and
    business processes.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Detecting whether a time-series data stream has high or low variance can be
    critical for many process decisions downstream. So, we start there.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: The flow is simple,
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: generate synthetic data using `SyntheticTS` module (discussed in my article
    here and can be found here)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: generate corresponding class labels to match these Numpy/Pandas data series
    (Note the **auto-generation of labels based on domain knowledge injection**)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: convert the synthetic series data to `tslearn` time-series objects(arrays)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: store them in the training dataset
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: feed the training data to a suitable time-series classifier from `tslearn`.
    We chose the `TimeSeriesMLPClassifier` method which is built atop the familiar
    multi-layer perceptron method of Scikit-learn essentially implementing a **fully
    connected deep learning network**.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/554f86dbdfcd97576b41b75895ed3e4d.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
- en: 'Training flow with Synthetic data, **Source**: Prepared entirely by the author'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: The `TimeSeriesMLPClassifier` has all the bells and whistles of the standard
    Scikit-learn MLP classifier,
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: hidden layer size and number of neurons
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: activation function
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: solver/optimizer (e.g. ‘Adam’)
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: learning rate
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: batch size
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: tolerance
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: momentum settings
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: early stopping criterion
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/e34a112829b154665fdd83338d88fa35.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
- en: Basically, we want to **synthesize time-series data with anomalies and other
    patterns**, automatically label them, and feed them to the `tslearn` algorithms
    for teaching our AI agent about these patterns.
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For brevity, in the notebook, I do not show the train/test split but that must
    be done as a standard data science workflow practice for real applications.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: We can plot the standard loss curve after training and do all sorts of hyperparameter
    tuning to make the performance top-notch.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e9b9fd191f5200237f93a4559c46b4ec.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: However, showing the deep learning classifier tuning is not the goal of this
    article. We would rather focus on the end re***sults i.e. what kind of classification
    decisions it made***.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Here are some random test results.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/18c8bee51733c8200e54b626cf8c14fc.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
- en: Label generation — manual or automatic?
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entire point of the article was to show that one can avoid manual labeling
    by synthetic data.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: I generated hundreds of synthetic time series with **random variances or shifts** to
    train the classifier. Because they were generated programmatically, they could
    be labeled automatically too.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: This point will be clear once you see the generation code in the actual Notebook.
    Here is the idea for the variance training.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/db52def0fe9ae4de102b47b85135ac99.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: Anomalies — high or low fractions of data?
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying anomalies is not enough. In most real-life situations, you have
    to also identify their frequency and occurrence pattern.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: This is because industrial data analytics systems are often responsible for
    generating alerts once they detect sufficient anomalies in the data stream. Consequently,
    to decide whether to raise an alert or not, they need to have a good idea about
    whether the anomaly count represents a significant fraction of the normal data
    or not.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: You don’t want to raise too many false alerts, do you? That will be bad for
    the reputation of an AI-driven system.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: So, we went through the same process of training an AI model about the fraction
    of anomalies in time series data. Here are the random test results,
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/932b3681b4556146a930cd4681073738.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
- en: Anomalies — how big are they in magnitude?
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In many cases, we are also interested in classifying the incoming data as having
    a high/medium/low magnitude of anomalies. For industrial data analytics, this
    feature may give an indication of the state of the machine or process abnormality.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: We followed the same training process as above and obtained these results,
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/64dba33cf025f15193e48850717ee135.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: Data drifts or shifts — where and how?
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another classic operation in industrial data analytics is the detect the drift/
    shift in the incoming sensor data from a machine. There could be a multitude of
    reasons,
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: the machine may be agings,
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a process recipe/setting is changed suddenly without proper logging,
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a small sub-component may be degrading over time
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bottom line is that an AI-driven system should be able to identify these categories
    — at least in terms of positive or negative shifts and their point of occurrence
    i.e.* whether the drift started early or late in the process lifecycle*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Identifying anomalies is not enough. In most real-life situations, you have
    to also identify their frequency and occurrence pattern. This is because industrial
    data analytics systems are often responsible for generating alerts once they detect
    sufficient anomalies in the data stream
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this case, we added the location of the shift (early or late in the whole
    time period) to the mix. So, we have the following classes to train the data on,
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: early positive shift
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: late positive shift
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: early negative shift
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: late negative shift
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Because of this increased complexity, we needed to generate a larger amount
    of synthetic data** than the previous experiments. Here are the results,'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c877eb1b4d9a62e96d312bf6c24d0cdb.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
- en: Summary
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Time-series classification is a highly interesting topic for many wonderful
    use cases. In this article, we showed, how **using synthetic data, we can train
    AI models** (deep learning networks with a few fully connected layers) for one-dimensional **time-series
    data mimicking industrial processes or sensor streams**.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: In particular, we focused on **teaching the AI model about various anomaly properties
    and data drift patterns** as these classifications are highly important indicators
    of machine degradation. In short, they form the bedrock of the so-called [**predictive
    analytics**](https://www.industr.com/en/how-convergence-of-data-analytics-iot-drives-industry-2551064) in
    the realm of **Industry 4.0** or **Smart Manufacturing**.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: We hope that the use of synthetic data for AI-driven predictive analytics will
    grow significantly in the future.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: You can check the author’s [**GitHub**](https://github.com/tirthajyoti?tab=repositories)** repositories **for
    code, ideas, and resources in machine learning and data science. If you are, like
    me, passionate about AI/machine learning/data science, please feel free to [add
    me on LinkedIn](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/) or [follow
    me on Twitter](https://twitter.com/tirthajyotiS).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio: [Tirthajyoti Sarkar](https://www.linkedin.com/in/tirthajyoti-sarkar-2127aa7/)**
    is a Data Science/ML Manager at Adapdix Corp. He contributes regularly to publications
    such as KDnuggets and TDS on diverse topics related to data science and machine
    learning. He has authored data science books and contributes to open source software.
    Tirthajyoti holds a Ph.D. in EE and is working on an M.S. degree in Computational
    Data Analytics. Email him at tirthajyoti at gmail[dot]com.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](https://towardsdatascience.com/teaching-ai-to-classify-time-series-patterns-with-synthetic-data-555d8e75ee8a).
    Reposted with permission.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[GPU-Powered Data Science (NOT Deep Learning) with RAPIDS](/2021/08/gpu-powered-data-science-deep-learning-rapids.html)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Why and how should you learn “Productive Data Science”?](/2021/07/learn-productive-data-science.html)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Monte Carlo integration in Python](/2020/12/monte-carlo-integration-python.html)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
