- en: Building Microservice for Multi-Chat Backends Using Llama and ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Llama 和 ChatGPT 构建多聊天后端的微服务
- en: 原文：[https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt](https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt](https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt)
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/96539f9eef41d5c2b771fbf02a8cb2c0.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后端的微服务](../Images/96539f9eef41d5c2b771fbf02a8cb2c0.png)'
- en: Microservices architecture promotes the creation of flexible, independent services
    with well-defined boundaries. This scalable approach enables developers to maintain
    and evolve services individually without affecting the entire application. However,
    realizing the full potential of microservices architecture, particularly for AI-powered
    chat applications, requires robust integration with the latest Large Language
    Models (LLMs) like Meta Llama V2 and OpenAI’s ChatGPT and other fine-tuned released
    based on each application use case to provide a multi-model approach for a diversified
    solution.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构促进了灵活、独立服务的创建，并定义了明确的边界。这种可扩展的方法使开发人员能够单独维护和演化服务，而不会影响整个应用程序。然而，要实现微服务架构的全部潜力，尤其是在
    AI 驱动的聊天应用中，需要与最新的大型语言模型（LLMs）如 Meta Llama V2 和 OpenAI 的 ChatGPT 以及基于每个应用场景发布的其他微调模型进行稳健的集成，以提供多模型方法以实现多样化解决方案。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的 top 3 课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的 IT'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: LLMs are large-scale models that generate human-like text based on their training
    on diverse data. By learning from billions of words on the internet, LLMs understand
    the context and generate tuned content in various domains. However, the integration
    of various LLMs into a single application often poses challenges due to the requirement
    of unique interfaces, access endpoints, and specific payloads for each model.
    So, having a single integration service that can handle a variety of models improves
    the architecture design and empowers the scale of independent services.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 是大规模模型，根据对多样数据的训练生成类似人类的文本。通过学习互联网上数十亿个单词，LLMs 理解上下文并生成各个领域的调整内容。然而，将各种
    LLM 集成到单个应用程序中通常会面临挑战，因为每个模型都需要独特的接口、访问端点和特定的有效负载。因此，拥有一个能够处理多种模型的单一集成服务可以改善架构设计，并增强独立服务的规模。
- en: This tutorial will introduce you to IntelliNode integrations for ChatGPT and
    LLaMA V2 in a microservice architecture using Node.js and Express.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将向你介绍如何在微服务架构中使用 Node.js 和 Express 集成 ChatGPT 和 LLaMA V2 的 IntelliNode。
- en: Chatbot Integration Options
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聊天机器人集成选项
- en: 'Here are a few chat integration options provided by IntelliNode:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些由 IntelliNode 提供的聊天集成选项：
- en: '**LLaMA V2**: You can integrate the LLaMA V2 model either via Replicate’s API
    for a straightforward process or via your AWS SageMaker host for an additional
    control.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**LLaMA V2**: 你可以通过 Replicate 的 API 进行简单的集成，也可以通过你的 AWS SageMaker 主机来获得额外的控制。'
- en: LLaMA V2 is a powerful open source Large Language Model (LLM) that has been
    pre-trained and fine-tuned with up to 70B parameters. It excels in complex reasoning
    tasks across various domains, including specialized fields like programming and
    creative writing. Its training methodology involves self-supervised data and alignment
    with human preferences through Reinforcement Learning with Human Feedback (RLHF).
    LLaMA V2 surpasses existing open-source models and is comparable to closed-source
    models like ChatGPT and BARD in usability and safety.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLaMA V2 是一个强大的开源大型语言模型（LLM），经过了高达 70B 参数的预训练和微调。它在各种领域的复杂推理任务中表现出色，包括编程和创意写作等专业领域。其训练方法包括自监督数据和通过强化学习与人类反馈（RLHF）对齐。LLaMA
    V2 超越了现有的开源模型，并且在可用性和安全性方面与 ChatGPT 和 BARD 等闭源模型可媲美。
- en: '**ChatGPT**: By simply providing your OpenAI API key, IntelliNode module allows
    integration with the model in a simple chat interface. You can access ChatGPT
    through GPT 3.5 or GPT 4 models. These models have been trained on vast amounts
    of data and fine-tuned to provide highly contextual and accurate responses.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**ChatGPT**：只需提供您的 OpenAI API 密钥，IntelliNode 模块即可在简单的聊天界面中实现与该模型的集成。您可以通过 GPT
    3.5 或 GPT 4 模型访问 ChatGPT。这些模型经过大量数据的训练和微调，以提供高度上下文相关和准确的响应。'
- en: Step-by-Step Integration
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 逐步集成
- en: 'Let’s start by initializing a new Node.js project. Open up your terminal, navigate
    to your project’s directory, and run the following command:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，初始化一个新的 Node.js 项目。打开终端，导航到项目目录，然后运行以下命令：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This command will create a new `package.json` file for your application.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将为您的应用程序创建一个新的 `package.json` 文件。
- en: 'Next, install Express.js, which will be used to handle HTTP requests and responses
    and intellinode for LLM models connection:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，安装 Express.js，它将用于处理 HTTP 请求和响应，以及用于 LLM 模型连接的 IntelliNode：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Once the installation concludes, create a new file named `*app.js*` in your
    project’s root directory. then, add the express initializing code in `app.js`.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，在项目根目录中创建一个名为 `*app.js*` 的新文件，然后在 `app.js` 中添加 express 初始化代码。
- en: Code by Author
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 作者代码
- en: Llama V2 Integration Using Replicate’s API
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Replicate 的 API 进行 Llama V2 集成
- en: Replicate provides a fast integration path with Llama V2 through API key, and
    IntelliNode provides the chatbot interface to decouple your business logic from
    the Replicate backend allowing you to switch between different chat models.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Replicate 提供了通过 API 密钥与 Llama V2 快速集成的路径，而 IntelliNode 提供了聊天机器人接口，将您的业务逻辑与 Replicate
    后端解耦，允许您在不同聊天模型之间切换。
- en: 'Let’s start by integrating with Llama hosted in Replica’s backend:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先从集成 Replica 后端托管的 Llama 开始：
- en: Code by Author
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 作者代码
- en: Get your trial key from [replicate.com](https://replicate.com/) to activate
    the integration.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [replicate.com](https://replicate.com/) 获取您的试用密钥以激活集成。
- en: Llama V2 Integration Using AWS SageMaker
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 AWS SageMaker 进行 Llama V2 集成
- en: Now, let’s cover Llama V2 integration via AWS SageMaker, providing privacy and
    extra layer of control.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们介绍通过 AWS SageMaker 进行 Llama V2 集成，提供隐私和额外的控制层。
- en: 'The integration requires to generate an API endpoint from your AWS account,
    first we will setup the integration code in our micro service app:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 该集成需要从您的 AWS 账户生成一个 API 端点，首先我们将在微服务应用程序中设置集成代码：
- en: Code by Author
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 作者代码
- en: The following steps are to create a Llama endpoint in your account, once you
    set up the API gateway copy the URL to use for running the ‘*/llama/aws*’ service.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤是创建您账户中的 Llama 端点，一旦设置了 API 网关，复制 URL 用于运行 '*/llama/aws*' 服务。
- en: '**To setup a Llama V2 endpoint in your AWS account:**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**要在您的 AWS 账户中设置 Llama V2 端点：**'
- en: 1- **SageMaker Service:** select the SageMaker service from your AWS account
    and click on domains.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 1- **SageMaker 服务：** 从您的 AWS 账户中选择 SageMaker 服务并点击域。
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/fa908c1810c1c06b2a8da3ed6615f130.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后端的微服务](../Images/fa908c1810c1c06b2a8da3ed6615f130.png)'
- en: aws account-select sagemaker
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-选择 sagemaker
- en: '**2- Create a SageMaker Domain**: Begin by creating a new domain on your AWS
    SageMaker. This step establishes a controlled space for your SageMaker operations.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**2- 创建 SageMaker 域**：首先在您的 AWS SageMaker 上创建一个新域。这一步骤为您的 SageMaker 操作建立一个受控空间。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/d3e4eb2c2fe35c765526b482edbe6478.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后端的微服务](../Images/d3e4eb2c2fe35c765526b482edbe6478.png)'
- en: aws account-sagemaker domain
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-sagemaker 域
- en: '**3- Deploy the Llama Model**: Utilize SageMaker JumpStart to deploy the Llama
    model you plan to integrate. It is recommended to start with the 2B model due
    to the higher monthly cost for running the 70B model.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**3- 部署 Llama 模型**：利用 SageMaker JumpStart 部署你计划集成的 Llama 模型。建议从 2B 模型开始，因为
    70B 模型的运行费用较高。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/3e897946137642e54a6d7f3d94056685.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/3e897946137642e54a6d7f3d94056685.png)'
- en: aws account-sagemaker jump start
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-sagemaker 快速启动
- en: '**4- Copy the Endpoint Name**: Once you have a model deployed, make sure to
    note the endpoint name, which is crucial for future steps.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**4- 复制端点名称**：一旦你部署了模型，确保记下端点名称，这对后续步骤至关重要。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/ad609dc12332f5d4c631826d65e4fcfe.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/ad609dc12332f5d4c631826d65e4fcfe.png)'
- en: aws account-sagemaker endpoint
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-sagemaker 端点
- en: '**5- Create Lambda Function**: AWS Lambda allows running the back-end code
    without managing servers. Create a Node.js lambda function to use for integrating
    the deployed model.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**5- 创建 Lambda 函数**：AWS Lambda 允许在不管理服务器的情况下运行后端代码。创建一个 Node.js Lambda 函数以用于集成部署的模型。'
- en: '**6- Set Up Environment Variable**: Create an environment variable inside your
    lambda named llama_endpoint with the value of the SageMaker endpoint.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**6- 设置环境变量**：在你的 Lambda 中创建一个名为 llama_endpoint 的环境变量，值为 SageMaker 端点。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/37275ac694fe83dc35855734bbe1b8d5.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/37275ac694fe83dc35855734bbe1b8d5.png)'
- en: aws account-lmabda settings
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-lambda 设置
- en: '**7- Intellinode Lambda Import**: You need to import the prepared Lambda zip
    file that establishes a connection to your SageMaker Llama deployment. This export
    is a zip file, and it can be found in the [lambda_llama_sagemaker](https://github.com/Barqawiz/IntelliNode/tree/main/samples/lambda_llama_sagemaker)
    directory.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**7- Intellinode Lambda 导入**：你需要导入准备好的 Lambda zip 文件，该文件建立了与 SageMaker Llama
    部署的连接。该导出是一个 zip 文件，可以在 [lambda_llama_sagemaker](https://github.com/Barqawiz/IntelliNode/tree/main/samples/lambda_llama_sagemaker)
    目录中找到。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/1c7df03875aad3f7548ed5ebabc00313.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/1c7df03875aad3f7548ed5ebabc00313.png)'
- en: aws account-lambda upload from zip file
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-lambda 从 zip 文件上传
- en: '**8- API Gateway Configuration**: Click on the “Add trigger” option on the
    Lambda function page, and select “API Gateway” from the list of available triggers.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**8- API 网关配置**：点击 Lambda 函数页面上的“添加触发器”选项，从可用触发器列表中选择“API 网关”。'
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/427a4ab9401c1456a2da220ed802a700.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/427a4ab9401c1456a2da220ed802a700.png)'
- en: aws account-lambda trigger![Building Microservice for Multi-Chat Backends Using
    Llama and ChatGPT](../Images/5fd367351cb4bf63c16a130be4171536.png)
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-lambda 触发器 ![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/5fd367351cb4bf63c16a130be4171536.png)
- en: aws account-api gateway trigger
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-api 网关触发器
- en: '**9- Lambda Function Settings**: Update the lambda role to grant necessary
    permissions to access SageMaker endpoints. Additionally, the function’s timeout
    period should be extended to accommodate the processing time. Make these adjustments
    in the “Configuration” tab of your Lambda function.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**9- Lambda 函数设置**：更新 Lambda 角色以授予访问 SageMaker 端点的必要权限。此外，函数的超时设置应延长，以适应处理时间。在
    Lambda 函数的“配置”选项卡中进行这些调整。'
- en: 'Click on the role name to update the permissions and povides the permission
    to access sagemaker:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 点击角色名称以更新权限，并提供访问 SageMaker 的权限：
- en: '![Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](../Images/b6a23770eebd8848a4ea0fd4ec22e592.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![使用 Llama 和 ChatGPT 构建多聊天后台的微服务](../Images/b6a23770eebd8848a4ea0fd4ec22e592.png)'
- en: aws account-lambda role
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: aws 账户-lambda 角色
- en: ChatGPT Integration
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT 集成
- en: 'Finally, we’ll illustrate the steps to integrate Openai ChatGPT as another
    option in the micro service architecture:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将说明将 Openai ChatGPT 作为微服务架构中的另一种选项的步骤：
- en: Code by Author
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 作者编写的代码
- en: Get your trial key from [platform.openai.com](https://platform.openai.com/).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从 [platform.openai.com](https://platform.openai.com/) 获取你的试用密钥。
- en: Execution Experiment
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行实验
- en: 'First export the API key in your terminal as follow:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在终端中导出 API 密钥，如下所示：
- en: Code by Author
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 作者编写的代码
- en: 'Then run the node app:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然后运行节点应用程序：
- en: '[PRE2]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Type the following url in the browser to test chatGPT service:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '在浏览器中输入以下网址以测试 chatGPT 服务:'
- en: '[PRE3]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We built a microservice empowered by the capabilities of Large Language Models
    such as Llama V2 and OpenAI’s ChatGPT. This integration opens the door for leveraging
    endless business scenarios powered by advanced AI.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建了一个利用 Llama V2 和 OpenAI 的 ChatGPT 等大型语言模型功能的微服务。这种集成为利用先进 AI 驱动的无限商业场景打开了大门。
- en: By translating your machine learning requirements into decoupled microservices,
    your application can gain the benefits of flexibility, and scalability. Instead
    of configuring your operations to suit the constraints of a monolithic model,
    the language models function can now be individually managed and developed; this
    promises better efficiency and easier troubleshooting and upgrade management.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将机器学习需求转化为解耦的微服务，您的应用可以获得灵活性和可扩展性的好处。语言模型的功能现在可以单独管理和开发，这承诺提供更高的效率以及更易于故障排除和升级管理。
- en: References
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'ChatGPT API: [link](https://platform.openai.com/).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ChatGPT API: [链接](https://platform.openai.com/)。'
- en: 'Replica API: [link](https://docs.replicastudios.com/#replica-api).'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Replica API: [链接](https://docs.replicastudios.com/#replica-api)。'
- en: 'SageMaker Llama Jump Start: [link](https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'SageMaker Llama Jump Start: [链接](https://aws.amazon.com/blogs/machine-learning/llama-2-foundation-models-from-meta-are-now-available-in-amazon-sagemaker-jumpstart/)'
- en: 'IntelliNode Get Started: [link](https://www.intellinode.ai/getting-started)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'IntelliNode 入门: [链接](https://www.intellinode.ai/getting-started)'
- en: 'Full code GitHub repo: [link](https://github.com/intelligentnode/IntelliServer)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '完整代码 GitHub 仓库: [链接](https://github.com/intelligentnode/IntelliServer)'
- en: '**[Ahmad Albarqawi](https://www.linkedin.com/in/barqawi/)** is a Engineer and
    data science master at Illinois Urbana-Champaign.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Ahmad Albarqawi](https://www.linkedin.com/in/barqawi/)** 是伊利诺伊大学香槟分校的工程师和数据科学硕士。'
- en: More On This Topic
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Llama, Llama, Llama: 3 Simple Steps to Local RAG with Your Content](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Llama, Llama, Llama: 使用您的内容进行本地 RAG 的 3 个简单步骤](https://www.kdnuggets.com/3-simple-steps-to-local-rag-with-your-content)'
- en: '[Using Groq Llama 3 70B Locally: Step by Step Guide](https://www.kdnuggets.com/using-groq-llama-3-70b-locally-step-by-step-guide)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在本地使用 Groq Llama 3 70B: 分步指南](https://www.kdnuggets.com/using-groq-llama-3-70b-locally-step-by-step-guide)'
- en: '[10 Hurdles of Building a Deep Tech Startup in the Age of ChatGPT](https://www.kdnuggets.com/2023/04/10-hurdles-building-deep-tech-startup-age-chatgpt.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 ChatGPT 时代建立深科技创业公司面临的 10 个障碍](https://www.kdnuggets.com/2023/04/10-hurdles-building-deep-tech-startup-age-chatgpt.html)'
- en: '[Visual ChatGPT: Microsoft Combine ChatGPT and VFMs](https://www.kdnuggets.com/2023/03/visual-chatgpt-microsoft-combine-chatgpt-vfms.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Visual ChatGPT: 微软结合 ChatGPT 和 VFM](https://www.kdnuggets.com/2023/03/visual-chatgpt-microsoft-combine-chatgpt-vfms.html)'
- en: '[Generative AI Playground: LLMs with Camel-5b and Open LLaMA 3B on…](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-llms-with-camel-5b-and-open-llama-3b)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[生成性 AI 游乐场: Camel-5b 和 Open LLaMA 3B 的 LLM](https://www.kdnuggets.com/2024/02/intel-generative-ai-playground-llms-with-camel-5b-and-open-llama-3b)'
- en: '[ChatGPT CLI: Transform Your Command-Line Interface Into ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ChatGPT CLI: 将您的命令行界面转换为 ChatGPT](https://www.kdnuggets.com/2023/07/chatgpt-cli-transform-commandline-interface-chatgpt.html)'
