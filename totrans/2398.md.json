["```py\n%%capture\n!pip install kaggle\n!kaggle competitions download -c spaceship-titanic\n!unzip -d ./dataset spaceship-titanic\n\n```", "```py\nimport numpy as np\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer,KNNImputer\nfrom sklearn.pipeline import FeatureUnion,make_pipeline,Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n```", "```py\ndf = pd.read_csv(\"dataset/train.csv\")\n\ndf\n\n```", "```py\ndf.shape\n\n>>> (8693, 14)\n\n```", "```py\nNA = pd.DataFrame(data=[df.isna().sum().tolist(), [\"{:.2f}\".format(i)+'%' \\\n           for i in (df.isna().sum()/df.shape[0]*100).tolist()]], \n           columns=df.columns, index=['NA Count', 'NA Percent']).transpose()\n\nNA.style.background_gradient(cmap=\"Pastel1_r\", subset=['NA Count'])\n\n```", "```py\nall_col = df.columns\ncat_na = ['HomePlanet', 'CryoSleep','Destination','VIP']\nnum_na = ['Age','RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\ndata1 = df.copy()\ndata2 = df.copy()\n\ndata1['Age'].isna().sum()\n\n>>> 179\n\n```", "```py\ndata1.Age[0:5]\n\n>>> 0    39.0\n>>> 1    24.0\n>>> 2    58.0\n>>> 3    33.0\n>>> 4    16.0\n\n```", "```py\nimp = SimpleImputer(strategy='mean')\ndata1['Age'] = imp.fit_transform(data1['Age'].values.reshape(-1, 1) )\n\ndata1['Age'].isna().sum()\n\n>>> 0\n\n```", "```py\ndata1['HomePlanet'].isna().sum()\n\n>>> 201\n\n```", "```py\ndata1.HomePlanet[0:5]\n\n>>> 0    Europa\n>>> 1     Earth\n>>> 2    Europa\n>>> 3    Europa\n>>> 4     Earth\n\n```", "```py\nimp = SimpleImputer(strategy=\"most_frequent\")\ndata1['HomePlanet'] = imp.fit_transform(data1['HomePlanet'].values.reshape(-1, 1))\n\n```", "```py\ndata1['HomePlanet'].isna().sum()\n\n>>> 0\n\n```", "```py\ndata2[num_na].isna().sum()\n\n```", "```py\n>>> Age             179\n>>> RoomService     181\n>>> FoodCourt       183\n>>> ShoppingMall    208\n>>> Spa             183\n>>> VRDeck          188\n\n```", "```py\nimp = IterativeImputer(max_iter=10, random_state=0)\ndata2[num_na] = imp.fit_transform(data2[num_na])\n\ndata2[num_na].isna().sum()\n\n```", "```py\n>>> Age             0\n>>> RoomService     0\n>>> FoodCourt       0\n>>> ShoppingMall    0\n>>> Spa             0\n>>> VRDeck          0\n\n```", "```py\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OrdinalEncoder\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\nX,y = df.drop(['Transported','PassengerId','Name','Cabin'],axis = 1) , df['Transported']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=0)\n```", "```py\nnumeric_transformer = Pipeline(steps=[\n   ('imputer', KNNImputer(n_neighbors=2, weights=\"uniform\")),\n   ('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n   ('imputer', SimpleImputer(strategy='most_frequent')),\n   ('onehot', OrdinalEncoder())])\n\n```", "```py\npreprocessor = ColumnTransformer(\n   remainder = 'passthrough',\n   transformers=[\n       ('numeric', numeric_transformer, num_na),\n       ('categorical', categorical_transformer, cat_na)\n])\n\n```", "```py\ntransform = Pipeline(\n   steps=[\n       (\"processing\", preprocessor),\n       (\"DecisionTreeClassifier\", DecisionTreeClassifier()),\n   ]\n)\n\n```", "```py\nmodel = transform.fit(X_train,y_train)\nmodel.score(X_test, y_test)\n>>> 0.75\n\n```", "```py\nfrom sklearn.metrics import classification_report\nprediction = model.predict(X_test)\nprint(classification_report(prediction, y_test))\n\n```", "```py\n                precision    recall  f1-score   support\n\n       False       0.70      0.74      0.72        43\n        True       0.80      0.75      0.77        57\n    accuracy                           0.75       100\n   macro avg       0.75      0.75      0.75       100\nweighted avg       0.75      0.75      0.75       100\n\n```"]