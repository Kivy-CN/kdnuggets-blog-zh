- en: Trust in AI is Priceless
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对 AI 的信任是无价的
- en: 原文：[https://www.kdnuggets.com/2022/08/trust-ai-priceless.html](https://www.kdnuggets.com/2022/08/trust-ai-priceless.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/08/trust-ai-priceless.html](https://www.kdnuggets.com/2022/08/trust-ai-priceless.html)
- en: '![Trust in AI is Priceless](../Images/73c95f144292631c4932253a6248fa51.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![对 AI 的信任是无价的](../Images/73c95f144292631c4932253a6248fa51.png)'
- en: As the co-founder and CTO of an IDE platform for data-centric AI ([Kili Technology](https://kili-technology.com/)),
    I see too many machine learning models failing to deliver. Sadly, it’s often due
    to a lack of focus on data quality.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个数据驱动的 AI IDE 平台（[Kili Technology](https://kili-technology.com/)）的联合创始人和首席技术官，我看到太多的机器学习模型无法交付成果。遗憾的是，这通常是因为对数据质量的关注不足。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT 事务'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Quick Catch-up
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 快速跟进
- en: 10 years ago, during the model-centric AI era, AI peeps like us struggled with
    the model. We lacked infrastructure, tools, toolkits, or frameworks to help us
    create and train ML models.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 十年前，在模型驱动的 AI 时代，我们这些 AI 从业者在模型上挣扎。我们缺乏基础设施、工具、工具包或框架来帮助我们创建和训练 ML 模型。
- en: Today, life-saving packages such as Tensorflow and PyTorch exist. We now have
    to focus on data, from its finding and sorting to its annotation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，像 Tensorflow 和 PyTorch 这样的拯救生命的包存在。我们现在必须专注于数据，从数据的发现、排序到标注。
- en: But it’s worth it. On many occasions, improving the data quality will have a
    more significant impact on its performance than any tuning of hyperparameters
    or neural network architecture.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但这很值得。在许多情况下，提高数据质量对性能的影响会比调整超参数或神经网络架构更为显著。
- en: 'You only need 2 things in [data-centric AI](https://kili-technology.com/blog/data-centric-ai-manifesto):'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你在 [数据驱动的 AI](https://kili-technology.com/blog/data-centric-ai-manifesto) 中只需要两个东西：
- en: Quality data, which consists of clean and diverse data
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高质量的数据，包括干净和多样化的数据
- en: Sufficient volume of training data.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 充足的训练数据量。
- en: Bigger is Not Always Better
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大的并不总是更好
- en: 'Big volumes of data are the key to many deep learning successes. But big volumes
    of data come with challenges:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 大量的数据是许多深度学习成功的关键。但大量的数据也带来了挑战：
- en: it is cumbersome and expensive in terms of hardware and human computing resources;
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在硬件和人力计算资源方面，它既繁琐又昂贵；
- en: 'it poses problems: bias, technical debt and compatibility with the new foundation
    model paradigm.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它带来了问题：偏差、技术债务和与新基础模型范式的兼容性。
- en: Model bias
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型偏差
- en: If you focus on labeling productivity and apply pre-annotation to documents
    too early, it encourages annotators to include errors from your model in the data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你专注于标注生产力，并过早地对文档进行预标注，会鼓励标注者将模型中的错误包含到数据中。
- en: 'If you want to minimize bias, there’s no free lunch. Here’s how to proceed:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想最小化偏差，没有免费的午餐。以下是如何进行：
- en: Start with rules-based automation if you have some a priori knowledge of the
    task. For instance, regular expressions and dictionaries are useful for NLP.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你对任务有一些先验知识，可以从基于规则的自动化开始。例如，正则表达式和字典对 NLP 很有用。
- en: Then go manual labeling. This is where you actually create value for your model
    because you annotate the hard part made of non-trivial examples and edge cases.
    Quality management is vital for this phase as it requires a lot of synchronization
    across the labelers to be consistent.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后进行手动标注。这是你真正为模型创造价值的地方，因为你标注了那些非平凡的例子和边缘案例。质量管理对这一阶段至关重要，因为它需要标注者之间的高度同步以保持一致。
- en: Finally, model pre-labeling to go [from a good to a great dataset](https://kili-technology.com/blog/create-dataset-for-machine-learning).
    It should only be used at the end; otherwise, you will create biases.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，模型预标注，以便 [从一个好的数据集变成一个出色的数据集](https://kili-technology.com/blog/create-dataset-for-machine-learning)。这应该只在最后使用；否则，你会产生偏差。
- en: '![Trust in AI is Priceless](../Images/f4348b47a78fd4f88e91c6afff26d2fb.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![对AI的信任是无价的](../Images/f4348b47a78fd4f88e91c6afff26d2fb.png)'
- en: Technical debt
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术债务
- en: 'In software development, doubling the amount of code means doubling many things:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件开发中，代码量翻倍意味着很多事情翻倍：
- en: the number of behaviors our system creates
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们系统创建的行为数量
- en: the number of unit tests required.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所需的单元测试数量。
- en: 'For AI, code = data. Doubling the amount of data means doubling:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI来说，代码 = 数据。数据量翻倍意味着：
- en: the number of behaviors our ML system creates
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们机器学习系统创建的行为数量
- en: the number of ML unit tests required
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所需的机器学习单元测试数量
- en: the technical debt otherwise.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 否则的技术债务。
- en: Not compatible with foundation models
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与基础模型不兼容
- en: Today, we have giant foundation models (GPT-3, BERT, or DALL-E 2) that have
    been pre-trained on all text or images on the Internet; they understand language
    rules. Since your model needs a huge generalization capability, it needs very
    little data. As a result, every data will have a stronger impact. Thus instead
    of annotating a large volume of data with potential errors, you need to annotate
    less and be more precise about the examples you feed your model, as bad data can
    easily influence them.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，我们拥有已经在互联网所有文本或图像上预训练的巨大基础模型（GPT-3、BERT或DALL-E 2）；它们理解语言规则。由于你的模型需要巨大的泛化能力，因此它需要的数据非常少。因此，每个数据将产生更强的影响。因此，与其标注大量潜在错误的数据，不如标注较少的数据并更准确地提供示例，因为不良数据很容易影响模型。
- en: Why is Getting Quality Data Challenging?
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么获取高质量数据具有挑战性？
- en: 'To reduce the amount of data needed by our ML models, we must improve its quality.
    However, it is challenging since we’ve to address these 2 points simultaneously:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少我们机器学习模型所需的数据量，我们必须提高数据质量。然而，这很有挑战性，因为我们必须同时解决这两点：
- en: '[data representativeness](https://kili-technology.com/blog/a-brief-introduction-to-imbalanced-datasets)
    (Is the data unbiased? Does the data cover the edge cases?)'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据代表性](https://kili-technology.com/blog/a-brief-introduction-to-imbalanced-datasets)（数据是否存在偏见？数据是否涵盖了边缘情况？）'
- en: labeling consistency (do the labelers annotate the same way? Have they understood
    the task?).
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签一致性（标注者是否以相同的方式进行标注？他们是否理解任务？）。
- en: Datasets are not easy to debug. It is not always easy to give a yes or no answer.
    For instance, in an image classification task, is an image of a house's window
    an image of a house?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集不容易调试。并非总是容易给出“是”或“否”的回答。例如，在图像分类任务中，一张房屋窗户的图像是否就是房屋的图像？
- en: The answer will depend on the context, on the task, on the usage, etc. This
    is true for non-expert tasks. This is also true for expert tasks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 答案将取决于背景、任务、用途等。这对于非专家任务是正确的，对于专家任务也是如此。
- en: 'For instance:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 比如：
- en: Rheumatoid arthritis and malaria have been treated with chloroquine for decades.
    -> treats the relation between chloroquine and malaria.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类风湿性关节炎和疟疾已经用了几十年的氯喹进行治疗。 -> 处理氯喹与疟疾之间的关系。
- en: Among 56 subjects reporting to a clinic with symptoms of malaria, 53 (95%) had
    ordinarily effective levels of chloroquine in blood. -> DOES NOT treat the relation
    between chloroquine and malaria.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在56名因疟疾症状前往诊所的受试者中，有53人（95%）血液中氯喹的水平通常是有效的。 -> 不处理氯喹与疟疾之间的关系。
- en: How to Manage Quality at Scale
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在规模上管理质量
- en: At Kili Technology, we’re committed to sharing [best practices](https://resources.kili-technology.com/nurture/directory-collaboration-project-management)
    with our users willing to manage quality and scale.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kili Technology，我们致力于与愿意管理质量和规模的用户分享[最佳实践](https://resources.kili-technology.com/nurture/directory-collaboration-project-management)。
- en: Label consistency
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标签一致性
- en: 'Here are some tips:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些建议：
- en: Iterate in small steps on the annotation. Here’s the specific process for [building
    quality datasets](https://kili-technology.com/blog/building-a-training-dataset-ml).
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在标注时小步迭代。这里是[构建高质量数据集](https://kili-technology.com/blog/building-a-training-dataset-ml)的具体过程。
- en: 'Just so you know: each iteration should last 3 days tops.'
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仅供参考：每次迭代应持续3天为限。
- en: The engineer responsible for building the model annotates 50 to 100 examples
    by hand, giving you an idea of the different classes that exist.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负责构建模型的工程师手动标注50到100个示例，帮助你了解存在的不同类别。
- en: Write solid definitions and concepts of classes you aim for your model to identify.
    This should include instructions on how to handle specific edge cases.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写你希望模型识别的类别的稳固定义和概念。这应包括处理特定边缘情况的说明。
- en: Iteratively get larger batches of documents annotated (100 or 200 at a time)
    by external partners or others within the company.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迭代获取更多批量的文档注释（每次100或200）由外部合作伙伴或公司内部的其他人进行。
- en: 'Iterate to debug at any step: [instructions](https://kili-technology.com/blog/my-state-of-the-art-machine-learning-model-does-not-reach-its-accuracy-promise-what-can-i-do#123),
    ontology, [consensus](https://docs.kili-technology.com/docs/consensus-overview)
    coverage.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在任何步骤迭代调试：[说明](https://kili-technology.com/blog/my-state-of-the-art-machine-learning-model-does-not-reach-its-accuracy-promise-what-can-i-do#123)、本体，[共识](https://docs.kili-technology.com/docs/consensus-overview)覆盖。
- en: Use a tool design to avoid wrong annotation gesture by design.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用工具设计来避免设计上的错误注释手势。
- en: Prevent bad annotations. For instance, in relation extraction, prohibit relationships
    in the UX that don't make sense.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止不良注释。例如，在关系抽取中，禁止UX中不合理的关系。
- en: Minimize the number and complexity of annotation actions. For example, on some
    tasks, it is better to draw the object first and then select the class, and on
    other tasks, the opposite is true.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最小化注释动作的数量和复杂性。例如，在某些任务中，最好先绘制对象然后选择类别，而在其他任务中则相反。
- en: 'Train your people: labeling needs proper training to get labelers to ramp up
    fast.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 培训你的人员：标注需要适当的培训，以使标注人员能够快速上手。
- en: Detect possible errors.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测可能的错误。
- en: Implement rule-based quality checks from the beginning of the project. e.g.,
    isn't the number of annotated vertebrae greater than the number of human vertebrae?
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从项目开始就实施基于规则的质量检查。例如，注释的椎骨数量是否大于人体椎骨数量？
- en: Use a model to compute the likelihood of your labels and prioritize the review
    at the end of your project.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用模型计算标签的可能性，并在项目结束时优先审查。
- en: Use metrics, such as the consensus at asset and annotators levels to debug your
    labeling process and prioritize your review.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用指标，例如资产和标注者级别的共识，来调试你的标注过程并优先进行审查。
- en: 'Set a pyramidal review system with layers: pre-annotation models, then labelers,
    then reviewers, and ML engineers.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设立一个金字塔式的审查系统，包括：预注释模型，然后是标注人员，然后是审查员，最后是ML工程师。
- en: '![Trust in AI is Priceless](../Images/f69e08d302b3764cb25f316102ac5a37.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![对AI的信任是无价的](../Images/f69e08d302b3764cb25f316102ac5a37.png)'
- en: Data representativeness
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据代表性
- en: 'Two important points here:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个重要的点：
- en: Have unbiased data.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有无偏的数据。
- en: Have sufficiently rich data.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有足够丰富的数据。
- en: 'Our world is full of biases that need to be removed from the models. For example,
    if I use the embeddings of GPT-2 to build a sentiment analysis model on financial
    news, the names of the companies alone are already tinged with a sentiment: Volkswagen
    is negative because of the scandal of the last few years, over-represented in
    the GPT-2 training data. To correct this, here are some ideas:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的世界充满了需要从模型中去除的偏差。例如，如果我使用GPT-2的嵌入来构建一个金融新闻情感分析模型，单公司的名称已经带有情感色彩：由于过去几年的丑闻，大众汽车在GPT-2训练数据中被过度代表，因此情感是负面的。为了纠正这一点，以下是一些想法：
- en: replace sensitive named entities (companies) with placeholders before training
    a language model;
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在训练语言模型之前，用占位符替换敏感的命名实体（公司）；
- en: generate counterfactual data to balance the feelings related to company names;
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成反事实数据以平衡与公司名称相关的情感；
- en: orthogonalize the embedding space to remove the bias effect.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正交化嵌入空间以去除偏差效应。
- en: 'Our world is full of [edge cases](https://kili-technology.com/blog/guide-to-human-in-the-loop-machine-learning#104).
    For example, a chair flying on the highway in self-driving cars images. To build
    a diversified dataset, you can reuse the boosting method, well known in ML, to
    the data. From a reservoir of data candidates:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的世界充满了[边缘案例](https://kili-technology.com/blog/guide-to-human-in-the-loop-machine-learning#104)。例如，自驾车图像中的一把椅子飞在高速公路上。为了建立一个多样化的数据集，你可以将ML中知名的提升方法应用于数据。从数据候选库中：
- en: Train an initial model and predict on the validation set.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练一个初始模型并在验证集上进行预测。
- en: Use another pre-trained model to extract embeddings.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用另一个预训练模型来提取嵌入。
- en: For each misclassified validation image, retrieve the nearest neighbors using
    the embeddings. Add these nearest neighbor images to the training set.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个分类错误的验证图像，使用嵌入检索最近邻。将这些最近邻图像添加到训练集中。
- en: Retrain the model with the added images and predict on the validation set.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用新增图像重新训练模型，并在验证集上进行预测。
- en: Repeat until you are good.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重复直到做得好为止。
- en: Conclusion
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Until now, the ML community has focused on data quantity. Now, we need quality.
    There are many other tips to get this quality at scale.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，机器学习社区一直关注数据的数量。现在，我们需要的是质量。还有许多其他方法可以在大规模上获得这种质量。
- en: P.S. [Tweet](http://@edarchimbaud) me your feedback!
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 附言：[推特](http://@edarchimbaud) 给我你的反馈！
- en: '**[Edouard d''Archimbaud](https://www.linkedin.com/in/edouard-d-archimbaud/)**
    ([**@edarchimbaud**](https://twitter.com/edarchimbaud)) is a ML engineer, CTO
    and cofounder of [Kili](https://kili-technology.com/), a leading training data
    platform for enterprise AI. He is passionate about **Data-centric AI**, the new
    paradigm for successful AI.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**[爱德华·达尔钦博](https://www.linkedin.com/in/edouard-d-archimbaud/)** （[**@edarchimbaud**](https://twitter.com/edarchimbaud)）是一名机器学习工程师，CTO以及[Kili](https://kili-technology.com/)的联合创始人，该公司是企业AI领先的训练数据平台。他对**数据中心人工智能**充满热情，这是成功AI的新范式。'
- en: More On This Topic
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[In Data We Trust: Data Centric AI](https://www.kdnuggets.com/2022/10/data-trust-data-centric-ai.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[我们信任数据：数据中心的人工智能](https://www.kdnuggets.com/2022/10/data-trust-data-centric-ai.html)'
- en: '[Sky''s the Limit: Learn how JetBlue uses Monte Carlo and Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[天空才是极限：了解JetBlue如何使用Monte Carlo和Snowflake…](https://www.kdnuggets.com/2022/12/monte-carlo-jetblue-snowflake-build-trust-improve-model-accuracy.html)'
- en: '[The Quest for Model Confidence: Can You Trust a Black Box?](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型信心的探索：你能信任黑箱吗？](https://www.kdnuggets.com/the-quest-for-model-confidence-can-you-trust-a-black-box)'
