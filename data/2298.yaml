- en: Simple NLP Pipelines with HuggingFace Transformers
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 HuggingFace Transformers 的简单 NLP 管道
- en: 原文：[https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html](https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html](https://www.kdnuggets.com/2023/02/simple-nlp-pipelines-huggingface-transformers.html)
- en: '![Simple NLP Pipelines with HuggingFace Transformers](../Images/1e310be2c1220fd85c3c9ca5c5c49028.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![使用 HuggingFace Transformers 的简单 NLP 管道](../Images/1e310be2c1220fd85c3c9ca5c5c49028.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：编辑
- en: An extensive package providing APIs and user-friendly tools to work with state-of-the-art
    pretrained models across language, vision, audio, and multi-modal modalities is
    what transformers by HuggingFace is all about. It consists of more than 170 pretrained
    models and supports frameworks such as PyTorch, TensorFlow, and JAX with the ability
    to interoperate among them in between code. The library is also deployment friendly
    as it allows the conversion of models to ONNX and TorchScript formats.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: HuggingFace 的 transformers 是一个提供 API 和用户友好工具的广泛软件包，用于处理最先进的预训练模型，涵盖语言、视觉、音频和多模态领域。它包含超过
    170 个预训练模型，并支持 PyTorch、TensorFlow 和 JAX 等框架，并能够在这些框架之间进行互操作。该库也友好于部署，因为它允许将模型转换为
    ONNX 和 TorchScript 格式。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速开启网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this blog, we will particularly explore the `pipelines` functionality of
    transformers which can be easily used for inference. Pipelines provide an abstraction
    of the complicated code and offer simple API for several tasks such as Text Summarization,
    Question Answering, Named Entity Recognition, Text Generation, and Text Classification
    to name a few. The best thing about these APIs is that all the tasks from preprocessing
    to model evaluation can be performed with just a few lines of code without requiring
    heavy computational resources.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇博客中，我们将特别探讨 transformers 的 `pipelines` 功能，该功能可以轻松用于推理。管道提供了复杂代码的抽象，并提供简单的
    API，用于执行多个任务，例如文本摘要、问答、命名实体识别、文本生成和文本分类等。最棒的是，这些 API 允许从预处理到模型评估的所有任务，只需几行代码，而无需大量计算资源。
- en: Now, let’s dive right into it!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们直接深入吧！
- en: The first step is to install the transformers package with the following command
    -
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是使用以下命令安装 transformers 包 -
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we will use the `pipeline` structure to implement different tasks.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用 `pipeline` 结构来实现不同的任务。
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The pipeline allows to specify multiple parameters such as `task`, `model`,
    `device`, `batch size`, and other task specific parameters.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道允许指定多个参数，如 `task`、`model`、`device`、`batch size` 以及其他特定任务的参数。
- en: Let’s begin with the first task.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一个任务开始。
- en: 1\. Text Summarization
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1\. 文本摘要
- en: The input to this task is a corpus of text and the model will output a summary
    of it based on the expected length mentioned in the parameters. Here, we have
    kept minimum length as 5 and maximum length as 30.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 该任务的输入是一个文本语料库，模型将根据参数中提到的期望长度输出摘要。在这里，我们将最小长度设置为 5，最大长度设置为 30。
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Output:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: One can also choose from the other options of models that have been fine-tuned
    for the summarization task - `bart-large-cnn`, `t5-small`, `t5-large`, `t5-3b`,
    `t5-11b`. You can check out the complete list of available models [here](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以从其他为摘要任务微调的模型中选择，如 `bart-large-cnn`、`t5-small`、`t5-large`、`t5-3b`、`t5-11b`。你可以在
    [这里](https://huggingface.co/models?pipeline_tag=summarization&sort=downloads)
    查看可用模型的完整列表。
- en: 2\. Question Answering
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2\. 问答
- en: In this task, we provide a question and a context. The model will choose the
    answer from the context based on the highest probability score. It also provides
    the starting and ending positions of the text.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在此任务中，我们提供一个问题和一个上下文。模型将根据最高概率分数从上下文中选择答案。它还提供了文本的起始和结束位置。
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Output:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Refer [here](https://huggingface.co/models?pipeline_tag=question-answering),
    to check the full list of available models for the Question-Answering task.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 参考[这里](https://huggingface.co/models?pipeline_tag=question-answering)查看问答任务的可用模型的完整列表。
- en: 3\. Named Entity Recognition
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 3\. 命名实体识别
- en: Named Entity Recognition deals with identifying and classifying the words based
    on the names of persons, organizations, locations and so on. The input is basically
    a sentence and the model will determine the named entity along with its category
    and its corresponding location in the text.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 命名实体识别涉及根据人名、组织名、地点名等来识别和分类单词。输入基本上是一个句子，模型将确定命名实体及其类别以及在文本中的相应位置。
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Output:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Check out [here](https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads),
    for other options of available models.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 查阅[这里](https://huggingface.co/models?pipeline_tag=token-classification&sort=downloads)了解其他可用模型的选项。
- en: 4\. Part-of-Speech Tagging
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4\. 词性标注
- en: PoS Tagging is useful to classify the text and provide its relevant parts of
    speech such as whether a word is a noun, pronoun, verb and so on. The model returns
    PoS tagged words along with their probability scores and respective locations.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 词性标注对于对文本进行分类以及提供相关的词性（例如一个词是否是名词、代词、动词等）非常有用。模型返回标注了词性的单词及其概率分数和相应的位置。
- en: '[PRE8]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Output:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE9]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 5\. Text Classification
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5\. 文本分类
- en: We will perform sentiment analysis and classify the text based on the tone.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将进行情感分析并根据语气对文本进行分类。
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Output:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE11]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Let’s try a few more examples.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再尝试几个例子。
- en: '[PRE12]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The full list of models for text classification can be found [here](https://huggingface.co/models?filter=text-classification).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类模型的完整列表可以在[这里](https://huggingface.co/models?filter=text-classification)找到。
- en: '6\. Text Generation:'
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6\. 文本生成：
- en: '[PRE14]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Output:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE15]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Access the full list of models for text generation [here](https://huggingface.co/models?filter=text-generation).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 访问[这里](https://huggingface.co/models?filter=text-generation)获取文本生成模型的完整列表。
- en: '7\. Text Translation:'
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7\. 文本翻译：
- en: Here, we will translate the language of text from one language to another. For
    example, we have chosen translation from English to French. We have used the basic
    t5-small model but you can access other advanced models [here](https://huggingface.co/models?pipeline_tag=translation).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将把文本的语言从一种语言翻译成另一种语言。例如，我们选择了从英语到法语的翻译。我们使用了基础的t5-small模型，但你可以在[这里](https://huggingface.co/models?pipeline_tag=translation)访问其他高级模型。
- en: '[PRE16]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Output:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 输出：
- en: '[PRE17]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Conclusion
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: You reached till the end, awesome! If you have followed along, you learned how
    to create basic NLP pipelines with Transformers. Refer to the [official documentation](https://huggingface.co/docs/transformers/main_classes/pipelines#natural-language-processing)
    by HuggingFace in order to check out other interesting applications in NLP such
    as Zero Shot Text Classification or Table Question Answering. In order to work
    with your own datasets or implement models from other domains such as vision,
    audio, or multimodal, check out [here](https://huggingface.co/docs/transformers/pipeline_tutorial#pipelines-for-inference).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经到达了最后，真棒！如果你跟随了整个过程，你学习了如何使用Transformers创建基础的NLP管道。参考HuggingFace的[官方文档](https://huggingface.co/docs/transformers/main_classes/pipelines#natural-language-processing)以查看NLP中的其他有趣应用，如零样本文本分类或表格问答。要处理你自己的数据集或实现其他领域（如视觉、音频或多模态）的模型，请查看[这里](https://huggingface.co/docs/transformers/pipeline_tutorial#pipelines-for-inference)。
- en: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** is a passionate
    AI developer and writer pursuing Master’s in Machine Learning from Université
    de Montréal. Yesha is intrigued to explore responsible AI techniques to solve
    challenges that benefit society and share her learnings with the community.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Yesha Shastri](https://www.linkedin.com/in/yeshashastri/)** 是一位热情的AI开发者和作家，正在蒙特利尔大学攻读机器学习硕士学位。Yesha
    对探索负责任的AI技术以解决对社会有益的挑战充满兴趣，并与社区分享她的学习成果。'
- en: More On This Topic
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Answering Questions with HuggingFace Pipelines and Streamlit](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用HuggingFace Pipelines和Streamlit回答问题](https://www.kdnuggets.com/2021/10/simple-question-answering-web-app-hugging-face-pipelines.html)'
- en: '[A Simple to Implement End-to-End Project with HuggingFace](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个简单易实施的端到端项目与 HuggingFace](https://www.kdnuggets.com/a-simple-to-implement-end-to-end-project-with-huggingface)'
- en: '[Fine-Tuning BERT for Tweets Classification with HuggingFace](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 HuggingFace 微调 BERT 进行推文分类](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)'
- en: '[HuggingFace Has Launched a Free Deep Reinforcement Learning Course](https://www.kdnuggets.com/2022/05/huggingface-launched-free-deep-reinforcement-learning-course.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[HuggingFace 推出了免费的深度强化学习课程](https://www.kdnuggets.com/2022/05/huggingface-launched-free-deep-reinforcement-learning-course.html)'
- en: '[Beyond Pipelines: Graphs as Scikit-Learn Metaestimators](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[超越管道：作为 Scikit-Learn 元估计器的图形](https://www.kdnuggets.com/2022/09/graphs-scikitlearn-metaestimators.html)'
- en: '[Unify Batch and ML Systems with Feature/Training/Inference Pipelines](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过特征/训练/推理管道统一批处理和 ML 系统](https://www.kdnuggets.com/2023/09/hopsworks-unify-batch-ml-systems-feature-training-inference-pipelines)'
