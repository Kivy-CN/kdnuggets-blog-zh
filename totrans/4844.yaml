- en: Complete Guide to Build ConvNet HTTP-Based Application using TensorFlow and
    Flask RESTful Python API
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 和 Flask RESTful Python API 构建 ConvNet 基于 HTTP 的应用程序完整指南
- en: 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)'
- en: This tutorial takes you along the steps required to create a convolutional neural
    network (CNN/ConvNet) using TensorFlow and get it into production by allowing
    remote access via a HTTP-based application using Flask RESTful API.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将引导你完成使用 TensorFlow 创建卷积神经网络 (CNN/ConvNet) 的步骤，并通过允许通过基于 HTTP 的 Flask RESTful
    API 应用程序进行远程访问来投入生产。
- en: In this tutorial, a CNN is to be built using TensorFlow NN (tf.nn) module. The
    CNN model architecture is created and trained and tested against the CIFAR10 dataset.
    To make the model remotely accessible, a Flask Web application is created using
    Python to receive an uploaded image and return its classification label using
    HTTP. Anaconda3 is used in addition to TensorFlow on Windows with CPU support.
    This tutorial assumes you have a basic understanding of CNN such as layers, strides,
    and padding. Also knowledge about Python is required.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将使用 TensorFlow NN (tf.nn) 模块构建一个 CNN。CNN 模型架构将被创建、训练并在 CIFAR10 数据集上进行测试。为了使模型可以远程访问，将使用
    Python 创建一个 Flask Web 应用程序，通过 HTTP 接收上传的图像并返回其分类标签。除了 TensorFlow 外，Windows 上还使用了
    Anaconda3 和 CPU 支持。本教程假设你对 CNN 有基本了解，如层、步幅和填充。同时需要了解 Python。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: 'The tutorial is summarized into the following steps:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程总结为以下步骤：
- en: Preparing the Environment by Installing Python, TensorFlow, PyCharm, and Flask
    API.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过安装 Python、TensorFlow、PyCharm 和 Flask API 准备环境。
- en: Downloading and Preparing the CIFAR-10 Dataset.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载并准备 CIFAR-10 数据集。
- en: Building the CNN Computational Graph using TensorFlow.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 TensorFlow 构建 CNN 计算图。
- en: Training the CNN.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练 CNN。
- en: Saving the Trained CNN Model.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保存训练好的 CNN 模型。
- en: Preparing the Test Data and Restoring the Trained CNN Model.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 准备测试数据并恢复训练好的 CNN 模型。
- en: Testing the Trained CNN Model.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试训练好的 CNN 模型。
- en: Building the Flask Web Application.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建 Flask Web 应用程序。
- en: Upload an Image using HTML Form.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 HTML 表单上传图像。
- en: Creating Helper HTML, JavaScript, and CSS Files.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建辅助 HTML、JavaScript 和 CSS 文件。
- en: HTTP-Based Remote Accessing the Trained Model for Prediction.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 基于 HTTP 的远程访问训练模型进行预测。
- en: 1\. Installing Python, TensorFlow, PyCharm, and Flask API
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1\. 安装 Python、TensorFlow、PyCharm 和 Flask API
- en: Before starting building the project, it is required to prepare its environment.
    Python is the first tool to start installing because the environment is fully
    dependent on it. If you already have the environment prepared, you can skip the
    first step.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始构建项目之前，需要准备环境。Python 是第一个需要安装的工具，因为环境完全依赖于它。如果你已经准备好了环境，可以跳过第一步。
- en: '**1.1 Anaconda/Python Installation**'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.1 Anaconda/Python 安装**'
- en: It is possible to install the native Python distribution but it is recommended
    to use an all-in-one package such as Anaconda because it does some stuff for you.
    In this project, Anaconda 3 is used. For Windows, the executable file can be downloaded
    from [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows).
    It could be installed easily.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可以安装原生 Python 发行版，但建议使用如 Anaconda 这样的全功能包，因为它会为你完成一些工作。在这个项目中，使用了 Anaconda 3。对于
    Windows，可以从 [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows)
    下载可执行文件。安装起来很简单。
- en: To ensure Anaconda3 is installed properly, the CMD command (*where python*)
    could be issued as in figure 1\. If Anaconda3 is installed properly, its installation
    path will appear in the command output.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保 Anaconda3 安装正确，可以如图 1 所示发出 CMD 命令（*where python*）。如果 Anaconda3 安装正确，命令输出中会出现其安装路径。
- en: '**Figure 1**'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1**'
- en: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)'
- en: '**1.2 TensorFlow Installation**'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.2 TensorFlow 安装**'
- en: After installation Python using Anaconda3, next is to install TensorFlow (TF).
    This tutorial uses TF on Windows with CPU support. The installation instructions
    are found in this page [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows).
    This YouTube video might be helpful ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU)).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Anaconda3 安装 Python 后，接下来是安装 TensorFlow (TF)。本教程使用支持 CPU 的 Windows 上的 TF。安装说明可以在此页面找到
    [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows)。这个
    YouTube 视频可能会有帮助 ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU))。
- en: 'TF installation steps are as follows:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: TF 安装步骤如下：
- en: '1) Creating a conda environment for TF by invoking this command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 通过调用以下命令创建 TF 的 conda 环境：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This creates an empty folder holding the virtual environment (venv) for TF installation.
    The venv is located under Anaconda3 installation directory in this location (\Anaconda3\envs\tensorflow).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这会创建一个空文件夹以保存 TF 安装的虚拟环境（venv）。venv 位于 Anaconda3 安装目录下的此位置（\Anaconda3\envs\tensorflow）。
- en: '2) Activating the venv for TensorFlow installation using this command:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 使用以下命令激活 TensorFlow 安装的 venv：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The above command tells that we are inside the venv and any library installation
    will be inside it. The command prompt is expected to be changed after this command
    to be (tensorflow)C:>. After getting into the directory, we are ready to install
    the library.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令表明我们在 venv 内部，任何库安装都将在其中进行。命令提示符在执行此命令后应更改为 (tensorflow)C:>。进入目录后，我们就准备好安装库了。
- en: '3) After activating the venv, the CPU-only version of Windows TensorFlow could
    be installed by issuing this command:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 激活 venv 后，可以通过发出以下命令安装 Windows TensorFlow 的 CPU-only 版本：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: To test whether TF is installed properly, we can try to import it as in figure
    2\. But remember before importing TF, its venv must be activated. Testing it from
    the CMD, we need to issue the **python** command in order to be able to interact
    with Python. Because no error occurred in the import line, TF is successfully
    installed.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试 TF 是否安装正确，我们可以尝试如图 2 所示导入它。但请记住，在导入 TF 之前，必须激活其 venv。从 CMD 测试时，我们需要发出 **python**
    命令以便能够与 Python 交互。由于在导入行中没有出现错误，因此 TF 安装成功。
- en: '**Figure 2**'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 2**'
- en: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c844eb00d8602568df89c350f94b4f75.png)'
- en: '**1.3 PyCharm Python IDE Installation**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.3 PyCharm Python IDE 安装**'
- en: For this project, it is recommended to use a Python IDE rather than entering
    commands in CMD. The IDE used in this tutorial is PyCharm. Its Windows executable
    file could be downloaded from this page [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows).
    Its installation instructions are pretty simple.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个项目，建议使用 Python IDE 而不是在 CMD 中输入命令。本教程使用的 IDE 是 PyCharm。其 Windows 可执行文件可以从此页面下载 [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows)。其安装说明相当简单。
- en: After downloading and installation PyCharm Python IDE, next is to link it with
    TF. This is done by setting its Python interpreter to the installed Python under
    the TF venv as in figure 3\. This is done by opening the settings of the IDE and
    choosing the Project interpreter to the **python.exe** file installed inside the
    TF venv.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 下载并安装 PyCharm Python IDE 后，接下来是将其与 TF 连接。这是通过将其 Python 解释器设置为 TF venv 下安装的 Python
    来完成的，如图 3 所示。通过打开 IDE 的设置，选择项目解释器为 TF venv 内的 **python.exe** 文件。
- en: '**Figure 3**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 3**'
- en: '![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)'
- en: '**1.4 Flask Installation**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**1.4 Flask安装**'
- en: 'The last tool to get installed is the Flask RESTful API. It is a library to
    be installed using pip/conda installer under the TF venv using the following CMD
    command:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个需要安装的工具是Flask RESTful API。这是一个需要使用pip/conda安装器在TF venv中安装的库，使用以下CMD命令：
- en: '[PRE3]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If not already installed, NumPy and SciPy should be installed inside the venv
    in order to be able to read and manipulate images.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果尚未安装，NumPy和SciPy应安装在venv中，以便能够读取和处理图像。
- en: By installing Anaconda (Python), TensorFlow, PyCharm, and Flask, we are ready
    to start building the project.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过安装Anaconda（Python）、TensorFlow、PyCharm和Flask，我们准备好开始构建项目。
- en: 2\. Downloading and Preparing the CIFAR-10 Dataset
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2\. 下载和准备CIFAR-10数据集
- en: The Python version of the 10 classes CIFAR dataset (CIFAR-10) could be downloaded
    from this page [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html).
    The dataset contains 60,000 images divided into training and testing data. There
    are five files holding the training data where each file has 10,000 images. The
    images are RGB of size 32x32x3\. The training files are named **data_batch_1**, **data_batch_2**,
    and so on. There is a single file holding the test data named **test_batch** with
    10,000 images. A metadata file named **batches.meta** is available that holds
    the dataset classes labels which are **airplane**, **automobile**, **bird**, **cat**, **deer**, **dog**, **frog**, **horse**, **ship**,
    and **truck**.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10数据集的Python版本可以从此页面[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)下载。该数据集包含60,000张图像，分为训练数据和测试数据。有五个文件保存训练数据，每个文件包含10,000张图像。这些图像为RGB，大小为32x32x3。训练文件命名为**data_batch_1**、**data_batch_2**等。测试数据保存在一个名为**test_batch**的文件中，包含10,000张图像。还有一个名为**batches.meta**的元数据文件，其中包含数据集类别标签，分别为**飞机**、**汽车**、**鸟**、**猫**、**鹿**、**狗**、**青蛙**、**马**、**船**和**卡车**。
- en: 'Because each file in the dataset is a binary file, it should be decoded in
    order to retrieve the actual image data. For such reason, a function called unpickle_patch
    is created to do such job defined as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据集中的每个文件都是二进制文件，因此应解码以检索实际的图像数据。因此，创建了一个名为unpickle_patch的函数来执行此任务，定义如下：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The method accepts the binary file name and returns a dictionary holding details
    about such file. The dictionary holds the data for all 10,000 samples within the
    file in addition to their labels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法接受二进制文件名并返回一个包含该文件详细信息的字典。字典包含文件中所有10,000个样本的数据以及它们的标签。
- en: In order to decode the entire training data, a new function called get_dataset_images
    is created. That function accepts the dataset path and works only on the training
    data. As a result, it filters the files under this path and returns only files
    starting with **data_batch_**. The testing data is prepared later after building
    and training the CNN.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解码整个训练数据，创建了一个名为get_dataset_images的新函数。该函数接受数据集路径，仅对训练数据进行操作。结果，它会过滤此路径下的文件，并仅返回以**data_batch_**开头的文件。测试数据将在构建和训练CNN之后准备。
- en: For each training file, it is decoded by calling the unpickle_patch function.
    Based on the dictionary returned by such function, the get_dataset_images function
    returns both the images data and their class labels. The images data is retrieved
    from the **‘data’** key and their class labels are retrieved from the **‘labels’** key.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个训练文件，通过调用unpickle_patch函数进行解码。根据该函数返回的字典，get_dataset_images函数返回图像数据及其类别标签。图像数据从**‘data’**键中获取，其类别标签从**‘labels’**键中获取。
- en: Because the images data are saved as 1D vector, it should be reshaped to be
    of 3 dimensions. This is because TensorFlow accepts the images of such shape.
    For such reason, the get_dataset_images function accepts the number of rows/columns
    in addition to the number of channels in each image as arguments.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 因为图像数据以1D向量形式保存，所以需要将其重塑为3维。这是因为TensorFlow接受这种形状的图像。因此，get_dataset_images函数接受除了每个图像的通道数外，还接受行/列数作为参数。
- en: 'The implementation of such function is as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数的实现如下：
- en: '[PRE5]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: By preparing the training data, we can build and train the CNN model using TF.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 通过准备训练数据，我们可以使用TF构建和训练CNN模型。
- en: 3\. Building the CNN Computational Graph using TensorFlow
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3\. 使用TensorFlow构建CNN计算图
- en: The computational graph of the CNN is created inside a function called create_CNN.
    It creates a stack of convolution (conv), ReLU, max pooling, dropout, and fully
    connected (FC) layers and returns the results of the last fully connected layer.
    The output of each layer is the input to the next layer. This requires consistency
    between the sizes of outputs and inputs of neighboring layers. Note that for each
    conv, ReLU, and max pooling layers, there are some of parameters to get specified
    such as strides across each dimension and padding.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: CNN的计算图在名为`create_CNN`的函数内创建。它创建了一系列卷积（conv）、ReLU、最大池化、丢弃（dropout）和全连接（FC）层，并返回最后一个全连接层的结果。每层的输出是下一层的输入。这要求相邻层之间的输出和输入大小保持一致。请注意，对于每个卷积、ReLU和最大池化层，有一些参数需要指定，例如每个维度的步幅和填充。
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Because the convolution layer applies the convolution operation between the
    input data and the set of filters used, the create_CNN function accepts the input
    data as an input argument. Such data is what returned by the get_dataset_images
    function. The convolution layer is created using the create_conv_layer function.
    The create_conv_layer function accepts the input data, filter size, and number
    of filters and returns the result of convolving the input data with the set of
    filters. The set of filters have their size set according to the depth of the
    input images. The create_conv_layer is defined as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于卷积层在输入数据和所用过滤器集之间应用卷积操作，因此`create_CNN`函数接受输入数据作为输入参数。这样的数据由`get_dataset_images`函数返回。卷积层使用`create_conv_layer`函数创建。`create_conv_layer`函数接受输入数据、过滤器大小和过滤器数量，并返回将输入数据与过滤器集卷积的结果。过滤器集的大小根据输入图像的深度进行设置。`create_conv_layer`定义如下：
- en: '[PRE7]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Another argument is the probability of keeping neurons in the dropout layer.
    It specifies how much neurons are dropped by the dropout layer. The dropout layer
    is implemented using the dropout_flatten_layer function as shown below. Such function
    returns a flattened array that will be the input to the fully connected layer.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个参数是丢弃层中保留神经元的概率。它指定丢弃层丢弃了多少神经元。丢弃层通过`dropout_flatten_layer`函数实现，如下所示。该函数返回一个扁平化的数组，该数组将作为全连接层的输入。
- en: '[PRE8]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Because the last FC layer should have number of output neurons equal to the
    number of dataset classes, the number of dataset classes is used as another input
    argument to the create_CNN function. The fully connected layer is created using
    the fc_layer function. Such function accepts the flattened result of the dropout
    layer, the number of features in such flattened result, and number of output neurons
    from such FC layer. Based on number of inputs and outputs, a weights tensor is
    created which get then multiplied by the flattened layer to get the returned result
    of the FC layer.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最后一个FC层应具有等于数据集类别数的输出神经元数量，因此数据集类别数作为另一个输入参数传递给`create_CNN`函数。全连接层使用`fc_layer`函数创建。该函数接受丢弃层的扁平化结果、扁平化结果中的特征数量以及该FC层的输出神经元数量。根据输入和输出的数量，创建一个权重张量，然后将其乘以扁平化层，以获得FC层的返回结果。
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The computational graph after being visualized using TensorBoard is shown in
    figure 4.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TensorBoard可视化后的计算图如图4所示。
- en: '**Figure 4**'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**图4**'
- en: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1788a19cf404695a782df8f482089d1c.png)'
- en: More On This Topic
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[What Makes Python An Ideal Programming Language For Startups](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[是什么使得Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)'
- en: '[Stop Learning Data Science to Find Purpose and Find Purpose to…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)'
- en: '[A $9B AI Failure, Examined](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[一个90亿美元的AI失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)'
- en: '[Top Resources for Learning Statistics for Data Science](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)'
- en: '[The 5 Characteristics of a Successful Data Scientist](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)'
