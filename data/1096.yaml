- en: Cutting Down Implementation Time by Integrating Jupyter and KNIME
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过集成Jupyter和KNIME来缩短实施时间
- en: 原文：[https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html](https://www.kdnuggets.com/2021/12/cutting-implementation-time-integrating-jupyter-knime.html)
- en: '**By [Mahantesh Pattadkal](https://medium.com/@mpattadkal), Data Scientist
    @ KNIME**'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**由 [Mahantesh Pattadkal](https://medium.com/@mpattadkal)，KNIME的数据科学家**'
- en: 'Data scientists are known for creating their own bubble within the 3I structure
    — Implement, Integrate, and Innovate. I personally lean towards the last two Is:
    Integrate new technologies for constant experimentation and Innovate to attain
    remarkable results.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家以在3I结构中创建自己的泡沫而闻名——实施、集成和创新。我个人倾向于最后两个I：集成新技术以进行持续实验和创新以获得显著成果。
- en: '* * *'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-5
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业的快车道。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行IT工作'
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: I have been working with Jupyter Notebook for the last 4–5 years and I feel
    very comfortable working with it. On the other hand, I share a lot of work projects
    with my teammate Paolo, who is an expert in building KNIME workflows. You’d think
    this could be a problem … it’s not!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经使用Jupyter Notebook工作了4-5年，并且对它非常熟悉。另一方面，我与我的队友Paolo分享了很多工作项目，他是构建KNIME工作流的专家。你可能会认为这会是个问题……其实不是！
- en: '[KNIME Analytics Platform](https://www.knime.com/knime-analytics-platform) and [Jupyter
    Notebook](https://jupyter.org/) are both known for their visual appeal in solving
    data analytics problems (Fig. 1). Jupyter Notebook presents a simplified script
    interface for over 40 programming languages via a web browser, but it is in the
    end a coding platform mostly popular among Python users. KNIME Analytics Platform
    runs completely on a graphical user interface controlled by drag-and-drop operations
    and [visual programming](https://en.wikipedia.org/wiki/Visual_programming_language).
    It provides a quick understanding of the logic and structure of complex data analysis
    by representing it via a visual and transparent workflow. You can also write snippets
    of Python code in KNIME Analytics Platform; the Jupyter Notebook user experience
    simplifies this input and execution of code resulting in a UI optimized for coders.
    Now, imagine the plethora of possible applications one can build on the synergy
    of these two platforms.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[KNIME Analytics平台](https://www.knime.com/knime-analytics-platform) 和 [Jupyter
    Notebook](https://jupyter.org/) 都以其解决数据分析问题的视觉吸引力而著称（图1）。Jupyter Notebook通过网页浏览器提供了一个简化的脚本接口，支持40多种编程语言，但它最终仍然是一个主要受Python用户欢迎的编码平台。KNIME
    Analytics平台完全在图形用户界面上运行，通过拖放操作和[可视化编程](https://en.wikipedia.org/wiki/Visual_programming_language)进行控制。它通过以可视化和透明的工作流表示复杂的数据分析，提供了对逻辑和结构的快速理解。您还可以在KNIME
    Analytics平台中编写Python代码片段；Jupyter Notebook用户体验简化了代码的输入和执行，结果是一个优化的编码人员UI。现在，想象一下这两个平台的协同作用可以构建出无数可能的应用。'
- en: In this article, we discuss two common life scenarios that require collaboration
    between Jupyter Notebook and KNIME Analytics Platform and show how simple this
    is.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们讨论了两个常见的生活场景，这些场景需要Jupyter Notebook与KNIME Analytics平台的协作，并展示了这种协作的简单性。
- en: Collaboration between Jupyter Notebook and KNIME Analytics Platform
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Jupyter Notebook与KNIME Analytics平台的协作
- en: 'In this section we describe two scenarios and how to:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了两个场景以及如何：
- en: Integrate a Jupyter Notebook in a KNIME workflow (scenario 1)
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在KNIME工作流中集成Jupyter Notebook（场景1）
- en: Integrate a KNIME workflow into Jupyter code (scenario 2)
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将KNIME工作流集成到Jupyter代码中（场景2）
- en: In **scenario 1,** my teammate [Paolo ](https://www.linkedin.com/in/paolo-tamagnini/)was
    in control of the project and, pressured by time, asked me for help in implementing
    a custom data transformation, which I did in Jupyter Notebook. Here, I will show
    how Paolo integrated my Jupyter script into his KNIME workflow.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在**场景 1**中，我的队友[Paolo](https://www.linkedin.com/in/paolo-tamagnini/)负责项目，并在时间压力下请求我帮助实施自定义数据转换，我在
    Jupyter Notebook 中完成了这项工作。在这里，我将展示 Paolo 如何将我的 Jupyter 脚本集成到他的 KNIME 工作流中。
- en: In **scenario 2**, I was in charge of the project and, yet still pressured by
    time, I asked Paolo to help me with building a workflow to train a classification
    model, which he provided in KNIME Analytics Platform. Here I will show how I integrated
    Paolo’s workflow into my Python script from Jupyter Notebook.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在**场景 2**中，我负责项目，仍然受到时间压力的影响，向 Paolo 请求帮助构建一个训练分类模型的工作流，他在 KNIME Analytics Platform
    中提供了这个工作流。这里我将展示我如何将 Paolo 的工作流集成到我的 Jupyter Notebook 的 Python 脚本中。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/f06e875b4d228bd629ea66a6794ebec7.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实施时间](../Images/f06e875b4d228bd629ea66a6794ebec7.png)'
- en: 'Fig. 1: Here we show the user interfaces of the two data science tools: on
    the left [KNIME Analytics Platform](https://www.knime.com/knime-analytics-platform) and
    on the right [Jupyter Notebook](https://jupyter.org/).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：这里展示了两个数据科学工具的用户界面：左侧是[KNIME Analytics Platform](https://www.knime.com/knime-analytics-platform)，右侧是[Jupyter
    Notebook](https://jupyter.org/)。
- en: Integrating a Jupyter Notebook in a KNIME Workflow — Scenario 1
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 KNIME 工作流中集成 Jupyter Notebook — 场景 1
- en: '*Flight delay prediction with machine learning*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*利用机器学习进行航班延误预测*'
- en: Paolo was requested to classify flights by their departure delay in the [Airline
    dataset.](http://stat-computing.org/dataexpo/2009/the-data.html) Each row in the
    flight delay dataset describes a flight, through its origin, destination, scheduled
    departure time, and so on. Any flight with a departure delay > 15 minutes was
    labeled as “delayed”. The requested task was to train a machine learning model
    to classify whether a flight will be delayed at departure, considering all other
    suitable flight attributes as input features.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Paolo 被要求根据起飞延误对航班进行分类，数据集为[Airline dataset](http://stat-computing.org/dataexpo/2009/the-data.html)。航班延误数据集中的每一行描述了一个航班，包括其出发地、目的地、计划起飞时间等。任何起飞延误超过
    15 分钟的航班都被标记为“延误”。请求的任务是训练一个机器学习模型，分类一个航班是否会在起飞时延误，考虑所有其他合适的航班属性作为输入特征。
- en: 'The steps taken to build a workflow to train and evaluate a machine learning
    model are usually the same: import the data, transform and clean the data, partition
    them into training set and test set, train the machine learning (ML) model of
    choice on the training set, apply the trained model to the test set, and score
    its performance with the scoring metric of choice. The [Run Jupyter in KNIME](https://kni.me/w/6rzm1Wn3Zsr4NO7-) workflow
    would then look more or less like the one in Fig. 2 (you can download it from
    the [KNIME Hub](https://hub.knime.com/)).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个训练和评估机器学习模型的工作流的步骤通常是相同的：导入数据，转换和清洗数据，将其分为训练集和测试集，在训练集上训练选择的机器学习 (ML) 模型，将训练好的模型应用于测试集，并使用选择的评分指标对其性能进行评分。
    [Run Jupyter in KNIME](https://kni.me/w/6rzm1Wn3Zsr4NO7-) 工作流将会大致类似于图 2（你可以从[KNIME
    Hub](https://hub.knime.com/)下载）。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/8057510e37b7ae02035dcf51139adb69.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实施时间](../Images/8057510e37b7ae02035dcf51139adb69.png)'
- en: Fig. 2\. The [Run Jupyter in KNIME](https://kni.me/w/6rzm1Wn3Zsr4NO7-) training
    workflow to train and evaluate a ML model to predict departure delays in flights.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. [Run Jupyter in KNIME](https://kni.me/w/6rzm1Wn3Zsr4NO7-) 训练工作流，用于训练和评估
    ML 模型以预测航班的起飞延误。
- en: The data cleaning and data transformation part is often time consuming, since
    it depends on the data domain as well. Paolo was pressured by time and asked me
    if I could implement that part.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 数据清洗和数据转换部分通常非常耗时，因为这也取决于数据领域。Paolo 被时间压力所迫，问我是否可以实现这一部分。
- en: Well, this seemed quite easy for me to do using Jupyter Notebook. Paolo could
    then import it in his workflow using a Python Script node. Let’s have a look at
    that step by step.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，使用 Jupyter Notebook 来做这件事似乎很简单。然后，Paolo 可以通过 Python Script 节点将其导入他的工作流。我们一步一步来看这个过程。
- en: Step 1\. Write the Python code in Jupyter Notebook.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤 1\. 在 Jupyter Notebook 中编写 Python 代码。
- en: Step 2\. Set up the Python Environment in KNIME Analytics Platform
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤 2\. 在 KNIME Analytics Platform 中设置 Python 环境
- en: Step 3\. Execute the Jupyter Notebook code from the KNIME workflow.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 步骤 3\. 执行 KNIME 工作流中的 Jupyter Notebook 代码。
- en: Step 1\. Write the Python code in Jupyter Notebook
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1. 在 Jupyter Notebook 中编写 Python 代码
- en: I have created a Python function called *Custom_Transformation* in Jupyter Notebook(Fig.
    3). The function implements some basic feature engineering and returns the original
    features set along with the transformed features.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我在 Jupyter Notebook（图 3）中创建了一个名为 *Custom_Transformation* 的 Python 函数。该函数实现了一些基本的特征工程，并返回了包括转换特征在内的原始特征集。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/37f87414c3a959dfd7703d8965455f51.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实现时间](../Images/37f87414c3a959dfd7703d8965455f51.png)'
- en: Fig. 3\. Python function for feature transformation.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. 用于特征转换的 Python 函数。
- en: Now, we need to import this code into Paolo’s KNIME workflow.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要将此代码导入到 Paolo 的 KNIME 工作流中。
- en: '**Step 2**. **Set up the Python environment in KNIME Analytics Platform**'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**步骤 2**. **在 KNIME Analytics Platform 中设置 Python 环境**'
- en: In KNIME Analytics Platform, click *File *→* Preferences *→* KNIME *→* Python*
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 KNIME Analytics Platform 中，点击 *文件* → *偏好设置* → *KNIME* → *Python*
- en: In the Python preference page (Fig. 4a), create a new Conda environment
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 偏好设置页面（图 4a），创建一个新的 Conda 环境
- en: Click *New environment* for Python 2 or Python 3 as per the installed Python
    version on your system.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据系统上安装的 Python 版本，点击 *新环境* 来选择 Python 2 或 Python 3。
- en: 'The *New Conda environment* dialog box opens (Fig. 4b). Now you have to:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新 Conda 环境* 对话框打开（图 4b）。现在你需要：'
- en: Enter the environment name in the field highlighted in yellow
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在黄色高亮显示的字段中输入环境名称
- en: Click *Create new environment*
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击 *创建新环境*
- en: Once the environment is created, click *Apply *and *Close *in the Preference
    page (Fig. 4a).
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境创建后，在偏好设置页面（图 4a）中点击 *应用* 和 *关闭*。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/e86b6a0a85643049cadcd794df6728ed.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实现时间](../Images/e86b6a0a85643049cadcd794df6728ed.png)'
- en: Fig. 4a. Python Preference window.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4a. Python 偏好设置窗口。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/9c1460028d7762c16c7c778e0a2c3e98.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实现时间](../Images/9c1460028d7762c16c7c778e0a2c3e98.png)'
- en: Fig. 4b. Dialog box for new Conda environment creation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4b. 创建新 Conda 环境的对话框。
- en: '*For a step-by-step guide of how to install the Python integration in KNIME
    and get it working, check my article *[*How to Set Up the Python Extension*](https://medium.com/low-code-for-advanced-data-science/how-to-set-up-the-python-extension-fd25ecee66e3)*.*'
  id: totrans-49
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*有关如何安装 KNIME 中的 Python 集成并使其正常工作，请查看我的文章 [*如何设置 Python 扩展*](https://medium.com/low-code-for-advanced-data-science/how-to-set-up-the-python-extension-fd25ecee66e3)。*'
- en: Step 3\. Execute the Jupyter Notebook code from a KNIME workflow
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3. 从 KNIME 工作流中执行 Jupyter Notebook 代码
- en: In the KNIME workflow in Fig. 2, we introduced a [Python Script](https://kni.me/n/6L0w9_dCmFzbn-rx) node
    (the second node from the left after the Table Reader node). This node loads and
    runs my code from Jupyter Notebook (Fig. 5).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 2 中的 KNIME 工作流中，我们引入了一个 [Python Script](https://kni.me/n/6L0w9_dCmFzbn-rx)
    节点（Table Reader 节点后的第二个节点）。该节点加载并运行我在 Jupyter Notebook（图 5）中的代码。
- en: 'The key instruction in the script is:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本中的关键指令是：
- en: '[PRE0]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This line uses the [knimepy](https://github.com/knime/knimepy) instruction
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这行使用了 [knimepy](https://github.com/knime/knimepy) 指令
- en: '[PRE1]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: to locate the Jupyter Notebook *Custom_Transformation*, and to load the Jupyter
    script into the *my_notebook* variable.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以定位 Jupyter Notebook 的 *Custom_Transformation*，并将 Jupyter 脚本加载到 *my_notebook*
    变量中。
- en: The next line executes the function
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下一行执行该函数
- en: '[PRE2]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: and returns the results into a pandas DataFrame named
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 并将结果返回到一个名为的 pandas DataFrame
- en: '[PRE3]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '***Note.**** The code in Jupyter Notebook should always provide an output of
    type pandas DataFrame.*'
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意。*** Jupyter Notebook 中的代码应始终提供 pandas DataFrame 类型的输出。'
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/141ca6e68e6ea6d4a1e290849b7670d5.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 来缩短实现时间](../Images/141ca6e68e6ea6d4a1e290849b7670d5.png)'
- en: Fig. 5\. Configuration dialog for the [Python Script ](https://kni.me/n/6L0w9_dCmFzbn-rx)node.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. [Python Script](https://kni.me/n/6L0w9_dCmFzbn-rx) 节点的配置对话框。
- en: 'The script to run the Jupyter Notebook inside the Python Script node is shown
    below:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 运行 Python 脚本节点中的 Jupyter Notebook 的脚本如下所示：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After executing the Python Script node, at its output we find the transformed
    features added to the original features now ready to be passed to the next node
    in the KNIME workflow.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 执行 Python 脚本节点后，我们会在其输出中找到添加到原始特征中的转换特征，这些特征现在可以传递到 KNIME 工作流中的下一个节点。
- en: Integrating a KNIME Workflow into Jupyter Code — Scenario 2
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将 KNIME 工作流集成到 Jupyter 代码中——场景 2
- en: '*Flight delay prediction with machine learning*'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用机器学习进行航班延误预测*'
- en: I was asked to implement the deployment application that predicts flight departure
    delays using the model previously trained on the flight delay dataset. I want
    to develop this application using Jupyter Notebook. To save time, I would like
    to borrow and integrate a deployment workflow from Paolo’s work. That is, I would
    like to integrate a KNIME workflow into my Jupyter Notebook.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我被要求实现一个部署应用程序，该程序使用以前在航班延误数据集上训练的模型来预测航班起飞延误。我想使用 Jupyter Notebook 开发这个应用程序。为了节省时间，我希望借用并整合
    Paolo 的工作中的部署工作流。也就是说，我希望将 KNIME 工作流集成到我的 Jupyter Notebook 中。
- en: This is done in three easy steps, specular to the three steps used in scenario
    1.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过三个简单的步骤完成，类似于场景 1 中使用的三个步骤。
- en: Step 1\. Build the KNIME workflow
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一步。构建 KNIME 工作流
- en: Step 2\. Set up the KNIME environment in Jupyter Notebook
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二步。在 Jupyter Notebook 中设置 KNIME 环境
- en: Step 3\. Execute the KNIME workflow from Jupyter Notebook
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三步。从 Jupyter Notebook 执行 KNIME 工作流
- en: Step 1\. Build the KNIME workflow
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第一步。构建 KNIME 工作流
- en: In our case Paolo already provided me with the KNIME workflow [Run KNIME in
    Jupyter](https://kni.me/w/WwfJYzXiTB-VpNql) via the KNIME Hub. The workflow deploys
    the machine learning model to predict flight departure delays (Fig. 6).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的案例中，Paolo 已经通过 KNIME Hub 提供了 KNIME 工作流 [在 Jupyter 中运行 KNIME](https://kni.me/w/WwfJYzXiTB-VpNql)。这个工作流部署了一个机器学习模型，用于预测航班起飞延误（图
    6）。
- en: Step 2\. Set up the KNIME package in a Jupyter Notebook
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第二步。在 Jupyter Notebook 中设置 KNIME 包
- en: In the Command/Anaconda Prompt, enter
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Command/Anaconda 提示符中，输入
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This installs the latest [knimepy](https://github.com/knime/knimepy) package.
    This package enables Jupyter Notebook to read and run KNIME workflows.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这会安装最新的 [knimepy](https://github.com/knime/knimepy) 包。该包使 Jupyter Notebook 能够读取和运行
    KNIME 工作流。
- en: Step 3\. Execute the KNIME workflow from a Jupyter Notebook
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步。从 Jupyter Notebook 执行 KNIME 工作流
- en: This is what I need to write in my Jupyter Notebook (Fig. 7 and Fig. 8) in order
    to import and run the selected KNIME workflow.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在 Jupyter Notebook 中需要编写的内容（图 7 和图 8），以便导入和运行选定的 KNIME 工作流。
- en: Import `knime` package
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入 `knime` 包
- en: Import the paths to the KNIME executable, to the workspace, and to the KNIME
    workflow
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 导入 KNIME 可执行文件、工作区和 KNIME 工作流的路径
- en: The command `knime.Workflow(...)` visualizes the workflow. I use it to double
    check that Jupyter is pointing to the intended workflow (Fig. 7)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令 `knime.Workflow(...)` 可视化工作流。我使用它来双重检查 Jupyter 是否指向了预期的工作流（图 7）
- en: This instruction `wf.data_table_inputs[0]=data_set` passes the external data
    stored as DataFrame from Jupyter to the KNIME workflow (Fig. 7).
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个指令 `wf.data_table_inputs[0]=data_set` 将存储为 DataFrame 的外部数据从 Jupyter 传递到 KNIME
    工作流（图 7）。
- en: The `wf.execute` command executes the KNIME workflow
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`wf.execute` 命令执行 KNIME 工作流'
- en: After the workflow is executed, the results are stored by default in `wf.data_table_outputs[0]` (Fig.
    8)
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作流执行后，结果默认存储在 `wf.data_table_outputs[0]` 中（图 8）
- en: '***Note.**** Make sure that the workflow being executed from Jupyter is not
    concurrently open in KNIME. This stalls execution as the workflow is already open
    for editing in KNIME.*'
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***注意。*** 确保从 Jupyter 执行的工作流在 KNIME 中没有同时打开。这会导致执行暂停，因为工作流已经在 KNIME 中打开进行编辑。*'
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/4259f6d5a8851d244e2f7eec6e15e2d6.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 缩短实现时间](../Images/4259f6d5a8851d244e2f7eec6e15e2d6.png)'
- en: Fig. 6\. Setting up the workspace in Jupyter Notebook and displaying the selected
    KNIME workflow [Run KNIME in Jupyter](https://kni.me/w/WwfJYzXiTB-VpNql).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6。在 Jupyter Notebook 中设置工作区并显示选定的 KNIME 工作流 [在 Jupyter 中运行 KNIME](https://kni.me/w/WwfJYzXiTB-VpNql)。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/af724824b112b3ec8c0b2e66a0530ba5.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![通过集成 Jupyter 和 KNIME 缩短实现时间](../Images/af724824b112b3ec8c0b2e66a0530ba5.png)'
- en: Fig. 7\. Code for executing the workflow.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7。执行工作流的代码。
- en: 'As of KNIME Analytics Platform 4.3, I can also call and execute KNIME workflows
    residing on a KNIME Server, rather than on my local client installation. This
    has three main advantages:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从 KNIME Analytics Platform 4.3 开始，我还可以调用并执行驻留在 KNIME 服务器上的 KNIME 工作流，而不是在本地客户端安装中。这有三个主要优点：
- en: '**Improved scalability**: Execution on a [KNIME Server](https://www.knime.com/elastic-hybrid-execution) can
    exploit more computational power from another machine on premise, from a server
    in the cloud, or even parallel computation of several KNIME Executors or via [KNIME
    Edge](https://www.knime.com/sites/default/files/2021-03/living-knime-edge-model-deployment-scale.pdf).'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**改进的可扩展性：** 在 [KNIME Server](https://www.knime.com/elastic-hybrid-execution)
    上执行可以利用来自本地另一台机器、云端服务器，甚至多个 KNIME 执行器的并行计算能力，或通过 [KNIME Edge](https://www.knime.com/sites/default/files/2021-03/living-knime-edge-model-deployment-scale.pdf)
    进行计算。'
- en: '**Greater accessibility**: Anyone with credentials and an internet connection
    can use the shared KNIME workflow deployed on the KNIME Server from their Jupyter
    Notebook'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更大的可访问性：** 任何拥有凭证和互联网连接的人都可以从他们的 Jupyter Notebook 中使用部署在 KNIME Server 上的共享
    KNIME 工作流。'
- en: '**Better security and versioning:** Combining Jupyter Notebook with KNIME Analytics
    Platform usually implies data scientists with different backgrounds collaborating
    in an organization where data access might be restricted. KNIME Server offers
    a safe and consistent way for sharing workflows, data and Jupyter Notebook edit
    after edit.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更好的安全性和版本控制：** 将 Jupyter Notebook 与 KNIME Analytics Platform 结合使用通常意味着背景不同的数据科学家在一个数据访问可能受到限制的组织中进行协作。KNIME
    Server 提供了一种安全且一致的方式来共享工作流、数据以及 Jupyter Notebook 的每次编辑。'
- en: The only change to the previous script consists in the path to the KNIME workflow
    on the KNIME server and the required username and password to access it, as shown
    in Fig. 8\. This script is also available on [GitHub](https://github.com/knime/knimepy) repository.
    Also, in this case, there isn’t the need to specify the knime executer path like
    before.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于之前的脚本唯一的更改是 KNIME 服务器上 KNIME 工作流的路径以及访问所需的用户名和密码，如图 8 所示。此脚本也可以在 [GitHub](https://github.com/knime/knimepy)
    仓库中找到。此外，此案例中不再需要像之前那样指定 knime 执行器路径。
- en: '![Cutting Down Implementation Time by Integrating Jupyter and KNIME](../Images/67f87d1096d4cac7565157e694e1f815.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![通过整合 Jupyter 和 KNIME 缩短实施时间](../Images/67f87d1096d4cac7565157e694e1f815.png)'
- en: Fig. 8\. Code snippet to execute workflow on KNIME Server from Jupyter Notebook.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8\. 从 Jupyter Notebook 执行工作流的代码片段。
- en: Collaboration is key!
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协作是关键！
- en: The fact that you don’t need to choose between Jupyter Notebook and KNIME Analytics
    Platform is an excellent feature to foster collaboration in a team. By mixing
    and matching Jupyter Notebook scripts and KNIME workflow snippets we efficiently
    produced a very advanced set of applications to train, apply, and deploy machine
    learning models for predictions.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要在 Jupyter Notebook 和 KNIME Analytics Platform 之间做选择这一点是促进团队协作的一个优秀特点。通过混合和匹配
    Jupyter Notebook 脚本和 KNIME 工作流片段，我们高效地创建了一套先进的应用程序，用于训练、应用和部署机器学习模型进行预测。
- en: Coupling this strategy with the KNIME Server enterprise features enables even
    greater collaboration among data scientists with different backgrounds and tools.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 将这一策略与 KNIME Server 企业功能相结合，可以在具有不同背景和工具的数据科学家之间实现更大的协作。
- en: Collaboration is always a key factor in a data science lab and whether you are
    looking for an open source solution or an enterprise one, KNIME software can help
    you there with its flexibility in integrating Jupyter and [many other tools](https://hub.knime.com/search?q=integration&type=Extension).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 协作始终是数据科学实验室中的关键因素，无论你是在寻找开源解决方案还是企业级解决方案，KNIME 软件都能以其在整合 Jupyter 和 [其他许多工具](https://hub.knime.com/search?q=integration&type=Extension)
    的灵活性来帮助你。
- en: '**References:**'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**参考文献：**'
- en: Download the Run Jupyter in KNIME and Run KNIME in Jupyter workflows from the
    KNIME Hub [here](https://hub.knime.com/mpattadkal/spaces/Public/latest/Jupyter%20Webinar/)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 KNIME Hub [这里](https://hub.knime.com/mpattadkal/spaces/Public/latest/Jupyter%20Webinar/)
    下载 Run Jupyter in KNIME 和 Run KNIME in Jupyter 工作流。
- en: Read another blog post on [KNIME and Jupyter](https://www.knime.com/blog/knime-and-jupyter) by
    Greg Landrum
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阅读 Greg Landrum 关于 [KNIME 和 Jupyter](https://www.knime.com/blog/knime-and-jupyter)
    的另一篇博客文章。
- en: Watch a recording of our webinar [Enhancing Jupyter Notebook with visual workflows
    Webinar](https://www.youtube.com/watch?v=1Rr8Q27k7cQ&t=1161s)
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观看我们关于 [增强 Jupyter Notebook 的视觉工作流网络研讨会](https://www.youtube.com/watch?v=1Rr8Q27k7cQ&t=1161s)
    的录播。
- en: '**Bio: [Mahantesh Pattadkal](https://medium.com/@mpattadkal)** is a data scientist
    at KNIME. The data science techniques he is interested in are machine learning,
    natural language processing, deep learning, predictive modeling and business analytics.
    He enjoys working with Python, SQL, Tensorflow/Keras, Pytorch, Excel, and R.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介：[Mahantesh Pattadkal](https://medium.com/@mpattadkal)** 是 KNIME 的数据科学家。他感兴趣的数据科学技术包括机器学习、自然语言处理、深度学习、预测建模和商业分析。他喜欢使用
    Python、SQL、Tensorflow/Keras、Pytorch、Excel 和 R。'
- en: As first published in [Low Code for Advanced Data Science](https://medium.com/low-code-for-advanced-data-science).
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 首次发表于 [低代码高级数据科学](https://medium.com/low-code-for-advanced-data-science)。
- en: '[Original](https://medium.com/low-code-for-advanced-data-science/cutting-down-implementation-time-by-integrating-jupyter-and-knime-f2fa920b25a4).
    Reposted with permission.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/low-code-for-advanced-data-science/cutting-down-implementation-time-by-integrating-jupyter-and-knime-f2fa920b25a4)。转载已获许可。'
- en: More On This Topic
  id: totrans-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 相关主题
- en: '[Codeless Time Series Analysis with KNIME](https://www.kdnuggets.com/2022/10/packt-codeless-time-series-analysis-knime.html)'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 KNIME 进行无代码时间序列分析](https://www.kdnuggets.com/2022/10/packt-codeless-time-series-analysis-knime.html)'
- en: '[Introducing TPU v4: Googles Cutting Edge Supercomputer for Large…](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[介绍 TPU v4：谷歌前沿超级计算机用于大型…](https://www.kdnuggets.com/2023/04/introducing-tpu-v4-googles-cutting-edge-supercomputer-large-language-models.html)'
- en: '[Integrating ChatGPT Into Data Science Workflows: Tips and Best Practices](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将 ChatGPT 集成到数据科学工作流中：提示与最佳实践](https://www.kdnuggets.com/2023/05/integrating-chatgpt-data-science-workflows-tips-best-practices.html)'
- en: '[Breaking Down Quantum Computing: Implications for Data Science and AI](https://www.kdnuggets.com/breaking-down-quantum-computing-implications-for-data-science-and-ai)'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解构量子计算：对数据科学和人工智能的影响](https://www.kdnuggets.com/breaking-down-quantum-computing-implications-for-data-science-and-ai)'
- en: '[Optimizing Data Analytics: Integrating GitHub Copilot in Databricks](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[优化数据分析：在 Databricks 中集成 GitHub Copilot](https://www.kdnuggets.com/optimizing-data-analytics-integrating-github-copilot-in-databricks)'
- en: '[Integrating Generative AI in Content Creation](https://www.kdnuggets.com/integrating-generative-ai-in-content-creation)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在内容创作中集成生成性人工智能](https://www.kdnuggets.com/integrating-generative-ai-in-content-creation)'
