- en: 'Financial Data Analysis – Data Processing 1: Loan Eligibility Prediction'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 财务数据分析 – 数据处理 1：贷款资格预测
- en: 原文：[https://www.kdnuggets.com/2018/09/financial-data-analysis-loan-eligibility-prediction.html](https://www.kdnuggets.com/2018/09/financial-data-analysis-loan-eligibility-prediction.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/09/financial-data-analysis-loan-eligibility-prediction.html](https://www.kdnuggets.com/2018/09/financial-data-analysis-loan-eligibility-prediction.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/), Computational
    Geophysicist and Machine Learning Enthusiast**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)，计算地球物理学家和机器学习爱好者**'
- en: '![](../Images/293b4a75c53681e17ad1aebb8977b940.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/293b4a75c53681e17ad1aebb8977b940.png)'
- en: Introduction
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 介绍
- en: Financial institutions/companies have been using predictive analytics for quite
    a long time. Recently, due to the availability of computational resources and
    tremendous research in machine learning made it possible to better data analysis
    hence better prediction. In the series of articles, I explain how to create a
    predictive loan model that identifies a bad applicant who is more likely to be
    charged off. In step by step processes, I show how to process raw data, clean
    unnecessary part of it, select relevant features, perform exploratory data analysis,
    and finally build a model.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 金融机构/公司已经使用预测分析有一段时间了。最近，由于计算资源的可用性以及在机器学习领域的巨大研究，使得更好的数据分析以及更好的预测成为可能。在这系列文章中，我将解释如何创建一个预测贷款模型，识别那些更有可能被拒绝的申请人。通过一步步的过程，我展示了如何处理原始数据、清理不必要的部分、选择相关特征、进行探索性数据分析，并最终建立模型。
- en: 'As an example, I use Lending club loan data dataset. Lending Club is the world’s
    largest online marketplace connecting borrowers and investors. An inevitable outcome
    of lending is default by borrowers. The idea of this tutorial is to create a predictive
    model that identifies applicants who are relatively risky for a loan. In order
    to accomplish this, I organized the whole series into four parts as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个例子，我使用了Lending Club贷款数据集。Lending Club是全球最大的在线市场，连接借款人和投资者。借贷的一个不可避免的结果是借款人违约。这个教程的目的是创建一个预测模型，以识别那些相对来说风险较大的贷款申请人。为此，我将整个系列分为以下四部分：
- en: '[**Data processing-1**](https://medium.com/@sabber/financial-data-analysis-80ba39149126):
    In this first part I show how to clean and remove unnecessary features. Data processing
    is very time-consuming, but better data would produce a better model. Therefore,
    careful and very detail examination is required to prepare better data. I show
    how to identify constant features, duplicate feature, duplicate rows, and features
    with a high number of missing values.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据处理-1**](https://medium.com/@sabber/financial-data-analysis-80ba39149126)：在这第一部分，我展示了如何清理和移除不必要的特征。数据处理是非常耗时的，但更好的数据将产生更好的模型。因此，需要进行仔细且非常详细的检查，以准备更好的数据。我展示了如何识别常量特征、重复特征、重复行以及具有大量缺失值的特征。'
- en: '[**Data processing-2**](https://medium.com/@sabber/financial-data-analysis-bf4b5e78c45c):
    In this part, I manually go through each and every features selected from part
    -1\. This is the most time-consuming part, but worth it for a better model.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**数据处理-2**](https://medium.com/@sabber/financial-data-analysis-bf4b5e78c45c)：在这一部分，我手动检查了从第1部分中选择的每一个特征。这是最耗时的部分，但为了得到更好的模型是值得的。'
- en: '[**EDA**](https://medium.com/@sabber/financial-data-analysis-2f86b1341e6e):
    In in this part, I do some exploratory data analysis (EDA) on the features selected
    in part-1 and 2\. A good EDA is required to get a better knowledge of the domain.
    We need to spend some quality time to find out the relations between the features.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**探索性数据分析**](https://medium.com/@sabber/financial-data-analysis-2f86b1341e6e)：在这一部分，我对第1部分和第2部分中选择的特征进行了探索性数据分析（EDA）。良好的EDA对于更好地了解领域是必需的。我们需要花费一些时间来找出特征之间的关系。'
- en: '[**Create a model**](https://medium.com/@sabber/financial-data-analysis-51e7275d0ae):
    Finally, In this last but not the last part, I create models. Creating a model
    is also not an easy task. It’s also an iterative process. I show how to start
    with a with a simple model, then slowly add complexity for better performance.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[**创建模型**](https://medium.com/@sabber/financial-data-analysis-51e7275d0ae)：最后，在这最后但并非最末部分中，我创建了模型。创建模型也不是一件容易的事。这也是一个迭代的过程。我展示了如何从一个简单的模型开始，然后逐步增加复杂性以获得更好的性能。'
- en: 'Alright, let’s get started with the part-1: data processing, cleaning and feature
    selections.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始第1部分：数据处理、清洗和特征选择。
- en: '**Data processing-1**'
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**数据处理-1**'
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In this project, I used three years of datasets (2014, 2015 and 2017(first-thrid
    quarter)) and stored in five separate CSV files. Lets read the files first:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个项目中，我使用了三年的数据集（2014年、2015年和2017年（第一至第三季度）），并存储在五个不同的 CSV 文件中。首先让我们读取这些文件：
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Since data are stored in separate files, we have to make sure that we have
    the same number of features in each file. We can check using the following code
    snippet:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据存储在不同的文件中，我们必须确保每个文件中的特征数量相同。我们可以使用以下代码片段来检查：
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The above code is self-explanatory, we first extract the column names the stack
    them together using Numpy ‘dstack’ object. If you look at the Jupyter-notebook
    on Github, you would see they are same. Which is good for us. We can move on to
    the next step. It’s time to check the shape of the data:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码不言而喻，我们首先提取列名，然后使用 Numpy 的 `dstack` 对象将它们堆叠在一起。如果你查看 Github 上的 Jupyter-notebook，你会看到它们是相同的。这对我们来说是好的。我们可以继续下一步。现在是检查数据形状的时候了：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We see that there are approximately one million examples and each of the examples
    has 151 features including target variable. Let’s look at the feature name to
    get familiar with the data. It’s imperative to get to know the domain, especially
    the details of the features relationship with the target variable. It’s not easy
    to learn overnight, that’s why need to spend some days or maybe a week to get
    familiar with the data before jumping into further detail analysis. Let’s see
    the feature names:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到大约有一百万个样本，每个样本包含 151 个特征，包括目标变量。让我们查看特征名称以熟悉数据。了解领域，尤其是特征与目标变量的关系的细节是至关重要的。要彻底了解并不容易，所以需要花费几天或一周的时间来熟悉数据，然后再深入分析。让我们查看特征名称：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Looking at the above features, it may seem scary first. But we will get through
    every feature and then select the relevant features. Let's start with the target
    feature “loan_status”
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 看着这些特征，可能一开始会感到害怕。但我们会逐一处理每个特征，然后选择相关特征。让我们从目标特征“loan_status”开始。
- en: '[PRE7]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We see that there are seven types of loan status. However, in this tutorial,
    we are interested in two classes: 1) Fully paid: those who paid the loan with
    interests and 2) Charged off: those who could not pay and finally charged off.
    Therefore, we select the data sets for these two classes:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到有七种贷款状态。然而，在本教程中，我们对两个类别感兴趣：1）全额偿还：那些已经还清贷款并支付利息的人，2）呆账：那些无法偿还贷款并最终被呆账处理的人。因此，我们选择这两个类别的数据集：
- en: '[PRE9]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Looking at the shape, we see that we now have half of the data point than original
    data and the same number of features. Before processing and cleaning manually,
    let’s do some general data processing steps first:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 看着形状，我们看到现在的数据点比原始数据少了一半，但特征数量相同。在进行手动处理和清理之前，让我们先做一些一般的数据处理步骤：
- en: Remove features associated with >85% missing values
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除与 >85% 缺失值相关的特征
- en: Remove constant features
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除常量特征
- en: Remove duplicates features
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除重复的特征
- en: Remove duplicate rows
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除重复的行
- en: Remove highly collinear features (In part 3 EDA)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除高度共线的特征（在第3部分EDA中）
- en: 'Alright, let’s get started with the typical data processing:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们开始典型的数据处理：
- en: '**1\. Remove features associated with 90% missing values:** In the code below
    I first use pandas’ built-in method ‘isnull()’ to find the rows associated with
    missing values. Then I sum them up to get the count for each feature. Finally,
    I sort the features according to the number of missing values and create a data
    frame for further analysis.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**1. 移除与 90% 缺失值相关的特征：** 在下面的代码中，我首先使用 pandas 的内置方法 `isnull()` 查找与缺失值相关的行。然后，我对它们进行求和以获取每个特征的计数。最后，我按缺失值的数量对特征进行排序，并创建一个数据框以便进一步分析。'
- en: In the above result, we see that there are 53 features which have 400000 missing
    values. I use the pandas’ drop method to remove these 53 features. Notice that
    in this function I set the “inplace” option to True”, which removes these features
    from original data frame **df** without returning anything.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述结果中，我们看到有 53 个特征缺失了 400000 个值。我使用 pandas 的 drop 方法移除这 53 个特征。注意在此函数中我将“inplace”选项设置为“True”，这会在不返回任何内容的情况下从原始数据框**df**中删除这些特征。
- en: '**2\. Remove constant features: **At this step, we remove features that have
    a single unique value. A feature associated with one unique value does not help
    the model to generalize well since it’s variance is zero. A tree-based model cannot
    take advantage of these type of features since the model can not split these features.
    To identify features with a single unique value is relatively straightforward:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 移除常量特征：**在这一步，我们移除具有单一唯一值的特征。一个与单一唯一值相关的特征无法帮助模型进行良好的泛化，因为它的方差为零。基于树的模型无法利用这些特征，因为模型无法对这些特征进行拆分。识别具有单一唯一值的特征相对简单：'
- en: In the above code, I create a function “find_constant_features” to identify
    constant features. The function goes through each feature and sees if it has less
    than two unique values. If so, the features are added to the constant feature
    list. We can also find out constant feature looking at the variance or standard
    deviation. If the feature has zero variance or standard deviation, we are sure
    that the feature has single unique value. The print statement shows that five
    features have single unique value. So we remove them using “inplace” option true.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的代码中，我创建了一个“find_constant_features”函数来识别常量特征。该函数逐个检查每个特征，看看是否具有少于两个唯一值。如果是，这些特征会被添加到常量特征列表中。我们还可以通过查看方差或标准差来找出常量特征。如果特征的方差或标准差为零，我们可以确定该特征具有单一唯一值。打印语句显示五个特征具有单一唯一值，因此我们使用“inplace”选项为
    true 移除了它们。
- en: '**3\. Remove duplicate features:** Duplicate features are those have the same
    value in multiple features with the same/different name. To find out the duplicate
    features I borrowed the following code from this [stack overflow link](https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 移除重复特征：**重复特征是指在多个特征中具有相同值的特征，不论名称是否相同。为了找出这些重复特征，我借用了以下代码，这些代码来自于这个[stackoverflow链接](https://stackoverflow.com/questions/14984119/python-pandas-remove-duplicate-columns)：'
- en: We see only one feature which seems to be duplicated. I am not going to remove
    the feature yet rather wait until we do EDA in the next part.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只看到一个似乎重复的特征。我不会立即移除该特征，而是等到我们在下一部分进行 EDA 时再处理。
- en: '**4\. Remove duplicate rows: **In this step, we remove all the duplicate rows.
    I use pandas built-in “drop_duplicates(inplace= True)” method to perform this
    action:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 移除重复行：**在这一步，我们移除所有重复的行。我使用 pandas 内置的“drop_duplicates(inplace= True)”方法来执行此操作：'
- en: '[PRE11]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The above four processings are basic which we need to do for any data science
    project. Let''s see the shape of the data after all of these steps:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 上述四个处理步骤是任何数据科学项目中需要做的基本步骤。让我们看看经过这些步骤后的数据形状：
- en: '[PRE12]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We see that we have 93 features after performing the above steps.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现经过上述步骤后，我们有 93 个特征。
- en: 'In the [next part](https://medium.com/@sabber/financial-data-analysis-bf4b5e78c45c) of
    this tutorial, I will go through each feature, then perform cleaning and remove
    it if necessary. In the meantime, if you have any question regarding this part,
    please feel free to write your comment below. You can reach out to me:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个教程的[next part](https://medium.com/@sabber/financial-data-analysis-bf4b5e78c45c)中，我将逐一检查每个特征，然后进行清理，必要时将其移除。同时，如果你对这一部分有任何问题，请随时在下方写下你的评论。你可以联系我：
- en: '[PRE13]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Bio: [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)** is the
    Founder of [xoolooloo.com](https://www.xoolooloo.com/). Computational Geophysicist
    and Machine Learning Enthusiast.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**个人简介: [Sabber Ahamed](https://www.linkedin.com/in/sabber-ahamed/)** 是 [xoolooloo.com](https://www.xoolooloo.com/)
    的创始人，计算地球物理学家及机器学习爱好者。'
- en: '[Original](https://medium.com/@sabber/financial-data-analysis-80ba39149126).
    Reposted with permission.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@sabber/financial-data-analysis-80ba39149126)。经许可转载。'
- en: '**Related:**'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Text Mining on the Command Line](/2018/07/text-mining-command-line.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[命令行上的文本挖掘](/2018/07/text-mining-command-line.html)'
- en: '[Three techniques to improve machine learning model performance with imbalanced
    datasets](/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[三种技术提升不平衡数据集上的机器学习模型性能](/2018/06/three-techniques-improve-machine-learning-model-performance-imbalanced-datasets.html)'
- en: '[Text Classification & Embeddings Visualization Using LSTMs, CNNs, and Pre-trained
    Word Vectors](/2018/07/text-classification-lstm-cnn-pre-trained-word-vectors.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[文本分类与嵌入可视化，使用 LSTM、CNN 和预训练词向量](/2018/07/text-classification-lstm-cnn-pre-trained-word-vectors.html)'
- en: '* * *'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT需求'
- en: '* * *'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[How ML Model Explainability Accelerates the AI Adoption Journey for…](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习模型可解释性如何加速金融服务领域的人工智能采纳](https://www.kdnuggets.com/2022/07/ml-model-explainability-accelerates-ai-adoption-journey-financial-services.html)'
- en: '[Data Science Project of Rotten Tomatoes Movie Rating Prediction:…](https://www.kdnuggets.com/2023/06/data-science-project-rotten-tomatoes-movie-rating-prediction-first-approach.html)'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[烂番茄电影评分预测的数据科学项目：…](https://www.kdnuggets.com/2023/06/data-science-project-rotten-tomatoes-movie-rating-prediction-first-approach.html)'
- en: '[Data Science Project of Rotten Tomatoes Movie Rating Prediction:…](https://www.kdnuggets.com/2023/07/data-science-project-rotten-tomatoes-movie-rating-prediction-second-approach.html)'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[烂番茄电影评分预测的数据科学项目：…](https://www.kdnuggets.com/2023/07/data-science-project-rotten-tomatoes-movie-rating-prediction-second-approach.html)'
- en: '[Multivariate Time-Series Prediction with BQML](https://www.kdnuggets.com/2023/07/multivariate-timeseries-prediction-bqml.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用BQML进行多变量时间序列预测](https://www.kdnuggets.com/2023/07/multivariate-timeseries-prediction-bqml.html)'
- en: '[OLAP vs. OLTP: A Comparative Analysis of Data Processing Systems](https://www.kdnuggets.com/2023/08/olap-oltp-comparative-analysis-data-processing-systems.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OLAP与OLTP：数据处理系统的比较分析](https://www.kdnuggets.com/2023/08/olap-oltp-comparative-analysis-data-processing-systems.html)'
- en: '[Data Representation for Natural Language Processing Tasks](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理任务的数据表示](https://www.kdnuggets.com/2018/11/data-representation-natural-language-processing.html)'
