- en: Labelling Data Using Snorkel
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Snorkel 标注数据
- en: 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html](https://www.kdnuggets.com/2020/07/labelling-data-using-snorkel.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/), [Stefan
    Denkovski](https://www.linkedin.com/in/stefandenkovski/), [Michal Malyska](https://www.linkedin.com/in/malyskamichal/),
    [Sally Moon](https://www.linkedin.com/in/sallysaeyoungmoon/), [Brandon Rufino](https://www.linkedin.com/in/brandon-rufino/),
    [NLP4H](https://nlp4h.com/authors/)**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：[Alister D’Costa](https://www.linkedin.com/in/alisterdcosta/)、[Stefan
    Denkovski](https://www.linkedin.com/in/stefandenkovski/)、[Michal Malyska](https://www.linkedin.com/in/malyskamichal/)、[Sally
    Moon](https://www.linkedin.com/in/sallysaeyoungmoon/)、[Brandon Rufino](https://www.linkedin.com/in/brandon-rufino/)、[NLP4H](https://nlp4h.com/authors/)**'
- en: '![Image for post](../Images/e16079ec47d75638df56b6c91eb5db14.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![帖子图片](../Images/e16079ec47d75638df56b6c91eb5db14.png)'
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前 3 个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织进行 IT'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: In this tutorial, we will walk through the process of using Snorkel to generate
    labels for an unlabelled dataset. We will provide you examples of basic Snorkel
    components by guiding you through a real clinical application of Snorkel. Specifically,
    we will use Snorkel to try to boost our results in predicting [Multiple Sclerosis
    (MS) severity scores](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss).
    Enjoy!
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将介绍如何使用 Snorkel 为未标注的数据集生成标签。我们将通过引导您了解 Snorkel 的实际临床应用，提供一些基本的 Snorkel
    组件示例。具体来说，我们将使用 Snorkel 来尝试提升我们在预测 [多发性硬化症 (MS) 严重程度评分](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)方面的结果。请享用！*
- en: '*Check out the *[*Snorkel Intro Tutorial*](https://www.snorkel.org/use-cases/01-spam-tutorial)* for
    a walk through on spam labelling. For more examples of high-performance in real-world
    uses of Snorkel, see *[*Snorkel’s publication list*](https://www.snorkel.org/resources/)*.*'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看 *[*Snorkel 入门教程*](https://www.snorkel.org/use-cases/01-spam-tutorial)* 了解垃圾邮件标注的过程。有关
    Snorkel 在现实世界应用中的高性能示例，请参见 *[*Snorkel 的出版物列表*](https://www.snorkel.org/resources/)*。*'
- en: '*Check out our other work focused on NLP for MS severity classification *[*here*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*.*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*查看我们关于 MS 严重程度分类的其他 NLP 工作 *[*这里*](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)*。*'
- en: What is Snorkel?
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Snorkel 是什么？
- en: 'Snorkel is a system that facilitates the process of building and managing training
    datasets without manual labelling. The first component of a Snorkel pipeline includes
    labelling functions, which are designed to be weak heuristic functions that predict
    a label given unlabelled data. The labelling functions that we developed for MS
    severity score labelling were the following:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel 是一个促进构建和管理训练数据集的系统，无需手动标注。Snorkel 流水线的第一个组件包括标注函数，这些函数被设计为弱启发式函数，用于在未标注的数据上预测标签。我们为
    MS 严重程度评分标注开发的标注函数如下：
- en: Multiple key-word searches (using regular expressions) within the text. For
    example, in finding a severity score we searched for the phrase in numeric format
    and in roman numeral format.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在文本中进行多个关键词搜索（使用正则表达式）。例如，在查找严重程度评分时，我们搜索了数字格式和罗马数字格式的短语。
- en: Common baselines such as logistic regression, linear discriminant analysis,
    and support vector machines which were trained using term frequency-inverse document
    frequency (or tf-idf for short) features.
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练使用术语频率-逆文档频率（或简写 tf-idf）特征的常见基线，如逻辑回归、线性判别分析和支持向量机。
- en: Word2Vec Convolutional Neural Network (CNN).
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Word2Vec 卷积神经网络（CNN）。
- en: Our MS-BERT classifier described [in this blog post](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e).
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的 MS-BERT 分类器在[这篇博客文章](https://medium.com/@nlp4health/ms-bert-using-neurological-examination-notes-for-multiple-sclerosis-severity-classification-f75f13600d3e)中进行了描述。
- en: The second component of the Snorkel pipeline is a generative model that outputs
    a single confidence weighted training label per data point given predictions from
    all the labelling functions. It does this by learning to estimate the accuracy
    and correlations of the labelling functions based on their agreements and disagreements.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel 管道的第二个组件是一个生成模型，它根据所有标记函数的预测，为每个数据点输出一个单一的置信度加权训练标签。它通过学习基于标记函数的一致性和不一致性来估计标记函数的准确性和相关性来实现这一点。
- en: Snorkel Tutorial
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Snorkel 教程
- en: To reiterate, in this article we demonstrate label generation for MS severity
    scores. A common measurement of MS severity is EDSS or the Expanded Disability
    Status Scale. This is a scale that increases from 0 to 10 depending on the severity
    of MS symptoms. We will refer to EDSS in general as the MS severity score but
    for our keen readers we thought we would provide this information. This score
    is further described [here](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，在这篇文章中，我们演示了 MS 严重性评分的标签生成。MS 严重性的一种常见测量方法是 EDSS 或扩展残疾状态量表。这是一个根据 MS 症状的严重程度从
    0 到 10 增加的量表。我们将一般提及 EDSS 作为 MS 严重性评分，但为了让我们的细心读者了解，我们提供了这些信息。这个评分在[这里](https://www.mstrust.org.uk/a-z/expanded-disability-status-scale-edss)有更详细的描述。
- en: 'Step 0: Acquire a Dataset'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 0：获取数据集
- en: In our task, we worked with a dataset compiled by a leading MS research hospital,
    containing over *70,000* MS consult notes for about 5000 patients. Of the 70,000
    notes only *16,000* are manually labeled by an expert for MS severity. This means
    that their are approximately *54,000* unlabelled notes. As you may or not be aware,
    having a larger dataset to train models generally lead to better model performance.
    Hence, we used Snorkel to generate what we call ‘silver’ labels for our *54,000* unlabelled
    notes. The *16,000* ‘gold’ labelled notes were used to train our classifiers before
    creating their respective labelling function.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的任务中，我们使用了一个由领先的 MS 研究医院编制的数据集，其中包含约 5000 名患者的超过 *70,000* 条 MS 咨询记录。在 70,000
    条记录中，仅 *16,000* 条由专家手动标记了 MS 严重性。这意味着大约有 *54,000* 条未标记的记录。如您所知，通常拥有更大的数据集来训练模型会导致更好的模型性能。因此，我们使用
    Snorkel 为我们的 *54,000* 条未标记记录生成了我们称之为“银色”标签的标签。这 *16,000* 条“黄金”标签记录用于训练我们的分类器，然后再创建其各自的标记函数。
- en: 'Step 1: Installing Snorkel'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 1：安装 Snorkel
- en: 'To install Snorkel to your project, you can run the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 Snorkel 安装到您的项目中，您可以运行以下命令：
- en: 'Step 2: Adding the Labelling Functions'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 2：添加标记函数
- en: Setting up
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置
- en: 'Labelling functions allow you to define weak heuristics and rules that predict
    a label given unlabelled data. These heuristics can be derived from expert knowledge
    or other labelling models. In the case of MS severity score prediction, our labelling
    functions included: key-word search functions derived from clinicians, baseline
    models trained to predict MS severity scores (tf-idf, word2vec cnn, etc.), and
    our MS-BERT classifier.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 标记函数允许您定义弱启发式和规则，给定未标记的数据预测标签。这些启发式方法可以源自专家知识或其他标记模型。在 MS 严重性评分预测的情况下，我们的标记函数包括：源自临床医生的关键词搜索函数、训练以预测
    MS 严重性评分的基线模型（tf-idf、word2vec cnn 等）以及我们的 MS-BERT 分类器。
- en: As you will see below, you mark labelling functions by adding “@labeling_function()”
    above the function. For each labelling function, a single row of a dataframe containing
    unlabelled data (i.e. one observation/sample) is passed in. Each labelling function
    applies heuristics or models to obtain a prediction for each row. If the prediction
    is not found, the function abstains (i.e. returns -1).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示，您可以通过在函数上方添加“@labeling_function()”来标记标记函数。对于每个标记函数，将传入一个包含未标记数据（即一个观察/样本）的一行数据框。每个标记函数应用启发式方法或模型来获取每一行的预测。如果找不到预测，函数将选择不标记（即返回
    -1）。
- en: When all labelling functions have been defined, you can make use of the “PandasLFApplier”
    to obtain a matrix of predictions given all labelling functions.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当所有标记函数定义完毕后，您可以使用 “PandasLFApplier” 来获得所有标记函数给出的预测矩阵。
- en: Upon running the following code, you will obtain a (N X num_lfs) L_predictions
    matrix, where N is number of observations in ‘df_unlabelled’ and ‘num_lfs’ is
    the number of labelling functions defined in ‘lfs’.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下代码后，你将获得一个（N X num_lfs）L_predictions 矩阵，其中 N 是‘df_unlabelled’中的观测数量，‘num_lfs’是‘lfs’中定义的标签函数数量。
- en: 'Labelling Function Example #1: Key-Word Search'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '标签函数示例 #1：关键词搜索'
- en: Below shows an example of a key-word search (using regular expressions) used
    to extract MS severity scores recorded in decimal form. The regular expression
    functions are applied to attempt to search for the MS severity score recorded
    in decimal form. If found, the function returns the score in the appropriate output
    format. Else, the function abstains (i.e. returns -1) to indicate that the score
    is not found.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下面展示了一个使用正则表达式的关键词搜索示例，用于提取以小数形式记录的 MS 严重性评分。正则表达式函数被应用于尝试搜索以小数形式记录的 MS 严重性评分。如果找到，该函数将返回适当输出格式的评分。否则，函数将回避（即返回
    -1）以表示未找到评分。
- en: 'Labelling Function Example #2: Trained Classifier'
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '标签函数示例 #2：训练的分类器'
- en: Above we see an example using a key-word search. To integrate a trained classifier,
    you must perform one extra step. That is, you must train and export your model
    before creating your labelling function. Here is an example of how we trained
    a logistic regression that was built on top of tf-idf features.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上面我们看到一个使用关键词搜索的示例。要集成训练好的分类器，你必须执行一个额外的步骤。即，在创建标签函数之前，你必须训练并导出你的模型。下面是一个基于
    tf-idf 特征训练逻辑回归的示例。
- en: 'With the model trained, implementing a labelling function is as simple as this:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 模型训练完成后，实现一个标签函数就像这样简单：
- en: 'Step 3(a): Using Snorkel’s Majority Vote'
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3(a)：使用 Snorkel 的多数投票
- en: Some would say the simpliest function Snorkel uses to generate a label is ‘Majority
    Vote’. Majority Vote, as the name implies, makes a prediction based on the most
    voted for class.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 有人说 Snorkel 用来生成标签的最简单函数是‘多数投票’。多数投票，顾名思义，根据最多投票的类别做出预测。
- en: To implement Majority Vote you must specify the ‘cardinality’ (i.e. number of
    classes).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现多数投票，你必须指定‘基数’（即类别数量）。
- en: 'Step 3(b): Using Snorkel’s Label Model'
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3(b)：使用 Snorkel 的标签模型
- en: To take advantage of Snorkel’s full functionality, we used the ‘Label Model’
    to generate a single confidence-weighted label given a matrix of predictions obtained
    from all the labelling functions (i.e. L_unlabelled). The Label Model predicts
    by learning to estimate the accuracy and correlations of the labelling functions
    based on their agreements and disagreements.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用 Snorkel 的所有功能，我们使用‘标签模型’根据所有标签函数（即 L_unlabelled）获得的预测矩阵生成一个单一的置信加权标签。标签模型通过学习估计标签函数的准确性和相关性来进行预测，基于它们的同意和不同意见。
- en: You can define a Label Model and specify ‘cardinality’. After you fit the Label
    Model with L_unlabelled, it will generate single predictions for the unlabelled
    data.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以定义一个标签模型并指定‘基数’。在你用 L_unlabelled 训练标签模型后，它将为未标记的数据生成单一预测。
- en: 'Step 4: Evaluation Tools'
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 4：评估工具
- en: LF Analysis — Coverage, Overlaps, Conflicts
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LF 分析 — 覆盖率、重叠、冲突
- en: To better understand how your labelling functions are functioning, you can make
    use of Snorkel’s LFAnalysis. The LF analysis reports the polarity, coverage, overlap,
    and conflicts of each labelling function.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解你的标签函数的工作情况，你可以使用 Snorkel 的 LFAnalysis。LF 分析报告每个标签函数的极性、覆盖率、重叠和冲突。
- en: 'The definition of these terms are as follows and you can refer to the [Snorkel
    documentation](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities) for
    more information:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这些术语的定义如下，你可以参考[Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html#snorkel.labeling.LFAnalysis.lf_polarities)获取更多信息：
- en: 'Polarity: Infer the polarities of each LF based on evidence in a label matrix.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 极性：根据标签矩阵中的证据推断每个 LF 的极性。
- en: 'Coverage: Computes the fraction of data points with at least one label.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 覆盖率：计算至少有一个标签的数据点的比例。
- en: 'Overlap: Computes the fraction of data points with at least two (non-abstain)
    labels.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重叠：计算至少有两个（非回避）标签的数据点的比例。
- en: 'Conflicts: Computes the fraction of data points each labelling function disagrees
    with at least one other labelling function.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 冲突：计算每个标签函数与至少一个其他标签函数不一致的数据点的比例。
- en: LFAnalysis will provide an analysis of how your labelling functions performed
    relative to each other.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LFAnalysis 将提供关于你的标签函数相对表现的分析。
- en: ‘get_label_buckets’
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '`get_label_buckets`'
- en: Snorkel provides some more evaluation tools to help you understand the quality
    of your labelling functions. In particular, ‘get_label_buckets’ is a handy way
    to combine labels and make comparisons. For more information, read the [Snorkel
    documentation](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Snorkel 提供了一些额外的评估工具来帮助你了解标注函数的质量。特别是，`get_label_buckets` 是一种将标签组合并进行比较的便捷方法。有关更多信息，请阅读
    [Snorkel 文档](https://snorkel.readthedocs.io/en/v0.9.1/packages/_autosummary/analysis/snorkel.analysis.get_label_buckets.html)。
- en: The following code allows you to compare the true labels (y_gold) and predicted
    labels (y_preds) to view data points that were correctly or incorrectly labelled
    by Snorkel. This will allow you to pin-point which data points are difficult to
    correctly label, so that you can fine-tune your labelling functions to cover these
    edge cases.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码允许你比较真实标签（y_gold）和预测标签（y_preds），以查看 Snorkel 正确或错误标注的数据点。这将帮助你找出哪些数据点难以正确标注，从而调整你的标注函数以覆盖这些边缘情况。
- en: Note, for this analysis we went back and created a L_train matrix which contains
    our labelling function predictions for our ‘gold’ labelled dataset.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，对于此分析，我们回到创建了一个 L_train 矩阵，其中包含我们对“金标准”标注数据集的标注函数预测。
- en: Alternatively, you can use ‘get_label_buckets’ to make comparisons between labelling
    functions.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用 `get_label_buckets` 来比较标注函数之间的差异。
- en: The following code allows you to compare the label predictions in L_unlabelled
    to observe how different labelling functions label datapoints differently.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码允许你比较 L_unlabelled 中的标签预测，以观察不同标注函数如何不同地标注数据点。
- en: 'Step 5: Deployment'
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 5 步：部署
- en: Choosing the Best Labelling Model to Label Unlabelled Data
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择最佳标注模型来标注未标注数据
- en: Following the procedure outlined above, we developed various labelling functions
    based on key-word searches, baseline models, and our MS-BERT classifier. We experimented
    with various ensembles of labelling functions and used Snorkel’s Label Model to
    obtain predictions for a held-out labelled dataset. This allowed us to determine
    which ensemble of labelling functions would be best to label our unlabelled dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 按照上述程序，我们基于关键词搜索、基准模型和我们的 MS-BERT 分类器开发了各种标注函数。我们尝试了各种标注函数的集成，并使用 Snorkel 的
    Label Model 对保留的标注数据集进行了预测。这使我们能够确定哪种标注函数的集成最适合标注我们的未标注数据集。
- en: As shown in the table below, we observed that the MS-BERT classifier (MSBC)
    alone outperformed all ensembles that contain itself by at least 0.02 on Macro-F1\.
    The addition of weaker heuristics and classifiers consistently decreased the ensemble’s
    performance. Furthermore, we observed that the amount of conflict for the MS-BERT
    classifier increased as weaker classifiers and heuristics were added to the ensemble.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如下表所示，我们观察到 MS-BERT 分类器（MSBC）单独的表现超越了所有包含它的集成模型，Macro-F1 上至少高出 0.02。添加较弱的启发式方法和分类器始终会降低集成模型的性能。此外，我们还观察到，随着较弱分类器和启发式方法的加入，MS-BERT
    分类器的冲突量增加。
- en: '![Figure](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/bcd40b9154f9ad113f7b3c41b440b185.png)'
- en: Note, Rule Based (RB) refers to our key-word searches. LDA refers to linear
    discriminant analysis. TFIDFs refer to all models built on top of tf-idf features
    (i.e. logistic regression, linear discriminant analysis, and support vector machines).
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，基于规则（RB）指的是我们的关键词搜索。LDA 指线性判别分析。TFIDF 指所有基于 tf-idf 特征构建的模型（即逻辑回归、线性判别分析和支持向量机）。
- en: To understand our findings, we have to remind ourselves that Snorkel’s label
    model learns to predict the accuracy and correlations of the labelling functions
    based on agreements and disagreements amongst each other. Therefore in the presence
    of a strong labelling function, such as our MS-BERT classifier, the addition of
    weaker labelling functions introduces more disagreements with the strong labelling
    functions and therefore decreases performance. From these findings, we learned
    that Snorkel may be more suited for situations where you *only* have weak heuristics
    and rules. However, if you already have a strong labelling function, developing
    a Snorkel ensemble with weaker heuristics may compromise performance.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解我们的发现，我们必须提醒自己，Snorkel 的标签模型通过基于相互之间的协议和分歧来预测标签函数的准确性和相关性。因此，在存在强标签函数的情况下，比如我们的
    MS-BERT 分类器，添加较弱的标签函数会导致与强标签函数之间出现更多的分歧，从而降低性能。通过这些发现，我们了解到 Snorkel 可能更适用于仅有弱启发式和规则的情况。然而，如果你已经拥有一个强标签函数，开发一个包含较弱启发式的
    Snorkel 集成可能会影响性能。
- en: Therefore, the MS-BERT classifier alone was chosen to label our unlabelled dataset.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，单独使用 MS-BERT 分类器来标注我们未标注的数据集。
- en: Semi-Supervised Labelling Results
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 半监督标注结果
- en: 'The MS-BERT classifier was used to obtain ‘silver’ labels for our unlabelled
    dataset. These ‘silver’ labels were combined with our ‘gold’ labels to obtain
    a silver+gold dataset. To infer the quality of the silver labels, new MS-BERT
    classifiers were developed: 1) MS-BERT+ (trained on silver+gold labelled data);
    and 2) MS-BERT-silver (trained on silver labelled data). These classifiers were
    evaluated on a held-out test dataset that was previously used to evaluate our
    original MS-BERT classifier (trained on gold labelled data). MS-BERT+ achieved
    a Macro-F1 of 0.86238 and a Micro-F1 of 0.92569, and MS-BERT-silver achieved a
    Macro-F1 of 0.82922 and a Micro-F1 of 0.91442\. Although their performance was
    slightly lower that our original MS-BERT classifier (Macro-F1 of 0.88296, Micro-F1
    of 0.94177), they still outperformed the previous best baseline models for MS
    severity prediction. The strong results of MS-BERT-silver helps show the effectiveness
    of using our MS-BERT classifier as a labelling function. It demonstrates potential
    to reduce tedious hours required by a professional to read through a patient’s
    consult note and manually generate MS severity scores.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 MS-BERT 分类器为我们未标注的数据集获取了“银”标签。这些“银”标签与我们的“金”标签结合，形成了银+金数据集。为了推断银标签的质量，开发了新的
    MS-BERT 分类器：1) MS-BERT+（在银+金标注数据上训练）；2) MS-BERT-silver（在银标注数据上训练）。这些分类器在一个之前用于评估我们原始
    MS-BERT 分类器（在金标注数据上训练）的保留测试数据集上进行了评估。MS-BERT+ 达到了 0.86238 的 Macro-F1 和 0.92569
    的 Micro-F1，而 MS-BERT-silver 达到了 0.82922 的 Macro-F1 和 0.91442 的 Micro-F1。尽管它们的性能略低于我们原始的
    MS-BERT 分类器（Macro-F1 为 0.88296，Micro-F1 为 0.94177），但它们仍然超越了之前最好的 MS 严重性预测基线模型。MS-BERT-silver
    的强劲结果有助于展示我们 MS-BERT 分类器作为标签函数的有效性。它展示了减少专业人员需要花费的繁琐时间来阅读患者咨询笔记并手动生成 MS 严重性评分的潜力。
- en: Thank You!
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谢谢大家！
- en: Thanks for reading everyone! If you have any questions please do not hesitate
    to contact us at nlp4health (at gmail dot) com. :)
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢大家阅读！如果你有任何问题，请随时通过 nlp4health (at gmail dot) com 联系我们。:)
- en: Acknowledgements
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 致谢
- en: We would like to thank the researchers and staff at the Data Science and Advanced
    Analytics (DSAA) department, St. Michael’s Hospital, for providing consistent
    support and guidance throughout this project. We would also like to thank Dr.
    Marzyeh Ghassemi, and Taylor Killan for providing us the opportunity to work on
    this exciting project. Lastly, we would like to thank Dr. Tony Antoniou and Dr.
    Jiwon Oh from the MS clinic at St. Michael’s Hospital for their support on the
    neurological examination notes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要感谢圣迈克尔医院数据科学与高级分析（DSAA）部门的研究人员和工作人员，在整个项目过程中提供了持续的支持和指导。我们还要感谢 Marzyeh Ghassemi
    博士和 Taylor Killan，感谢他们让我们有机会参与这个激动人心的项目。最后，我们要感谢圣迈克尔医院 MS 诊所的 Tony Antoniou 博士和
    Jiwon Oh 博士，感谢他们在神经系统检查笔记方面的支持。
- en: '*Originally published at *[*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/)*.*'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*最初发布于* [*https://nlp4h.com*](https://nlp4h.com/blog/snorkel_tutorial/) *。*'
- en: '**Bio: [The authors](https://nlp4h.com/authors/)** are a group of graduate
    students at University of Toronto working on NLP for healthcare.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [作者们](https://nlp4h.com/authors/)** 是一组在多伦多大学从事医疗保健 NLP 研究的研究生。'
- en: '[Original](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f).
    Reposted with permission.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始](https://medium.com/swlh/a-snorkel-tutorial-using-clinical-notes-to-predict-multiple-sclerosis-severity-scores-e3863801630f)。经授权转载。'
- en: '**Related:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Hand labeling is the past. The future is #NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[人工标注是过去的事。未来是#NoLabel AI](/2020/02/hand-labeling-past-future-nolabel-ai.html)'
- en: '[From Languages to Information: Another Great NLP Course from Stanford](/2020/06/languages-information-another-great-nlp-course-stanford.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从语言到信息：斯坦福大学另一门优秀的 NLP 课程](/2020/06/languages-information-another-great-nlp-course-stanford.html)'
- en: '[The Unreasonable Progress of Deep Neural Networks in Natural Language Processing
    (NLP)](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络在自然语言处理（NLP）中的不合理进展](/2020/06/unreasonable-progress-deep-neural-networks-nlp.html)'
- en: More On This Topic
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[How to Determine the Best Fitting Data Distribution Using Python](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何使用 Python 确定最佳数据分布](https://www.kdnuggets.com/2021/09/determine-best-fitting-data-distribution-python.html)'
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Eurybia 检测数据漂移以确保生产中的 ML 模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[4 Ways Hackers Are Using Data Science to Steal Billions](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[黑客如何利用数据科学窃取数十亿](https://www.kdnuggets.com/2022/02/4-ways-hackers-data-science-steal-billions.html)'
- en: '[Using Data Science to Make Clean Energy More Equitable](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用数据科学使清洁能源更具公平性](https://www.kdnuggets.com/2022/03/data-science-make-clean-energy-equitable.html)'
- en: '[How to Ace Data Science Assessment Test by Using Automatic EDA Tools](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何通过使用自动化 EDA 工具在数据科学评估测试中脱颖而出](https://www.kdnuggets.com/2022/04/ace-data-science-assessment-test-automatic-eda-tools.html)'
- en: '[Introduction to Data Visualization Using Matplotlib](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Matplotlib 的数据可视化介绍](https://www.kdnuggets.com/2022/12/introduction-data-visualization-matplotlib.html)'
