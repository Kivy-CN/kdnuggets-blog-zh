# 成为数据科学家必知的十种机器学习算法

> 原文：[https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html](https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](2018/04/10-machine-learning-algorithms-data-scientist.html/2#comments)

**作者：Muktabh Mayank，[ParallelDots](https://paralleldots.com/)**

![机器学习算法](../Images/da0e3450c1e1433e14e7a1b2c34d159e.png)

机器学习从业者有着不同的个性。有些人会说“我是X方面的专家，X可以在任何类型的数据上进行训练”，其中X代表某种算法，而另一些人则认为“合适的工具用于合适的工作”。很多人还遵循“全才中的专才”策略，他们在一个领域拥有深入的专业知识，并对机器学习的其他领域略有了解。不过，作为实际工作的数据科学家，我们不得不了解一些常见的[机器学习算法](https://www.kdnuggets.com/2016/08/10-algorithms-machine-learning-engineers.html)，这些算法将帮助我们应对遇到的新领域问题。这是对常见机器学习算法的快速回顾以及有关它们的资源，这些都可以帮助你入门。

### 1. 主成分分析（PCA）/SVD

PCA是一种无监督方法，用于理解由向量组成的数据集的全局属性。在这里分析数据点的协方差矩阵，以了解哪些维度（大多数）/数据点（有时）更重要（即在它们之间具有高方差，但与其他点的协方差较低）。考虑矩阵的前几个主成分，可以将其视为具有最高特征值的特征向量。SVD本质上也是一种计算有序成分的方法，但你不需要获得点的协方差矩阵即可获得它。

![机器学习算法](../Images/d799bb2104583027c8fffea1197d84e1.png)

该算法通过减少数据点的维度来帮助应对维度灾难。

**库：**

[https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html)

[http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)

**入门教程：**

[https://arxiv.org/pdf/1404.1100.pdf](https://arxiv.org/pdf/1404.1100.pdf)

### 2a. 最小二乘法和多项式拟合

记得你大学里的数值分析代码吗？那时你用来将线条和曲线拟合到点上以得到一个方程。你可以在机器学习中将它们用于拟合非常小的数据集的曲线（对于大数据集或具有许多维的数据集，你可能会遇到严重的过拟合问题，所以没必要使用）。普通最小二乘法（OLS）有封闭形式解，因此你不需要使用复杂的优化技术。

![](../Images/4751b805d2c61703c32e03f0fbb1e165.png)

很明显，使用这个算法来拟合简单的曲线/回归

### 库：

[https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html)[https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html](https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.polyfit.html)

### 入门教程：

[https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf](https://lagunita.stanford.edu/c4x/HumanitiesScience/StatLearning/asset/linear_regression.pdf)

### 2b. 约束线性回归

最小二乘法可能会被离群点、虚假字段和数据噪声混淆。因此，我们需要约束条件来减少我们在数据集上拟合的线的方差。正确的方法是拟合一个线性回归模型，这将确保权重不会出现异常。模型可以具有L1范数（LASSO）、L2范数（岭回归）或两者（弹性回归）。均方损失被优化。

![](../Images/727b71525e3373fc2f7d83ce4e350469.png)

使用这些算法来拟合带约束的回归线，避免过拟合并遮蔽模型中的噪声维度。

**库：**

[http://scikit-learn.org/stable/modules/linear_model.html](http://scikit-learn.org/stable/modules/linear_model.html)

**入门教程：**

[https://www.youtube.com/watch?v=5asL5Eq2x0A](https://www.youtube.com/watch?v=5asL5Eq2x0A)

[https://www.youtube.com/watch?v=jbwSCwoT51M](https://www.youtube.com/watch?v=jbwSCwoT51M)

### 3. K均值聚类

每个人最喜欢的无监督聚类算法。给定一组以向量形式表示的数据点，我们可以根据它们之间的距离对点进行聚类。这是一个期望最大化算法，它迭代地移动聚类的中心，然后将点与每个聚类中心结合。算法的输入是要生成的聚类数量和尝试使聚类收敛的迭代次数。

![机器学习算法](../Images/351e4ae23251bd092d8c3315e482ceb1.png)

从名称中可以明显看出，你可以使用这个算法在数据集中创建K个聚类

**库：**

[http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)

**入门教程：**

[https://www.youtube.com/watch?v=hDmNF9JG3lo](https://www.youtube.com/watch?v=hDmNF9JG3lo)

[https://www.datascience.com/blog/k-means-clustering](https://www.datascience.com/blog/k-means-clustering)

### 4\. 逻辑回归

逻辑回归是受限的线性回归，具有非线性（通常使用 sigmoid 函数，或者你也可以使用 tanh）应用于权重之后，因此将输出限制在接近 +/- 类别（在 sigmoid 情况下是 1 和 0）。交叉熵损失函数通过梯度下降进行优化。给初学者的提示：逻辑回归用于分类，而不是回归。你也可以把逻辑回归看作是一个单层神经网络。逻辑回归使用梯度下降或 L-BFGS 等优化方法进行训练。NLP 领域的人经常用最大熵分类器这个名字。

这就是 Sigmoid 函数的样子：

![](../Images/0e1fce437687ecfe4d3fb5b72127f730.png)

使用 LR 来训练简单但非常强大的分类器。

**库：**

[http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)

**入门教程：**

[https://www.youtube.com/watch?v=-la3q9d7AKQ](https://www.youtube.com/watch?v=-la3q9d7AKQ)

### 5\. SVM（支持向量机）

SVM 是线性模型，类似于线性/逻辑回归，区别在于它们有不同的基于边距的损失函数（支持向量的推导是我见过的最美丽的数学结果之一，与特征值计算一起）。你可以使用 L-BFGS 或者甚至是 SGD 等优化方法来优化损失函数。

![](../Images/076c7aab2765ed2bf0c959f351786eaf.png)

SVM 的另一个创新是使用内核对数据进行特征工程。如果你对领域有良好的洞察，你可以用更智能的内核替换传统的 RBF 内核，从中获益。

SVM 的一个独特之处是能够学习单类分类器。

SVM 可以用于训练分类器（甚至是回归器）

**库：**

[http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html](http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)

**入门教程：**

[https://www.youtube.com/watch?v=eHsErlPJWUU](https://www.youtube.com/watch?v=eHsErlPJWUU)

**注意：** 基于 SGD 的逻辑回归和 SVM 训练可以在 SKLearn 的 [http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) 中找到，我常用它，因为它允许我通过一个通用接口检查 LR 和 SVM。你也可以使用 mini batches 在大于 RAM 大小的数据集上进行训练。

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的轨道。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析能力

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织在 IT 领域

* * *

### 更多相关主题

+   [每个数据科学家都应该了解的三个 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [成功数据科学家的 5 个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)

+   [停止学习数据科学以寻找目标，并通过寻找目标来……](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [学习数据科学统计的最佳资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成为一名出色数据科学家所需的 5 个关键技能](https://www.kdnuggets.com/2021/12/5-key-skills-needed-become-great-data-scientist.html)

+   [一个 $9B 人工智能失败的案例分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)
