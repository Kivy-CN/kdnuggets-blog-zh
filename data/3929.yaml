- en: Get a 2–6x Speed-up on Your Data Pre-processing with Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Python中实现数据预处理的2–6倍加速
- en: 原文：[https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html](https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html](https://www.kdnuggets.com/2018/10/get-speed-up-data-pre-processing-python.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: Python is the go-to programming language for all things machine learning. It’s
    easy to use and has many fantastic libraries that make crunching data a breeze!
    But things get a big trickier when we’re dealing with lots of data….
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Python 是进行所有机器学习工作的首选编程语言。它易于使用，并拥有许多出色的库，使得数据处理轻松愉快！但是，当处理大量数据时情况就会变得有些复杂……
- en: These days, the term “big data” usually refers to a dataset that’s on the order
    of at least hundreds of thousands if not *millions* of data points! At such a
    scale, every little computation adds up and we need to keep efficiency in mind
    when coding each step of the pipeline. One critical step that is often overlooked
    when thinking about our machine learning system’s efficiency is the *pre-processing* stage,
    where we must apply some kind of operation to all of our data points.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，“大数据”一词通常指的是数据集的规模至少达到数十万，甚至是*百万*的数据点！在这样的规模下，每一点计算都会累积，我们在编写每一步处理程序时需要保持高效。在考虑机器学习系统的效率时，一个常常被忽视的关键步骤是*预处理*阶段，我们必须对所有数据点应用某种操作。
- en: By default, Python programs execute as a single process using a single CPU.
    Most modern machines made for machine learning have *at least *2 CPU cores. That
    means, for the example of 2 CPU cores, that 50% or more of your computer’s processing
    power won’t be doing anything by default when you run your pre-processing! The
    situation gets even worse when you get to 4 cores (modern Intel i5) or 6cores
    (modern Intel i7).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Python程序作为单个进程使用单个CPU执行。大多数现代机器学习机器至少拥有*2*个CPU核心。这意味着，对于2核的例子，当你运行预处理时，50%或更多的计算机处理能力不会被利用！当核心数达到4（现代Intel
    i5）或6（现代Intel i7）时，情况会变得更糟。
- en: But thankfully, there is a somewhat hidden feature in a built-in Python library
    that lets us take advantage of all of our CPU cores! Thanks to Python’s `concurrent.futures` module,
    it only takes 3 lines of code to turn a normal program into one that can process
    data in parallel across the CPU cores.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Python内置库中有一个略微隐藏的功能，让我们可以充分利用所有CPU核心！得益于Python的`concurrent.futures`模块，只需3行代码，就能将普通程序转变为能够在CPU核心间并行处理数据的程序。
- en: The standard approach
  id: totrans-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 标准方法
- en: Let’s take a simple example where we have a dataset of images in a single folder;
    maybe we even have thousands or millions of those images! For the sake of processing
    time we’ll use 1000 here. We would like to resize all images to size 600x600 before
    passing it to our deep neural network. This is what it would look like in some
    pretty standard Python code you would often see on GitHub.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以一个简单的例子开始，我们在一个文件夹中有一个图像数据集；也许我们甚至有成千上万张图像！为了处理时间的考虑，我们这里使用1000张。我们希望在将图像传递给我们的深度神经网络之前，将所有图像的尺寸调整为600x600。这是一些你在GitHub上常见的标准Python代码。
- en: 'This program follows a simple pattern you’ll often see in data processing scripts:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序遵循一个在数据处理脚本中常见的简单模式：
- en: You start with a list of files (or other data) that you want to process.
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你从一个需要处理的文件（或其他数据）列表开始。
- en: You process each piece of data, one at a time, using a `for` loop and then running
    the pre-processing on each loop iteration
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你逐个处理每一块数据，使用`for`循环，并在每次循环迭代时运行预处理。
- en: 'Let’s test this program on a folder with 1000 jpeg files and see how long it
    takes to run:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个包含1000个jpeg文件的文件夹上测试这个程序，看看运行需要多长时间：
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: On my i7–8700k with 6 CPU cores, that gave me a run time of **7.9864 seconds**!
    It seems a bit slow for such a high-end CPU. Let’s see what we can do to speed
    things up.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我的i7–8700k六核CPU上，这个过程花费了**7.9864秒**！对于如此高端的CPU来说，这似乎有点慢。让我们看看如何加快速度。
- en: The fast way
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 快速方法
- en: To understand how we would want Python to process things in parallel, it helps
    to think intuitively about parallel processing itself. Let’s say we have to perform
    the same single task of hitting nails into a piece of wood and that we have 1000
    nails in our bucket. If we say that each nail takes 1 second, then with 1 person
    we would finish the job in 1000 seconds. But if we have 4 people on the team,
    we would divide the bucket into 4 equal piles and then each person on the team
    would work on their own pile of nails. With this method, we would finish in only
    250 seconds!
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解我们希望Python如何并行处理事物，直观地考虑并行处理本身会有所帮助。假设我们需要在一块木头上钉入相同的钉子，并且我们有1000个钉子。如果每个钉子需要1秒钟，那么1个人完成这项工作需要1000秒。但如果我们有4个人在团队中，我们将桶中的钉子分成4堆，然后每个人处理自己的一堆钉子。这样，我们只需250秒就能完成！
- en: 'We can have Python do something similar for us in our example here with the
    1000 images:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以让Python在这个例子中对1000张图片做类似的事情：
- en: Split the list of jpg files into 4 smaller groups.
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将jpg文件列表拆分成4个较小的组。
- en: Run 4 separate instances of the Python interpreter.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行4个单独的Python解释器实例。
- en: Have each instance of Python process one of the 4 smaller groups of data.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让每个Python实例处理4个较小的数据组中的一个。
- en: Combine the results from the 4 processes to get the final list of results
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将4个过程的结果结合起来，得到最终的结果列表。
- en: The great part about all this is that Python handles all the hard work for us.
    We just tell it which function we want to run and how many instances of Python
    to use and it does all the rest! We only have to change **3 lines of code**.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 最棒的地方是Python为我们处理所有的繁重工作。我们只需要告诉它我们想运行哪个函数以及要使用多少个Python实例，它就会完成其他所有工作！我们只需更改**3行代码**。
- en: 'From the above code:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的代码来看：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'boots up as many Python processes as you have CPU cores, in my case 6\. The
    actually processing line is this one:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 启动与你的CPU核心数相同数量的Python进程，在我的情况下是6个。实际的处理行是这一行：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The **executor.map() **takes as input the function you would like to run and
    a list where each element of the list is a **single input to our function**. Since
    we have 6 cores, we will be processing 6 items from that list at the same time!
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**executor.map()** 接受你想运行的函数和一个列表作为输入，列表中的每个元素是**函数的单一输入**。由于我们有6个核心，我们将同时处理列表中的6个项目！'
- en: 'If we again run our program using:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们再次运行我们的程序：
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We get a run time of **1.14265 seconds**, a nearly x6 speed-up!
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的运行时间为**1.14265秒**，速度提升了近6倍！
- en: '*Note: There is some overhead in spawning more Python processes and shuffling
    data around between them, so you won’t always get this much of a speed improvement.
    But overall your speed-up will usually be quite significant*'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*注意：启动更多Python进程并在它们之间传递数据会有一些开销，因此你不会总是得到如此大的速度提升。但总体而言，你的速度提升通常会相当显著。*'
- en: Is it always super fast?
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 是否总是非常快？
- en: Using Python parallel pools is a great solution when you have a list of data
    to process and you are performing a similar computation on each data point. But,
    it’s not always going to be the perfect solution. The data processed by parallel
    pools won’t be processed in any predictable order. If you need the result from
    the processing to be in a specific order, then this method probably isn’t right
    for you.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python并行池是处理数据列表并对每个数据点执行相似计算的好方法。但是，它并不总是完美的解决方案。并行池处理的数据不会按任何可预测的顺序处理。如果你需要结果按特定顺序处理，那么这个方法可能不适合你。
- en: 'The data you are processing also needs to be a type that Python knows how to
    “pickle”. Luckily, these are quite common. From the official Python documentation:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你处理的数据也需要是Python知道如何“序列化”的类型。幸运的是，这些类型相当常见。来自官方Python文档：
- en: '`None`, `True`, and `False`'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`None`、`True` 和 `False`'
- en: integers, floating point numbers, complex numbers
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 整数、浮点数、复数
- en: strings, bytes, bytearrays
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串、字节、字节数组
- en: tuples, lists, sets, and dictionaries containing only picklable objects
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅包含可序列化对象的元组、列表、集合和字典。
- en: functions defined at the top level of a module (using `[def](https://docs.python.org/3/reference/compound_stmts.html#def)`,
    not `[lambda](https://docs.python.org/3/reference/expressions.html#lambda)`)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模块的顶层定义的函数（使用`[def](https://docs.python.org/3/reference/compound_stmts.html#def)`，而不是`[lambda](https://docs.python.org/3/reference/expressions.html#lambda)`）
- en: built-in functions defined at the top level of a module
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模块的顶层定义的内置函数。
- en: classes that are defined at the top level of a module
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模块的顶层定义的类。
- en: instances of such classes whose `[__dict__](https://docs.python.org/3/library/stdtypes.html#object.__dict__)` or
    the result of calling `[__getstate__()](https://docs.python.org/3/library/pickle.html#object.__getstate__)` is
    picklable (see section [Pickling Class Instances](https://docs.python.org/3/library/pickle.html#pickle-inst) for
    details).
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类实例的 `[`[__dict__](https://docs.python.org/3/library/stdtypes.html#object.__dict__)`
    或调用 `[`__getstate__()](https://docs.python.org/3/library/pickle.html#object.__getstate__)`
    的结果是可以 picklable 的（详见 [Pickling 类实例](https://docs.python.org/3/library/pickle.html#pickle-inst)）。
- en: Like to read about nerd stuff?
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 喜欢阅读关于极客的内容？
- en: Follow me on [twitter](https://twitter.com/GeorgeSeif94) where I post all about
    the latest and greatest AI, Technology, and Science!
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [twitter](https://twitter.com/GeorgeSeif94) 上关注我，那里我会发布关于最新最棒的 AI、科技和科学的内容！
- en: '**Bio: [George Seif](https://towardsdatascience.com/@george.seif94)** is a
    Certified Nerd and AI / Machine Learning Engineer.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [George Seif](https://towardsdatascience.com/@george.seif94)** 是一名认证的极客和
    AI / 机器学习工程师。'
- en: '[Original](https://towardsdatascience.com/heres-how-you-can-get-a-2-6x-speed-up-on-your-data-pre-processing-with-python-847887e63be5).
    Reposted with permission.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/heres-how-you-can-get-a-2-6x-speed-up-on-your-data-pre-processing-with-python-847887e63be5)。经许可转载。'
- en: '**Related:**'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关:**'
- en: '[5 “Clean Code” Tips That Will Dramatically Improve Your Productivity](/2018/10/5-clean-code-tips-dramatically-improve-productivity.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5 个“清晰代码”技巧将极大提高您的生产力](/2018/10/5-clean-code-tips-dramatically-improve-productivity.html)'
- en: '[The 5 Clustering Algorithms Data Scientists Need to Know](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学家需要了解的5种聚类算法](/2018/06/5-clustering-algorithms-data-scientists-need-know.html)'
- en: '[Selecting the Best Machine Learning Algorithm for Your Regression Problem](/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[为回归问题选择最佳的机器学习算法](/2018/08/selecting-best-machine-learning-algorithm-regression-problem.html)'
- en: '* * *'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3个课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织的 IT'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Easy Guide To Data Preprocessing In Python](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Python 中数据预处理的简易指南](https://www.kdnuggets.com/2020/07/easy-guide-data-preprocessing-python.html)'
- en: '[Learn Data Cleaning and Preprocessing for Data Science with This Free eBook](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过这本免费电子书学习数据清理和预处理](https://www.kdnuggets.com/2023/08/learn-data-cleaning-preprocessing-data-science-free-ebook.html)'
- en: '[7 Steps to Mastering Data Cleaning and Preprocessing Techniques](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[掌握数据清理和预处理技术的7个步骤](https://www.kdnuggets.com/2023/08/7-steps-mastering-data-cleaning-preprocessing-techniques.html)'
- en: '[Harnessing ChatGPT for Automated Data Cleaning and Preprocessing](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 ChatGPT 进行自动化数据清理和预处理](https://www.kdnuggets.com/2023/08/harnessing-chatgpt-automated-data-cleaning-preprocessing.html)'
- en: '[Cleaning and Preprocessing Text Data in Pandas for NLP Tasks](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在 Pandas 中清理和预处理文本数据以用于 NLP 任务](https://www.kdnuggets.com/cleaning-and-preprocessing-text-data-in-pandas-for-nlp-tasks)'
- en: '[How to Get Your First Job in Data Science without Any Work Experience](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何在没有工作经验的情况下获得首份数据科学工作](https://www.kdnuggets.com/2021/02/first-job-data-science-without-work-experience.html)'
