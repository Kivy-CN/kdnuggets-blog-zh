- en: Word Morphing – an original idea
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Word Morphing – 一个原创想法
- en: 原文：[https://www.kdnuggets.com/2018/11/word-morphing-original-idea.html](https://www.kdnuggets.com/2018/11/word-morphing-original-idea.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2018/11/word-morphing-original-idea.html](https://www.kdnuggets.com/2018/11/word-morphing-original-idea.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
- en: '![](../Images/cd297b34131042afd6e7c13b51c5d6c5.png)'
  id: totrans-3
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd297b34131042afd6e7c13b51c5d6c5.png)'
- en: '**Smooth image transition (morphing) from a tiger to a human (image courtesy:
    Google Images)**'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**平滑的图像过渡（变形）从老虎到人类（图片来源：Google Images）**'
- en: 'In order to perform word morphing, we’ll define a graph *G* where the set of
    nodes *N* represent words, and there’s some non negative weight function *f*:*N*×*N*→ℝ.
    Given a start word *S* and an end word *E*, our goal is to find a path within
    the graph which minimizes the sum of weights induced by *f*:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行词形变化，我们将定义一个图*G*，其中节点集合*N*表示单词，并且存在一个非负权重函数*f*:*N*×*N*→ℝ。给定一个起始单词*S*和一个结束单词*E*，我们的目标是找到图中的一条路径，该路径最小化由*f*引起的权重总和：
- en: '![](../Images/b5e754c708acf0ba033ea289c94eecea.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b5e754c708acf0ba033ea289c94eecea.png)'
- en: '**Fig. 1\. Optimal path with minimal cost induced by f**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**图 1\. 由 f 引起的最小成本的最佳路径**'
- en: Usually when people talk about word morphing they mean searching for a path
    between *S* and *E* where there’s an edge only between words such that one can
    be achieved from the other by changing one letter, as can be seen [here](http://wordmorph.sarangconsulting.com/faq.php#1.2).
    In this case, *f*(*n*₁,*n*₂) is 1 when such a change exists, and ∞ otherwise.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，当人们谈论词形变化时，他们指的是在*S*和*E*之间寻找一条路径，其中只有当通过改变一个字母可以从一个单词得到另一个单词时，才存在边，如[这里](http://wordmorph.sarangconsulting.com/faq.php#1.2)所示。在这种情况下，当存在这样的变化时，*f*(*n*₁,*n*₂)为1，否则为∞。
- en: 'In this post I’ll show you how to morph between semantically similar words,
    i.e. *f *will be related to semantics. Here’s an example to illustrate the difference
    between the two approaches: given *S*=*tooth*, *E*=*light*, the approach of changing
    one character at a time [can result](http://wordmorph.sarangconsulting.com/?source=tooth&target=light&submit=MORPH+WORDS) in'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我将展示如何在语义上相似的单词之间进行变形，即*f*将与语义相关。以下是一个示例，说明这两种方法之间的差异：给定*S*=*tooth*，*E*=*light*，一次只改变一个字符的方法[可能结果](http://wordmorph.sarangconsulting.com/?source=tooth&target=light&submit=MORPH+WORDS)为
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: while the semantics approach which will be defined in this post results in
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 而本文将定义的语义方法会导致
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You can find the entire code [here](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/word%20morph/word-morph.ipynb).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[这里](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/word%20morph/word-morph.ipynb)找到完整的代码。
- en: Word Semantics
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 词汇语义
- en: 'In order to capture word semantics we’ll use pre-trained word2vec embeddings
    [1]. To those of you who are not familiar with the algorithm, here’s an excerpt
    from [Wikipedia](https://en.wikipedia.org/wiki/Word2vec):'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了捕捉词汇语义，我们将使用预训练的word2vec嵌入[1]。对于那些不熟悉该算法的人，以下是来自[维基百科](https://en.wikipedia.org/wiki/Word2vec)的摘录：
- en: '*Word2vec takes as its input a large corpus of text and produces a vector space,
    typically of several hundred dimensions, with each unique word in the corpus being
    assigned a corresponding vector in the space. Word vectors are positioned in the
    vector space such that words that share common contexts in the corpus are located
    in close proximity to one another in the space.*'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Word2vec 以大规模文本语料库为输入，生成一个向量空间，通常为数百维，其中语料库中的每个唯一单词都分配了一个相应的向量。词向量在向量空间中被定位，使得在语料库中共享共同上下文的单词在空间中彼此接近。*'
- en: It means every node in the graph can be associated with some vector in high
    dimensionality space (300 in our case). Therefore, we can naturally define a distance
    function between every two nodes. We’ll use cosine similarity, since this is the
    metric usually used when one wants to semantically compare between word embeddings.
    From now on, I’ll overload a node symbol *n* to be its associated word’s embedding
    vector.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着图中的每个节点都可以与高维空间中的某个向量关联（在我们的案例中为300维）。因此，我们可以自然地定义每两个节点之间的距离函数。我们将使用余弦相似度，因为这是通常用于语义比较词嵌入的度量。从现在开始，我将重载节点符号*n*为其相关单词的嵌入向量。
- en: To use the word2vec embeddings, we’ll download Google’s pre-trained embeddings
    from [here](https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download),
    and use gensim package to access them.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用word2vec嵌入，我们将从[这里](https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download)下载Google的预训练嵌入，并使用gensim包来访问它们。
- en: Choosing the Weight Function
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择权重函数
- en: Given the cosine similarity distance function, we can define our *f* function
    to be
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 给定余弦相似度距离函数，我们可以将我们的 *f* 函数定义为
- en: '![](../Images/7e5a1b6ec3fde71bcafae3c9aab28ff2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7e5a1b6ec3fde71bcafae3c9aab28ff2.png)'
- en: '**Eq. 1\. Definition of weight function using cosine similarity**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**公式 1\. 使用余弦相似度定义权重函数**'
- en: 'However, using this approach we’ll face a problem: the best path might include
    edges with high weight, which will result in successive words that aren’t semantically
    similar.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用这种方法我们会面临一个问题：最佳路径可能包括权重较高的边，这将导致相邻词语在语义上不相似。
- en: To tackle this, we can change *f* to be
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，我们可以将 *f* 修改为
- en: '![](../Images/622a2118ff10d8ce666ebffe4d32857d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/622a2118ff10d8ce666ebffe4d32857d.png)'
- en: '**Eq. 2\. Definition of weight function using cosine similarity limited to
    nearest neighbors**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**公式 2\. 使用限制为最近邻的余弦相似度定义权重函数**'
- en: where *neighbors*(*n*₁) denotes the nearest nodes in the graph to *n*₁ in terms
    of cosine similarity. The number of neighbors is configurable.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *neighbors*(*n*₁) 表示图中与 *n*₁ 在余弦相似度方面最接近的节点。邻居的数量是可配置的。
- en: A* Search
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: A* 搜索
- en: Now that we have our graph defined, we’ll use a well known search algorithm
    called A* [2].
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了图，我们将使用一个叫做 A* 的著名搜索算法[2]。
- en: In this algorithm, every node has a cost composed of two terms - *g*(*n*)+*h*(*n*).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个算法中，每个节点的成本由两个部分组成——*g*(*n*)+*h*(*n*)。
- en: '*g*(*n*) is the cost of the shortest path from *S* to *n*, and *h*(*n*) is
    a heuristic estimating the cost of the shortest path from *n* to *E*. In our case,
    the heuristic function will be *f*.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '*g*(*n*) 是从 *S* 到 *n* 的最短路径成本，而 *h*(*n*) 是一个启发式函数，用于估计从 *n* 到 *E* 的最短路径成本。在我们的例子中，启发式函数将是
    *f*。'
- en: The search algorithm maintains a data structure called *the open set*. Initially
    this set contains *S*, and at each iteration of the algorithm we pop out the node
    in the open set with the minimal cost *g*(*n*)+*h*(*n*), and add its neighbors
    to the open set. The algorithm stops when the node with the minimal cost is *E*.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索算法维护一个叫做 *开放集* 的数据结构。最初这个集合包含 *S*，在算法的每次迭代中，我们弹出开放集中成本最小的节点 *g*(*n*)+*h*(*n*)，并将其邻居添加到开放集中。算法在成本最小的节点为
    *E* 时停止。
- en: This algorithm works with whatever heuristic function we choose. But in order
    to actually find the optimal path, the heuristic function must be admissible,
    meaning it can’t overestimate the true cost. Unfortunately, *f* is not admissible.
    However, we’ll use the [observation](https://en.wikipedia.org/wiki/Cosine_similarity#Properties) that
    if the vectors have length 1, then the cosine similarity can be obtained using
    a monotonic transformation over the euclidean distance. It means the two are interchangeable
    in terms of ranking words by similarity. The euclidean distance is admissible
    (you can prove it using the [triangle inequality](https://en.wikipedia.org/wiki/Triangle_inequality)),
    so we can use that instead, by defining
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个算法可以与我们选择的任何启发式函数一起使用。但为了实际找到最佳路径，启发式函数必须是可接纳的，意味着它不能高估真实成本。不幸的是，*f* 不是可接纳的。然而，我们将使用[观察](https://en.wikipedia.org/wiki/Cosine_similarity#Properties)，即如果向量的长度为1，那么余弦相似度可以通过对欧几里得距离进行单调变换来获得。这意味着在按相似度对词进行排序时，两者是可以互换的。欧几里得距离是可接纳的（你可以通过[三角不等式](https://en.wikipedia.org/wiki/Triangle_inequality)证明），所以我们可以使用它来代替，定义为
- en: '![](../Images/68bdd4f48324c0afc88eb1f153e958a4.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/68bdd4f48324c0afc88eb1f153e958a4.png)'
- en: '**Eq. 3\. Definition of weight function using euclidean distance**'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**公式 3\. 使用欧几里得距离定义权重函数**'
- en: So to sum up, we’ll normalize the word embeddings, use the euclidean distance
    as a mean to find semantically similar words, and the same euclidean distance
    to direct A* search process in order to find the optimal path.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们将对词嵌入进行归一化，使用欧几里得距离作为找到语义上相似词的手段，并用相同的欧几里得距离来指导 A* 搜索过程，以找到最佳路径。
- en: 'I chose *neighbors*(*n*) to include its 1000 nearest nodes. However, in order
    to make the search more efficient, we can dilute these using dilute_factor of
    10: we pick the nearest neighbor, the 10''th nearest neighbor, the 20''th, and
    so on - until we have 100 nodes. The intuition behind it is that the best path
    from some intermediate node to *E* might pass through its nearest neighbor. If
    it doesn''t, it might be the case that it won''t pass through the second neighbor
    neither, since the first and second neighbors might be almost the same. So to
    save some computations, we just skip some of the nearest neighbors.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我选择了*邻居*（*n*）来包含其1000个最近的节点。然而，为了使搜索更高效，我们可以使用稀释因子为10对这些节点进行稀释：我们选择最近的邻居，第10近邻，第20近邻，以此类推——直到我们得到100个节点。这样做的直觉是，从某个中间节点到*E*的最佳路径可能会经过其最近的邻居。如果没有，可能是因为它也不会经过第二个邻居，因为第一个和第二个邻居可能几乎是相同的。因此，为了节省计算，我们只是跳过了一些最近的邻居。
- en: 'And here comes the fun part:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在进入有趣的部分：
- en: 'The results:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 结果：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Final thoughts
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 最后思考
- en: Implementing the word morphing project was fun, but not as fun as playing around
    and trying this tool on whatever pair of words I could have thought of. I encourage
    you to go ahead and [play with it](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/word%20morph/word-morph.ipynb) yourself.
    Let me know in the comments what interesting and surprising morphings you have
    found :)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 实施词形变化项目很有趣，但不如玩这个工具并尝试任何我能想到的单词对有趣。我鼓励你自己去[尝试一下](https://github.com/yoel-zeldes/yoel-zeldes.github.io/blob/source/content/word%20morph/word-morph.ipynb)。在评论中告诉我你发现了哪些有趣和惊人的词形变化:)
- en: '*This post was originally posted at *[*www.anotherdatum.com*](http://www.anotherdatum.com/)*.*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文最初发布于*[*www.anotherdatum.com*](http://www.anotherdatum.com/)*。*'
- en: References
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] [https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] [https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality)'
- en: '[2] [https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/astarNilsson.pdf](https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/astarNilsson.pdf)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[2] [https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/astarNilsson.pdf](https://www.cs.auckland.ac.nz/courses/compsci709s2c/resources/Mike.d/astarNilsson.pdf)'
- en: '**Bio**: [Yoel Zeldes](https://medium.com/@yoelzeldes) is a Algorithms Engineer
    at Taboola and is also a Machine Learning enthusiast, who especially enjoys the
    insights of Deep Learning.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**： [Yoel Zeldes](https://medium.com/@yoelzeldes) 是 Taboola 的算法工程师，同时也是一位机器学习爱好者，特别喜欢深度学习的见解。'
- en: '[Original](https://towardsdatascience.com/word-morphing-9f87ee577775). Reposted
    with permission.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://towardsdatascience.com/word-morphing-9f87ee577775)。已获得许可转载。'
- en: '**Resources:**'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[on-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[Sorry I didn’t get that! How to understand what your users want](https://www.kdnuggets.com/2018/11/sorry-understand-what-users-want.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[抱歉，我没明白！如何理解用户的需求](https://www.kdnuggets.com/2018/11/sorry-understand-what-users-want.html)'
- en: '[Multi-Class Text Classification with Doc2Vec & Logistic Regression](https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多类别文本分类与 Doc2Vec 和逻辑回归](https://www.kdnuggets.com/2018/11/multi-class-text-classification-doc2vec-logistic-regression.html)'
- en: '[10 Free Must-See Courses for Machine Learning and Data Science](https://www.kdnuggets.com/2018/11/10-free-must-see-courses-machine-learning-data-science.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10 个免费必看机器学习和数据科学课程](https://www.kdnuggets.com/2018/11/10-free-must-see-courses-machine-learning-data-science.html)'
- en: '* * *'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前3名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的 IT 工作'
- en: '* * *'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Automate Microsoft Excel and Word Using Python](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
- en: '[The Ultimate Guide To Different Word Embedding Techniques In NLP](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理中的不同词嵌入技术终极指南](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
