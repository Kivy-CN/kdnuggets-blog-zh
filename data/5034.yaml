- en: Deep Residual Networks for Image Classification with Python + NumPy
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Python + NumPy进行的图像分类深度残差网络
- en: 原文：[https://www.kdnuggets.com/2016/07/deep-residual-neworks-image-classification-python-numpy.html](https://www.kdnuggets.com/2016/07/deep-residual-neworks-image-classification-python-numpy.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2016/07/deep-residual-neworks-image-classification-python-numpy.html](https://www.kdnuggets.com/2016/07/deep-residual-neworks-image-classification-python-numpy.html)
- en: '**By Daniele Ciriello, Independent Machine Learning Researcher**.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者：Daniele Ciriello，独立机器学习研究员**'
- en: Overview
  id: totrans-3
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 概述
- en: I wanted to implement [“Deep Residual Learning for Image Recognition”](https://arxiv.org/abs/1512.03385) from
    scratch with Python for [my master’s thesis in computer engineering](http://www.slideshare.net/DanieleCiriello1/reti-neurali-di-convoluzione-per-la-visione-artificiale),
    I ended up implementing a [simple (CPU-only) deep learning framework](https://github.com/dnlcrl/PyFunt/) along
    with the [residual model](https://github.com/dnlcrl/deep-residual-networks-pyfunt),
    and trained it on [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), [MNIST](http://yann.lecun.com/exdb/mnist/) and [SFDDD](https://www.kaggle.com/c/state-farm-distracted-driver-detection). [Results](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs)
    speak by themselves.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望用Python从头实现 [“深度残差学习用于图像识别”](https://arxiv.org/abs/1512.03385) 以用于 [我的计算机工程硕士论文](http://www.slideshare.net/DanieleCiriello1/reti-neurali-di-convoluzione-per-la-visione-artificiale)，最后我实现了一个 [简单（仅限CPU）的深度学习框架](https://github.com/dnlcrl/PyFunt/) 以及 [残差模型](https://github.com/dnlcrl/deep-residual-networks-pyfunt)，并在 [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)、 [MNIST](http://yann.lecun.com/exdb/mnist/) 和 [SFDDD](https://www.kaggle.com/c/state-farm-distracted-driver-detection)上进行了训练。 [结果](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs)不言自明。
- en: Convolutional Neural Networks for Computer Vision
  id: totrans-5
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机视觉中的卷积神经网络
- en: On Monday, June 13rd, I graduated with a master’s degree in computer engineering,
    presenting a thesis on deep convolutional neural networks for computer vision.
    For now it is available only in Italian, I am working on the english translation
    but don’t know if and when I’ll got the time to finish it, so I try to describe
    in brief each chapter.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在6月13日星期一，我获得了计算机工程硕士学位，并展示了一篇关于计算机视觉中深度卷积神经网络的论文。目前只有意大利语版，我正在进行英文翻译，但不知道是否以及何时能完成，所以我尝试简要描述每一章。
- en: 'The document is composed as follows:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 文档组成如下：
- en: '**Introduction**'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍**'
- en: An introduction of the topic, the description of the thesis’ structure and a
    rapid description of the neural networks history from perceptrons to NeoCognitron.
  id: totrans-9
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主题介绍、论文结构描述以及从感知机到NeoCognitron的神经网络历史的快速描述。
- en: '**Neural Networks fundamentals**'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**神经网络基础**'
- en: A description of the fundamental mathematical concepts behind deep learning.
  id: totrans-11
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习背后的基本数学概念描述。
- en: '**State of the Art**'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前沿技术**'
- en: A description of the main concepts that permitted the goals achieved in the
    last decade, an introduction of image classification and object localization problems,
    ILSVRC and the models that obtained best results from 2012 to 2015 in both the
    tasks.
  id: totrans-13
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 描述了过去十年中实现目标的主要概念，引入了图像分类和对象定位问题，ILSVRC以及从2012到2015年在这两项任务中获得最佳结果的模型。
- en: '**Implementing a Deep Learning Framework**'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实现深度学习框架**'
- en: This chapter contains an explanation on how to implement both forward and backward
    steps for each one of the layers used by the residual model, the residual model’s
    implementation and some method to test a network before training.
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本章包含了如何实现残差模型中每一层的前向和后向步骤的解释、残差模型的实现以及在训练前测试网络的一些方法。
- en: '**Experimental Results**'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验结果**'
- en: After developed the model and a solver to train it, I conducted several experiments
    with the residual model on CIFAR-10, in this chapter I show how I tested the model
    and how the behavior of the network changes when one removes the residual paths,
    applies data-augmenting functions to reduce overfitting or increases the number
    of the layers, then I show how to foil a trained network using random generated
    images or images from the dataset.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在开发了模型和训练求解器之后，我在CIFAR-10上进行了几个实验。在本章中，我展示了如何测试模型以及当去除残差路径、应用数据增强函数以减少过拟合或增加层数时，网络的行为如何变化，然后我展示了如何使用随机生成的图像或数据集中的图像来欺骗训练好的网络。
- en: '**Conclusions**'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**结论**'
- en: Here I describe other results obtained training the same model on MNIST and
    SFDDD (check below for more infos), an overview of the project and possible future
    works with it.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我描述了在 MNIST 和 SFDDD 上训练相同模型所获得的其他结果（更多信息请查看下面），项目概述以及可能的未来工作。
- en: 'Thesis links:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 论文链接：
- en: '[Italian](http://www.slideshare.net/DanieleCiriello1/reti-neurali-di-convoluzione-per-la-visione-artificiale)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[意大利语](http://www.slideshare.net/DanieleCiriello1/reti-neurali-di-convoluzione-per-la-visione-artificiale)'
- en: English (WIP)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 英语（进行中）
- en: 'Presentation links:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 演示链接：
- en: '[slides + transcript, Italian](https://www.slideshare.net/DanieleCiriello1/pres-tesi-lm2016transcriptita)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片 + 记录，意大利语](https://www.slideshare.net/DanieleCiriello1/pres-tesi-lm2016transcriptita)'
- en: '[slides + transcript, English](https://www.slideshare.net/DanieleCiriello1/pres-tesi-lm2016transcripteng)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[幻灯片 + 记录，英语](https://www.slideshare.net/DanieleCiriello1/pres-tesi-lm2016transcripteng)'
- en: Below I describe in brief how I got all of that, the sources I used, the structure
    of the residual model I trained and the results I obtained. Please keep in mind
    that my first objective was to develop and train the model so I didn’t spent much
    time on the design aspect of the framework, but I’m working on it (and pull requests
    are welcome)!
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我简要描述了如何获得所有这些内容，我使用的来源，训练的残差模型结构以及获得的结果。请记住，我的首要目标是开发和训练模型，因此我没有花太多时间在框架的设计方面，但我正在继续努力（欢迎提交拉取请求）！
- en: PyFunt, PyDatSet and Deep Residual Networks
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyFunt、PyDatSet 和 深度残差网络
- en: '[Pyfunt](https://github.com/dnlcrl/PyFunt) is a simple pythonic imperative
    deep learning framework: it mainly provides the implementations for the forward
    and backward steps for most notorious neural layers, some useful initialization
    function, and a solver, that is essentially a class that you instantiate and to
    which you pass the model to be trained and the data loaded with [pydatset](https://github.com/dnlcrl/PyDatSet),
    which contains functions to import some dataset and a set of functions to artificially
    augment the training set. Just to clarify, PyFunt and PyDatSet are the names for
    the repos, pyfunt and pydatset are the names for the packages (so you import them
    with `from pydatset import ...`).'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[Pyfunt](https://github.com/dnlcrl/PyFunt) 是一个简单的 Python 风格的命令式深度学习框架：它主要提供了大多数知名神经层的前向和反向步骤的实现，一些有用的初始化函数和一个求解器，它本质上是一个类，你实例化它，并将要训练的模型和使用 [pydatset](https://github.com/dnlcrl/PyDatSet)
    加载的数据传递给它，该数据集包含导入一些数据集的函数和一组人工增强训练集的函数。为了澄清，PyFunt 和 PyDatSet 是这些库的名称，pyfunt
    和 pydatset 是包的名称（因此你可以用`from pydatset import ...`导入它们）。'
- en: The residual model implementation resides in [deep-residual-networks-pyfunt](https://github.com/dnlcrl/deep-residual-networks-pyfunt),
    which also contains the train.py file.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 残差模型的实现位于 [deep-residual-networks-pyfunt](https://github.com/dnlcrl/deep-residual-networks-pyfunt)，其中也包含了
    `train.py` 文件。
- en: The residual model proposed in the reference paper is derived from the VGG model,
    in which convolution filters of 3x3 applied with a step of 1 if the number of
    channels is constant, 2 if the number of features got doubled (this is done to
    preserve the computational complexity on each convolutional layer). So the residual
    model is composed by a cascade of many residual block (or residual layers), which
    are groups of convolutional layers in series where the output of the last layer
    output is added to the original input to the block, authors suggest a couple of
    conv layer for each residual block should work well.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 参考论文中提出的残差模型源于 VGG 模型，其中 3x3 的卷积滤波器应用于通道数保持不变的情况下步长为 1，如果特征数量翻倍则步长为 2（这样做是为了在每个卷积层中保持计算复杂度）。因此，残差模型由多个残差块（或残差层）级联组成，这些块是串联的卷积层组，其中最后一层的输出加到块的原始输入上，作者建议每个残差块中使用几层卷积层会效果很好。
- en: Each residual block is composed where, if dimensionality reduction is applied
    (using a convolution step of 2 instead of 1), downsampling and zero-padding must
    be applied to the input before the addition, in order to permit the sum of the
    two ndarrays (skip_path + conv_out).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 每个残差块的组成是，如果应用了降维（使用 2 的卷积步骤而不是 1），则必须对输入应用下采样和零填充，然后才能进行加法，以允许两个 ndarray（skip_path
    + conv_out）的求和。
- en: A parametric residual network have in total (6*n)+2 layers, composed as below
    (right values represents the dimension of a [3,32,32] sample like CIFAR images).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一个参数化的残差网络总共有（6*n）+2 层，组成如下（右边的值表示类似 CIFAR 图像的 [3,32,32] 样本的尺寸）。
- en: You can see below a sort of package diagram that shows how train.py uses the
    other components to train the residual model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在下面看到一个包图，展示了`train.py`如何使用其他组件来训练残差模型。
- en: '![Package Diagram](../Images/730871585cbfb796dd62009c17a98089.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![包图示](../Images/730871585cbfb796dd62009c17a98089.png)'
- en: After I had every piece I started experimenting what happens when you remove
    the residual paths, when you apply or not data augmenting functions for the training
    set, when increase the number of layers or the number of filters for each layer.
    Below you can find some image of the results but I suggest to give a look at the [respective
    JuPyter notebooks](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs) (in
    addition to thesis and presentation linked above), for a deeper understanding,
    as you can find a more exhaustive description of the results on all datasets I
    show below.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在拥有所有数据后，我开始实验当你移除残差路径时会发生什么，当你应用或不应用数据增强函数时会有什么变化，增加层数或每层滤波器数量时会有什么变化。下面你可以看到一些结果的图像，但我建议你查看[各个JuPyter笔记本](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs)（以及上述链接的论文和演示文稿），以获得更深入的理解，因为你可以在下面显示的所有数据集上找到更详尽的结果描述。
- en: Results
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果
- en: I trained the residual model on [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), [MNIST](http://yann.lecun.com/exdb/mnist/) and [SFDDD](https://www.kaggle.com/c/state-farm-distracted-driver-detection),
    and results are really exciting, at least for me. The networks learn well in nearly
    every test I’ve done, obviously my limit is the capacity of my desktop PC.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我在[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)、[MNIST](http://yann.lecun.com/exdb/mnist/)和[SFDDD](https://www.kaggle.com/c/state-farm-distracted-driver-detection)上训练了残差模型，结果非常令人兴奋，至少对我来说如此。网络在几乎所有测试中表现良好，显然我的限制在于桌面PC的容量。
- en: CIFAR-10
  id: totrans-38
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: CIFAR-10
- en: '![CIFAR-10](../Images/e6598865c0a7ddb5bc8fa5f36fba7a8c.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![CIFAR-10](../Images/e6598865c0a7ddb5bc8fa5f36fba7a8c.png)'
- en: One of the experiments on CIFAR-10 implied training a simple 20 layers resnet,
    applying data-augmenting regularization functions I obtained a similar result
    showed in the reference paper as you can see below.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在CIFAR-10上的一个实验中，训练了一个简单的20层resnet，通过应用数据增强的正则化函数，我得到了与参考论文中显示的类似的结果，如下所示。
- en: '![Results on CIFAR-10](../Images/a4e47363095822dd08d07d3b91ea6ef4.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![CIFAR-10的结果](../Images/a4e47363095822dd08d07d3b91ea6ef4.png)'
- en: '![Results on CIFAR-10 from MSRA](../Images/ef984d86fec0245bee9dc4ce4340095a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![来自MSRA的CIFAR-10结果](../Images/ef984d86fec0245bee9dc4ce4340095a.png)'
- en: The training for this model took approximately 10 hours. more infos are available
    in [this jupyter ipython notebook](https://github.com/dnlcrl/deep-residual-networks-pyfunt/blob/master/docs/CIFAR-10%20Experiments.ipynb) from
    the repo’s docs folder.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型的训练大约花费了10小时。更多信息可以在[这个jupyter ipython notebook](https://github.com/dnlcrl/deep-residual-networks-pyfunt/blob/master/docs/CIFAR-10%20Experiments.ipynb)中找到，位于代码库的文档文件夹中。
- en: MNIST
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: MNIST
- en: '![MNIST](../Images/8d32dd9236d6f830da9ad628386182de.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST](../Images/8d32dd9236d6f830da9ad628386182de.png)'
- en: MNIST is a much simpler dataset in comparison with CIFAR-10, so the training
    times are relatively shorter and I also tried to use the half of the number of
    filters of each conv layers.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 与CIFAR-10相比，MNIST是一个更简单的数据集，因此训练时间相对较短，我还尝试使用每个卷积层的一半滤波器数量。
- en: '![MNIST results](../Images/e0a37e9d58924e90a8a706d73cbe92fc.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST结果](../Images/e0a37e9d58924e90a8a706d73cbe92fc.png)'
- en: More infos for experiments with residual networks on MNIST are available [here](https://github.com/dnlcrl/deep-residual-networks-pyfunt/blob/master/docs/MNIST%20Experiments.ipynb).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 关于MNIST上残差网络的更多实验信息可以在[这里](https://github.com/dnlcrl/deep-residual-networks-pyfunt/blob/master/docs/MNIST%20Experiments.ipynb)找到。
- en: '![MNIST wrong classification from the best model](../Images/e02bb43ee49a269ebe34cf06dde3a77e.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![MNIST最佳模型的错误分类](../Images/e02bb43ee49a269ebe34cf06dde3a77e.png)'
- en: In the image above you can see all the wrongly classified validation samples
    from the 32 layers network, trained for just 30 epochs(!). upper left are the
    ground-truth class, lower left the wrong classification from the net and lower
    right the second classification for confidence.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图像中，你可以看到32层网络错误分类的所有验证样本，训练仅进行了30个epoch(!)。左上角是实际类别，左下角是网络的错误分类，右下角是第二次分类的置信度。
- en: SFDDD
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: SFDDD
- en: '![SFDDD](../Images/62b2f902e28116382a959b85f2e9582c.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![SFDDD](../Images/62b2f902e28116382a959b85f2e9582c.png)'
- en: State Farm Distracted Driver Detection is a dataset from State Farm on [kaggle.com](https://kaggle.com/),
    it contains 640x480 images of drivers in 10 classes of distraction. For this dataset
    I decided to resize all the images to 64x48 and use random cropping of 32x32 for
    training and using the center 32x32 crop for testing. I also tried to directly
    scale all images to 32x32 but results were worse (confirming the fact that scaling
    the images doesn’t help a lot conv nets to learn more general features).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: State Farm Distracted Driver Detection 是来自State Farm的数据集，托管在 [kaggle.com](https://kaggle.com/)，包含了640x480的驾驶员图片，分为10个分心类别。对于这个数据集，我决定将所有图片调整为64x48，并使用32x32的随机裁剪进行训练，使用中心32x32裁剪进行测试。我也尝试了将所有图片直接缩放到32x32，但结果更差（确认了缩放图片并不大有助于卷积网络学习更通用的特征）。
- en: Below you can see the learning curves for two models of respectively 32 and
    44 layers, it looks that both models produce a low error after 80 epochs, but
    the problem here is that for the validation set I used 2k images randomly extracted
    from the training set, so my validation set has a correlation factor which is
    higher than the correlation between the original training set and the validation
    set proposed by State Farm (on which I got an error of circa 3%).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以看到两个分别具有32层和44层的模型的学习曲线，看来两个模型在80个epoch后都产生了较低的误差，但问题在于我用于验证集的是从训练集中随机提取的2k张图片，因此我的验证集的相关因子高于State
    Farm提出的原始训练集和验证集之间的相关性（我在其上获得的误差约为3%）。
- en: '![SFDDD](../Images/a00598f164027ed60aec7c1f638da7c1.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![SFDDD](../Images/a00598f164027ed60aec7c1f638da7c1.png)'
- en: Below you can see the saliency maps for six images for the class “talking on
    phone with right hand”, in where the lighter zones represent the portions of the
    images that most contributed to a correct classification from the network.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 下面你可以看到六张图片的显著性图，类别为“用右手打电话”，其中较亮的区域表示对网络正确分类贡献最大的图像部分。
- en: '![SFDDD](../Images/511f026c6dbc0fc5e84f78812dc9caa3.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![SFDDD](../Images/511f026c6dbc0fc5e84f78812dc9caa3.png)'
- en: Other infos will be available [here](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs) after
    competition ends.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 其他信息将在比赛结束后 [这里](https://github.com/dnlcrl/deep-residual-networks-pyfunt/tree/master/docs) 提供。
- en: Final Words
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结束语
- en: I hope my projects could help you learn something new. If not, maybe *you* can
    teach me something new, comments and pull requests are welcome as always!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望我的项目能够帮助你学到新东西。如果没有，也许 *你* 可以教我一些新东西，评论和拉取请求始终欢迎！
- en: Sources
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 来源
- en: When I started to think I wanted to implement [“Deep Residual Networks for Image
    Recognition”](https://arxiv.org/abs/1512.03385), on GitHub there was only [this
    project](https://github.com/gcr/torch-residual-networks) from [gcr](http://sneakygcr.net/),
    based on Lua + Torch, this code really helped me a lot when I had to implement
    the residual model.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始考虑实现 [“深度残差网络用于图像识别”](https://arxiv.org/abs/1512.03385)时，GitHub上只有 [this
    project](https://github.com/gcr/torch-residual-networks) 来自 [gcr](http://sneakygcr.net/)，基于Lua
    + Torch，这段代码在我实现残差模型时确实帮助了我很多。
- en: '[Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/) by [Michael
    Nielsen](http://michaelnielsen.org/) contains a really well organized exhaustive
    introduction to the subject and a lot of code to help the user understand what
    is going on on each part of the process.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '[神经网络与深度学习](http://neuralnetworksanddeeplearning.com/) 由 [Michael Nielsen](http://michaelnielsen.org/) 编写，包含了对该主题非常全面且组织良好的介绍，以及大量代码以帮助用户理解过程中的各个部分。'
- en: '[colah.github.io](http://colah.github.io/archive.html) by [Christopher Olah](http://colah.github.io/about.html) has
    a lot of very well written posts about deep learning and NNs, for example I found [this
    post about convolution layers](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/) really
    illuminating.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '[colah.github.io](http://colah.github.io/archive.html) 由 [Christopher Olah](http://colah.github.io/about.html) 编写，包含了大量关于深度学习和神经网络的优质文章，例如我发现 [this
    post about convolution layers](http://colah.github.io/posts/2014-07-Conv-Nets-Modular/) 非常有启发性。'
- en: '[Stanford’s CS231N](http://cs231n.github.io/) by [Andrej Karpathy](https://twitter.com/karpathy) et
    Al., a really interesting course about CNN for visual recognition, I mainly used
    the course material and my assignments’ solutions to build[PyFunt](https://github.com/dnlcrl/PyFunt).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '[斯坦福大学的CS231N](http://cs231n.github.io/) 由 [Andrej Karpathy](https://twitter.com/karpathy) 等人编写，是一门关于视觉识别CNN的非常有趣的课程，我主要使用了课程材料和作业解决方案来构建[PyFunt](https://github.com/dnlcrl/PyFunt)。'
- en: '[Arxiv](https://arxiv.org/), a repository of e-prints of scientific papers
    in the fields of mathematics, physics, astronomy, computer science, quantitative
    biology, statistics, and quantitative finance, which can be accessed online. Check
    also [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/) by [Karpathy](https://twitter.com/karpathy).'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[Arxiv](https://arxiv.org/)，一个提供数学、物理、天文学、计算机科学、定量生物学、统计学和定量金融领域科学论文的电子版库，可以在线访问。也可以查看[Arxiv
    Sanity Preserver](http://www.arxiv-sanity.com/)由[Karpathy](https://twitter.com/karpathy)提供。'
- en: Many other awesome resources are listed here: [https://github.com/ChristosChristofidis/awesome-deep-learning](https://dnlcrl.github.io/projects/2016/06/22/awesome-deep-learning).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他精彩的资源列在这里：[https://github.com/ChristosChristofidis/awesome-deep-learning](https://dnlcrl.github.io/projects/2016/06/22/awesome-deep-learning)。
- en: When I started studying deep learning I kept track of the best papers and collected
    titles, authors, years and links in [this google sheet](https://docs.google.com/spreadsheets/d/1DBFylWzALpMpZLLrukHGt29L1tDUsKq4A11sxIbB-Js/edit?usp=sharing),
    which I should update frequently.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始学习深度学习时，我跟踪了最佳论文，并在[this google sheet](https://docs.google.com/spreadsheets/d/1DBFylWzALpMpZLLrukHGt29L1tDUsKq4A11sxIbB-Js/edit?usp=sharing)中收集了标题、作者、年份和链接，我会定期更新。
- en: '**Bio: [Daniele Ciriello](https://twitter.com/dnlcrl)** holds a Master''s Degree
    in Computer Engineering, and is a Deep Learning enthusiast and lover of Python
    and open source.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**简历： [Daniele Ciriello](https://twitter.com/dnlcrl)** 拥有计算机工程硕士学位，是深度学习爱好者，并热爱Python和开源。'
- en: '[Original](https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html).
    Reposted with permission.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html)。已获许可转载。'
- en: '**Related:**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[An Introduction to Scientific Python (and a Bit of the Maths Behind It) –
    NumPy](/2016/06/intro-scientific-python-numpy.html)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[科学Python简介（以及一些相关数学） – NumPy](/2016/06/intro-scientific-python-numpy.html)'
- en: '[Peeking Inside Convolutional Neural Networks](/2016/06/peeking-inside-convolutional-neural-networks.html)'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深入了解卷积神经网络](/2016/06/peeking-inside-convolutional-neural-networks.html)'
- en: '[Learning to Code Neural Networks](/2016/01/learning-to-code-neural-networks.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[学习编写神经网络代码](/2016/01/learning-to-code-neural-networks.html)'
- en: '* * *'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升您的数据分析能力'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持您的组织IT'
- en: '* * *'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用卷积神经网络（CNNs）进行图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Tensorflow训练图像分类模型指南](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
- en: '[Multilabel Classification: An Introduction with Python''s Scikit-Learn](https://www.kdnuggets.com/2023/08/multilabel-classification-introduction-python-scikitlearn.html)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多标签分类：使用Python的Scikit-Learn简介](https://www.kdnuggets.com/2023/08/multilabel-classification-introduction-python-scikitlearn.html)'
- en: '[NumPy for Image Processing](https://www.kdnuggets.com/numpy-for-image-processing)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于图像处理的NumPy](https://www.kdnuggets.com/numpy-for-image-processing)'
- en: '[More Performance Evaluation Metrics for Classification Problems You…](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分类问题的更多性能评估指标](https://www.kdnuggets.com/2020/04/performance-evaluation-metrics-classification.html)'
- en: '[Fine-Tuning BERT for Tweets Classification with HuggingFace](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用HuggingFace对BERT进行微调以进行推文分类](https://www.kdnuggets.com/2022/01/finetuning-bert-tweets-classification-ft-hugging-face.html)'
