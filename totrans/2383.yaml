- en: How to Avoid Overfitting
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何避免过拟合
- en: 原文：[https://www.kdnuggets.com/2022/08/avoid-overfitting.html](https://www.kdnuggets.com/2022/08/avoid-overfitting.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2022/08/avoid-overfitting.html](https://www.kdnuggets.com/2022/08/avoid-overfitting.html)
- en: '![How to Avoid Overfitting?](../Images/569d3cb65a771a94a3c42900ea9615bf.png)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![如何避免过拟合？](../Images/569d3cb65a771a94a3c42900ea9615bf.png)'
- en: Image by Editor
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 编辑器提供的图片
- en: Overfitting is a regular mistake that many Data Scientists make. It can take
    your hours of coding and throw it all in the trash bin. Your model can produce
    inaccurate outputs and lead to further problems in the decision making process.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是许多数据科学家常犯的一个常规错误。它可能会使你数小时的编码工作付诸东流。你的模型可能会产生不准确的输出，并导致决策过程中的进一步问题。
- en: '* * *'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织的IT需求'
- en: '* * *'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Before we get into how to avoid overfitting, let’s go over what overfitting
    it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论如何避免过拟合之前，先来了解一下什么是过拟合。
- en: What is Overfitting?
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是过拟合？
- en: Overfitting is when a statistical model fits exactly against its training data.
    It is a type of modeling error which explains that your functions are too closely
    fit to a limited set of data points. This is due to the model solely focusing
    on variables it knows and automatically assumes that these predictions will work
    on testing or unseen data. This leads to the model failing to predict future observations
    accurately.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合是指统计模型完全贴合其训练数据。这是一种建模错误，表明你的函数过于紧密地贴合有限的数据点。这是因为模型仅专注于它知道的变量，并自动假设这些预测将适用于测试或未见过的数据。这导致模型无法准确预测未来的观察值。
- en: One of the reasons overfitting happens is due to the complexity of the model
    or the dataset. If the model is too complex or the model trains on a sample dataset
    that is very large - the model starts to memorize information on the dataset that
    is irrelevant. When information is memorized, the model fits too closely to the
    training set and is unable to generalize well to new data.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合发生的原因之一是模型或数据集的复杂性。如果模型过于复杂，或者模型在一个非常大的样本数据集上进行训练——模型开始记住数据集中无关的信息。当信息被记住时，模型对训练集的拟合过于紧密，无法很好地对新数据进行泛化。
- en: Although this is good when working with training data as it will produce a low
    error, it becomes very useless when working with testing data as it produces a
    high error. One way to indicate if your model is overfitting is if it has a low
    error rate but a high variance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在处理训练数据时，这种情况会产生低误差，但在处理测试数据时却变得非常无用，因为它会产生高误差。判断你的模型是否过拟合的一种方法是查看其是否具有低误差率但高方差。
- en: What is Underfitting?
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是欠拟合？
- en: The opposite of Overfitting is Underfitting. Underfitting is when a model fails
    to identify the relationship between the input and output variables accurately.
    This can be due to the model being very simple, and can be resolved by adding
    more input features or using high variance models such as Decision Trees.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 过拟合的对立面是欠拟合。欠拟合是指模型无法准确识别输入和输出变量之间的关系。这可能是由于模型过于简单，可以通过增加更多输入特征或使用高方差模型如决策树来解决。
- en: The worst thing about Underfitting is that it can neither model training data
    nor generalize new data - producing a high error rate on both the training set
    and unseen data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 欠拟合最糟糕的地方在于它既不能建模训练数据，也不能对新数据进行泛化——在训练集和未见过的数据上都会产生高误差率。
- en: Signal and Noise
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 信号和噪声
- en: Another aspect we need to understand before we get into how to avoid Overfitting
    is Signal and Noise.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们了解如何避免过拟合之前，我们需要理解信号和噪声。
- en: A Signal is the true underlying pattern that helps the model to learn the data.
    For example, the relationship between age and height in teenagers is a clear relationship.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 信号是帮助模型学习数据的真实潜在模式。例如，青少年年龄与身高之间的关系就是一个明确的关系。
- en: Noise is random and irrelevant data in the dataset. Using the same example for
    Signal, if we sample a school that is well known for majoring in sports - this
    will cause outliers. Naturally there will be a higher population of pupils who
    attend the school due to their physical attributes, such as height in basketball.
    This will cause randomness in your model - showing how Noise interferes with Signal.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声是数据集中随机且无关的数据。以信号的示例来说，如果我们采样一所以体育专业闻名的学校——这将导致离群值。由于身体特征，如篮球的身高，学校的学生人数会更高。这将导致模型中的随机性——显示噪声如何干扰信号。
- en: If you produce an efficient machine learning model that performs well, it will
    be able to distinguish the difference between Signal and Noise.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你产生一个高效的机器学习模型，能够区分信号和噪声，它将表现良好。
- en: Goodness of fit is a statistical term that refers to how closely a model’s predicted
    values match the observed values. When a model learns the noise instead of learning
    the signal, that leads to Overfitting. A model that is too complex or too simple
    raises the possibility of learning Noise.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合优度是一个统计术语，指的是模型预测值与观察值的匹配程度。当模型学习噪声而不是学习信号时，就会导致过拟合。模型过于复杂或过于简单会提高学习噪声的可能性。
- en: Techniques to Prevent Overfitting
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 防止过拟合的技术
- en: Training with more data
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练更多数据
- en: I’m going to start off with the simplest technique you can use. Increasing the
    volume of your data in the training phase will not only improve the accuracy of
    your model but can also reduce Overfitting. This allows for your model to identify
    more signals, learn the patterns and minimize error.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我将从你可以使用的最简单技术开始。在训练阶段增加数据量不仅可以提高模型的准确性，还能减少过拟合。这使得你的模型能够识别更多的信号，学习模式并减少错误。
- en: This will help the model to generalize well to new data as there are more opportunities
    for the model to understand the relationship between input and output variables.
    However, you need to ensure that the additional training data you use is clean
    - if not, you could be doing the reverse and adding more complexity.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这将帮助模型更好地推广到新数据，因为模型有更多机会理解输入与输出变量之间的关系。然而，你需要确保所使用的额外训练数据是干净的——否则，你可能会做反向操作，增加更多复杂性。
- en: Feature Selection
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征选择
- en: The next simplest technique you can use to reduce Overfitting is Feature Selection.
    This is the process of reducing the number of input variables by selecting only
    the relevant features that will ensure your model performs well.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 减少过拟合的下一个简单技术是特征选择。这是通过仅选择相关特征来减少输入变量数量的过程，从而确保你的模型表现良好。
- en: Depending on your task at hand, there are some features that have no relevance
    or correlation to other features. Therefore, these can be removed as it is overwhelming
    your model to learn something it does not need to. In order to figure out which
    features have a direct correlation to your task at hand, you can test the different
    features by training them on individual models.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的任务，有些特征与其他特征没有相关性或关联。因此，这些特征可以被移除，因为它们使你的模型学习不需要的东西。为了找出与任务直接相关的特征，你可以通过在单独的模型上训练不同的特征来测试它们。
- en: Not only will you be improving your models performance, but you will also be
    reducing the computational cost of modeling.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你不仅会提高模型性能，还会减少建模的计算成本。
- en: Data Augmentation
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据增强
- en: Data Augmentation is a set of techniques which artificially increase the amount
    of data by generating new data points from existing data.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一组通过从现有数据生成新数据点来人工增加数据量的技术。
- en: Although adding more clean data is an option, it is also a very expensive option.
    Data Augmentation reduces that cost by making data appear more diverse as the
    sample data look slightly different each time it is processed by the model. Each
    dataset will appear unique to the model - increasing its learning rate and performance.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然增加更多干净数据是一种选择，但这也是一种非常昂贵的选择。数据增强通过使数据看起来更为多样化来降低成本，因为样本数据每次被模型处理时略有不同。每个数据集对模型来说都显得独特——提高了学习速率和性能。
- en: Noise can also be used in this technique to improve the model's stability. Adding
    Noise to the data makes the data more diverse without reducing the quality of
    the data quality. However, the choice of adding Noise should be done carefully
    and in moderation to prevent overfitting.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 噪声也可以在这个技术中使用，以提高模型的稳定性。向数据中添加噪声使数据更加多样化，而不会降低数据质量。然而，添加噪声的选择应该谨慎进行，以防止过拟合。
- en: Early stopping
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提前停止
- en: Measuring the performance of your model during the training phase through each
    iteration is a good technique to prevent overfitting. You can do this by pausing
    the training before the model starts to learn the noise. However, you need to
    take into consideration that when using the ‘Early Stopping’ technique, there
    is the risk of pausing the training process too early - which can lead to underfitting.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练阶段通过每次迭代测量模型性能是一种有效的防止过拟合的技术。你可以通过在模型开始学习噪声之前暂停训练来实现这一点。然而，需要考虑的是，当使用“提前停止”技术时，有暂停训练过程过早的风险——这可能导致欠拟合。
- en: Regularization
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 正则化
- en: Regularization is forcing your model to be simpler to minimize the loss function
    and prevent overfitting or underfitting. It discourages the model from learning
    something that is very complex.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是强制你的模型变得更简单，以最小化损失函数并防止过拟合或欠拟合。它不鼓励模型学习非常复杂的东西。
- en: This technique aims to penalize the coefficient, which is helpful when reducing
    Overfitting as a model that is suffering from Overfitting has a coefficient that
    is generally inflated. If the coefficient inflates, the effect of it is that the
    cost function will increase.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这种技术旨在惩罚系数，这有助于减少过拟合，因为过拟合的模型通常具有膨胀的系数。如果系数膨胀，其效果是成本函数将增加。
- en: Regularization is also a hyperparameter for techniques such as Cross-Validation
    - making the process easier.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化也是像交叉验证这样的技术的一个超参数——使得过程更简单。
- en: Cross Validation
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Cross-Validation is one of the most well known techniques used to measure against
    overfitting. It is used to evaluate how well the results of statistical analysis
    can generalize to unseen data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证是用于衡量过拟合的最知名技术之一。它用于评估统计分析的结果对未见数据的泛化能力。
- en: The process of Cross-Validation is to generate multiple train-test splits from
    your training data - which are used to tune your model. The parameters will then
    undergo Cross-Validation which will select the best parameters and feed this back
    into the model to be retrained. This will improve the overall performance and
    accuracy of the model as well as help the model generalize better to unseen data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的过程是从你的训练数据中生成多个训练-测试拆分——这些拆分用于调整你的模型。然后，参数将经历交叉验证，以选择最佳参数并将其反馈到模型中进行再训练。这将提高模型的整体性能和准确性，并帮助模型更好地泛化到未见数据。
- en: Examples of Cross-Validation techniques are Hold-out, K-folds, Leave-one-out
    and Leave-p-out.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证技术的示例包括 Hold-out、K-folds、Leave-one-out 和 Leave-p-out。
- en: The benefits of Cross-Validation is that it is simple to understand, easy to
    implement, and it generally has a lower bias in comparison to other methods.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证的好处在于它简单易懂，易于实现，并且与其他方法相比，通常具有较低的偏差。
- en: 'If you would like to know more about the most well used Cross-Validation technique
    K-fold, have a read of this article: [Why Use k-fold Cross Validation?](/2022/07/kfold-cross-validation.html)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于最常用的交叉验证技术 K-fold 的信息，可以阅读这篇文章：[为什么使用 k-fold 交叉验证？](/2022/07/kfold-cross-validation.html)
- en: Ensembling
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成
- en: The last technique I will speak about is Ensembling. Ensemble methods create
    multiple models and then combine the predictions produced by these models to improve
    the results. The most popular ensemble methods include boosting and bagging.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我将要讲的最后一种技术是集成。集成方法创建多个模型，然后结合这些模型产生的预测以改善结果。最流行的集成方法包括提升和 Bagging。
- en: Bagging
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Bagging
- en: Bagging is an acronym for ‘Bootstrap Aggregation’ and is an ensemble method
    used to decrease the variance in the prediction model. Bagging aims to reduce
    the chance of overfitting complex models by focusing on the ‘strong learners’
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: Bagging 是“Bootstrap Aggregation”的缩写，是一种用于减少预测模型方差的集成方法。Bagging 旨在通过关注“强学习者”来减少过拟合复杂模型的可能性。
- en: It trains a large number of strong learners in parallel and then combines the
    strong learners together in order to optimize and produce accurate predictions.
    Algorithms that are known for having high variance are decision trees, like classification
    and regression trees (CART)
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 它并行训练大量强学习者，然后将这些强学习者组合在一起，以优化和产生准确的预测。决策树，例如分类和回归树（CART），通常以高方差而闻名。
- en: Boosting
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提升算法
- en: Boosting focuses on converting a ‘weak learner’ to a stronger one by improving
    the predictive flexibility of much simpler models. It decreases  the bias error
    by building and improving simpler models into strong predictive models.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 提升算法专注于通过提高简单模型的预测灵活性，将“弱学习者”转变为更强的学习者。它通过构建和改进简单模型为强预测模型，从而减少偏差错误。
- en: The weak learners are trained in sequence so that they can focus on learning
    from their previous mistakes. Once this is done, the weak learners are all combined
    into a strong learner.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 弱学习者按顺序训练，以便它们能够专注于学习之前的错误。完成这些后，所有的弱学习者将合并成一个强学习者。
- en: 'If you would like to know more about Ensemble Techniques, have a read of this
    article: [When Would Ensemble Techniques be a Good Choice?](/2022/07/would-ensemble-techniques-good-choice.html)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于集成技术的信息，可以阅读这篇文章：[集成技术何时是一个好的选择？](/2022/07/would-ensemble-techniques-good-choice.html)
- en: Conclusion
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'You made it to the end. In this article we have gone through:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经读到了最后。在这篇文章中，我们已经探讨了：
- en: What is Overfitting?
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是过拟合？
- en: What is Underfitting?
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是欠拟合？
- en: Signal and Noise
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信号与噪声
- en: Techniques to prevent Overfitting
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防止过拟合的技术
- en: Stay tuned for more articles that go further into this topic such as The Variance
    Bias Trade-off and more.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 敬请关注更多深入探讨此主题的文章，例如《方差-偏差权衡》等。
- en: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** is a Data Scientist
    and Freelance Technical Writer. She is particularly interested in providing Data
    Science career advice or tutorials and theory based knowledge around Data Science.
    She also wishes to explore the different ways Artificial Intelligence is/can benefit
    the longevity of human life. A keen learner, seeking to broaden her tech knowledge
    and writing skills, whilst helping guide others.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**[Nisha Arya](https://www.linkedin.com/in/nisha-arya-ahmed/)** 是一位数据科学家和自由技术写作人。她特别关注提供数据科学职业建议或教程以及围绕数据科学的理论知识。她还希望探索人工智能在延长人类生命方面的不同方式。作为一个热衷学习者，她寻求拓宽自己的技术知识和写作技能，同时帮助指导他人。'
- en: More On This Topic
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[KDnuggets News, August 24: Implementing DBSCAN in Python • How to…](https://www.kdnuggets.com/2022/n34.html)'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[KDnuggets新闻，8月24日：在Python中实现DBSCAN • 如何……](https://www.kdnuggets.com/2022/n34.html)'
- en: '[Top 5 Reasons Why You Should Avoid a Data Science Career](https://www.kdnuggets.com/2022/04/top-5-reasons-avoid-data-science-career.html)'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免数据科学职业的前5个理由](https://www.kdnuggets.com/2022/04/top-5-reasons-avoid-data-science-career.html)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Crucial Challenges in Conversational AI Development and How to Avoid Them](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[对话式人工智能开发中的3个关键挑战及如何避免](https://www.kdnuggets.com/3-crucial-challenges-in-conversational-ai-development-and-how-to-avoid-them)'
- en: '[5 Common Python Gotchas (And How To Avoid Them)](https://www.kdnuggets.com/5-common-python-gotchas-and-how-to-avoid-them)'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个常见的Python陷阱（以及如何避免它们）](https://www.kdnuggets.com/5-common-python-gotchas-and-how-to-avoid-them)'
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[避免这5个每个AI新手常犯的错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
