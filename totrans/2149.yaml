- en: How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/how-to-finetune-mistral-ai-7b-llm-with-hugging-face-autotrain](https://www.kdnuggets.com/how-to-finetune-mistral-ai-7b-llm-with-hugging-face-autotrain)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain](../Images/b6981736e060f20b69ebe17ff9798b3c.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Editor
  prefs: []
  type: TYPE_NORMAL
- en: With the progress of LLM research worldwide, many models have become more accessible.
    One of the small yet powerful open-source models is [Mistral AI 7B LLM](https://mistral.ai/).
    The model boasts adaptability on many use cases, showing better performance than
    LlaMA 2 13B on all benchmarks, employing a [sliding window attention (SWA)](https://arxiv.org/pdf/1904.10509.pdf)
    mechanism and being easy to deploy.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Mistral 7 B's overall performance benchmark can be seen in the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain](../Images/f03b284e0c26fd081dbae259afb81539.png)'
  prefs: []
  type: TYPE_IMG
- en: Mistral 7B Performance Benchmark ([Jiang *et al.* (2023)](https://arxiv.org/pdf/2310.06825.pdf))
  prefs: []
  type: TYPE_NORMAL
- en: The Mistral 7B model is available in the [HuggingFace](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1)
    as well. With this, we can use the Hugging Face AutoTrain to fine-tune the model
    for our use cases. [Hugging Face’s AutoTrain](https://huggingface.co/docs/autotrain/v0.6.10/index)
    is a no-code platform with Python API that we can use to fine-tune any LLM model
    available in HugginFace easily.
  prefs: []
  type: TYPE_NORMAL
- en: This tutorial will teach us to fine-tune Mistral AI 7B LLM with Hugging Face
    AutoTrain. How does it work? Let’s get into it.
  prefs: []
  type: TYPE_NORMAL
- en: Environment and Dataset Preparation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To fine-tune the LLM with Python API, we need to install the Python package,
    which you can run using the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Also, we would use the Alpaca sample dataset from [HuggingFace](https://huggingface.co/datasets/tatsu-lab/alpaca),
    which required datasets package to acquire and the transformers package to manipulate
    the Hugging Face model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we must format our data for fine-tuning the Mistral 7B model. In general,
    there are two foundational models that Mistral released: [Mistral 7B v0.1](https://docs.mistral.ai/llm/mistral-v0.1)
    and [Mistral 7B Instruct v0.1](https://docs.mistral.ai/llm/mistral-instruct-v0.1).
    The Mistral 7B v0.1 is the base foundation model, and the Mistral 7B Instruct
    v0.1 is a Mistral 7B v0.1 model that has been fine-tuned for conversation and
    question answering.'
  prefs: []
  type: TYPE_NORMAL
- en: We would need a CSV file containing a text column for the fine-tuning with Hugging
    Face AutoTrain. However, we would use a different text format for the base and
    instruction models during the fine-tuning.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s look at the dataset we used for our sample.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The code above would take ten percent samples of the actual data. We would only
    need that much for this tutorial as it would take longer to train for bigger data.
    Our data sample looks like the image below.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain](../Images/4cd0e21304bf8a7f1fbae7882f1ae4e6.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: The dataset already contains the text columns with a format we need to fine-tune
    our LLM model. That’s why we don’t need to perform anything. However, I would
    provide a code if you have another dataset that needs the formatting.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: For the Hugging Face AutoTrain, we would need the data in the CSV format so
    that we would save the data with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Then, move the CSV result into a folder called data. That’s all you need to
    prepare the dataset for fine-tuning Mistral 7B v0.1.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to fine-tune the Mistral 7B Instruct v0.1 for conversation and question
    answering, we need to follow the chat template format provided by Mistral, shown
    in the code block below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: If we use our previous example dataset, we need to reformat the text column.
    We would use only the data without any input for the chat model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Then, we could reformat the data with the following code.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We will end up with a dataset appropriate for fine-tuning the Mistral 7B Instruct
    v0.1 model.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Finetune Mistral AI 7B LLM with Hugging Face AutoTrain](../Images/7b1930b4a2f258cd2001cb658385c2e7.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: With all the preparation set, we can now initiate the AutoTrain to fine-tune
    our Mistral model.
  prefs: []
  type: TYPE_NORMAL
- en: Training and Fine-tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let’s set up the Hugging Face AutoTrain environment to fine-tune the Mistral
    model. First, let’s run the AutoTrain setup using the following command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Next, we would provide the information required for AutoTrain to run. For this
    tutorial, let’s use the Mistral 7B Instruct v0.1.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Then, we would add the Hugging Face information if you want to push your model
    to the repository.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Lastly, we would initiate the model parameter information in the variables below.
    You can change them to see if the result is good.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We can tweak many parameters but will not discuss them in this article. Some
    tips to improve the LLM fine-tuning include using a lower learning rate to maintain
    pre-learned representations and vice versa, avoiding overfitting by adjusting
    the number of epochs, using larger batch size for stability, or adjusting the
    gradient accumulation if you have a memory problem.
  prefs: []
  type: TYPE_NORMAL
- en: When all the information is ready, we will set up the environment to accept
    all the information we have set up previously.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We would use the following command to run the AutoTrain in our notebook.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: If the fine-tuning process succeeds, we will have a new directory of our fine-tuned
    model. We would use this directory to test our newly fine-tuned model.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: With the model and tokenizer ready to use, we would try the model with an input
    example.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '**Output:**'
  prefs: []
  type: TYPE_NORMAL
- en: Give three tips for staying healthy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Eat a balanced diet: Make sure to include plenty of fruits, vegetables, lean
    proteins, and whole grains in your diet. This will help you get the nutrients
    you need to stay healthy and energized.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Exercise regularly: Aim for at least 30 minutes of moderate exercise, such
    as brisk walking or cycling, every day. This will help you maintain a healthy
    weight, reduce your risk of chronic diseases, and improve your overall physical
    and mental health.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Get enough sleep: Aim for 7-9 hours of quality sleep each night. This will
    help you feel more rested and alert during the day, and it will also help you
    maintain a healthy weight and reduce your risk of chronic diseases.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output from the model has been close to the actual output from our training
    data, shown in the image below.
  prefs: []
  type: TYPE_NORMAL
- en: Eat a balanced diet and make sure to include plenty of fruits and vegetables.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Exercise regularly to keep your body active and strong.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get enough sleep and maintain a consistent sleep schedule.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mistral models certainly are powerful for their size, as simple fine-tuning
    has already shown a promising result. Try out your dataset to see if it suits
    your work.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Mistral AI 7B family model is a powerful LLM model that boasts higher performance
    than LLaMA and great adaptability. As the model is available in the Hugging Face,
    we can employ HuggingFace AutoTrain to fine-tune the model. There are two models
    currently available to fine-tune in the Hugging Face; Mistral 7B v0.1 for the
    base foundation model, and the Mistral 7B Instruct v0.1 for conversation and question
    answering. The fine-tuning showed promising results even with a quick training
    process.
  prefs: []
  type: TYPE_NORMAL
- en: '**[](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**[Cornellius Yudha
    Wijaya](https://www.linkedin.com/in/cornellius-yudha-wijaya/)**** is a data science
    assistant manager and data writer. While working full-time at Allianz Indonesia,
    he loves to share Python and data tips via social media and writing media. Cornellius
    writes on a variety of AI and machine learning topics.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Mistral 7B-V0.2: Fine-Tuning Mistral’s New Open-Source LLM with…](https://www.kdnuggets.com/mistral-7b-v02-fine-tuning-mistral-new-open-source-llm-with-hugging-face)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Use Hugging Face AutoTrain to Fine-tune LLMs](https://www.kdnuggets.com/how-to-use-hugging-face-autotrain-to-finetune-llms)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Web LLM: Bring LLM Chatbots to the Browser](https://www.kdnuggets.com/2023/05/webllm-bring-llm-chatbots-browser.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Top 10 Machine Learning Demos: Hugging Face Spaces Edition](https://www.kdnuggets.com/2022/05/top-10-machine-learning-demos-hugging-face-spaces-edition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A community developing a Hugging Face for customer data modeling](https://www.kdnuggets.com/2022/08/objectiv-community-developing-hugging-face-customer-data-modeling.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Build AI Chatbot in 5 Minutes with Hugging Face and Gradio](https://www.kdnuggets.com/2023/06/build-ai-chatbot-5-minutes-hugging-face-gradio.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
