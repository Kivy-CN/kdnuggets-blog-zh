# 使用 TensorFlow 和 Flask RESTful Python API 构建 ConvNet 基于 HTTP 的应用程序完整指南

> 原文：[https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html](https://www.kdnuggets.com/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/05/complete-guide-convnet-tensorflow-flask-restful-python-api.html?page=2#comments)

本教程将引导你完成使用 TensorFlow 创建卷积神经网络 (CNN/ConvNet) 的步骤，并通过允许通过基于 HTTP 的 Flask RESTful API 应用程序进行远程访问来投入生产。

本教程将使用 TensorFlow NN (tf.nn) 模块构建一个 CNN。CNN 模型架构将被创建、训练并在 CIFAR10 数据集上进行测试。为了使模型可以远程访问，将使用 Python 创建一个 Flask Web 应用程序，通过 HTTP 接收上传的图像并返回其分类标签。除了 TensorFlow 外，Windows 上还使用了 Anaconda3 和 CPU 支持。本教程假设你对 CNN 有基本了解，如层、步幅和填充。同时需要了解 Python。

* * *

## 我们的前三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业生涯。

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织 IT

* * *

本教程总结为以下步骤：

1.  通过安装 Python、TensorFlow、PyCharm 和 Flask API 准备环境。

1.  下载并准备 CIFAR-10 数据集。

1.  使用 TensorFlow 构建 CNN 计算图。

1.  训练 CNN。

1.  保存训练好的 CNN 模型。

1.  准备测试数据并恢复训练好的 CNN 模型。

1.  测试训练好的 CNN 模型。

1.  构建 Flask Web 应用程序。

1.  使用 HTML 表单上传图像。

1.  创建辅助 HTML、JavaScript 和 CSS 文件。

1.  基于 HTTP 的远程访问训练模型进行预测。

### 1\. 安装 Python、TensorFlow、PyCharm 和 Flask API

在开始构建项目之前，需要准备环境。Python 是第一个需要安装的工具，因为环境完全依赖于它。如果你已经准备好了环境，可以跳过第一步。

**1.1 Anaconda/Python 安装**

可以安装原生 Python 发行版，但建议使用如 Anaconda 这样的全功能包，因为它会为你完成一些工作。在这个项目中，使用了 Anaconda 3。对于 Windows，可以从 [https://www.anaconda.com/download/#windows](https://www.anaconda.com/download/#windows) 下载可执行文件。安装起来很简单。

为确保 Anaconda3 安装正确，可以如图 1 所示发出 CMD 命令（*where python*）。如果 Anaconda3 安装正确，命令输出中会出现其安装路径。

**图 1**

![](../Images/dc4450e2a17d3d6874da0365e7f3a634.png)

**1.2 TensorFlow 安装**

使用 Anaconda3 安装 Python 后，接下来是安装 TensorFlow (TF)。本教程使用支持 CPU 的 Windows 上的 TF。安装说明可以在此页面找到 [https://www.tensorflow.org/install/install_windows](https://www.tensorflow.org/install/install_windows)。这个 YouTube 视频可能会有帮助 ([https://youtu.be/MsONo20MRVU](https://youtu.be/MsONo20MRVU))。

TF 安装步骤如下：

1) 通过调用以下命令创建 TF 的 conda 环境：

```py
C:> conda create -n tensorflow pip python=3.5

```

这会创建一个空文件夹以保存 TF 安装的虚拟环境（venv）。venv 位于 Anaconda3 安装目录下的此位置（\Anaconda3\envs\tensorflow）。

2) 使用以下命令激活 TensorFlow 安装的 venv：

```py
C:> activate tensorflow

```

上述命令表明我们在 venv 内部，任何库安装都将在其中进行。命令提示符在执行此命令后应更改为 (tensorflow)C:>。进入目录后，我们就准备好安装库了。

3) 激活 venv 后，可以通过发出以下命令安装 Windows TensorFlow 的 CPU-only 版本：

```py
(tensorflow)C:> pip install --ignore-installed --upgrade tensorflow

```

为了测试 TF 是否安装正确，我们可以尝试如图 2 所示导入它。但请记住，在导入 TF 之前，必须激活其 venv。从 CMD 测试时，我们需要发出 **python** 命令以便能够与 Python 交互。由于在导入行中没有出现错误，因此 TF 安装成功。

**图 2**

![](../Images/c844eb00d8602568df89c350f94b4f75.png)

**1.3 PyCharm Python IDE 安装**

对于这个项目，建议使用 Python IDE 而不是在 CMD 中输入命令。本教程使用的 IDE 是 PyCharm。其 Windows 可执行文件可以从此页面下载 [https://www.jetbrains.com/pycharm/download/#section=windows](https://www.jetbrains.com/pycharm/download/#section=windows)。其安装说明相当简单。

下载并安装 PyCharm Python IDE 后，接下来是将其与 TF 连接。这是通过将其 Python 解释器设置为 TF venv 下安装的 Python 来完成的，如图 3 所示。通过打开 IDE 的设置，选择项目解释器为 TF venv 内的 **python.exe** 文件。

**图 3**

![](../Images/f2a8dea501640dc9d2fd5bcafcac3083.png)

**1.4 Flask安装**

最后一个需要安装的工具是Flask RESTful API。这是一个需要使用pip/conda安装器在TF venv中安装的库，使用以下CMD命令：

```py
C:> pip install Flask-API

```

如果尚未安装，NumPy和SciPy应安装在venv中，以便能够读取和处理图像。

通过安装Anaconda（Python）、TensorFlow、PyCharm和Flask，我们准备好开始构建项目。

### 2\. 下载和准备CIFAR-10数据集

CIFAR-10数据集的Python版本可以从此页面[https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)下载。该数据集包含60,000张图像，分为训练数据和测试数据。有五个文件保存训练数据，每个文件包含10,000张图像。这些图像为RGB，大小为32x32x3。训练文件命名为**data_batch_1**、**data_batch_2**等。测试数据保存在一个名为**test_batch**的文件中，包含10,000张图像。还有一个名为**batches.meta**的元数据文件，其中包含数据集类别标签，分别为**飞机**、**汽车**、**鸟**、**猫**、**鹿**、**狗**、**青蛙**、**马**、**船**和**卡车**。

由于数据集中的每个文件都是二进制文件，因此应解码以检索实际的图像数据。因此，创建了一个名为unpickle_patch的函数来执行此任务，定义如下：

```py
def unpickle_patch(file):

    """
    Decoding the binary file.
    :param file:File to decode it data.
    :return:Dictionary of the file holding details including input data and output labels.
    """
    patch_bin_file = open(file, 'rb')#Reading the binary file.
    patch_dict = pickle.load(patch_bin_file, encoding='bytes')#Loading the details of the binary file into a dictionary.
    return patch_dict#Returning the dictionary.

```

该方法接受二进制文件名并返回一个包含该文件详细信息的字典。字典包含文件中所有10,000个样本的数据以及它们的标签。

为了解码整个训练数据，创建了一个名为get_dataset_images的新函数。该函数接受数据集路径，仅对训练数据进行操作。结果，它会过滤此路径下的文件，并仅返回以**data_batch_**开头的文件。测试数据将在构建和训练CNN之后准备。

对于每个训练文件，通过调用unpickle_patch函数进行解码。根据该函数返回的字典，get_dataset_images函数返回图像数据及其类别标签。图像数据从**‘data’**键中获取，其类别标签从**‘labels’**键中获取。

因为图像数据以1D向量形式保存，所以需要将其重塑为3维。这是因为TensorFlow接受这种形状的图像。因此，get_dataset_images函数接受除了每个图像的通道数外，还接受行/列数作为参数。

该函数的实现如下：

```py
def get_dataset_images(dataset_path, im_dim=32, num_channels=3):

    """
    This function accepts the dataset path, reads the data, and returns it after being reshaped to match the requierments of the CNN.
    :param dataset_path:Path of the CIFAR10 dataset binary files.
    :param im_dim:Number of rows and columns in each image. The image is expected to be rectangular.
    :param num_channels:Number of color channels in the image.
    :return:Returns the input data after being reshaped and output labels.
    """
    num_files = 5#Number of training binary files in the CIFAR10 dataset.
    images_per_file = 10000#Number of samples withing each binary file.
    files_names = os.listdir(patches_dir)#Listing the binary files in the dataset path.
    """
    Creating an empty array to hold the entire training data after being reshaped.
    The dataset has 5 binary files holding the data. Each binary file has 10,000 samples. Total number of samples in the dataset is 5*10,000=50,000.
    Each sample has a total of 3,072 pixels. These pixels are reshaped to form a RGB image of shape 32x32x3.
    Finally, the entire dataset has 50,000 samples and each sample of shape 32x32x3 (50,000x32x32x3).
    """
    dataset_array = numpy.zeros(shape=(num_files * images_per_file, im_dim, im_dim, num_channels))
    #Creating an empty array to hold the labels of each input sample. Its size is 50,000 to hold the label of each sample in the dataset.
    dataset_labels = numpy.zeros(shape=(num_files * images_per_file), dtype=numpy.uint8)
    index = 0#Index variable to count number of training binary files being processed.
    for file_name in files_names:
        """
        Because the CIFAR10 directory does not only contain the desired training files and has some  other files, it is required to filter the required files.
        Training files start by 'data_batch_' which is used to test whether the file is for training or not.
        """
        if file_name[0:len(file_name) - 1] == "data_batch_":
            print("Working on : ", file_name)
            """
            Appending the path of the binary files to the name of the current file.
            Then the complete path of the binary file is used to decoded the file and return the actual pixels values.
            """
            data_dict = unpickle_patch(dataset_path+file_name)
            """
            Returning the data using its key 'data' in the dictionary.
            Character b is used before the key to tell it is binary string.
            """
            images_data = data_dict[b"data"]
            #Reshaping all samples in the current binary file to be of 32x32x3 shape.
            images_data_reshaped = numpy.reshape(images_data, newshape=(len(images_data), im_dim, im_dim, num_channels))
            #Appending the data of the current file after being reshaped.
            dataset_array[index * images_per_file:(index + 1) * images_per_file, :, :, :] = images_data_reshaped
            #Appening the labels of the current file.
            dataset_labels[index * images_per_file:(index + 1) * images_per_file] = data_dict[b"labels"]
            index = index + 1#Incrementing the counter of the processed training files by 1 to accept new file.
    return dataset_array, dataset_labels#Returning the training input data and output labels.

```

通过准备训练数据，我们可以使用TF构建和训练CNN模型。

### 3\. 使用TensorFlow构建CNN计算图

CNN的计算图在名为`create_CNN`的函数内创建。它创建了一系列卷积（conv）、ReLU、最大池化、丢弃（dropout）和全连接（FC）层，并返回最后一个全连接层的结果。每层的输出是下一层的输入。这要求相邻层之间的输出和输入大小保持一致。请注意，对于每个卷积、ReLU和最大池化层，有一些参数需要指定，例如每个维度的步幅和填充。

```py
def create_CNN(input_data, num_classes, keep_prop):

    """
    Builds the CNN architecture by stacking conv, relu, pool, dropout, and fully connected layers.
    :param input_data:patch data to be processed.
    :param num_classes:Number of classes in the dataset. It helps determining the number of outputs in the last fully connected layer.
    :param keep_prop:probability of dropping neurons in the dropout layer.
    :return: last fully connected layer.
    """
    #Preparing the first convolution layer.
    filters1, conv_layer1 = create_conv_layer(input_data=input_data, filter_size=5, num_filters=4)
    """
    Applying ReLU activation function over the conv layer output. 
    It returns a new array of the same shape as the input array.
    """
    relu_layer1 = tensorflow.nn.relu(conv_layer1)
    print("Size of relu1 result : ", relu_layer1.shape)
    """
    Max pooling is applied to the ReLU layer result to achieve translation invariance.
    It returns a new array of a different shape from the the input array relative to the strides and kernel size used.
    """
    max_pooling_layer1 = tensorflow.nn.max_pool(value=relu_layer1,
                                                ksize=[1, 2, 2, 1],
                                                strides=[1, 1, 1, 1],
                                                padding="VALID")
    print("Size of maxpool1 result : ", max_pooling_layer1.shape)

    #Similar to the previous conv-relu-pool layers, new layers are just stacked to complete the CNN architecture.
    #Conv layer with 3 filters and each filter is of sisze of 5x5.
    filters2, conv_layer2 = create_conv_layer(input_data=max_pooling_layer1, filter_size=7, num_filters=3)
    relu_layer2 = tensorflow.nn.relu(conv_layer2)
    print("Size of relu2 result : ", relu_layer2.shape)
    max_pooling_layer2 = tensorflow.nn.max_pool(value=relu_layer2,
                                                ksize=[1, 2, 2, 1],
                                                strides=[1, 1, 1, 1],
                                                padding="VALID")
    print("Size of maxpool2 result : ", max_pooling_layer2.shape)

    #Conv layer with 2 filters and a filter sisze of 5x5.
    filters3, conv_layer3 = create_conv_layer(input_data=max_pooling_layer2, filter_size=5, num_filters=2)
    relu_layer3 = tensorflow.nn.relu(conv_layer3)
    print("Size of relu3 result : ", relu_layer3.shape)
    max_pooling_layer3 = tensorflow.nn.max_pool(value=relu_layer3,
                                                ksize=[1, 2, 2, 1],
                                                strides=[1, 1, 1, 1],
                                                padding="VALID")
    print("Size of maxpool3 result : ", max_pooling_layer3.shape)

    #Adding dropout layer before the fully connected layers to avoid overfitting.
    flattened_layer = dropout_flatten_layer(previous_layer=max_pooling_layer3, keep_prop=keep_prop)

    #First fully connected (FC) layer. It accepts the result of the dropout layer after being flattened (1D).
    fc_resultl = fc_layer(flattened_layer=flattened_layer, num_inputs=flattened_layer.get_shape()[1:].num_elements(),
                          num_outputs=200)
    #Second fully connected layer accepting the output of the previous fully connected layer. Number of outputs is equal to the number of dataset classes.
    fc_result2 = fc_layer(flattened_layer=fc_resultl, num_inputs=fc_resultl.get_shape()[1:].num_elements(),
                          num_outputs=num_classes)
    print("Fully connected layer results : ", fc_result2)
    return fc_result2#Returning the result of the last FC layer.

```

由于卷积层在输入数据和所用过滤器集之间应用卷积操作，因此`create_CNN`函数接受输入数据作为输入参数。这样的数据由`get_dataset_images`函数返回。卷积层使用`create_conv_layer`函数创建。`create_conv_layer`函数接受输入数据、过滤器大小和过滤器数量，并返回将输入数据与过滤器集卷积的结果。过滤器集的大小根据输入图像的深度进行设置。`create_conv_layer`定义如下：

```py
def create_conv_layer(input_data, filter_size, num_filters):

    """
    Builds the CNN convolution (conv) layer.
    :param input_data:patch data to be processed.
    :param filter_size:#Number of rows and columns of each filter. It is expected to have a rectangular filter.
    :param num_filters:Number of filters.
    :return:The last fully connected layer of the network.
    """
    """
    Preparing the filters of the conv layer by specifiying its shape. 
    Number of channels in both input image and each filter must match.
    Because number of channels is specified in the shape of the input image as the last value, index of -1 works fine.
    """
    filters = tensorflow.Variable(tensorflow.truncated_normal(shape=(filter_size, filter_size, tensorflow.cast(input_data.shape[-1], dtype=tensorflow.int32), num_filters),
                                                              stddev=0.05))
    print("Size of conv filters bank : ", filters.shape)

    """
    Building the convolution layer by specifying the input data, filters, strides along each of the 4 dimensions, and the padding.
    Padding value of 'VALID' means the some borders of the input image will be lost in the result based on the filter size.
    """
    conv_layer = tensorflow.nn.conv2d(input=input_data,
                                      filter=filters,
                                      strides=[1, 1, 1, 1],
                                      padding="VALID")
    print("Size of conv result : ", conv_layer.shape)
    return filters, conv_layer#Returing the filters and the convolution layer result.

```

另一个参数是丢弃层中保留神经元的概率。它指定丢弃层丢弃了多少神经元。丢弃层通过`dropout_flatten_layer`函数实现，如下所示。该函数返回一个扁平化的数组，该数组将作为全连接层的输入。

```py
def dropout_flatten_layer(previous_layer, keep_prop):

    """
    Applying the dropout layer.
    :param previous_layer: Result of the previous layer to the dropout layer.
    :param keep_prop: Probability of keeping neurons.
    :return: flattened array.
    """
    dropout = tensorflow.nn.dropout(x=previous_layer, keep_prob=keep_prop)
    num_features = dropout.get_shape()[1:].num_elements()
    layer = tensorflow.reshape(previous_layer, shape=(-1, num_features))#Flattening the results.
    return layer

```

由于最后一个FC层应具有等于数据集类别数的输出神经元数量，因此数据集类别数作为另一个输入参数传递给`create_CNN`函数。全连接层使用`fc_layer`函数创建。该函数接受丢弃层的扁平化结果、扁平化结果中的特征数量以及该FC层的输出神经元数量。根据输入和输出的数量，创建一个权重张量，然后将其乘以扁平化层，以获得FC层的返回结果。

```py
def fc_layer(flattened_layer, num_inputs, num_outputs):

    """
    uilds a fully connected (FC) layer.
    :param flattened_layer: Previous layer after being flattened.
    :param num_inputs: Number of inputs in the previous layer.
    :param num_outputs: Number of outputs to be returned in such FC layer.
    :return:
    """
    #Preparing the set of weights for the FC layer. It depends on the number of inputs and number of outputs.
    fc_weights = tensorflow.Variable(tensorflow.truncated_normal(shape=(num_inputs, num_outputs),
                                                              stddev=0.05))
    #Matrix multiplication between the flattened array and the set of weights.
    fc_resultl = tensorflow.matmul(flattened_layer, fc_weights)
    return fc_resultl#Output of the FC layer (result of matrix multiplication).

```

使用TensorBoard可视化后的计算图如图4所示。

**图4**

![](../Images/1788a19cf404695a782df8f482089d1c.png)

### 相关主题

+   [每个数据科学家都应该知道的三个R库（即使你使用Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)

+   [是什么使得Python成为初创公司的理想编程语言](https://www.kdnuggets.com/2021/12/makes-python-ideal-programming-language-startups.html)

+   [停止学习数据科学以寻找目标，并通过寻找目标来…](https://www.kdnuggets.com/2021/12/stop-learning-data-science-find-purpose.html)

+   [一个90亿美元的AI失败，分析](https://www.kdnuggets.com/2021/12/9b-ai-failure-examined.html)

+   [学习数据科学统计学的顶级资源](https://www.kdnuggets.com/2021/12/springboard-top-resources-learn-data-science-statistics.html)

+   [成功数据科学家的5个特征](https://www.kdnuggets.com/2021/12/5-characteristics-successful-data-scientist.html)
