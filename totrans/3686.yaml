- en: 'Baize: An Open-Source Chat Model (But Different?)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html](https://www.kdnuggets.com/2023/04/baize-opensource-chat-model-different.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Baize: An Open-Source Chat Model (But Different?)](../Images/50548f8074b6acba37a44c61cd822558.png)'
  prefs: []
  type: TYPE_IMG
- en: Image by Author
  prefs: []
  type: TYPE_NORMAL
- en: I think it’s safe to say 2023 is the year of [Large Language Models (LLMs)](/2023/03/top-free-courses-large-language-models.html).
    From the widespread adoption of ChatGPT, which is built on the GPT-3 family of
    LLMs, to the release of [GPT-4](/2023/03/gpt4-everything-need-know.html) with
    enhanced reasoning capabilities, it has been a year of milestones in generative
    AI. And we wake up everyday to the release of [new applications](/2023/04/langchain-101-build-gptpowered-applications.html)
    in the NLP space that leverage the ChatGPT’s capabilities to address novel problems.
  prefs: []
  type: TYPE_NORMAL
- en: In this article, we’ll learn about **Baize**, a recently released open-source
    chat model.
  prefs: []
  type: TYPE_NORMAL
- en: What is Baize?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Baize is an open-source chat model. Cool. But why another chat model? **'
  prefs: []
  type: TYPE_NORMAL
- en: Well, in a typical session with a chatbot, you don't have a single question
    that you’re seeking an answer to. Rather, you’ll ask a series of questions that
    the bot answers. This conversation chain continues—until you get your answers
    or an acceptable solution to your problem—in this multi-turn chat.
  prefs: []
  type: TYPE_NORMAL
- en: So if you want to start building your own chat models, such a **multi-turn chat
    corpus** is not super common to come by. Baize aims at facilitating the generation
    of such a corpus using ChatGPT and uses it to fine-tune a LLaMA model. This helps
    you build better chatbots with reduced training time.
  prefs: []
  type: TYPE_NORMAL
- en: '[Project Baize](https://github.com/project-baize) is funded by the McAuley
    lab at UC San Diego, and is the result of collaboration between researchers at
    UC San Diego, Sun Yat-Sen university, and Microsoft Research, Asia.'
  prefs: []
  type: TYPE_NORMAL
- en: Baize is named after the Chinese mythical creature Baize that can understand
    human languages [1]. And understanding human languages is something we’d all like
    chat models to have, yes? The research paper for Baize was first uploaded to arxiv
    on 3rd April, 2023\. The model’s weights and code have all been made available
    on GitHub solely for research purposes. So now is a great time to explore this
    new open-source chat model.
  prefs: []
  type: TYPE_NORMAL
- en: And, yeah, let's learn more about Baize.
  prefs: []
  type: TYPE_NORMAL
- en: How Does Baize Work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The working of Baize can be (almost) summed up in two key points:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate a large corpus of multi-turn chat data by leveraging ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the generated corpus to fine-tune LLaMA
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Baize: An Open-Source Chat Model (But Different?)](../Images/8d6eabc389d5ff21e1ccc6acfb01aa06.png)'
  prefs: []
  type: TYPE_IMG
- en: The Pipeline for Training Baize | [Image source](https://arxiv.org/abs/2304.01196v2)
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection with ChatGPT Self-Chatting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We mentioned that Baize uses ChatGPT to construct the chat corpus. It does so
    using a process called **self-chatting** in which *ChatGPT has a conversation
    with itself*.
  prefs: []
  type: TYPE_NORMAL
- en: A typical chat session requires a human and an AI. The **self-chatting** process
    in the data collection pipeline is designed such that ChatGPT has a conversation
    with itself—to supply both sides of the conversation. For the self-chatting process,
    a template is provided along with the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: The quality of conversations generated by ChatGPT is quite high (we’ve seen
    this more in our social media feeds than in our own ChatGPT sessions). So we get
    a high-quality dialogue corpus.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the data used by Baize:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a **seed** that *sets the topic* for the chat session. It can be a
    question or a phrase that supplies the central idea of the conversation. In the
    training of Baize, questions from StackOverflow and Quora were used as seeds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the training of Baize, ChatGPT (gpt-turbo-3.5) model is used in the self-chatting
    data collection pipeline. The generated corpus has about **115K** dialogues—with
    approximately 55K dialogues coming from each of the above sources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition, data from Stanford Alpaca was also used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Currently three versions of the model: Baize-7B, Baize-13B, and Baize-30B have
    been released. (In Baize-XB, XB denotes X billion parameters.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The seed can also be sampled from a specific domain. Meaning we can run the
    data collection process to construct a domain-specific chat corpus. In this direction,
    the Baize-Healthcare model is available, trained on the publicly available [MedQuAD
    dataset](https://paperswithcode.com/dataset/medquad) to create a corpus of about
    47K dialogues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-Tuning in Low-Resource Settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The next part is the fine-tuning of the LLaMA model on the generated corpus.
    Model Fine-tuning is generally a resource-intensive task. As tuning all the parameters
    of a large language model is infeasible under resource constraints, Baize uses
    [Low-Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685) to fine tune the
    LLaMA model.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, at inference time, there’s a prompt that instructs Baize not to
    indulge in conversations that are unethical and sensitive. This mitigates the
    need for human intervention in moderation.
  prefs: []
  type: TYPE_NORMAL
- en: The [functional app](https://huggingface.co/spaces/project-baize/Baize-7B) fetches
    the LLaMA model and LoRA weights from the HugingFace hub.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and Limitations of Baize
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let’s go over some of the advantages and limitations of Baize.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start by stating some advantages of Baize:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High availability**: You can try out [Baize-7B on HuggingFaces spaces](https://huggingface.co/spaces/project-baize/Baize-7B)
    or [run it locally](https://github.com/project-baize/baize-chatbot#how-to-run-locally).
    Baize is not restricted by the number of API calls and alleviates concerns of
    availability in times of high demand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Built-in moderation support**: The prompts at inference time to stop indulging
    in conversations on sensitive and unethical topics is advantageous as it minimizes
    efforts needed to moderate conversations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chat corpora generation**: As mentioned, Baize can help build large corpora
    of multi-turn conversations. This can be helpful in training chat models at scale.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Accessibility in low-resource settings**: As mentioned in [1], we can run
    Baize on a single GPU machine, which makes it accessible in low-resource settings
    that have limited access to computation resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Domain-specific applications**: By carefully sampling the seed from a specific
    domain, we can have chat bots for domain-specific applications such as healthcare,
    agriculture, finance and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reproducibility and customization**: The code is publicly available and the
    data collection and training pipeline is reproducible. If you want to collect
    data from various specific sources to build a custom corpus, you can modify the
    <code>collection.py</code> script in the project’s codebase.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limitations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like all LLM-powered chat apps, Baize has the following limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inaccurate information**: Just the way ChatGPT’s responses are sometimes
    prone to inaccuracies resulting from outdated training data and contextual nuances,
    Baize’s responses might as well be technically inaccurate at times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Challenge with up-to-date information**: The LLaMA model is not trained on
    recent data. This makes it challenging for tasks that require up-to-date information
    for accurate and helpful response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bias and toxicity**: By changing the inference prompt, the behavior of the
    model to decline engaging in sensitive, unethical conversations can be manipulated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping Up
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: That’s all for today! To explore more about Baize, be sure to try out the demo
    on HuggingFace spaces or run it locally. ChatGPT and GPT-4 have inspired a wide
    range of applications in the NLP space.
  prefs: []
  type: TYPE_NORMAL
- en: With novel OpenAI wrappers hitting the developer space almost everyday, it can
    be overwhelming to keep up with these rapid advancements and releases. At the
    same time, we’re excited to see what the future of generative AI holds.
  prefs: []
  type: TYPE_NORMAL
- en: References and Resources for Further Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[1] C Xu, D Guo, N Duan, J McAuley, [Baize: An Open-Source Model with Parameter-Efficient
    Tuning on Self-Chat Data](https://arxiv.org/abs/2304.01196v2), arXiv, 2023.'
  prefs: []
  type: TYPE_NORMAL
- en: '[2] [Project Baize on GitHub](https://github.com/project-baize/baize-chatbot)'
  prefs: []
  type: TYPE_NORMAL
- en: '[3] [Demo on HuggingFace Spaces](https://huggingface.co/spaces/project-baize/Baize-7B)'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Bala Priya C](https://www.linkedin.com/in/bala-priya/)** is a technical
    writer who enjoys creating long-form content. Her areas of interest include math,
    programming, and data science. She shares her learning with the developer community
    by authoring tutorials, how-to guides, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Meet Gorilla: UC Berkeley and Microsoft’s API-Augmented LLM…](https://www.kdnuggets.com/2023/06/meet-gorilla-uc-berkeley-microsoft-apiaugmented-llm-outperforms-gpt4-chatgpt-claude.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Your Ultimate Guide to Chat GPT and Other Abbreviations](https://www.kdnuggets.com/2023/06/ultimate-guide-chat-gpt-abbreviations.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Building Microservice for Multi-Chat Backends Using Llama and ChatGPT](https://www.kdnuggets.com/building-microservice-for-multichat-backends-using-llama-and-chatgpt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Introducing DataCamps AI-Powered Chat Interface: DataLab](https://www.kdnuggets.com/introducing-datacamps-ai-powered-chat-interface-datalab)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Different Ways to Load Data in Python](https://www.kdnuggets.com/2020/08/5-different-ways-load-data-python.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Ultimate Guide To Different Word Embedding Techniques In NLP](https://www.kdnuggets.com/2021/11/guide-word-embedding-techniques-nlp.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
