- en: 'How our Obsession with Algorithms Broke Computer Vision: And how Synthetic
    Computer Vision can fix it'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2021/10/obsession-algorithms-broke-computer-vision.html](https://www.kdnuggets.com/2021/10/obsession-algorithms-broke-computer-vision.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[comments](#comments)'
  prefs: []
  type: TYPE_NORMAL
- en: '**By [Paul Pop](https://www.linkedin.com/in/paul-pop/), Co-founder and CEO
    at Neurolabs**'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/1e7e56aacfd8b6b1665e1afc882cfe48.png)'
  prefs: []
  type: TYPE_IMG
- en: Synthetic Computer Vision aims to translate what’s in the Virtual world back
    to the Real world. (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: ????️ The Current State of Computer Vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: As of today, there has been over $15B worth of investments in over 1,800 Computer
    Vision startups in the past 8 years, according to [Crunchbase](https://www.crunchbase.com/login?redirect_to=%2Fhub%2Fcomputer-vision-companies).
    More than 20 of these companies are currently valued above $1B and there’s a lot
    more to come according to [Forbes](https://www.forbes.com/sites/robtoews/2021/02/28/a-wave-of-billion-dollar-computer-vision-startups-is-coming/).
  prefs: []
  type: TYPE_NORMAL
- en: Why are these companies valued so greatly? To put it simply, they are teaching
    computers how to see. By doing so, they are automating tasks that have previously
    been accomplished using human sight.
  prefs: []
  type: TYPE_NORMAL
- en: This boom followed a 2012 technology **inflection** point in Computer Vision,
    with the advent of Neural Networks — algorithms that mimic the human brain and
    are trained using colossal amounts of human-labelled data. Since 2012, algorithms
    have steadily improved and have become a match for humans in many visual tasks,
    for example counting objects, [lip reading](https://www.technologyreview.com/2016/11/21/69566/ai-has-beaten-humans-at-lip-reading/) or [cancer
    screening](https://www.nature.com/articles/s41598-019-48995-4).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the 10 years that followed everybody did their part: academia led the way
    with better algorithms; large companies invested in an army of humans who have
    diligently labelled these image datasets. Some of these efforts were even open
    sourced for the benefit of the community, such as [ImageNet](https://www.image-net.org/),
    a 14 million image dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, now as these systems are getting deployed to productions, we
    are hitting a brick wall:'
  prefs: []
  type: TYPE_NORMAL
- en: The labelled **data that we have is unreliable**. A [systematic study from MIT
    researchers](https://venturebeat.com/2021/03/28/mit-study-finds-systematic-labeling-errors-in-popular-ai-benchmark-datasets/) of
    popular ML datasets, found an average error rate of [incorrect labelling of 5.93%](https://l7.curtisnorthcutt.com/label-errors) for
    ImageNet and an average of 3.4% across other datasets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There is **little effort dedicated to solving the data problem**. The intellectual
    efforts of academia are almost entirely focused on algorithm development, ignoring
    the fundamental need for good data — a guesstimate by Andrew Ng puts the ratio
    at [99% algorithm focus vs 1% data](https://www.youtube.com/watch?t=526&v=06-AZXmwHjo&feature=youtu.be).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Computer Vision **algorithms don’t generalise** well from one domain to another
    An algorithm trained to detect cars in the south of France will struggle to detect
    the same car in snowy Norway. Likewise a system trained on specific cameras might
    fail with another camera make and model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: ♟️ Searching for inspiration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Already in 1946 Alan Turing suggested chess as a benchmark for computer capabilities,
    which was since throughly researched receiving a lot of media attention.
  prefs: []
  type: TYPE_NORMAL
- en: A commonly accepted way to measure performance in chess is through the [Elo
    rating system](https://en.wikipedia.org/wiki/Elo_rating_system), which provides
    a valid comparison of player skills. The graph below shows world champions and
    chess game engines. The human performance is hovering around the 2800 rating for
    the past 50 years, which is then suppressed by computers in 2010.
  prefs: []
  type: TYPE_NORMAL
- en: Until the last decade, we humans have designed chess algorithms to play based
    on rules we could design and understand. The Deep Learning revolution allowed
    us to break beyond human understanding, bringing a leap forward — just like it
    has for Computer Vision.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/57cfd50d649de09f6afcb9701341ee18.png)'
  prefs: []
  type: TYPE_IMG
- en: Chess engine and human ELO ratings (Image by author)
  prefs: []
  type: TYPE_NORMAL
- en: As good as the progress of Deep Learning chess game engines was, it has now
    been suppressed by the next level of chess engine: **AlphaZero** from DeepMind.
    What’s more impressive, is that **AlphaZero did not use any human sourced data** to
    achieve this performance. It was built without any knowledge of historical chess
    games, or any human guidance for finding optimal moves. AlphaZero was the teacher
    and the student — it taught itself how to better play the game by competing against
    itself and learning through the process.
  prefs: []
  type: TYPE_NORMAL
- en: AlphaZero won against [Stockfish 8](https://www.notion.so/neurolabs/chess.com/news/view/updated-alphazero-crushes-stockfish-in-new-1-000-game-match),
    best engine at the time, without losing a single game, keeping that edge even
    when Alpha Zero was given [an order of magnitude less time](https://chess24.com/en/read/news/alphazero-really-is-that-good) to
    compute its next move.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the remarkable improvements that AlphaZero, one has to wonder: ***Can
    we translate its success in chess to Computer Vision?***
  prefs: []
  type: TYPE_NORMAL
- en: '???? The new wave: Data-Centric AI'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within the new paradigm of [Data Centric AI](https://www.forbes.com/sites/gilpress/2021/06/16/andrew-ng-launches-a-campaign-for-data-centric-ai/?sh=6d7fce8574f5),
    the goal is not to create better algorithms, but increase performance by changing
    the data itself. Even if we disregard the hurdle of obtaining and labelling image
    datasets in the first place, questions still remain around the quality of the
    data: are we uniformly covering all possible use cases? is the data covering edge
    cases?'
  prefs: []
  type: TYPE_NORMAL
- en: If we are to follow the path of Data-Centric Computer Vision, one must be in
    control of the data sourcing process. The data needs to be balanced and we need
    to have a good understanding of the parameters that are influencing what a Computer
    Vision model learns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a simple example in which we look at controlling 3 of such parameters:
    camera angle, lighting and occlusions. Can you imagine gathering a real dataset
    in which you have to diligently control the values of only these 3 parameters,
    whilst gathering 1000s of relevant images? With real data, the task is Sisyphean.'
  prefs: []
  type: TYPE_NORMAL
- en: ???? How do we manage data today?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the past 5 years, there we have made tremendous progress in optimising the
    data gathering process and the quality of the data labels. Moreover, we have learned
    to make the most of the datasets, by using a variety of *data augmentation* techniques.
    Given an image in our dataset, we apply mathematical functions to it in order
    to create more variety in our data.
  prefs: []
  type: TYPE_NORMAL
- en: There are now over 400 companies with a total [market value of $1.3T](https://www.grandviewresearch.com/industry-analysis/data-collection-labeling-market) (a
    little over the market value of Facebook, ) catering to the data needs of our
    latest algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: But does the current path lead to a dead end? Are we reaching the limits of
    the algorithms built on top of human sourced datasets? Like in chess, as long
    as we’re using human sourced data as input for our algorithms, we’re bound by
    design not to significantly surpass our own abilities.
  prefs: []
  type: TYPE_NORMAL
- en: '*In chess, the post-Deep Learning breakthrough came once we’ve stopped building
    on suboptimal human data and allowed the machines to build their own data in order
    to optimise what they learn. In computer vision we must do the same, allowing
    the machine to generate the data they need to optimise its own learning.*'
  prefs: []
  type: TYPE_NORMAL
- en: ???? What’s next for Computer Vision?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The truly scalable way of creating training data is through **Virtual Reality
    engines**. In terms of fidelity, the output has [become indistinguishable](https://www.youtube.com/watch?v=S3DEM6XDDTk) from
    the real world, giving full scene control to the user. This allows the user to **generate
    smart data**, that is truly useful for the Computer Vision model to learn. **Synthetic
    Data can become the bedrock needed for the new Data-Centric AI framework**.
  prefs: []
  type: TYPE_NORMAL
- en: We have good reasons to believe that the time for wide adoption of visual Synthetic
    Data is now.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual Reality engines have dedicated components for Synthetic Data generation
    ([NVIDIA IsaacSim](https://developer.nvidia.com/isaac-sim), [Unity Perception](https://github.com/Unity-Technologies/com.unity.perception))
    and the resulting data is not only eye-candy, but also [essential for training
    better](https://www.prnewswire.com/news-releases/survey-of-industry-leaders-shows-synthetic-data-is-essential-to-building-more-capable-ai-models-301377167.html) algorithms.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3D assets are quickly becoming a commodity — newest [iPhone comes with LiDAR](https://www.geoweeknews.com/news/apple-debuts-its-own-api-for-reality-capture-and-3d-object-creation-but-where-s-the-lidar) and
    first generation apps for 3D scans are producing great [results](https://www.linkedin.com/posts/albandenoyel_photogrammetry-objectcapture-3dcapture-activity-6833436374952099840-MPTn).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The Metaverse is coming and is a big deal](https://www.forbes.com/sites/cathyhackl/2020/07/05/the-metaverse-is-coming--its-a-very-big-deal/).
    If a fraction of the [$60B forecasted growth](https://www.marketsandmarkets.com/Market-Reports/augmented-reality-market-82758548.html) comes
    to fruition, we will live in a world where Virtual Reality will become habitual.
    Digital Twins have real applications today: one example from BMW, the [factory
    of the future](https://www.youtube.com/watch?v=6-DaWgg4zF8) and another is Google’s [Supply
    Chain Twin](https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2021/09/14/google-launches-digital-twin-tool-for-logistics-and-manufacturing/amp/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The innovators of the industry have started using Virtual Reality to improve
    Computer Vision algorithms: Tesla [is using virtual worlds](https://www.youtube.com/watch?v=6hkiTejoyms) to
    generate edge cases and novel views for driving scenarios.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ????️‍????️ Synthetic Computer Vision (SCV)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having access to the right tools to build our own data, we can envision a world
    in which Computer Vision algorithms are developed and trained without the tedious
    process of manual data labelling. [Gartner](https://blogs.gartner.com/andrew_white/2021/07/24/by-2024-60-of-the-data-used-for-the-development-of-ai-and-analytics-projects-will-be-synthetically-generated/)
    predicts that Synthetic Data will be more predominant than real data within the
    next 3 years.
  prefs: []
  type: TYPE_NORMAL
- en: '![https://cdn-images-1.medium.com/max/1200/1*MkwOeoFy4iOGgnL4Hg-RLA.png](../Images/6129f79a62e64989a54c925c03652de6.png)'
  prefs: []
  type: TYPE_IMG
- en: Why not go a step further? What about a world in which **humans are not needed
    to label images** for Computer Vision?
  prefs: []
  type: TYPE_NORMAL
- en: ???? The future is bright
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With Synthetic Computer Vision, we build in Virtual Reality and deploy for the
    Real world. The same way that AlphaZero taught itself what’s important in chess,
    we let the algorithms decide what they need to see in order to optimally learn.
  prefs: []
  type: TYPE_NORMAL
- en: In Synthetic Computer Vision (SCV), we train Computer Vision models using Virtual
    Reality engines and deploy the models in the real world.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ????Beyond RGB images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Reality is much more than what the [human eye can see](https://youtu.be/RZdfE_7cde0?t=188).
    The algorithms that we’ve built are mostly focused on what a human can understand
    and label. But it does not have to be like that — we can build algorithms for
    sensors that measure beyond human perception. And we can train these algorithms
    programatically in Virtual Reality, without having doubts over their validity.
  prefs: []
  type: TYPE_NORMAL
- en: ???? Smarter not harder
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Instead of building larger models and using more computational power to solve
    our problems, we can be smart about how we source data from which our algorithms
    learn. Algorithms don't need more of the same data to learn, they need a variety
    of everything.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Mind showed that AlphaZero was only the start of the road as they’ve applied
    the same principles to [Go](https://www.youtube.com/watch?v=WXuK6gekU1Y), [Starcraft](https://www.youtube.com/watch?v=cUTMhmVh1qs)
    and [protein folding](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology).
    Today, we have all the necessary building blocks to build an *AlphaZero for Computer-Vision*,
    a self-learning system that is not limited by **human input** by design. A system
    that is capable of creating and manipulating virtual scenes through which it teaches
    itself how to solve Visual Automation tasks.
  prefs: []
  type: TYPE_NORMAL
- en: ???? The pioneers in Synthetic Data generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The foundation for Synthetic Computer Vision is provided by the **Synthetic
    Data** it is built upon. There are roughly [30 early stage companies](https://drive.google.com/file/d/1xhgmO9U8WZoYFi7tviUDiyLWz-SYvRFe/view)
    operating in the visual Synthetic Data Generation space. Some are focused on a
    specific use case in one vertical, while the majority are operating horizontally
    across multiple verticals.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure](../Images/8b5c9e05b12ba7c47c117849a73279a2.png)'
  prefs: []
  type: TYPE_IMG
- en: Synthetic Data companies grouped by focus (Image by author).
  prefs: []
  type: TYPE_NORMAL
- en: It's 2021 and we are only at the beginning of the road. Keep in mind that Synthetic
    Data is only **one part of the puzzle** that awaits to be solved!
  prefs: []
  type: TYPE_NORMAL
- en: ❓Questions for you, Dear Reader
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s easy to imagine that in 10 years your smartphone will have better capabilities
    than you do for generic visual perception but how are we going to get there?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are (augmented) data labellers here to stay or simply a stepping stone?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will labelling move from 2D to the 3D world, or can we do without this approach
    altogether?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: State-of-the-Art results are achieved using Deep Learning algorithms in Computer
    Vision — can Synthetic Computer Vision enable a new wave of improved algorithms
    which were previously unavailable?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Bio: [Paul Pop](https://www.linkedin.com/in/paul-pop/)** is Co-founder and
    CEO at Neurolabs. Background in Computer Science and AI from the University of
    Edinburgh and have been working in Computer Vision for the past decade. Led the
    team that build the Computer Vision player tracking system used in most European
    football leagues today, whilst at Hudl.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Open Source Datasets for Computer Vision](/2021/08/open-source-datasets-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[An overview of synthetic data types and generation methods](/2021/02/overview-synthetic-data-types-generation-methods.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Teaching AI to Classify Time-series Patterns with Synthetic Data](/2021/10/teaching-ai-classify-time-series-patterns-synthetic-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Data access is severely lacking in most companies, and 71% believe…](https://www.kdnuggets.com/2023/07/mostly-data-access-severely-lacking-synthetic-data-help.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Most Common Data Quality Issues and How to Fix Them](https://www.kdnuggets.com/2022/11/10-common-data-quality-issues-fix.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Community for Synthetic Data is Here and This is Why We Need It](https://www.kdnuggets.com/2022/04/community-synthetic-data-need.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Democratize AI/ML and Data Science with AI-generated Synthetic Data](https://www.kdnuggets.com/2022/11/mostly-ai-democratize-aiml-data-science-aigenerated-synthetic-data.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
