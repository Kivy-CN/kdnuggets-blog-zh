- en: Basic Image Data Analysis Using Python – Part 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html](https://www.kdnuggets.com/2018/09/image-data-analysis-python-p3.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '![Python image analysis fig 1](../Images/83d60005fe08b263cf8c69bbe8998971.png)'
  prefs: []
  type: TYPE_IMG
- en: Previously we’ve seen some of the very basic image analysis operations in Python.
    In this last part of basic image analysis, we’ll go through some of the following
    contents.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following contents is the reflection of my completed academic image processing
    course in the previous term. So, I am not planning on putting anything into production
    sphere. Instead, the aim of this article is to try and realize the fundamentals
    of a few basic image processing techniques. For this reason, I am going to stick
    to using [**SciKit-Image**](https://scikit-image.org/) - [**numpy**](http://www.numpy.org/) mainly
    to perform most of the manipulations, although I will use other libraries now
    and then rather than using most wanted tools like [**OpenCV**](https://opencv.org/) :'
  prefs: []
  type: TYPE_NORMAL
- en: I wanted to complete this series into two section but due to fascinating contents
    and its various outcome, I have to split it into too many part. However, one may
    find whole series into two section only on my homepage, included below.
  prefs: []
  type: TYPE_NORMAL
- en: '**Find the whole series:** [**Part 1**](https://www.kdnuggets.com/2018/07/basic-image-data-analysis-numpy-opencv-p1.html)**,**
    [**Part 2**](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)
    **All source code:** [**GitHub-Image-Processing-Python**](https://github.com/iphton/Image-Processing-in-Python)'
  prefs: []
  type: TYPE_NORMAL
- en: But if you’re not interested to redirect, stick with me here . In the previous
    article, we’ve gone through some of the following basic operations. To keep pace
    with today’s content, continuous reading is highly appreciated.
  prefs: []
  type: TYPE_NORMAL
- en: '[Importing images and observe it’s properties](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#1-bullet)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Splitting the layers](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#2-bullet)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Greyscale](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#3-bullet)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Using Logical Operator on pixel values](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#4-bullet)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Masking using Logical Operator](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-1/#5-bullet)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’m so excited, let’s begin!
  prefs: []
  type: TYPE_NORMAL
- en: Intensity Transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s begin with importing an image.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '![Python image analysis fig 2](../Images/f53b2232b2f9c48c4f39496b7094396b.png)'
  prefs: []
  type: TYPE_IMG
- en: Image Negative
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The intensity transformation function mathematically defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: where r is the pixels of the input image and s is the pixels of the output image.
    T is a transformation function that maps each value of r to each value of s.
  prefs: []
  type: TYPE_NORMAL
- en: Negative transformation, which is the invert of identity transformation. In
    negative transformation, each value of the input image is subtracted from the
    L−1 and mapped onto the output image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this case, the following transition has been done:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: So, each value is subtracted by **255**. So what happens is that the lighter
    pixels become dark and the darker picture becomes light. And it results in image
    negative.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Python image analysis fig 3](../Images/5a34fa6e0801651033e3ff1d87292f9b.png)'
  prefs: []
  type: TYPE_IMG
- en: Log transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The log transformations can be defined by this formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Where s and r are the pixel values of the output and the input image and c is
    a constant. The value 1 is added to each of the pixel value of the input image
    because if there is a pixel intensity of 0 in the image, then **log(0)** is equal
    to infinity. So, 1 is added, to make the minimum value at least 1.
  prefs: []
  type: TYPE_NORMAL
- en: During log transformation, the dark pixels in an image are expanded as compared
    to the higher pixel values. The higher pixel values are kind of compressed in
    log transformation. This result in the following image enhancement.
  prefs: []
  type: TYPE_NORMAL
- en: The value of c in the log transform adjust the kind of enhancement we are looking
    for.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![Python image analysis fig 4](../Images/dd918a573ffe99b82543baa0d954bd8d.png)'
  prefs: []
  type: TYPE_IMG
- en: Gamma Correction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Gamma correction, or often simply gamma, is a nonlinear operation used to encode
    and decode luminance or tristimulus values in video or still image systems. Gamma
    correction is also known as the **Power Law Transform**. First, our image pixel
    intensities must be scaled from the range **0, 255** to **0, 1.0**. From there,
    we obtain our output gamma corrected image by applying the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Where **Vi** is our input image and **G** is our gamma value. The output image,
    **Vo** is then scaled back to the range **0-255**.
  prefs: []
  type: TYPE_NORMAL
- en: A gamma value, **G < 1** is sometimes called an **encoding gamma**, and the
    process of encoding with this compressive power-law nonlinearity is called **gamma
    compression**; Gamma values < 1 will shift the image towards the darker end of
    the spectrum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Conversely, a gamma value **G > 1** is called a **decoding gamma** and the
    application of the expansive power-law nonlinearity is called **gamma expansion**.
    Gamma values > 1 will make the image appear lighter. A gamma value of **G = 1**
    will have no effect on the input image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![Python image analysis fig 5](../Images/866cd402d5d49c45b3d747564db2fca5.png)'
  prefs: []
  type: TYPE_IMG
- en: '**The Reason for Gamma Correction**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The reason we apply gamma correction is that our eyes perceive color and luminance
    differently than the sensors in a digital camera. When a sensor on a digital camera
    picks up twice the amount of photons, the signal is doubled. However, our eyes
    do not work like this. Instead, our eyes perceive double the amount of light as
    only a fraction brighter. Thus, while a digital camera has a linear relationship
    between brightness our eyes have a non-linear relationship. In order to account
    for this relationship, we apply gamma correction.
  prefs: []
  type: TYPE_NORMAL
- en: 'There is some other linear transformation function. Listed below:'
  prefs: []
  type: TYPE_NORMAL
- en: Contrast Stretching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intensity-Level Slicing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bit-Plane Slicing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve discussed briefly in our previous [article](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html) is
    that, when a computer sees an image, it sees an array of pixel values. Now, depending
    on the resolution and size of the image, it will see a 32 x 32 x 3 array of numbers
    where the 3 refers to RGB values or channels. Just to drive home the point, let’s
    say we have a color image in PNG form and its size is 480 x 480\. The representative
    array will be 480 x 480 x 3\. Each of these numbers is given a value from 0 to
    255 which describes the pixel intensity at that point.
  prefs: []
  type: TYPE_NORMAL
- en: Like we mentioned before, the input is a 32 x 32 x 3 array of pixel values.
    Now, the best way to explain a convolution is to imagine a flashlight that is
    shining over the top left of the image. Let’s say that the flashlight shines cover
    a 3 x 3 area. And now, let’s imagine this flashlight sliding across all the areas
    of the input image. In machine learning terms, this flashlight is called a **filter** or [**kernel**](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details) or
    sometimes referred to as **weights** or **mask** and the region that it is shining
    over is called the [**receptive field**](https://en.wikipedia.org/wiki/Receptive_field).
  prefs: []
  type: TYPE_NORMAL
- en: Now, this filter is also an array of numbers where the numbers are called weights
    or parameters. A very important note is that the depth of this filter has to be
    the same as the depth of the input, so the dimensions of this filter are 3 x 3
    x 3.
  prefs: []
  type: TYPE_NORMAL
- en: An image **kernel** or **filter** is a small matrix used to apply effects like
    the ones we might find in Photoshop or Gimp, such as blurring, sharpening, outlining
    or embossing. They’re also used in machine learning for **feature extraction**,
    a technique for determining the most important portions of an image. For more,
    have a look at Gimp’s excellent documentation on using [Image kernel’s](https://docs.gimp.org/en/plug-in-convmatrix.html).
    We can find a list of most common kernels [here](https://en.wikipedia.org/wiki/Kernel_(image_processing)#Details).
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s take the filter to the top left corner. As the filter is sliding,
    or **convolving**, around the input image, it is multiplying the values in the
    filter with the original pixel values of the image (aka computing element-wise
    multiplications). These multiplications are all summed up. So now we have a single
    number. Remember, this number is just representative of when the filter is at
    the top left of the image. Now, we repeat this process for every location on the
    input volume. Next step would be moving the filter to the right by a **stride** or **step** 1
    unit, then right again by **stride** 1, and so on. Every unique location on the
    input volume produces a number. We can also choose stride or the step size 2 or
    more, but we have to care whether it will fit or not on the input image.
  prefs: []
  type: TYPE_NORMAL
- en: '![Python image analysis fig 6](../Images/888bb82ac03be1227141c2fba72b3c81.png)'
  prefs: []
  type: TYPE_IMG
- en: 'After sliding the filter over all the locations, we will find out that, what
    we’re left with is a 30 x 30 x 1 array of numbers, which we call an **activation
    map** or **feature map**. The reason we get a 30 x 30 array is that there are
    900 different locations that a 3 x 3 filter can fit on a 32 x 32 input image.
    These 900 numbers are mapped to a 30 x 30 array. We can calculate the convolved
    image by following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: where N and F represent Input image size and kernel size respectively and S represent
    stride or step size. So, in this case, the output would be
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Let’s say we’ve got a following 3x3 filter, convolving on a 5x5 matrix and according
    to the equation we should get a 3x3 matrix, technically called **activation map** or **feature
    map**.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look somewhat visually,
  prefs: []
  type: TYPE_NORMAL
- en: '![Python image analysis fig 7](../Images/3bc29603afbe93b6c007a8621ee94991.png)'
  prefs: []
  type: TYPE_IMG
- en: Moreover, we practically use more filters instead of one. Then our output volume
    would be 28x28xn (where n is the number of **activation map**).
  prefs: []
  type: TYPE_NORMAL
- en: By using more filters, we are able to preserve the spatial dimensions better.
  prefs: []
  type: TYPE_NORMAL
- en: However, For the pixels on the border of the image matrix, some elements of
    the kernel might stand out of the image matrix and therefore does not have any
    corresponding element from the image matrix. In this case, we can eliminate the
    convolution operation for these positions which end up an output matrix smaller
    than the input or we can apply [**padding**](https://www.quora.com/What-are-the-roles-of-stride-and-padding-in-a-convolutional-neural-network) to
    the input matrix.
  prefs: []
  type: TYPE_NORMAL
- en: Now, I do realize that some of these topics are quite complex and could be made
    in whole posts by themselves. In an effort to remain concise yet retain comprehensiveness,
    I will provide links to resources where the topic is explained in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first apply some custom uniform window to the image. This has the effect
    of burning the image, by averaging each pixel with those nearby:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '![Python image analysis fig 8](../Images/694f2bde257965d4b73bb74db3b180aa.png)'
  prefs: []
  type: TYPE_IMG
- en: Please, check this more [here.](https://iphton.github.io/iphton.github.io/Image-Processing-in-Python-Part-2/#4-bullet)
    I’ve discussed more in depth and played with various types of kernel and showed
    the differences.
  prefs: []
  type: TYPE_NORMAL
- en: '**Bio:** [Mohammed Innat](https://twitter.com/innat_2k14) is currently a fourth
    year undergraduate student majoring in electronics and communication. He is passionate
    about applying his knowledge of machine learning and data science to areas in
    healthcare and crime forecast where better solutions can be engineered in the
    medical sector and security department.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Basic Image Data Analysis Using Numpy and OpenCV – Part 1]("https://www.kdnuggets.com/2018/07/basic-image-data-analysis-numpy-opencv-p1.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Basic Image Processing in Python, Part 2](https://www.kdnuggets.com/2018/07/image-data-analysis-numpy-opencv-p2.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Only Numpy: Implementing GANs and Adam Optimizer using Numpy](https://www.kdnuggets.com/2018/08/only-numpy-implementing-gans-adam-optimizer.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, June 29: 20 Basic Linux Commands for Data Science…](https://www.kdnuggets.com/2022/n26.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[It''s alive! Build your first robots with Python and some cheap,…](https://www.kdnuggets.com/2023/06/manning-build-first-robots-python-cheap-basic-components.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[A Guide to Train an Image Classification Model Using Tensorflow](https://www.kdnuggets.com/2022/12/guide-train-image-classification-model-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How I Did Automatic Image Labeling Using Grounding DINO](https://www.kdnuggets.com/2023/05/automatic-image-labeling-grounding-dino.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to Implement Agentic RAG Using LangChain: Part 1](https://www.kdnuggets.com/how-to-implement-agentic-rag-using-langchain-part-1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[The 8 Basic Statistics Concepts for Data Science](https://www.kdnuggets.com/2020/06/8-basic-statistics-concepts.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
