["```py\nollama run llama3\n```", "```py\nfrom llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\nfrom llama_index.embeddings.huggingface import HuggingFaceEmbedding\nfrom llama_index.llms.ollama import Ollama\n\n# My local documents\ndocuments = SimpleDirectoryReader(\"data\").load_data()\n\n# Embeddings model\nSettings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n\n# Language model\nSettings.llm = Ollama(model=\"llama3\", request_timeout=360.0)\n\n# Create index\nindex = VectorStoreIndex.from_documents(documents)\n\n# Perform RAG query\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"What are the 5 stages of RAG?\")\nprint(response)\n```", "```py\nThe five key stages within RAG are: Loading, Indexing, Storing, Querying, and Evaluation.\n```"]