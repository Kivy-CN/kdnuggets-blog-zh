- en: 'Machine Learning Is Not Like Your Brain Part Two: Perceptrons vs Neurons'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html](https://www.kdnuggets.com/2022/05/machine-learning-like-brain-part-two-perceptrons-neurons.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: While today’s artificial intelligence (AI) is able to do some extraordinary
    things, its functionality has very little to do with the way in which a human
    brain works to achieve the same tasks. AI – and specifically machine learning
    (ML) – works by analyzing massive data sets, looking for patterns and correlations
    without understanding the data it is processing. As a result, an ML system requiring
    thousands of tagged samples is fundamentally different from the mind of a child,
    which can learn from just a few experiences of untagged data.
  prefs: []
  type: TYPE_NORMAL
- en: For today’s AI to overcome such inherent limitations and evolve into its next
    phase (artificial general intelligence), we should examine the differences between
    the brain, which already implements general intelligence and its artificial counterparts.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, this nine-part series examines in progressively greater detail
    the capabilities and limitations of biological neurons and how these relate to
    ML. In Part One, we examined how a neuron’s slowness makes its approach to learning
    through thousands of training samples implausible. In Part Two, we’ll take a look
    at the fundamental algorithm of the perceptron and how it differs from any model
    of a biological neuron which involves spikes.
  prefs: []
  type: TYPE_NORMAL
- en: The perceptron underlying most ML algorithms is fundamentally different from
    any model of a biological neuron. The perceptron has a value calculated as a function
    of the sum of incoming signals via synapses, each of which is the product of the
    synapse weight and the value of the perceptron from which it comes. In contrast,
    the biological neuron accumulates charge over time until a threshold is reached,
    giving it a modicum of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, while the perceptron has an analog value, the neuron simply emits
    spikes. The perceptron has no intrinsic memory, while the neuron does. And while
    many say the perceptron’s value is analogous to the spiking rate of the neuron,
    this analogy breaks down because the perceptron ignores the relative spike timing
    or the phase of an incoming signal and considers only the frequency. As a result,
    the biological neuron can respond differently based on the order of spike arrival,
    while the perceptron cannot.
  prefs: []
  type: TYPE_NORMAL
- en: To provide an illustration, synapses with positive weights contribute to the
    internal charge of a neuron and stimulate it to fire when the accumulated charge
    exceeds a threshold level (defined as 1), while negatively weighted synapses inhibit
    firing. Consider a neuron stimulated by two inputs weighted .5 and -.5\. If the
    input sequence is .5, -.5, .5, -.5, the neuron will never fire because each positive
    input is followed by a negative input which zeros out the accumulated charge.
    If the inputs fire in the sequence of .5, .5, -.5, -.5, the neuron will fire after
    the second positively-weighted spike.
  prefs: []
  type: TYPE_NORMAL
- en: '![Illustrating how a neuron (Out) stimulated with a weight of .25 will accumulate
    charge and fire every 4th input spike of the input neuron (In)](../Images/96855caae85113d6c9ece0f307c799f0.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustrating how a neuron (Out) stimulated with a weight of .25 will accumulate
    charge and fire every 4th input spike of the input neuron (In).![With In1 and
    In2 stimulateing with weights of .5 and -.5 respectively Out will never fire.
    ](../Images/bc42a0211eef87928c13f82171395d9e.png)
  prefs: []
  type: TYPE_NORMAL
- en: With In1 and In2 stimulateing with weights of .5 and -.5 respectively Out will
    never fire.
  prefs: []
  type: TYPE_NORMAL
- en: '![But changing the timing of the incoming spikes lets Out fire. The perceptron
    model doesn’t support this function because it ignores the timing/phase of incoming
    signals.](../Images/9ff4ce6830b2cacd3411df2425e8e0b7.png)'
  prefs: []
  type: TYPE_IMG
- en: But changing the timing of the incoming spikes lets Out fire. The perceptron
    model doesn’t support this function because it ignores the timing/phase of incoming
    signals.
  prefs: []
  type: TYPE_NORMAL
- en: In both cases, the average input frequency is .5 (half the maximum firing rate).
    The perceptron model will give the same output, 0, in either case, because the
    summation of weighted inputs or .5*.5 + .5*-.5 will always equal 0 regardless
    of the input timing. This means that the perceptron model cannot be reliably implemented
    in biological neurons and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: This is such an essential difference between the neural network and the biological
    neuron that I will devote a separate article to exploring it, along with the other
    biological factors which make today’s AI different from the brain’s function at
    a very fundamental level.
  prefs: []
  type: TYPE_NORMAL
- en: The biological neuron models allow for single spikes to have meaning. The overwhelming
    majority of the brain’s neurons spike only rarely, so it is likely that many neurons
    *do* have specific meanings. For example, since you understand what a ball is,
    it is likely that your brain contains a “ball neuron” (or perhaps many) that fires
    if you see a ball or hear the word. In a biological model, that neuron might fire
    only once when a ball is recognized. The perceptron model of firing rates doesn’t
    allow this, however, because the firing rate of a single spike isn’t defined.
  prefs: []
  type: TYPE_NORMAL
- en: In the next article, I’ll discuss how the connections in the brain are not organized
    in the orderly layers of ML, and how this requires some modification to the basic
    perceptron algorithm which may prevent backpropagation from working at all.
  prefs: []
  type: TYPE_NORMAL
- en: '**Next up**: Fundamental Architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Charles Simon](https://futureai.guru/Founder.aspx)** is a nationally recognized
    entrepreneur and software developer, and the CEO of FutureAI. Simon is the author
    of Will the Computers Revolt?: Preparing for the Future of Artificial Intelligence,
    and the developer of Brain Simulator II, an AGI research software platform. For
    more information, [visit here](https://futureai.guru/Founder.aspx).'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part One: Neurons Are Slow,…](https://www.kdnuggets.com/2022/04/machine-learning-like-brain-part-one-neurons-slow-slow-slow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part 5: Biological Neurons…](https://www.kdnuggets.com/2022/07/machine-learning-like-brain-part-5-biological-neurons-cant-summation-inputs.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning is Not Like Your Brain Part Seven: What Neurons…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-seven-neurons-good.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part 3: Fundamental Architecture](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-3-fundamental-architecture.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part 4: The Neuron’s…](https://www.kdnuggets.com/2022/06/machine-learning-like-brain-part-4-neuron-limited-ability-represent-precise-values.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Machine Learning Is Not Like Your Brain Part 6: The Importance of…](https://www.kdnuggets.com/2022/08/machine-learning-like-brain-part-6-importance-precise-synapse-weights-ability-set-quickly.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
