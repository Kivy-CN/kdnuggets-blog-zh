- en: 'Data-Centric AI: The Latest Research You Need to Know'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2022/02/datacentric-ai-latest-research-need-know.html](https://www.kdnuggets.com/2022/02/datacentric-ai-latest-research-need-know.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![Data-Centric AI: The Latest Research You Need to Know](../Images/fed9eb27fdbd33a0cc676a227318abea.png)'
  prefs: []
  type: TYPE_IMG
- en: '[Technology photo created by rawpixel.com - www.freepik.com](https://www.freepik.com/photos/technology)'
  prefs: []
  type: TYPE_NORMAL
- en: While a vast majority of research efforts today are preoccupied solely with
    ML models and algorithms, the data itself tends to be secondary and is treated
    as fixed. This claim is potentially detrimental – there’s a big risk of favoring
    theory over practice as the models are becoming more divorced from the ground
    truth. There’s a need to combat this trend by providing incentive and information
    to researchers and practitioners alike to work with the data instead.
  prefs: []
  type: TYPE_NORMAL
- en: '**Let’s take a closer look**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Two interesting ideas to examine:'
  prefs: []
  type: TYPE_NORMAL
- en: When faced with the problem of model improvement, one should address it not
    by reworking the algorithms, but rather by seeking to improve data quality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When working with the data, one should look at the process as a whole (which
    includes a careful selection of labelers), not just the technical aspect of it
    (for example, aggregation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some useful resources and contests to check out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data-Centric AI Competition](https://https-deeplearning-ai.github.io/data-centric-comp/)
    was organized by Andrew Ng and his team who invited participants from all over
    the globe to improve the contest’s data without touching the algorithm, thereby
    bypassing the common model-centric approach. The dataset consisted of Roman numerals
    that had to be tweaked by applying any number of data-centric techniques – fixing
    incorrect labels, adding own data, data augmentation, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A [paper](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/3b8a614226a953a8cd9526fca6fe9ba5-Abstract-round2.html)
    by Koch et al supported by a [short talk](https://neurips.cc/virtual/2021/poster/29818)
    by Koch focused on how dataset usage patterns differ across different ML subcommunities.
    The main conclusion of this research was that aside from NLP, researchers tend
    to utilize the very same datasets for different tasks. As a result, there’s an
    observed drop in benchmarks representing real-world data science problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[MLCommons Foundation](https://mlcommons.org/en/) is dedicated to accelerating
    ML innovation and has a variety of handy materials and techniques listed on its
    page.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DataPerf](https://dataperf.org/) is an initiative from several universities,
    companies, and respected researchers to create benchmarks for training sets, test
    sets, and a range of data-centric algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of the articles are available on the Proceedings page [here](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021),
    as are [Datasets and Benchmarks](https://neurips.cc/virtual/2021/events/Datasets%20and%20Benchmarks)
    and [the Data-Centric AI Workshop](https://neurips.cc/virtual/2021/workshop/21860)
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '**Data quality**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s extremely important to measure the quality of data sets; however, there’s
    currently no universally agreed-upon method of how to do it. While the accuracy
    of models can be gauged using different metrics, a reliable approach to data evaluation
    is yet to be found. Data-related problems can result in poor performance of the
    model when noisy sets are involved. At the same time, improperly labeled data
    can also lead to a seemingly healthy ML model learning to adopt erroneous and
    even potentially dangerous patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'A number of studies look at various dataset errors – the first step to boosting
    data quality:'
  prefs: []
  type: TYPE_NORMAL
- en: Northcutt, Athalye, and Mueller [studied](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/f2217062e9a397a1dca429e7d70bc6ca-Abstract-round1.html)
    [errors](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/f2217062e9a397a1dca429e7d70bc6ca-Abstract-round1.html)
    in ten of the most commonly used CV, NLP, and audio datasets in order to figure
    out how these mistakes can affect benchmarks. The result of their efforts is [Cleanlab](https://neurips.cc/virtual/2021/poster/22763),
    an open-source solution that helps identify label errors. [Github link](https://github.com/cleanlab/cleanlab)
    is enclosed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A [paper](https://datacentricai.org/papers/57_CameraReady_main.pdf) that formed
    the basis for a [lightning talk](https://neurips.cc/virtual/2021/workshop/21860)
    was introduced by Kang et al. The team proposed *learned observation assertions,*
    a probabilistic technique designed to test ML pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data collection procedures are also worth discussing. The main question is
    again about maintaining high quality and ideally moving towards mainstream software
    engineering in terms of finding universal standards and methodologies. Two interesting
    resources to check out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Technical Debt in AI](https://neurips.cc/virtual/2021/workshop/21860) from
    Google Brain (starts at 5:53).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Excellence for AI Workshop](https://eval.how/dew2020/index.html) that
    ran in conjunction with [REAIS](https://eval.how/reais-2020/) (Rigorous Evaluation
    of AI Systems). Here’s a [summary](https://arxiv.org/ftp/arxiv/papers/2111/2111.10391.pdf)
    of the main points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data collection and labeling**'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another question about data collection is about having enough data variability
    to accurately represent less common real-world occurrences. Some of the offered
    solutions centered around setting data collection parameters by hand (for example,
    weather patterns and number of pedestrians for AV), using learning iterations
    to continuously add unusual cases to the set, and utilizing synthetic data. Among
    them are these research efforts:'
  prefs: []
  type: TYPE_NORMAL
- en: A comprehensive talk about [data collection in the context of AV](https://neurips.cc/virtual/2021/datasets-and-benchmarks/47107#wse-detail-47186)
    by Raquel Urtasun, University of Toronto Professor and Founder of Waabi (from
    minute 57).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A research paper titled [Data Augmentation for Intent Classification](https://datacentricai.org/papers/138_CameraReady_Data_Aug_v5.pdf)
    by Chen and Yin with a corresponding [lightning talk](https://neurips.cc/virtual/2021/workshop/21860).
    The researchers used mixed augmentation techniques to generate pseudo-labeled
    training examples from seed data within the airline and telecommunications industries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A paper by Pavlichenko et al. on [CrowdSpeech](https://openreview.net/forum?id=3_hgF1NAXU7)contributes
    a big dataset to address one of the most common problems in crowdsourcing, audio
    transcription aggregation. The dataset contains transcripted recordings of a well-known
    speech recognition dataset, [LibriSpeech](https://www.openslr.org/12). Interestingly,
    the best aggregation model was initially designed for text summarization but outperformed
    other models, including the task-specific ones. Also, to allow processing of other
    languages, the authors created a pipeline called Vox DIY that replicates a similar
    dataset for virtually any natural language.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The issue of supervised data labeling, inadequate instructions, and training
    of the labelers are also quite interesting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Human-Computer Interaction and Crowdsourcing for Data-Centric AI](https://neurips.cc/virtual/2021/workshop/21860)
    by Michael Bernstein from Stanford (from 1:12) – the researcher talks about both
    “good” and “bad” data from a decade of crowdsourcing research.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data-Centric AI with Programmatic Supervision: [a talk](https://neurips.cc/virtual/2021/workshop/21860)
    by Alex Ratner about data labeling using Snorkel (from 5:38).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Data management is another challenge the AI community is facing. How do we
    manage data sets embedded within complex pipelines when numerous actions and edits
    are required over extended periods? Is there a need for version control and keeping
    a changelog? These two talks focus specifically on data documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Data Cards](https://datacentricai.org/papers/112_CameraReady_Data_Cards.pdf)
    is a template suggested by Pushkarna and Zaldivar of Google Research. The method
    is used to summarize critical information about datasets. A [lightning talk](https://neurips.cc/virtual/2021/workshop/21860)
    is available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[DAG Cards](https://datacentricai.org/papers/43_CameraReady_neurips_data_centric_2021_DAG_CARDS_camera_ready.pdf)
    by Tagliabue et al is one of the latest proposals for flexible pipeline documentation.
    This [lightning talk](https://neurips.cc/virtual/2021/workshop/21860) summarizes
    the logic behind it along with its main advantages.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ethics**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Question of ethics is a highly contentious topic. Among some of the key aspects
    to bare in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Privacy, including but not limited to GDPR guidelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biases – avoiding dataset stereotypes that often negatively affect training
    models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minorities – a lack of dataset diversification with many social groups often
    being underrepresented or excluded altogether.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Little can be done to solve these problems by modifying algorithms; consequently,
    it’s the data-collection and data-labeling processes that need to be refined.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A solid starting point for this is to identify the causes of these problems
    and their frequency. Check our these three talks dedicated to this endeavor:'
  prefs: []
  type: TYPE_NORMAL
- en: A [talk](https://neurips.cc/virtual/2021/poster/22773) by Bao et al supported
    by their research paper titled [It’s COMPASlicated](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/92cc227532d17e56e07902b254dfad10-Abstract-round1.html).
    The authors criticize Risk Assessment Instrument (RAI) data sets used by law enforcement—namely
    COMPAS—that are inherently biased and racist.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A [research paper](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/077e29b11be80ab57e1a2ecabb7da330-Paper-round2.pdf)
    and [talk](https://neurips.cc/virtual/2021/poster/29847) by Peng, Mathur, and
    Narayanan that focuses on the ethically problematic facial recognition data sets
    and the implications of their usage by analyzing 1000 papers that cited these
    sets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data-centric AI workshop paper proposes a new large-scale dataset for learning
    from subjective human opinions on people's ages, [IMDB-WIKI-SbS](https://datacentricai.org/papers/115_CameraReady_NeurIPS_2021_Data_Centric_AI_IMDB_WIKI_SbS-2.pdf),
    which allows designing better recommender and ranking algorithms. It is worth
    admitting that the dataset is balanced w.r.t. age and gender groups, and it is
    currently difficult for the machine learning models to handle photos in all the
    groups equally well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the ethical problems are apparent, the solutions are not. One of the few
    research examples that attempt to make amends to an existing data set is [Feminist
    Curation of Text for Data-Centric AI](https://datacentricai.org/papers/79_CameraReady_DCAI_Workshop_NeurIPS_2021_final.pdf)
    by Bartl and Leavy. Bartl’s [lightning talk](https://neurips.cc/virtual/2021/workshop/21860)
    outlines how the researchers leveraged feminist linguistics for the asssessment
    and mitigation of gender biases in text data sets and language models.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, a useful paper worth checking out is titled [The Disagreement Deconvolution](http://www.kayur.org/papers/chi2021.pdf).
    This paper co-authored by Bernstein focuses on how majority voting in aggregation
    can sometimes lead to poor results as showcased by the ROC-AUC metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '**[Alexey Umnov](https://www.linkedin.com/in/alexey-umnov-710b72222/)** is
    a Machine Learning Consultant at Toloka and PhD.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[KDnuggets News, April 13: Python Libraries Data Scientists Should…](https://www.kdnuggets.com/2022/n15.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Naïve Bayes Algorithm: Everything You Need to Know](https://www.kdnuggets.com/2020/06/naive-bayes-algorithm-everything.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Minimum: 10 Essential Skills You Need to Know to Start…](https://www.kdnuggets.com/2020/10/data-science-minimum-10-essential-skills.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Want to Use Your Data Skills to Solve Global Problems? Here’s What…](https://www.kdnuggets.com/2022/04/jhu-want-data-skills-solve-global-problems.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Everything You Need to Know About Tensors](https://www.kdnuggets.com/2022/05/everything-need-know-tensors.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6 Things You Need To Know About Data Management And Why It Matters…](https://www.kdnuggets.com/2022/05/6-things-need-know-data-management-matters-computer-vision.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
