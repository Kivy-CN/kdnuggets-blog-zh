["```py\nEXEC Insert_StagingCrime \n```", "```py\nBULK INSERT Staging_Crime \nFROM 'C:\\Projects\\Crime Prediction\\Data\\Baltimore Incident Data.csv'\nWITH (FIRSTROW = 2, FORMATFILE = 'C:\\Projects\\Crime Prediction\\Data\\FormatFile.fmt') \n```", "```py\nSELECT TOP 10 *\nFROM [dbo].[Staging_Crime] \n```", "```py\nEXEC Insert_Crime \n```", "```py\nEXEC Update_CrimeCoordinates \n```", "```py\nSELECT TOP 10 c.CrimeId, gs.*\nFROM [dbo].[Crime] c\nJOIN GridSmall gs\n    ON gs.GridSmallId = c.GridSmallId \n```", "```py\nEXEC Insert_CrimeGrid \n```", "```py\n# Load required libraries\nlibrary(RODBC)\nlibrary(xgboost)\nlibrary(ROCR)\nlibrary(caret) \n```", "```py\nLoading required package: gplots\n\nAttaching package: 'gplots'\n\nThe following object is masked from 'package:stats':\n\n    lowess\n\nLoading required package: lattice\nLoading required package: ggplot2\nRegistered S3 methods overwritten by 'ggplot2':\n  method         from \n  [.quosures     rlang\n  c.quosures     rlang\n  print.quosures rlang \n```", "```py\n# Set seed\nset.seed(1001)\n\n# Read in data\ndbhandle <- odbcDriverConnect('driver={SQL Server};server=DESKTOP-VLN71V7\\\\SQLEXPRESS;database=crime;trusted_connection=true')\n\ntrain <- sqlQuery(dbhandle, 'select IncidentOccurred as target, GridSmallId, GridLargeId, DayOfWeek, MonthOfYear, DayOfYear, Year, PriorIncident1Day, PriorIncident2Days, PriorIncident3Days, PriorIncident7Days, PriorIncident14Days, PriorIncident30Days, PriorIncident1Day_Large, PriorIncident2Days_Large, PriorIncident3Days_Large, PriorIncident7Days_Large, PriorIncident14Days_Large, PriorIncident30Days_Large from crimegrid where crimedate <= \\'2/20/2017\\' and crimedate >= \\'6/1/2012\\'')\ntest <- sqlQuery(dbhandle, 'select IncidentOccurred as target, GridSmallId, GridLargeId, DayOfWeek, MonthOfYear, DayOfYear, Year, PriorIncident1Day, PriorIncident2Days, PriorIncident3Days, PriorIncident7Days, PriorIncident14Days, PriorIncident30Days, PriorIncident1Day_Large, PriorIncident2Days_Large, PriorIncident3Days_Large, PriorIncident7Days_Large, PriorIncident14Days_Large, PriorIncident30Days_Large from crimegrid where crimedate >= \\'2/21/2017\\' and crimedate <= \\'2/27/2017\\'')\n\n# Convert integers to numeric for DMatrix\ntrain[] <- lapply(train, as.numeric)\ntest[] <- lapply(test, as.numeric)\n\nhead(train) \n```", "```py\n# Get feature names (all but first column which is the target)\nfeature.names <- names(train)[2:ncol(train)]\n\nprint(feature.names)\n\n# Make train and test matrices\ndtrain <- xgb.DMatrix(data.matrix(train[,feature.names]), label=train$target)\ndtest <- xgb.DMatrix(data.matrix(test[,feature.names]), label=test$target) \n```", "```py\n [1] \"GridSmallId\"               \"GridLargeId\"              \n [3] \"DayOfWeek\"                 \"MonthOfYear\"              \n [5] \"DayOfYear\"                 \"Year\"                     \n [7] \"PriorIncident1Day\"         \"PriorIncident2Days\"       \n [9] \"PriorIncident3Days\"        \"PriorIncident7Days\"       \n[11] \"PriorIncident14Days\"       \"PriorIncident30Days\"      \n[13] \"PriorIncident1Day_Large\"   \"PriorIncident2Days_Large\" \n[15] \"PriorIncident3Days_Large\"  \"PriorIncident7Days_Large\" \n[17] \"PriorIncident14Days_Large\" \"PriorIncident30Days_Large\" \n```", "```py\n# Training parameters\nwatchlist <- list(eval = dtest, train = dtrain)\n\nparam <- list(  objective           = \"binary:logistic\", \n                booster             = \"gbtree\",\n                eta                 = 0.01,\n                max_depth           = 10,\n                eval_metric         = \"auc\"\n) \n```", "```py\n# Run model\nclf <- xgb.train(   params                  = param, \n                    data                    = dtrain, \n                    nrounds                 = 100, \n                    verbose                 = 2, \n                    early_stopping_rounds   = 10,\n                    watchlist               = watchlist,\n                    maximize               = TRUE) \n```", "```py\n[14:30:32] WARNING: amalgamation/../src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n[1]\teval-auc:0.858208\ttrain-auc:0.858555 \nMultiple eval metrics are present. Will use train_auc for early stopping.\nWill train until train_auc hasn't improved in 10 rounds.\n\n[2]\teval-auc:0.858208\ttrain-auc:0.858555 \n[3]\teval-auc:0.858208\ttrain-auc:0.858555 \n[4]\teval-auc:0.858208\ttrain-auc:0.858556 \n[5]\teval-auc:0.858208\ttrain-auc:0.858556 \n[6]\teval-auc:0.858208\ttrain-auc:0.858556 \n[7]\teval-auc:0.858311\ttrain-auc:0.858997 \n[8]\teval-auc:0.858311\ttrain-auc:0.858997 \n[9]\teval-auc:0.858311\ttrain-auc:0.858997 \n[10]\teval-auc:0.858315\ttrain-auc:0.859000 \n[11]\teval-auc:0.858436\ttrain-auc:0.859110 \n[12]\teval-auc:0.858436\ttrain-auc:0.859110 \n[13]\teval-auc:0.858512\ttrain-auc:0.859157 \n[14]\teval-auc:0.858493\ttrain-auc:0.859157 \n[15]\teval-auc:0.858496\ttrain-auc:0.859160 \n[16]\teval-auc:0.858498\ttrain-auc:0.859160 \n[17]\teval-auc:0.858498\ttrain-auc:0.859160 \n[18]\teval-auc:0.858342\ttrain-auc:0.859851 \n[19]\teval-auc:0.858177\ttrain-auc:0.859907 \n[20]\teval-auc:0.858228\ttrain-auc:0.859971 \n[21]\teval-auc:0.858231\ttrain-auc:0.859971 \n[22]\teval-auc:0.858206\ttrain-auc:0.860695 \n[23]\teval-auc:0.858207\ttrain-auc:0.860695 \n[24]\teval-auc:0.858731\ttrain-auc:0.860894 \n[25]\teval-auc:0.858702\ttrain-auc:0.860844 \n[26]\teval-auc:0.858607\ttrain-auc:0.860844 \n[27]\teval-auc:0.858574\ttrain-auc:0.860842 \n[28]\teval-auc:0.858602\ttrain-auc:0.860892 \n[29]\teval-auc:0.858576\ttrain-auc:0.860843 \n[30]\teval-auc:0.858574\ttrain-auc:0.860841 \n[31]\teval-auc:0.858607\ttrain-auc:0.860893 \n[32]\teval-auc:0.858578\ttrain-auc:0.860843 \n[33]\teval-auc:0.858611\ttrain-auc:0.860894 \n[34]\teval-auc:0.858612\ttrain-auc:0.860895 \n[35]\teval-auc:0.858614\ttrain-auc:0.860898 \n[36]\teval-auc:0.858615\ttrain-auc:0.860899 \n[37]\teval-auc:0.858616\ttrain-auc:0.860897 \n[38]\teval-auc:0.858573\ttrain-auc:0.860870 \n[39]\teval-auc:0.858546\ttrain-auc:0.860822 \n[40]\teval-auc:0.858575\ttrain-auc:0.860872 \n[41]\teval-auc:0.858622\ttrain-auc:0.860898 \n[42]\teval-auc:0.858578\ttrain-auc:0.860875 \n[43]\teval-auc:0.858583\ttrain-auc:0.860870 \n[44]\teval-auc:0.859223\ttrain-auc:0.861768 \n[45]\teval-auc:0.859220\ttrain-auc:0.861760 \n[46]\teval-auc:0.859221\ttrain-auc:0.861760 \n[47]\teval-auc:0.859099\ttrain-auc:0.861719 \n[48]\teval-auc:0.859112\ttrain-auc:0.861735 \n[49]\teval-auc:0.859112\ttrain-auc:0.861735 \n[50]\teval-auc:0.859094\ttrain-auc:0.861734 \n[51]\teval-auc:0.859125\ttrain-auc:0.861785 \n[52]\teval-auc:0.859021\ttrain-auc:0.861771 \n[53]\teval-auc:0.859028\ttrain-auc:0.861784 \n[54]\teval-auc:0.859029\ttrain-auc:0.861781 \n[55]\teval-auc:0.859028\ttrain-auc:0.861784 \n[56]\teval-auc:0.859035\ttrain-auc:0.861788 \n[57]\teval-auc:0.859037\ttrain-auc:0.861789 \n[58]\teval-auc:0.859035\ttrain-auc:0.861775 \n[59]\teval-auc:0.859035\ttrain-auc:0.861774 \n[60]\teval-auc:0.859010\ttrain-auc:0.861738 \n[61]\teval-auc:0.859011\ttrain-auc:0.861739 \n[62]\teval-auc:0.859039\ttrain-auc:0.861778 \n[63]\teval-auc:0.859016\ttrain-auc:0.861739 \n[64]\teval-auc:0.859017\ttrain-auc:0.861741 \n[65]\teval-auc:0.859018\ttrain-auc:0.861746 \n[66]\teval-auc:0.859019\ttrain-auc:0.861747 \n[67]\teval-auc:0.859024\ttrain-auc:0.861755 \nStopping. Best iteration:\n[57]\teval-auc:0.859037\ttrain-auc:0.861789 \n```", "```py\n# Compute feature importance matrix\nimportance_matrix <- xgb.importance(feature.names, model = clf)\n\n# Graph important features\nxgb.plot.importance(importance_matrix[1:10,]) \n```", "```py\n# Predict on test data\npreds <- predict(clf, dtest)\n\n# Graph AUC curve\nxgb.pred <- prediction(preds, test$target)\nxgb.perf <- performance(xgb.pred, \"tpr\", \"fpr\")\n\nplot(xgb.perf,\n     avg=\"threshold\",\n     colorize=TRUE,\n     lwd=1,\n     main=\"ROC Curve w/ Thresholds\",\n     print.cutoffs.at=seq(0, 1, by=0.05),\n     text.adj=c(-0.5, 0.5),\n     text.cex=0.5)\ngrid(col=\"lightgray\")\naxis(1, at=seq(0, 1, by=0.1))\naxis(2, at=seq(0, 1, by=0.1))\nabline(v=c(0.1, 0.3, 0.5, 0.7, 0.9), col=\"lightgray\", lty=\"dotted\")\nabline(h=c(0.1, 0.3, 0.5, 0.7, 0.9), col=\"lightgray\", lty=\"dotted\")\nlines(x=c(0, 1), y=c(0, 1), col=\"black\", lty=\"dotted\") \n```", "```py\n# Set our cutoff threshold\npreds.resp <- ifelse(preds >= 0.5, 1, 0)\n\n# Create the confusion matrix\nconfusionMatrix(as.factor(preds.resp), as.factor(test$target), positive = \"1\") \n```", "```py\nConfusion Matrix and Statistics\n\n          Reference\nPrediction      0      1\n         0 280581    454\n         1     62    367\n\n               Accuracy : 0.9982         \n                 95% CI : (0.998, 0.9983)\n    No Information Rate : 0.9971         \n    P-Value [Acc > NIR] : < 2.2e-16      \n\n                  Kappa : 0.5864         \n\n Mcnemar's Test P-Value : < 2.2e-16      \n\n            Sensitivity : 0.447016       \n            Specificity : 0.999779       \n         Pos Pred Value : 0.855478       \n         Neg Pred Value : 0.998385       \n             Prevalence : 0.002917       \n         Detection Rate : 0.001304       \n   Detection Prevalence : 0.001524       \n      Balanced Accuracy : 0.723397       \n\n       'Positive' Class : 1 \n```", "```py\n# Read in the grid coordinates\ngridsmall <- sqlQuery(dbhandle, 'select * from gridsmall')\n\n# Merge the predictions with the test data\nresults <- cbind(test, preds)\n\n# Merge the grid coordinates with the test data\nresults <- merge(results, gridsmall, by=\"GridSmallId\")\n\nhead(results)\n\n# Save to file\nwrite.csv(results,\"Data\\\\CrimePredictions.csv\", row.names = TRUE) \n```"]