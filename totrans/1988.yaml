- en: How to Digest 15 Billion Logs Per Day and Keep Big Queries Within 1 Second
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/how-to-digest-15-billion-logs-per-day-and-keep-big-queries-within-1-second](https://www.kdnuggets.com/how-to-digest-15-billion-logs-per-day-and-keep-big-queries-within-1-second)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This data warehousing use case is about **scale**. The user is [China Unicom](https://en.wikipedia.org/wiki/China_Unicom),
    one of the world's biggest telecommunication service providers. Using Apache Doris,
    they deploy multiple petabyte-scale clusters on dozens of machines to support
    their 15 billion daily log additions from their over 30 business lines. Such a
    gigantic log analysis system is part of their cybersecurity management. For the
    need of real-time monitoring, threat tracing, and alerting, they require a log
    analytic system that can automatically collect, store, analyze, and visualize
    logs and event records.
  prefs: []
  type: TYPE_NORMAL
- en: From an architectural perspective, the system should be able to undertake real-time
    analysis of various formats of logs, and of course, be scalable to support the
    huge and ever-enlarging data size. The rest of this post is about what their log
    processing architecture looks like, and how they realize stable data ingestion,
    low-cost storage, and quick queries with it.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: System Architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This is an overview of their data pipeline. The logs are collected into the
    data warehouse, and go through several layers of processing.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Digest 15 Billion Logs Per Day and Keep Big Queries Within 1 Second](../Images/b108109efb2bb3713cad25563eb774f0.png)'
  prefs: []
  type: TYPE_IMG
- en: '**ODS**: Original logs and alerts from all sources are gathered into Apache
    Kafka. Meanwhile, a copy of them will be stored in HDFS for data verification
    or replay.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DWD**: This is where the fact tables are. Apache Flink cleans, standardizes,
    backfills, and de-identifies the data, and write it back to Kafka. These fact
    tables will also be put into Apache Doris, so that Doris can trace a certain item
    or use them for dashboarding and reporting. As logs are not averse to duplication,
    the fact tables will be arranged in the [Duplicate Key model](https://doris.apache.org/docs/dev/data-table/data-model#duplicate-model)
    of Apache Doris.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DWS**: This layer aggregates data from DWD and lays the foundation for queries
    and analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ADS**: In this layer, Apache Doris auto-aggregates data with its Aggregate
    Key model, and auto-updates data with its Unique Key model.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture 2.0 evolves from Architecture 1.0, which is supported by ClickHouse
    and Apache Hive. The transition arised from the user's needs for real-time data
    processing and multi-table join queries. In their experience with the old architecture,
    they found inadequate support for concurrency and multi-table joins, manifested
    by frequent timeouts in dashboarding and OOM errors in distributed joins.
  prefs: []
  type: TYPE_NORMAL
- en: '![How to Digest 15 Billion Logs Per Day and Keep Big Queries Within 1 Second](../Images/1f417c578ba07a2feb49352f7afd467e.png)'
  prefs: []
  type: TYPE_IMG
- en: Now let's take a look at their practice in data ingestion, storage, and queries
    with Architecture 2.0.
  prefs: []
  type: TYPE_NORMAL
- en: Real-Case Practice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Stable ingestion of 15 billion logs per day
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the user's case, their business churns out 15 billion logs every day. Ingesting
    such data volume quickly and stably is a real problem. With Apache Doris, the
    recommended way is to use the Flink-Doris-Connector. It is developed by the Apache
    Doris community for large-scale data writing. The component requires simple configuration.
    It implements Stream Load and can reach a writing speed of 200,000~300,000 logs
    per second, without interrupting the data analytic workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'A lesson learned is that when using Flink for high-frequency writing, you need
    to find the right parameter configuration for your case to avoid data version
    accumulation. In this case, the user made the following optimizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Flink Checkpoint**: They increase the checkpoint interval from 15s to 60s
    to reduce writing frequency and the number of transactions processed by Doris
    per unit of time. This can relieve data writing pressure and avoid generating
    too many data versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Pre-Aggregation**: For data of the same ID but comes from various tables,
    Flink will pre-aggregate it based on the primary key ID and create a flat table,
    in order to avoid excessive resource consumption caused by multi-source data writing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Doris Compaction**: The trick here includes finding the right Doris backend
    (BE) parameters to allocate the right amount of CPU resources for data compaction,
    setting the appropriate number of data partitions, buckets, and replicas (too
    much data tablets will bring huge overheads), and dialing up max_tablet_version_num
    to avoid version accumulation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These measures together ensure daily ingestion stability. The user has witnessed
    stable performance and low compaction score in Doris backend. In addition, the
    combination of data pre-processing in Flink and the [Unique Key model](https://doris.apache.org/docs/dev/data-table/data-model#unique-model)
    in Doris can ensure quicker data updates.
  prefs: []
  type: TYPE_NORMAL
- en: Storage strategies to reduce costs by 50%
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The size and generation rate of logs also impose pressure on storage. Among
    the immense log data, only a part of it is of high informational value, so storage
    should be differentiated. The user has three storage strategies to reduce costs.
  prefs: []
  type: TYPE_NORMAL
- en: '**ZSTD (ZStandard) compression algorithm**: For tables larger than 1TB, specify
    the compression method as "ZSTD" upon table creation, it will realize a compression
    ratio of 10:1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tiered storage of hot and cold data**: This is supported by the [new feature](https://blog.devgenius.io/hot-cold-data-separation-what-why-and-how-5f7c73e7a3cf)
    of Doris. The user sets a data "cooldown" period of 7 days. That means data from
    the past 7 days (namely, hot data) will be stored in SSD. As time goes by, hot
    data "cools down" (getting older than 7 days), it will be automatically moved
    to HDD, which is less expensive. As data gets even "colder", it will be moved
    to object storage for much lower storage costs. Plus, in object storage, data
    will be stored with only one copy instead of three. This further cuts down costs
    and the overheads brought by redundant storage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Differentiated replica numbers for different data partitions**: The user
    has partitioned their data by time range. The principle is to have more replicas
    for newer data partitions and less for the older ones. In their case, data from
    the past 3 months is frequently accessed, so they have 2 replicas for this partition.
    Data that is 3~6 months old has two replicas, and data from 6 months ago has one
    single copy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these three strategies, the user has reduced their storage costs by 50%.
  prefs: []
  type: TYPE_NORMAL
- en: Differentiated query strategies based on data size
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some logs must be immediately traced and located, such as those of abnormal
    events or failures. To ensure real-time response to these queries, the user has
    different query strategies for different data sizes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Less than 100G**: The user utilizes the dynamic partitioning feature of Doris.
    Small tables will be partitioned by date and large tables will be partitioned
    by hour. This can avoid data skew. To further ensure balance within a data partition,
    they use the snowflake ID as the bucketing field. They also set a starting offset.
    Data of the recent 20 days will be kept. This is the balance point between data
    backlog and analytic needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**100G~1T**: These tables have their materialized views, which are the pre-computed
    result sets stored in Doris. Thus, queries on these tables will be much faster
    and less resource-consuming. The DDL syntax of materialized views in Doris is
    the same as those in PostgreSQL and Oracle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**More than 100T**: These tables are put into the Aggregate Key model of Apache
    Doris and pre-aggregate them. **In this way, we enable queries of 2 billion log
    records to be done in 1~2s.**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These strategies have shortened the response time of queries. For example, a
    query of a specific data item used to take minutes, but now it can be finished
    in milliseconds. In addition, for big tables that contain 10 billion data records,
    queries on different dimensions can all be done in a few seconds.
  prefs: []
  type: TYPE_NORMAL
- en: Ongoing Plans
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The user is now testing with the newly added [inverted index](https://blog.devgenius.io/what-is-inverted-index-and-how-we-made-log-analysis-10-times-more-cost-effective-with-it-6afc6cc81d20)
    in Apache Doris. It is designed to speed up full-text search of strings as well
    as equivalence and range queries of numerics and datetime. They have also provided
    their valuable feedback about the auto-bucketing logic in Doris: Currently, Doris
    decides the number of buckets for a partition  based on the data size of the previous
    partition. The problem for the user is, most of their new data comes in during
    daytime, but little at nights. So in their case, Doris creates too many buckets
    for night data but too few in daylight, which is the opposite of what they need.
    They hope to add a new auto-bucketing logic, where the reference for Doris to
    decide the number of buckets is the data size and distribution of the previous
    day. They''ve come to the [Apache Doris community](https://join.slack.com/t/apachedoriscommunity/shared_invite/zt-1t3wfymur-0soNPATWQ~gbU8xutFOLog)
    and we are now working on this optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '**[Zaki Lu](https://www.linkedin.com/in/zaki-lu-99a06b148/)** is a former product
    manager at Baidu and now DevRel for the Apache Doris open source community.'
  prefs: []
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Deep Learning with Python: Second Edition by François Chollet](https://www.kdnuggets.com/2022/01/manning-deep-learning-python-second-edition-francois-chollet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Kubernetes In Action: Second Edition](https://www.kdnuggets.com/2022/03/manning-kubernetes-action-second-edition.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Data Science Project of Rotten Tomatoes Movie Rating Prediction:…](https://www.kdnuggets.com/2023/07/data-science-project-rotten-tomatoes-movie-rating-prediction-second-approach.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Python in Finance: Real Time Data Streaming within Jupyter Notebook](https://www.kdnuggets.com/python-in-finance-real-time-data-streaming-within-jupyter-notebook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Effective Small Language Models: Microsoft’s 1.3 Billion Parameter phi-1.5](https://www.kdnuggets.com/effective-small-language-models-microsoft-phi-15)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5 Things to Keep in Mind Before Selecting Your Next Data Science Job](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
