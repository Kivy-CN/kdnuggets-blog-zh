- en: Neural Networks – an Intuition
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经网络——一种直观理解
- en: 原文：[https://www.kdnuggets.com/2019/02/neural-networks-intuition.html](https://www.kdnuggets.com/2019/02/neural-networks-intuition.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2019/02/neural-networks-intuition.html](https://www.kdnuggets.com/2019/02/neural-networks-intuition.html)
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_IMG
  zh: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](#comments)'
- en: '**By [Prateek Karkare](https://www.linkedin.com/in/prateek-karkare-09622a27/),
    Research Associate at Nanyang Technological University** .'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**由[Prateek Karkare](https://www.linkedin.com/in/prateek-karkare-09622a27/)，南洋理工大学研究助理**。'
- en: Humans have always been fascinated by nature. The flight of birds led us to
    invent airplanes; shark skin inspired us to make faster swimsuits and numerous
    other machines which draw inspiration from nature. Today we are in the era of
    building intelligent machines, and there is no better inspiration than the brain.
    Humans are particularly blessed by evolution with a brain capable of performing
    the most complex tasks.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 人类一直对自然充满了好奇。鸟类的飞行促使我们发明了飞机；鲨鱼皮肤启发我们制作了更快的泳衣以及许多其他从自然中汲取灵感的机器。今天我们正处于构建智能机器的时代，而大脑无疑是最好的灵感来源。人类特别被进化赋予了一个能够执行最复杂任务的大脑。
- en: Since early 1940 scientists have been trying to build mathematical models and
    algorithms which mimic computations as they are performed inside the brain. Of
    course we are still far away in achieving the kind of feat brain does, but we
    are getting there.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 自1940年代初以来，科学家们一直在尝试构建数学模型和算法，以模拟大脑内部的计算。尽管我们仍然离大脑所能实现的壮举有很长的距离，但我们正在逐步接近。
- en: Several simplified learning models have been proposed in the quest of making
    intelligent machines and the most popular among them is the Artificial Neural
    Network or ANN or simply a Neural Network. Neural networks are one of the most
    powerful algorithms used in the field of machine learning and artificial intelligence
    nowadays. As the name suggests it draws inspiration from neurons in our brain
    and the way they are connected. Let us take a quick peek inside our brain.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在追求制造智能机器的过程中，提出了几个简化的学习模型，其中最流行的是人工神经网络（ANN），或简称神经网络。神经网络是当前机器学习和人工智能领域中最强大的算法之一。顾名思义，它汲取了我们大脑中神经元及其连接方式的灵感。让我们快速窥视一下我们的脑袋。
- en: '![](../Images/0247a766b16057ef1b0eb0ff63510eaa.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0247a766b16057ef1b0eb0ff63510eaa.png)'
- en: '**Source: [http://biomedicalengineering.yolasite.com/neurons.php](http://biomedicalengineering.yolasite.com/neurons.php)**'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源：[http://biomedicalengineering.yolasite.com/neurons.php](http://biomedicalengineering.yolasite.com/neurons.php)**'
- en: Neurons are connected inside our brain as depicted in the picture above. This
    picture shows only 2 neurons connected to each other. In reality, thousands of
    neurons connect to a single neuron’s cell body through dendrites, on an average
    a single neuron connects to 10,000 other neurons. Let us simplify this picture
    to make an artificial neural network model.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 神经元在我们大脑中连接，如上图所示。此图仅显示了两个彼此连接的神经元。实际上，成千上万的神经元通过树突与单个神经元的细胞体连接，平均而言，一个神经元连接到10,000个其他神经元。让我们简化这个图像，以建立一个人工神经网络模型。
- en: '![](../Images/89d57406c6260452f9f2e839d44d2f79.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/89d57406c6260452f9f2e839d44d2f79.png)'
- en: '**A multi-layer neural network**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**多层神经网络**'
- en: For now, assume that the cell body will just hold a number and the connection
    arrow describes the direction of data flow and how **strongly **each neuron is
    connected to other neurons. Don’t worry about what *strongly *means here we will
    see that in a while. We have taken some inspiration from biology about neurons
    and their connectivity. Let’s see how this helps in doing some tasks which our
    brain does.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设细胞体仅仅存储一个数字，而连接箭头描述了数据流的方向以及**每个神经元连接其他神经元的强度**。不用担心这里的*强度*是什么意思，我们稍后会看到。我们从神经元及其连接性的生物学中获取了一些灵感。让我们看看这如何帮助我们完成大脑所做的一些任务。
- en: '![](../Images/b94228474fe6e9990397ae18dfd2b88e.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b94228474fe6e9990397ae18dfd2b88e.png)'
- en: Perceptron
  id: totrans-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 感知器
- en: '**Source: [https://www.javascripttuts.com](https://www.javascripttuts.com/)**'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源：[https://www.javascripttuts.com](https://www.javascripttuts.com/)**'
- en: Well, that’s Megatron.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那就是Megatron。
- en: Perceptron is a machine learning algorithm invented by Frank Rosenblatt in 1957\.
    Perceptron is a linear classifier, you can read about what linear classifier is
    and a classification algorithm [**here**](https://medium.com/x8-the-ai-community/practical-aspects-logistic-regression-in-layman-terms-73fbcae58625).
    Let’s look at a very small classification example. Let us try to build a machine
    which identifies whether an object is a cricket ball or not.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器是一种由 Frank Rosenblatt 于 1957 年发明的机器学习算法。感知器是一种线性分类器，你可以阅读有关线性分类器及分类算法的内容
    [**这里**](https://medium.com/x8-the-ai-community/practical-aspects-logistic-regression-in-layman-terms-73fbcae58625)。让我们看看一个非常小的分类示例。让我们尝试构建一个机器来识别一个对象是否是板球。
- en: '![](../Images/1296ee1865e1e53b40b9eec5af027b97.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1296ee1865e1e53b40b9eec5af027b97.png)'
- en: Let us arbitrarily choose some properties of this ball.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们任意选择一些这个球的属性。
- en: It is Red, we will call this property **R **of the ball
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是红色的，我们将称这个属性为**R**。
- en: It is spherical, we will call this property **S **of the ball
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是球形的，我们将称这个属性为**S**。
- en: '![](../Images/8eb774bb4d2dbef7a985d092d5e6aac8.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8eb774bb4d2dbef7a985d092d5e6aac8.png)'
- en: Depending on the arbitrarily chosen properties, also known as **features, **we
    will classify the object as a cricket ball or not. The above table tells us that
    if a ball is red and spherical, it is a cricket ball, in all other cases, it is
    not. Let’s see how to do this with a neural network.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 根据任意选择的属性，也称为**特征**，我们将对象分类为板球或非板球。上表告诉我们，如果一个球是红色的且是球形的，它就是一个板球，否则就不是。让我们看看如何用神经网络来实现这一点。
- en: To build our super tiny *brain *which can identify a cricket ball we will take
    a neuron which just adds up the inputs and outputs the sum —
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建我们超级小的*大脑*，它可以识别板球，我们将使用一个神经元，该神经元仅加总输入并输出总和 —
- en: '![](../Images/4eb9aa4c85f3f466a2c21513a7e3cc9d.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4eb9aa4c85f3f466a2c21513a7e3cc9d.png)'
- en: Breaking down the above figure; *b, R* *and* *S* are input neurons or simply
    the inputs to the network, *w0, w1 and w2* are the **strengths** of connections
    to the middle neuron which sums up the inputs to it.* b *here is a constant which
    is called *bias. *The last step which is the rightmost neuron is just a function
    called **activation function **which outputs 1 if the input to it is positive
    and 0 if the input it negative. Mathematically it looks like —
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 解析上述图；*b, R* *和* *S* 是输入神经元或简单来说是网络的输入，*w0, w1 和 w2* 是连接到中间神经元的**权重**，它将输入值加总。*b*
    在这里是一个常量，称为 *偏置*。最后一步是最右侧的神经元，它是一个称为**激活函数**的函数，如果输入为正则输出 1，如果输入为负则输出 0。数学上它看起来像
    —
- en: '![](../Images/08128755263e1243ae4cc440a382dcfa.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/08128755263e1243ae4cc440a382dcfa.png)'
- en: if this SUM > 0, Output = 1 or *Yes* and SUM < 0, Output = 0 or *No*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个SUM > 0，则输出 = 1 或 *是*；如果SUM < 0，则输出 = 0 或 *否*。
- en: Let us look at how this helps in classifying our cricket ball. We choose some
    arbitrary numbers for our connection strengths *w *and our constant *b. *How do
    we arrive at those values which is a part of *learning* those weights by *training *the
    neural network is a topic for part-2 of this series. For now let’s just assume
    we got these numbers from somewhere —
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看这如何帮助我们分类板球。我们为我们的连接强度 *w* 和常量 *b* 选择了一些任意的数字。如何获得这些值，即通过*训练*神经网络来学习这些权重，是本系列第2部分的主题。现在我们只需假设我们从某处获得了这些数字
    —
- en: '![](../Images/d0a71cf9cd3127fc46453fa01cab4c9a.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d0a71cf9cd3127fc46453fa01cab4c9a.png)'
- en: Let us fit these values
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们拟合这些值
- en: 'Case 1: When the object is neither a sphere (S=0) nor red (R=0)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 案例 1：当对象既不是球体 (S=0) 也不是红色 (R=0) 时
- en: '![](../Images/e2ba6d91e20e41d94aaae16120d2ad61.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2ba6d91e20e41d94aaae16120d2ad61.png)'
- en: '![](../Images/7dea1db2ba4205e17f8921c8b2aaf7aa.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7dea1db2ba4205e17f8921c8b2aaf7aa.png)'
- en: The SUM<0 which means the output is 0 or *No*. Our perceptron says that this
    is not a cricket ball.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: SUM < 0 这意味着输出为 0 或 *否*。我们的感知器表示这不是一个板球。
- en: 'Case 2: When the object is a sphere (S=1) but not red (R=0)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 案例 2：当对象是球体 (S=1) 但不是红色 (R=0) 时
- en: '![](../Images/1ceb6acc3227e36bf2fb07bb238c73fe.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1ceb6acc3227e36bf2fb07bb238c73fe.png)'
- en: '![](../Images/61e6b2e2cdae448b969a8c6e81cb7e38.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/61e6b2e2cdae448b969a8c6e81cb7e38.png)'
- en: The SUM<0 which means the output is 0 or No, not a cricket ball
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: SUM < 0 这意味着输出为 0 或 否，不是一个板球。
- en: Case:3 When the object is not a sphere (S=0) but red (R=1)
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 案例 3：当对象不是球体 (S=0) 但红色 (R=1) 时
- en: '![](../Images/6e717f7c2ef77ea3d1a5701c90e2a0a0.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6e717f7c2ef77ea3d1a5701c90e2a0a0.png)'
- en: '![](../Images/f37b7603bc149abbdb293594b66ef49a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f37b7603bc149abbdb293594b66ef49a.png)'
- en: The SUM<0 which means the output is 0 or No, not a cricket ball
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: SUM < 0 这意味着输出为 0 或 否，不是一个板球。
- en: 'Case 4: When the object is a sphere (S=1) and red (R=1)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 情况 4：当对象是一个球体（S=1）并且是红色（R=1）
- en: '![](../Images/ec712947e9c5cc86f45c86df4d85522f.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ec712947e9c5cc86f45c86df4d85522f.png)'
- en: '![](../Images/f8265630f5546c4600369832ee104d26.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f8265630f5546c4600369832ee104d26.png)'
- en: The SUM>0 which means the output is 1\. Et Voila! Our perceptron says it is
    a cricket ball.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SUM>0，这意味着输出是 1。Et Voila! 我们的感知器说这是一个板球。
- en: This is the most rudimentary idea behind a neural network. We connect lot of
    these perceptrons in a particular manner and what we get is a neural network.
    I’ve oversimplified the idea a little bit but it still captures the essence of
    a perceptron.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这是神经网络的最基本思想。我们以特定的方式连接这些感知器，最终得到一个神经网络。我已经将这个思想简化了一些，但它仍然捕捉到了感知器的本质。
- en: Multi-layer Perceptron
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多层感知器
- en: We take this idea of a perceptron and stack them together to create *layers *of
    these neurons which is called a **Multi-layer perceptron** (MLP) or a **Neural
    Network**.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将感知器的这一思想堆叠在一起，创建*层*的这些神经元，这就是所谓的**多层感知器**（MLP）或**神经网络**。
- en: '![](../Images/56f4157954ee99028c3020fb72a65441.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/56f4157954ee99028c3020fb72a65441.png)'
- en: In our simplified perceptron model we were just using a step function for the
    output. In practice lot of different transformations or **activation functions** are
    used.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们简化的感知器模型中，我们仅使用了一个阶跃函数作为输出。在实际应用中，使用了许多不同的变换或**激活函数**。
- en: We chose our features, red color and spherical shape manually and rather arbitrarily
    but it is not always practical to choose such features for many other complex
    tasks. The MLP addresses this problem to some extent. The inputs to MLP could
    simply be just the pixel values of an image, the hidden layer then combines and
    transforms these pixel values to create features in the hidden layer. Essentially
    a single layer of perceptrons transforms the data and sends it to the following
    layer.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们手动且随意选择了红色和球形特征，但对于许多其他复杂任务，这种特征选择并不总是实际的。MLP 在某种程度上解决了这个问题。MLP 的输入可以直接是图像的像素值，隐藏层然后结合和转换这些像素值以在隐藏层中创建特征。本质上，单层感知器将数据转换并发送到下一层。
- en: '![](../Images/15ef716f5fc6f70da4060dbd37a06b5b.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/15ef716f5fc6f70da4060dbd37a06b5b.png)'
- en: '**A 28 pixel x 28 pixel image of a handwritten digit**'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**28 像素 x 28 像素的手写数字图像**'
- en: Suppose our MLP is trying to identify a digit by looking at images of handwritten
    digits similar to the one above. With a MLP we can pass this image as their pixel
    values directly without extracting any features out of it to the input layer.
    The hidden layer then *combines and transforms *these pixels to create some features.
    Each neuron in the hidden layer tries to *learn* some features as a part of the
    training process. For instance neuron number 1 in the hidden layer might learn
    to respond to horizontal edges in the image, neuron 2 might respond to a vertical
    edge in the image and so on. Now if the input image has a horizontal edge and
    a vertical edge together, neuron 1 and 2 in the hidden layer would respond and
    the output neuron will now combine these two features and might say it is a 7
    since 7 roughly has a vertical edge and a horizontal edge.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的 MLP 试图通过查看类似上面手写数字的图像来识别一个数字。使用 MLP，我们可以直接将这个图像的像素值传递到输入层，而无需提取任何特征。然后，隐藏层会*结合和转换*这些像素来创建一些特征。隐藏层中的每个神经元都在训练过程中尝试*学习*一些特征。例如，隐藏层中的神经元
    1 可能学习响应图像中的水平边缘，神经元 2 可能响应图像中的垂直边缘，以此类推。如果输入图像同时具有水平边缘和垂直边缘，隐藏层中的神经元 1 和 2 将响应，输出神经元将结合这两个特征，并可能说这是一个
    7，因为 7 大致有一个垂直边缘和一个水平边缘。
- en: Of course the MLPs don’t always learn features which necessarily make sense
    but it essentially is a transformation of the input data. For example for a MLP
    which takes in the handwritten digit image as input having 16 neurons in hidden
    layer learns the features something like —
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，MLPs 并不总是学习到具有实际意义的特征，但它本质上是对输入数据的转换。例如，对于一个接收手写数字图像作为输入、隐藏层有 16 个神经元的 MLP，它会学习到类似以下的特征—
- en: '![](../Images/ebc0b7ddd92292edec553e3fee9fa2b6.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ebc0b7ddd92292edec553e3fee9fa2b6.png)'
- en: '**Each square represents the learned features by a neuron in the hidden layer**'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**每个方块代表隐藏层中一个神经元学习到的特征**'
- en: As you can clearly see the patterns are more or less random and don’t make sense.
    This inference process and transformations of MLP is best explained in this awesome
    YouTube series by 3Blue1Brown — [**What is a Neural Network**](https://www.youtube.com/watch?v=aircAruvnKk).
    I would highly encourage you to go to this channel and watch the videos to get
    an intuition about neural networks. A nice tool to visualize some of the things
    which a neural network does is [**Tensorflow Playground**](https://playground.tensorflow.org/)and
    if you have some background in Linear Algebra the visualizations in this [blog](http://colah.github.io/) are
    nice.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以清楚看到的，模式或多或少是随机的，没有意义。这一推断过程和MLP的变换在3Blue1Brown的精彩YouTube系列中得到了最佳解释——[**什么是神经网络**](https://www.youtube.com/watch?v=aircAruvnKk)。我强烈建议你去这个频道观看视频，以获得对神经网络的直观了解。一个很好的工具来可视化神经网络做的一些事情是
    [**Tensorflow Playground**](https://playground.tensorflow.org/)，如果你有一些线性代数的背景，这个
    [博客](http://colah.github.io/)中的可视化也很不错。
- en: Neural Networks Today and Tomorrow
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 神经网络的今天与明天
- en: So what tasks a neural network can perform apart from identifying a cricket
    ball or a handwritten digit? Today neural networks are deployed for a wide range
    of tasks. **Image Recognition, Voice Recognition, Natural Language Processing, **[**Time
    series data**](https://medium.com/x8-the-ai-community/time-series-what-is-all-the-hype-about-e1ffd8957f1a)and
    many many other applications. Image classification is one particular field where
    neural networks have become the de facto algorithm. Neural networks have surpassed
    humans in identifying images accurately. Of course there are lot of sophisticated
    techniques and math to build such high fidelity neural networks.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，神经网络除了识别板球或手写数字之外还能完成什么任务呢？如今，神经网络被部署用于广泛的任务。**图像识别、语音识别、自然语言处理、**[**时间序列数据**](https://medium.com/x8-the-ai-community/time-series-what-is-all-the-hype-about-e1ffd8957f1a)和许多其他应用。图像分类是神经网络成为事实上的算法的一个特定领域。神经网络在准确识别图像方面已经超越了人类。当然，构建这样高保真度的神经网络有很多复杂的技术和数学。
- en: '![](../Images/3d7aa48fca3223bc1b88a6819843cc05.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3d7aa48fca3223bc1b88a6819843cc05.png)'
- en: '**Source: xkcd.com**'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源: xkcd.com**'
- en: Neural networks are everywhere. Companies deploy them to give you recommendations
    about which video you might like to watch on YouTube, identify your voice and
    commands when you speak to Siri or Google Now or Alexa. Neural networks are now
    generating their own paintings and music pieces. Still, there are a lot of challenges.
    Neural networks can be huge with hundreds of layers with hundreds of neurons in
    each layer which makes computing a big challenge with the current hardware technology.
    Training neural networks is another huge challenge. Several GPUs are employed
    together to train these neural networks which take several hours to days.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络无处不在。公司利用它们来推荐你可能喜欢在YouTube上观看的视频，识别你对Siri、Google Now或Alexa说话时的声音和指令。神经网络现在也在生成自己的绘画和音乐作品。然而，仍然存在很多挑战。神经网络可以非常庞大，具有数百层，每层有数百个神经元，这使得在当前硬件技术下计算成为一个大挑战。训练神经网络是另一个巨大的挑战。为了训练这些神经网络，通常需要多个GPU一起工作，这个过程可能需要几个小时到几天。
- en: But they are the present and the future in our quest for building machines with
    intelligence and capabilities as sophisticated as the human brain. We are still
    far away from making an artificial brain which can someday “download” all of your
    consciousness creating a machine copy of yourself. But for now that is just science
    fiction!
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们是我们在追求构建具有与人脑一样复杂智能和能力的机器过程中的现在与未来。我们离制造一个可以有一天“下载”你所有意识并创造你自身机器副本的人工大脑还有很长的路要走。但目前，这仅仅是科幻小说！
- en: '![](../Images/cd416cc6dbdd7efc86b66a48d356b54a.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/cd416cc6dbdd7efc86b66a48d356b54a.png)'
- en: '**Source: xkcd.com**'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**来源: xkcd.com**'
- en: Neural network is a vast subject and the idea behind this article is to elicit
    enough curiosity to give you a small impetus to go and explore the topic. So go
    and click those YouTube and TensorFlow links in the article and have fun learning!.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络是一个广阔的主题，本文的目的是引发足够的好奇心，让你有一些小动力去探索这个话题。所以，去点击文章中的那些YouTube和TensorFlow链接，享受学习的乐趣吧！
- en: Look out for the part-2 of this series on How to train your D̶r̶a̶g̶o̶n NN.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 注意本系列的第二部分，关于如何训练你的D̶r̶a̶g̶o̶n NN。
- en: '**Bio**: [Prateek Karkare](https://www.linkedin.com/in/prateek-karkare-09622a27/) is
    an Electrical engineer in training with a keen interest in Physics, Computer Sciences
    and Biology.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介**: [Prateek Karkare](https://www.linkedin.com/in/prateek-karkare-09622a27/)
    是一名电气工程师学员，对物理学、计算机科学和生物学充满浓厚兴趣。'
- en: '[Original](https://medium.com/datadriveninvestor/neural-networks-an-intuition-640821d5bd83).
    Reposted with permission.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/datadriveninvestor/neural-networks-an-intuition-640821d5bd83)。经许可转载。'
- en: '**Resources:**'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**资源：**'
- en: '[On-line and web-based: Analytics, Data Mining, Data Science, Machine Learning
    education](https://www.kdnuggets.com/education/online.html)'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在线和基于网络的：分析、数据挖掘、数据科学、机器学习教育](https://www.kdnuggets.com/education/online.html)'
- en: '[Software for Analytics, Data Science, Data Mining, and Machine Learning](https://www.kdnuggets.com/software/index.html)'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用于分析、数据科学、数据挖掘和机器学习的软件](https://www.kdnuggets.com/software/index.html)'
- en: '**Related:**'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[NLP Overview: Modern Deep Learning Techniques Applied to Natural Language
    Processing](https://www.kdnuggets.com/2019/01/nlp-overview-modern-deep-learning-techniques.html)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[自然语言处理概述：现代深度学习技术应用于自然语言处理](https://www.kdnuggets.com/2019/01/nlp-overview-modern-deep-learning-techniques.html)'
- en: '[The Backpropagation Algorithm Demystified](https://www.kdnuggets.com/2019/01/backpropagation-algorithm-demystified.html)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[揭秘反向传播算法](https://www.kdnuggets.com/2019/01/backpropagation-algorithm-demystified.html)'
- en: '[Supervised Learning: Model Popularity from Past to Present](https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html)'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[监督学习：模型从过去到现在的流行度](https://www.kdnuggets.com/2018/12/supervised-learning-model-popularity-from-past-present.html)'
- en: '* * *'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在的组织进行IT支持'
- en: '* * *'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关主题
- en: '[Stable Diffusion: Basic Intuition Behind Generative AI](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[稳定扩散：生成AI背后的基本直觉](https://www.kdnuggets.com/2023/06/stable-diffusion-basic-intuition-behind-generative-ai.html)'
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[用PyTorch解释性神经网络](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度神经网络不会引导我们走向AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[在神经网络之前尝试的10个简单方法](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
- en: '[Explainable Forecasting and Nowcasting with State-of-the-art Deep…](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[解释性预测和实时预测：最先进的深度学习技术](https://www.kdnuggets.com/2021/12/sota-explainable-forecasting-and-nowcasting.html)'
- en: '[Image Classification with Convolutional Neural Networks (CNNs)](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[卷积神经网络（CNNs）的图像分类](https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html)'
