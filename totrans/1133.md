# 处理数据泄漏

> 原文：[https://www.kdnuggets.com/2021/10/dealing-data-leakage.html](https://www.kdnuggets.com/2021/10/dealing-data-leakage.html)

[评论](#comments)

**由 [Susan Currie Sivek 博士](https://www.linkedin.com/in/ssivek/)，高级数据科学记者**

![图片](../Images/0837488b007543b7781e158aa9753758.png)

* * *

## 我们的三大课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业轨道

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌 IT 支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你的组织的 IT

* * *

捕捉到的静态画面 [通过 GIPHY](https://giphy.com/gifs/cartoonhangover-cartoons-bravestwarriors-etBlg1EQTz6pCzdKmd)

你正在为即将到来的考试做准备。考试是开卷的，因此你在复习时使用参考资料，你做得很好。

但当你在考试日到来时，突然被告知考试不再是开卷的了。结果并不那么理想。

[通过 GIPHY](https://giphy.com/gifs/funny-exam-vXKDrRey28YCY)

这听起来像是学术过度成就者的焦虑梦，但它类似于当目标泄漏发生在机器学习模型中时的情况。假设你构建了一个模型，旨在预测某个结果，并用有助于模型做出预测的信息来训练它。这个模型可能表现得很好……也许表现得异常好。但如果有些信息在模型实际需要做出预测时不可用，那么它的真实表现将会更差。这就是目标泄漏的结果——数据科学家的焦虑梦！

我最近听到我们的一位 Alteryx 专家称目标泄漏为机器学习中最棘手的问题。但它是如何发生的，你如何避免这个问题？它与“数据泄漏”有何关系？

[通过 GIPHY](https://giphy.com/gifs/underground-leak-sprinkler-Nf1O8cYzypC1O)

### 目标泄漏

目标泄漏发生在模型使用在预测时不可用的数据进行训练时。模型在初始训练和测试时表现良好，但当投入生产时，缺少现在缺失的数据导致模型表现不佳。就像你带着书学习，然后在没有书的情况下参加考试一样，模型缺少了那些在训练期间提高其表现的有用信息。

这里有一些代表目标泄漏的场景：

+   在用于训练模型的数据集中包括要预测的结果作为特征（这可能听起来很傻，但确实会发生；例如，复制并重命名目标变量字段，然后忘记这一重复，可能会导致你无意中使用额外版本的目标作为预测变量）；

+   在预测学生是否会接受某所大学的录取通知的模型中，包括表示学生在大学就读了多少年的特征；

+   在预测潜在客户是否会订阅的模型中，包括表示订阅月份数的特征；

+   在预测某种类型外墙的房屋火灾的模型中，包括表示火灾相关保险索赔是否被批准的特征；以及

+   包括来自其他数据集的信息，这些信息在预测时未能提供给模型的详细内容。

在所有这些情况下，模型构建时包括了在预测时无法知晓的信息。我们无法知道一个客户会订阅多少个月，当我们还在试图弄清楚他们是否会订阅的时候。（我们可以构建一个模型来预测一个订阅者会订阅多少个月？当然可以。但我们将基于已知订阅者的数据，而不是可能会订阅或不会订阅的整个池子。）类似地，如果我们告诉模型用某些材料建造的房屋的人曾经提出过火灾保险索赔，我们就将火灾发生后的知识引入了我们的模型，用来预测火灾。

即使是看似无害的细节，如文件大小或时间戳，也可能无意中成为目标变量的代理。例如，2013年Kaggle比赛[不得不暂停](https://www.kaggle.com/c/the-icml-2013-whale-challenge-right-whale-redux/discussion/4865#25839)并重新修订数据集，正是由于这种问题。发现（并认真报告）数据泄露的团队在排行榜上短暂领先！

数据泄露导致的结果是对训练数据的过拟合。你的模型可能在拥有这些额外知识时表现得非常好——在开卷考试中表现出色——但在预测时没有这些信息时表现不佳。

[通过GIPHY](https://giphy.com/gifs/fix-having-leak-hQtlzrmpE0gKY)

### 训练-测试污染

另一种数据泄露的形式有时被称为“训练-测试污染”。这个问题可能不具体涉及你的目标变量，但确实会影响模型性能。这是我们可能无意中将未来数据的知识添加到训练数据中的另一种方式，导致性能指标看起来比实际生产环境中更好。（顺便说一下，如果你寻找更多关于这个主题的阅读，请注意，“数据泄露”也是网络安全人士用来谈论[数据泄露](https://en.wikipedia.org/wiki/Data_breach)的术语。）

训练-测试污染常见的方式是先对整个数据集进行预处理，然后再将其拆分为训练集和测试集，或在使用交叉验证之前进行预处理。

例如，[数据归一化](https://community.alteryx.com/t5/Data-Science/Normalization-Standardization-and-Regularization-in-Alteryx-and/ba-p/733996?utm_content=827583&utm_source=kdn)需要使用数据集中每个变量的数值范围。对整个数据集进行归一化时，会在模型评估时提供这种“知识”。然而，投入生产的模型没有这种知识，因此在预测时表现不佳。同样，标准化整个数据集会不适当地向模型提供整个数据集的均值和标准差。填补缺失值也使用了有关数据集的汇总统计信息（例如，中位数、均值）。

所有这些线索都可以帮助模型在你的训练和测试数据上表现得更好，但当它最终接触到全新的数据时，表现可能不会那么好。[这篇文章](https://machinelearningmastery.com/data-preparation-without-data-leakage/)提供了对这种数据泄漏的深入探索，包括演示代码。

如果你使用[k折交叉验证](https://community.alteryx.com/t5/Data-Science/Holdouts-and-Cross-Validation-Why-the-Data-Used-to-Evaluate-your/ba-p/448982?utm_content=827583&utm_source=kdn)来评估模型，会出现另一个问题。只要你的数据集只包含来自每个个体/来源的一个观察值，这种泄漏不应成为你的问题。然而，如果你在数据集中有来自每个人或来源的多个观察值（即数据行），则在为训练和测试模型创建子集或“折”时，来自同一来源的所有观察值需要一起分组。

例如，如果观察来自A人的数据同时包含在训练组和测试组中，你可能会用A人的训练数据来预测A人的测试数据。模型在测试集上的表现会看起来更好——而测试集又包括A人——因为它已经从训练集中对A人有所了解。但在实际生产中，它不会有这种先前曝光的优势。有关此问题的更多详细说明（有时称为“群体泄漏”），请查看这篇文章。

[通过 GIPHY](https://giphy.com/gifs/xyShS1HDFNNZe)

### 处理数据泄漏

当你家里的水龙头漏水时，你可以通过声音和积水来发现它。但这些类型的泄漏可能很难察觉。你仍然可以进行预防性维护和修理来应对这个挑战。

模型表现异常良好可能是泄露的迹象。如果您的模型表现得令人震惊且非常好，要抵制自我赞扬并急于发布的诱惑。这样的表现可能是普通的过拟合结果，但也可能反映了目标或数据泄露。

为了尽量避免数据泄露，您可以进行全面的[探索性数据分析](https://community.alteryx.com/t5/Data-Science/Adventures-in-Data-Exploratory-Data-Analysis/ba-p/545267?utm_content=827583&utm_source=kdn)（EDA），并寻找与结果变量特别高相关性的特征。仔细查看这些关系以确保如果将这些高相关性的特征一起使用于模型中时不会出现泄露的可能性是很值得的。如果您的数据集维度较高，特征较多，这项审查可能会很具挑战性，因此在Alteryx Designer中使用像[皮尔逊相关工具](https://community.alteryx.com/t5/Alteryx-Designer-Knowledge-Base/Tool-Mastery-Pearson-Correlation/ta-p/388744?utm_content=827583&utm_source=kdn)的工具，并对其输出进行过滤和/或可视化可能会有所帮助。

为了避免训练-测试污染，请确保在应用任何变换（如归一化）之前，将数据分割为训练集/测试集/保留集，然后在训练集上训练模型。接下来，对测试集/保留集应用相同的变换参数，然后测试模型的表现。

[via GIPHY](https://giphy.com/gifs/cartoonhangover-cartoons-bravestwarriors-etBlg1EQTz6pCzdKmd)

此外，请确保您完全理解数据集中所有的特征。[这个Kaggle示例](https://www.kaggle.com/alexisbcook/data-leakage)展示了在信用卡申请批准数据集中，名为“支出”的特征如果用于预测批准申请的模型中可能会导致目标泄露。作为特征名的“支出”可能意味着很多事情，但在这种情况下，它指的是信用卡用户在卡上花费了多少。这一特征暗示他们确实获得了信用卡批准，并不恰当地影响了模型对批准的预测，因为支出信息在预测时是不可用的。

最后，检查特征的相对重要性和审查其他可解释性工具可以帮助您发现泄露。在上面的信用卡申请批准示例中，“支出”可能看起来像是预测信用卡批准的一个非常重要的特征。如果有疑问，您可以尝试移除一个特征，看看模型表现如何变化，然后确定模型是否突然在更现实的水平上表现。

[via GIPHY](https://giphy.com/gifs/season-16-the-simpsons-16x16-xT5LMXBrV5NkVZHKms)

### 使模型防泄露

我希望这篇概述能为你提供一些新的技巧，帮助你避免这些泄露情况！通过仔细的 EDA 和对数据集的透彻了解，以及正确的预处理和交叉验证设置，你应该能很好地保持目标的完整性并防止数据集的污染。

### 推荐阅读

+   [询问数据科学家: 数据泄露](https://insidebigdata.com/2014/11/26/ask-data-scientist-data-leakage/)

+   [机器学习中的数据泄露](https://machinelearningmastery.com/data-leakage-machine-learning/)

+   [机器学习中的目标泄露](https://aiukraine.com/wp-content/uploads/2018/09/12_00-Yuriy-Guts-Target-Leakage-in-Machine-Learning-.pdf)

最初发布在 [Alteryx Community 数据科学博客](https://community.alteryx.com/t5/Data-Science/Dealing-with-Data-Leakage/ba-p/827583?utm_content=827583&utm_source=kdn) 上。

**简介: [苏珊·柯瑞·西维克（Susan Currie Sivek）博士](https://www.linkedin.com/in/ssivek/)** 是 Alteryx Community 的高级数据科学记者，她与全球观众探讨数据科学概念。她也是 [数据科学混音器](https://community.alteryx.com/t5/Data-Science-Mixer/bg-p/mixer?utm_content=733996&utm_source=kdn) 播客的主持人。她在学术界和社会科学方面的背景为她调查数据和沟通复杂理念的方式提供了深刻见解，同时她在新闻学方面的培训也为她的工作增添了一抹创造力。

[原文](https://community.alteryx.com/t5/Data-Science/Dealing-with-Data-Leakage/ba-p/827583?utm_content=827583&utm_source=kdn)。经许可转载。

**相关:**

+   [机器学习的持续训练 – 成功策略的框架](/2021/04/continuous-training-machine-learning.html)

+   [关于 AI 训练数据的 5 篇必读论文](/2020/06/5-essential-papers-ai-training-data.html)

+   [Python 中的数据集拆分最佳实践](/2020/05/dataset-splitting-best-practices-python.html)

### 更多相关话题

+   [处理文本数据中的噪声标签](https://www.kdnuggets.com/2023/04/dealing-noisy-labels-text-data.html)

+   [处理推荐和搜索中的位置偏差](https://www.kdnuggets.com/2023/03/dealing-position-bias-recommendations-search.html)

+   [导航数据科学职位名称: 数据分析师 vs 数据科学家…](https://www.kdnuggets.com/navigating-data-science-job-titles-data-analyst-vs-data-scientist-vs-data-engineer)

+   [数据科学家、数据工程师及其他数据职业的解释](https://www.kdnuggets.com/2021/05/data-scientist-data-engineer-data-careers-explained.html)

+   [适用于数据工程师和数据科学家的高保真合成数据](https://www.kdnuggets.com/2022/tonic-high-fidelity-synthetic-data-engineers-scientists-alike.html)

+   [数据科学家 vs 数据分析师 vs 数据工程师](https://www.kdnuggets.com/2022/01/data-scientist-data-analyst-data-engineer.html)
