["```py\n# K meansfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score \nfrom sklearn.metrics import calinski_harabasz_score\nfrom sklearn.metrics import davies_bouldin_score# Fit K-Means\nkmeans_1 = KMeans(n_clusters=4,random_state= 10)# Use fit_predict to cluster the dataset\npredictions = kmeans_1.fit_predict(cluster_df)# Calculate cluster validation metricsscore_kemans_s = silhouette_score(cluster_df, kmeans_1.labels_, metric='euclidean')score_kemans_c = calinski_harabasz_score(cluster_df, kmeans_1.labels_)score_kemans_d = davies_bouldin_score(cluster_df, predictions)print('Silhouette Score: %.4f' % score_kemans_s)\nprint('Calinski Harabasz Score: %.4f' % score_kemans_c)\nprint('Davies Bouldin Score: %.4f' % score_kemans_d)\n```", "```py\n# Inter cluster distance map\nfrom yellowbrick.cluster import InterclusterDistance# Instantiate the clustering model and visualizervisualizer = InterclusterDistance(kmeans_1)visualizer.fit(cluster_df)        # Fit the data to the visualizer\nvisualizer.show()        # Finalize and render the figure\n```", "```py\n# Dendrogram for Hierarchical Clustering\nimport scipy.cluster.hierarchy as shc\nfrom matplotlib import pyplot\npyplot.figure(figsize=(10, 7))  \npyplot.title(\"Dendrograms\")  \ndend = shc.dendrogram(shc.linkage(cluster_df, method='ward'))\n```", "```py\n# Agglomerative clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.cluster import AgglomerativeClustering\nfrom matplotlib import pyplot# define the model\nmodel = AgglomerativeClustering(n_clusters=4)\n# fit model and predict clusters\nyhat = model.fit(cluster_df)\nyhat_2 = model.fit_predict(cluster_df)\n# retrieve unique clusters\nclusters = unique(yhat)# Calculate cluster validation metricsscore_AGclustering_s = silhouette_score(cluster_df, yhat.labels_, metric='euclidean')score_AGclustering_c = calinski_harabasz_score(cluster_df, yhat.labels_)score_AGclustering_d = davies_bouldin_score(cluster_df, yhat_2)print('Silhouette Score: %.4f' % score_AGclustering_s)\nprint('Calinski Harabasz Score: %.4f' % score_AGclustering_c)\nprint('Davies Bouldin Score: %.4f' % score_AGclustering_d)\n```", "```py\n# parameter tuning for eps\nfrom sklearn.neighbors import NearestNeighbors\nnearest_neighbors = NearestNeighbors(n_neighbors=11)\nneighbors = nearest_neighbors.fit(cluster_df)\ndistances, indices = neighbors.kneighbors(cluster_df)\ndistances = np.sort(distances[:,10], axis=0)from kneed import KneeLocator\ni = np.arange(len(distances))\nknee = KneeLocator(i, distances, S=1, curve='convex', direction='increasing', interp_method='polynomial')\nfig = plt.figure(figsize=(5, 5))\nknee.plot_knee()\nplt.xlabel(\"Points\")\nplt.ylabel(\"Distance\")print(distances[knee.knee])\n```", "```py\n# dbscan clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.cluster import DBSCAN\nfrom matplotlib import pyplot\n# define dataset\n# define the model\nmodel = DBSCAN(eps=1.9335816413107338, min_samples= 18)# rule of thumb for min_samples: 2*len(cluster_df.columns)# fit model and predict clusters\nyhat = model.fit_predict(cluster_df)\n# retrieve unique clusters\nclusters = unique(yhat)# Calculate cluster validation metricsscore_dbsacn_s = silhouette_score(cluster_df, yhat, metric='euclidean')score_dbsacn_c = calinski_harabasz_score(cluster_df, yhat)score_dbsacn_d = davies_bouldin_score(cluster_df, yhat)print('Silhouette Score: %.4f' % score_dbsacn_s)\nprint('Calinski Harabasz Score: %.4f' % score_dbsacn_c)\nprint('Davies Bouldin Score: %.4f' % score_dbsacn_d)\n```", "```py\n# gaussian mixture clustering\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.mixture import GaussianMixture\nfrom matplotlib import pyplot\n# define the model\nmodel = GaussianMixture(n_components= 26,covariance_type= \"full\", random_state = 10)\n# fit the model\nmodel.fit(cluster_df)\n# assign a cluster to each example\nyhat = model.predict(cluster_df)\n# retrieve unique clusters\nclusters = unique(yhat)# Calculate cluster validation scorescore_dbsacn_s = silhouette_score(cluster_df, yhat, metric='euclidean')score_dbsacn_c = calinski_harabasz_score(cluster_df, yhat)score_dbsacn_d = davies_bouldin_score(cluster_df, yhat)print('Silhouette Score: %.4f' % score_dbsacn_s)\nprint('Calinski Harabasz Score: %.4f' % score_dbsacn_c)\nprint('Davies Bouldin Score: %.4f' % score_dbsacn_d)\n```"]