# 神经网络内部的交互式代码

> 原文：[https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html](https://www.kdnuggets.com/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html)

![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [评论](/2018/06/inside-mind-neural-network-interactive-code-tensorflow.html?page=2#comments)

**由 [Jae Duk Seo](https://jaedukseo.me/)，瑞尔森大学**

![图片](../Images/a4da8f275f7ca7b1878ead38e8e6fccb.png)

从这个 [网站](https://giphy.com/gifs/trippy-9lRBSGg6l68Hm) 获取的 GIF

我一直想了解我的模型的内部工作原理。 从今天开始，我希望学习与此主题相关的内容。对于这篇文章，我想涵盖三个主题：权重直方图、神经元激活的可视化，以及 [内部/积分梯度](https://arxiv.org/pdf/1703.01365.pdf)。

> **请注意，这篇文章是为了让未来的我能回顾这些材料。**

### **继续阅读前**

TechTalksTV 的原创视频 ([https://vimeo.com/user72337760](https://vimeo.com/user72337760)) 如果出现任何问题，我会尽快删除视频。原始视频链接在这里: [https://vimeo.com/238242575](https://vimeo.com/238242575)

这个视频超出了本文的范围，但它确实帮助我理解了内部梯度和积分梯度，以及如何理解神经网络的内部工作原理的总体概况。

### **数据集/网络架构/准确率/类别数量**

![](../Images/af8e4afbaff1d7d1dfa91156b7a15eee.png)![](../Images/e33ace5e093d9f0b2ca6f6542c2527be.png)

图片来自这个网站

**红色矩形** → 输入图像 (32*32*3)

**黑色矩形** → 使用 ELU() 的卷积/是否使用均值池化

**橙色矩形** → 用于分类的 Softmax

像往常一样，我们将使用 CIFAR 10 数据集来训练我们的 [全卷积网络](https://towardsdatascience.com/iclr-2015-striving-for-simplicity-the-all-convolutional-net-with-interactive-code-manual-b4976e206760)，并尝试了解为什么网络将某些图像预测为它的类别。

需要注意的一点是，由于这篇文章主要是了解网络的内部工作原理，我将仅使用测试集中的 50 张图像来测量准确率。

![](../Images/b24a63688c6bb3253076ba8f6cd87ccf.png)![](../Images/8c6d61d1bc614a70916de7465f04a928.png)

**左侧图像** → 测试图像（50 张图像）的准确率/成本随时间变化

**右侧图像** → 训练图像（50000 张图像）的准确率/成本随时间变化

![](../Images/f0ec4efc84c79de081b0168401a6e4ad.png)

如上所见，该模型在第 7 个周期的最终准确率为 81%。(如果您想访问完整的训练日志，[请点击这里](https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/blob/master/Understanding_Concepts/COUNTERFACTUALS/viz/z_viz.txt)。) 最后，让我们看看每个数字代表的每个类别。

![](../Images/a731e3ab8e9e13dd818a977c4656f3f1.png)

图像来自这个[网站](https://github.com/EN10/CIFAR)

### **权重直方图（训练前 / 训练后）**

![](../Images/601705b2077ada4a42dd471c99e0157c.png)

训练前的权重直方图

上图是每一层的权重直方图，为了便于可视化，我将每个直方图分为三层。在最左侧，我们可以观察到权重的均值一般为0，标准差（stddev）值在0.04到0.06之间。这是预期的，因为我们为每一层声明了不同的标准差值。此外，一些曲线比其他曲线小的原因是每层的权重数量不同。（例如，第0层只有3 * 3 * 128个权重，而第2层有3 * 128 * 128个权重。）

![](../Images/e6a2ac82dc52da96d1cf867bcb4c8978.png)

不同的标准差值！[](../Images/9a9a8c0bbc3af2032a4463163434f23f.png)

训练后的权重直方图

一开始，我们可以观察到明显的差异，特别是在前面三层。分布的范围从-5增大到5。然而，似乎大多数权重集中在-1和1之间（或接近零）。对于第4到第6层，均值似乎发生了变化，而最终的三层也是如此。

### **可视化某些层的激活值**

![](../Images/a232b4af38654cb6efe3556e31821e77.png)

网络的测试输入

使用[Yosinski及其同事](https://arxiv.org/pdf/1506.06579.pdf)的方法，我们来可视化图像在第3层、第6层和第9层后的变化。（请注意，我最初发现这种方法由[Arthur Juliani](https://medium.com/@awjuliani?source=post_header_lockup)在这篇[博客文章](https://medium.com/@awjuliani/visualizing-neural-network-layer-activation-tensorflow-tutorial-d45f8bf7bbc4)中使用。）

![](../Images/9e203f792f2e37e543c7279c8a815ec2.png)

第3层后的激活

**绿色框**→ 捕获绿色值的通道

**蓝色框**→ 捕获蓝色值的通道

现在有128个通道，因此我不会可视化所有通道。相反，我会如上所示可视化前27个通道。我们可以看到在第3层之后，某些颜色值被网络捕获。

![](../Images/ad2a1aa223f7176144fb0bd7e1b9bb34.png)

第6层的激活

**红色框**→ 捕获红色值的通道

然而，在第六层之后，似乎某些滤波器能够更好地捕获红色而不是绿色或蓝色。

<cener>![](../Images/9bbc0ff32982fe294cfc501dd22f3ee6.png)

第9层后的激活</cener>

最后，在第九层（全球平均池化之前），我们可以可视化每个深度为1的通道（因此看起来像灰度图像）。然而（至少对我而言），这些图像似乎不具备人类可理解性。所有图像可以在[此处找到](https://github.com/JaeDukSeo/Daily-Neural-Network-Practice-2/tree/master/Understanding_Concepts/COUNTERFACTUALS/viz)，我还创建了一个GIF，汇总了所有的变化。

![](../Images/903cfcf07afc8b305a6892c902b1f520.png)

**GIF的顺序**→ 输入图像、层3后的激活、层6后的激活、层9后的激活

* * *

## 我们的前三个课程推荐

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity) - 快速进入网络安全职业的捷径

![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics) - 提升你的数据分析技能

![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport) - 支持你所在组织的IT需求

* * *

### 更多相关话题

+   [使用TensorFlow和Keras构建和训练你的第一个神经网络](https://www.kdnuggets.com/2023/05/building-training-first-neural-network-tensorflow-keras.html)

+   [6个令人惊叹的ChatGPT扩展插件，随时随地使用](https://www.kdnuggets.com/2023/04/6-chatgpt-mindblowing-extensions-anywhere.html)

+   [选择下一个数据科学职位前需要牢记的5件事](https://www.kdnuggets.com/2022/01/5-things-keep-mind-selecting-next-job.html)

+   [数据管理：如何保持在客户心中的领先地位？](https://www.kdnuggets.com/2022/04/data-management-stay-top-customer-mind.html)

+   [DeepMind在利用深度学习推进数学研究中的新努力](https://www.kdnuggets.com/2021/12/inside-deepmind-new-efforts-deep-learning-advance-mathematics.html)

+   [AIMET神经网络优化](https://www.kdnuggets.com/2022/04/qualcomm-neural-network-optimization-aimet.html)
