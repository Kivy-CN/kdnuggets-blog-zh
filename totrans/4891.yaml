- en: Using Genetic Algorithm for Optimizing Recurrent Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://www.kdnuggets.com/2018/01/genetic-algorithm-optimizing-recurrent-neural-network.html](https://www.kdnuggets.com/2018/01/genetic-algorithm-optimizing-recurrent-neural-network.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![c](../Images/3d9c022da2d331bb56691a9617b91b90.png) [comments](#comments)'
  prefs: []
  type: TYPE_IMG
- en: '**By Aaqib Saeed, University of Twente**'
  prefs: []
  type: TYPE_NORMAL
- en: Recently, there has been a lot of work on automating machine learning, from
    a selection of appropriate algorithm to feature selection and hyperparameters
    tuning. Several tools are available (e.g. *AutoML* and *TPOT*), that can aid the
    user in the process of performing hundreds of experiments efficiently. Likewise,
    the deep neural network architecture is usually designed by experts; through a
    trial and error approach. Although, this approach resulted in state-of-the-art
    models in several domains but is very time-consuming. Lately, due to increase
    in available computing power, researchers are employing [Reinforcement Learning](https://openreview.net/pdf?id=r1Ue8Hcxg) and [Evolutionary
    Algorithms](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf) to automatically
    search for optimal neural architectures.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: In this tutorial, we will see how to apply a Genetic Algorithm (GA) for finding
    an optimal window size and a number of units in Long Short-Term Memory (LSTM)
    based Recurrent Neural Network (RNN). For this purpose, we will train and evaluate
    models for time-series prediction problem using [Keras](https://github.com/fchollet/keras).
    For GA, a python package called [DEAP](https://github.com/DEAP/deap) will be used.
    The main idea of the tutorial is to familiarize the reader about employing GA,
    to find optimal settings automatically; hence, only two parameters will be explored.
    Moreover, reader’s knowledge (theoretical and applied) about RNNs is assumed.
    If you are unfamiliar with them, please consult following resources [[1]](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) and [[2]](https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html).
  prefs: []
  type: TYPE_NORMAL
- en: The ipython netbook with the complete code is available at the following [link](https://github.com/aqibsaeed/Genetic-Algorithm-RNN).
  prefs: []
  type: TYPE_NORMAL
- en: Genetic Algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The genetic algorithm is a heuristic search and an optimization method inspired
    by the process of natural selection. They are widely used for finding a near optimal
    solution to optimization problems with large parameter space. The process of evolution
    of species (solutions in our case) is mimicked, by depending on biologically inspired
    components e.g. crossover. Furthermore, as it doesn’t take auxiliary information
    into account, (e.g. derivatives) it can be used for both discrete and continuous
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'For using a GA, two preconditions have to be fulfilled, a) a solution representation
    or defining a chromosome and b) a fitness function to evaluate produced solutions.
    In our case, a binary array is a genetic representation of a solution (see **Figure
    1**) and model’s Root-Mean-Square Error (RMSE) on validation set will act a fitness
    value. Moreover, three basic operations that constitute a GA, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection**: It defines which solutions to preserve for further reproduction
    e.g. roulette wheel selection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Crossover**: It describes how new solutions are created from existing ones
    e.g. n-point crossover.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mutation**: Its aim is to introduce diversity and novelty into the solution
    pool by means of randomly swapping or turning-off solution bits e.g. binary mutation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Genetic representation of a solution](../Images/bba3790751846c9f5fc72ffb4653617c.png)'
  prefs: []
  type: TYPE_IMG
- en: Occasionally, a technique called “Elitism” is also used, which preserve few
    best solutions from the population, and pass on to next generation. **Figure 2** depicts
    a complete genetic algorithm, where, initial solutions (population) are randomly
    generated. Next, they are evaluated according to a fitness function and selection,
    crossover and mutation are performed afterwards. This process is repeated for
    a defined number of iteration (called generations in GA terminology). At the end,
    a solution with highest fitness score is selected as the best solution. To learn
    more, please check following resources [[3]](http://www.flll.jku.at/div/teaching/Ga/GA-Notes.pdf) and [[4]](http://www.cs.cmu.edu/~tom/mlbook.html).
  prefs: []
  type: TYPE_NORMAL
- en: '![Genetic Algorithm](../Images/39049a30d230fa390264432946b6aa1a.png)'
  prefs: []
  type: TYPE_IMG
- en: Implementation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, we have a fair understanding of what GA is and how it works. Next, let’s
    get to coding.
  prefs: []
  type: TYPE_NORMAL
- en: We will use wind power forecast data, which is available at the following [link](https://www.kaggle.com/c/GEF2012-wind-forecasting/data).
    It consists of normalized (between zero and one) wind power measurements from
    seven wind farms. To keep things simple, we will use first wind farm data (column
    named **wp1**) but I encourage the reader to experiment and extend the code to
    forecast energy for all seven, wind farms.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s import required packages, load the dataset and define two helper functions.
    The first method `prepare_dataset` will segment the data into chunks to create *X*, *Y* pair
    for model training. The *X* will the wind power values from the past (e.g. *1* to *t-1*)
    and *Y* will be future value at time *t*. The second method `train_evaluate` perform
    three things, 1) decoding GA solution to get window size and number of units.
    2) Prepare the dataset using window size found by GA and divide into train and
    validation set, and 3) train LSTM model, calculate RMSE on validation set and
    return it as a fitness score of the current GA solution.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Next, use DEAP package to define things to run GA. We will use a binary representation
    for the solution of length ten. It will be randomly initialized using Bernoulli
    distribution. Likewise, ordered crossover, shuffle mutation and roulette wheel
    selection is used. The GA parameter values are initialized arbitrarily; I will
    suggest you, to play around with different settings.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The K best-found solution via GA can be seen easily seen using `tools.selBest(population,k
    = 1)`. Afterward, the optimal configuration can be used to train on the complete
    training set and test it on holdout test set.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this tutorial, we saw how to employ GA to automatically find optimal window
    size (or lookback) and a number of units to use in RNN. For further learning,
    I would suggest you, to experiment with different GA parameter configurations,
    extend genetic representation to include more parameters to explore and share
    your findings and questions below in the comment section below.
  prefs: []
  type: TYPE_NORMAL
- en: '**References:**'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding LSTM Networks, by Christopher Olah
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recurrent Neural Networks in Tensorflow I, by R2RT
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Genetic Algorithms: Theory and Applications, by Ulrich Bodenhofer'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9, Genetic Algorithms of Machine Learning book, by Tom M. Mitchell
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Author](../Images/f9c21800dc7ef2fdf98de5b260d7c466.png)**Bio: [Aaqib Saeed](http://aqibsaeed.github.io/)**
    is a graduate student of Computer Science (specializing in Data Science and Smart
    Services) at University of Twente (The Netherlands).'
  prefs: []
  type: TYPE_NORMAL
- en: '[Original](http://aqibsaeed.github.io/2017-08-11-genetic-algorithm-for-optimizing-rnn/).
    Reposted with permission.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Related:**'
  prefs: []
  type: TYPE_NORMAL
- en: '[Urban Sound Classification with Neural Networks in Tensorflow](/2016/09/urban-sound-classification-neural-networks-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Implementing a CNN for Human Activity Recognition in Tensorflow](/2016/11/implementing-cnn-human-activity-recognition-tensorflow.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Today I Built a Neural Network During My Lunch Break with Keras](/2017/12/today-built-neural-network-during-lunch-break-keras.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More On This Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[Optimizing Genes with a Genetic Algorithm](https://www.kdnuggets.com/2022/04/optimizing-genes-genetic-algorithm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Genetic Algorithm Key Terms, Explained](https://www.kdnuggets.com/2018/04/genetic-algorithm-key-terms-explained.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Strategies for Optimizing Performance and Costs When Using Large…](https://www.kdnuggets.com/strategies-for-optimizing-performance-and-costs-when-using-large-language-models-in-the-cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10 Simple Things to Try Before Neural Networks](https://www.kdnuggets.com/2021/12/10-simple-things-try-neural-networks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Interpretable Neural Networks with PyTorch](https://www.kdnuggets.com/2022/01/interpretable-neural-networks-pytorch.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Deep Neural Networks Don''t Lead Us Towards AGI](https://www.kdnuggets.com/2021/12/deep-neural-networks-not-toward-agi.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
