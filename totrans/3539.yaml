- en: 7 common mistakes when doing Machine Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 个做机器学习时常见的错误
- en: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html](https://www.kdnuggets.com/2015/03/machine-learning-data-science-common-mistakes.html)
- en: By Cheng-Tao Chu ([@chengtao_chu](https://twitter.com/chengtao_chu)) .
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：程涛（[@chengtao_chu](https://twitter.com/chengtao_chu)）。
- en: Statistical modeling is a lot like engineering.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 统计建模很像工程学。
- en: '![statistics1](../Images/0e70aa3c1fdb3fb7f30b800354621863.png) In engineering,
    there are various ways to build a key-value storage, and each design makes a different
    set of assumptions about the usage pattern. In statistical modeling, there are
    various algorithms to build a classifier, and each algorithm makes a different
    set of assumptions about the data.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '![statistics1](../Images/0e70aa3c1fdb3fb7f30b800354621863.png) 在工程学中，有多种方法可以构建键值存储，每种设计对使用模式做出不同的假设。在统计建模中，有各种算法可以构建分类器，每种算法对数据做出不同的假设。'
- en: When dealing with small amounts of data, it’s reasonable to try as many algorithms
    as possible and to pick the best one since the cost of experimentation is low.
    But as we hit “big data”, it pays off to analyze the data upfront and then design
    the modeling pipeline (pre-processing, modeling, optimization algorithm, evaluation,
    productionization) accordingly.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 当处理少量数据时，尝试尽可能多的算法并选择最佳算法是合理的，因为实验成本较低。但当面对“大数据”时，提前分析数据并据此设计建模流程（预处理、建模、优化算法、评估、生产化）是值得的。
- en: As pointed out in my previous [post](http://ml.posthaven.com/why-building-a-data-science-team-is-hard),
    there are dozens of ways to solve a given modeling problem. Each model assumes
    something different, and it’s not obvious how to navigate and identify which assumptions
    are reasonable. In industry, most practitioners pick the modeling algorithm they
    are most familiar with rather than pick the one which best suits the data. In
    this post, I would like to share some common mistakes (the don't-s). I’ll save
    some of the best practices (the do-s) in a future post.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在之前的[帖子](http://ml.posthaven.com/why-building-a-data-science-team-is-hard)中指出的，有许多方法可以解决给定的建模问题。每种模型假设的情况不同，如何判断这些假设是否合理并不明显。在行业中，大多数从业者选择他们最熟悉的建模算法，而不是选择最适合数据的算法。在这篇文章中，我想分享一些常见的错误（即“不要做”的事）。一些最佳实践（即“要做”的事）我会在未来的文章中分享。
- en: '**1\. Take default loss function for granted**'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 以为默认损失函数是正确的**'
- en: Many practitioners train and pick the best model using the default loss function
    (e.g., squared error). In practice, off-the-shelf loss function rarely aligns
    with the business objective. Take fraud detection as an example. When trying to
    detect fraudulent transactions, the business objective is to minimize the fraud
    loss. The off-the-shelf loss function of binary classifiers weighs false positives
    and false negatives equally. To align with the business objective, the loss function
    should not only penalize false negatives more than false positives, but also penalize
    each false negative in proportion to the dollar amount. Also, data sets in fraud
    detection usually contain highly imbalanced labels. In these cases, bias the loss
    function in favor of the rare case (e.g., through up/down sampling).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 许多从业者使用默认的损失函数（例如，平方误差）训练并选择最佳模型。实际上，现成的损失函数很少与业务目标一致。以欺诈检测为例。当尝试检测欺诈交易时，业务目标是最小化欺诈损失。现成的二分类器损失函数对假阳性和假阴性给予相同的权重。为了与业务目标对齐，损失函数不仅应对假阴性施加比假阳性更大的惩罚，还应根据金额对每个假阴性施加惩罚。此外，欺诈检测中的数据集通常包含高度不平衡的标签。在这些情况下，应通过上采样/下采样来倾斜损失函数，偏向于稀有情况。
- en: '**2\. Use plain linear models for non-linear interaction**'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 对非线性交互使用简单线性模型**'
- en: When building a binary classifier, many practitioners immediately jump to logistic
    regression because it’s simple. But, many also forget that logistic regression
    is a linear model and the non-linear interaction among predictors need to be encoded
    manually. Returning to fraud detection, high order interaction features like "billing
    address = shipping address and transaction amount < $50" are required for good
    model performance. So one should prefer non-linear models like SVM with kernel
    or tree based classifiers that bake in higher-order interaction features.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建二元分类器时，许多从业者会立刻选择逻辑回归，因为它简单。然而，许多人也会忘记逻辑回归是线性模型，并且预测变量之间的非线性交互需要手动编码。回到欺诈检测，高阶交互特征如“账单地址
    = 送货地址且交易金额 < $50”对模型性能至关重要。因此，应优先选择像带有核的SVM或树基分类器等非线性模型，它们可以内置高阶交互特征。
- en: '**3\. Forget about outliers**'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 忘记异常值**'
- en: Outliers are interesting. Depending on the context, they either deserve special
    attention or should be completely ignored. Take the example of revenue forecasting.
    If unusual spikes of revenue are observed, it's probably a good idea to pay extra
    attention to them and figure out what caused the spike. But if the outliers are
    due to mechanical error, measurement error or anything else that’s not generalizable,
    it’s a good idea to filter out these outliers before feeding the data to the modeling
    algorithm.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值很有趣。根据上下文，它们可能值得特别关注，或者应该完全忽略。例如，在收入预测中，如果观察到收入的异常峰值，可能应该额外关注一下，找出峰值的原因。但如果异常值是由于机械故障、测量误差或其他无法普遍化的原因造成的，那么在将数据输入建模算法之前，最好过滤掉这些异常值。
- en: '![statistics-bars](../Images/4397b851f09b620efd73fc1acd8d17e3.png) Some models
    are more sensitive to outliers than others. For instance, AdaBoost might treat
    those outliers as "hard" cases and put tremendous weights on outliers while decision
    tree might simply count each outlier as one false classification. If the data
    set contains a fair amount of outliers, it''s important to either use modeling
    algorithm robust against outliers or filter the outliers out.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![statistics-bars](../Images/4397b851f09b620efd73fc1acd8d17e3.png) 一些模型对异常值比其他模型更敏感。例如，AdaBoost可能会将这些异常值视为“困难”案例，并对异常值施加巨大权重，而决策树可能只是将每个异常值计为一个错误分类。如果数据集中包含大量异常值，那么要么使用对异常值具有鲁棒性的建模算法，要么在建模之前过滤掉异常值。'
- en: '* * *'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的三大课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你所在组织的IT需求'
- en: '* * *'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Avoid These 5 Common Mistakes Every Novice in AI Makes](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个AI新手都会犯的5个常见错误](https://www.kdnuggets.com/avoid-these-5-common-mistakes-every-novice-in-ai-makes)'
- en: '[5 Common Data Science Mistakes and How to Avoid Them](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5个常见的数据科学错误及如何避免](https://www.kdnuggets.com/5-common-data-science-mistakes-and-how-to-avoid-them)'
- en: '[How To Tackle 3 Common Machine Learning Challenges](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[如何应对3个常见的机器学习挑战](https://www.kdnuggets.com/2022/09/comet-tackle-3-common-machine-learning-challenges.html)'
- en: '[Mistakes That Newbie Data Scientists Should Avoid](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[新手数据科学家应该避免的错误](https://www.kdnuggets.com/2022/06/mistakes-newbie-data-scientists-avoid.html)'
- en: '[3 Mistakes That Could Be Affecting the Accuracy of Your Data Analytics](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3个可能影响数据分析准确性的错误](https://www.kdnuggets.com/2023/03/3-mistakes-could-affecting-accuracy-data-analytics.html)'
- en: '[Software Mistakes and Tradeoffs: New book by Tomasz Lelek and…](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《软件错误与权衡：Tomasz Lelek 等新书》](https://www.kdnuggets.com/2021/12/manning-software-mistakes-tradeoffs-book.html)'
