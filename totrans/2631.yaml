- en: Microsoft Explores Three Key Mysteries of Ensemble Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微软探索集成学习的三大关键谜团
- en: 原文：[https://www.kdnuggets.com/2021/02/microsoft-explores-three-key-mysteries-ensemble-learning.html](https://www.kdnuggets.com/2021/02/microsoft-explores-three-key-mysteries-ensemble-learning.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2021/02/microsoft-explores-three-key-mysteries-ensemble-learning.html](https://www.kdnuggets.com/2021/02/microsoft-explores-three-key-mysteries-ensemble-learning.html)
- en: '[comments](#comments)![Figure](../Images/1ebdf4aaa12665aa2b118860856d78fc.png)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)![图示](../Images/1ebdf4aaa12665aa2b118860856d78fc.png)'
- en: Source: [https://www.quora.com/What-is-ensemble-learning](https://www.quora.com/What-is-ensemble-learning)
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.quora.com/What-is-ensemble-learning](https://www.quora.com/What-is-ensemble-learning)'
- en: '* * *'
  id: totrans-4
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Our Top 3 Course Recommendations
  id: totrans-6
  prefs:
  - PREF_BQ
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三个课程推荐
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google 网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速进入网络安全职业生涯。'
- en: ''
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google 数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: ''
  id: totrans-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT 支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持你的组织进行 IT 维护'
- en: ''
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '* * *'
- en: ''
  id: totrans-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'I recently started a new newsletter focus on AI education and**already has
    over 50,000 subscribers**. TheSequence is a no-BS( meaning no hype, no news etc)
    AI-focused newsletter that takes 5 minutes to read. The goal is to keep you up
    to date with machine learning projects, research papers and concepts. Please give
    it a try by subscribing below:'
  id: totrans-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我最近启动了一个新的新闻通讯，专注于人工智能教育，**已经有超过 50,000 名订阅者**。TheSequence 是一个没有废话（即没有炒作、没有新闻等）的
    AI 专注型新闻通讯，阅读时间为 5 分钟。目标是让你及时了解机器学习项目、研究论文和概念。请通过下面的订阅尝试一下：
- en: '[![Image](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[![图片](../Images/f2aed90f956dea213be7c9bbf9cd7072.png)](https://thesequence.substack.com/)'
- en: '**Ensemble learning** is one of the oldest and less-understood techniques used
    to improve the performance of deep learning models. The theory behind ensemble
    learning is very simple: the performance of a group of independently-trained neural
    networks should outperform the best in the group in the long term. Furthermore,
    we also know that the performance of an ensemble of models can be transferred
    to a single model using a technique known as **knowledge distillation**. The world
    of ensemble learning is super exciting, except, that we don’t quite understand
    it. Recently, Microsoft Research published a groundbreaking paper that tries that
    shade some light into the magic of ensembles by understanding **three fundamental
    mysteries of the space**.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**集成学习** 是提升深度学习模型性能的最古老且较少被理解的技术之一。集成学习的理论非常简单：独立训练的神经网络组的性能应该在长期内超越组中的最佳者。此外，我们还知道，通过一种称为**知识蒸馏**的技术，可以将模型集成的性能转移到单一模型上。集成学习的世界非常令人兴奋，只是我们还没有完全理解。最近，微软研究院发布了一篇开创性的论文，试图通过理解**该领域的三大根本谜团**来揭示集成的魔力。'
- en: 'Microsoft Research works tries to understand the following two theoretical
    questions about ensemble learning:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究院致力于理解以下两个关于集成学习的理论问题：
- en: '*1)* *How does ensemble improve the test-time performance in deep learning
    when we simply average over a few independently trained neural networks?*'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*1)* *当我们简单地对几个独立训练的神经网络进行平均时，集成如何提升深度学习的测试性能？*'
- en: '*2)* *How can such superior test-time performance of ensemble be later “distilled”
    into a single neural network of the same architecture, simply by training the
    single model to match the output of the ensemble over the same training data set?*'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*2)* *如何将如此优越的集成测试性能，通过训练单个模型以匹配集成输出在相同的训练数据集上，之后“提炼”成具有相同架构的单一神经网络？*'
- en: 'The answer to those theoretical questions runs into what Microsoft Research,
    somewhat theatrically, likes to call the three mysteries of ensemble learning:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些理论问题的答案涉及到微软研究院有点戏剧性地称之为集成学习三大谜团的内容：
- en: 'Mystery 1: Ensemble'
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '谜团 1: 集成'
- en: The first mystery of ensemble learning is related to the performance boost. *Given
    a set of neural networks N1, N2…NM, an ensemble that simply takes an average of
    the outputs is likely to produce a significant performance boost. However that
    performance doesn’t materialize when training (N1 + N2 +…Nm)/M*. Puzzling….
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 集成学习的第一个神秘问题与性能提升有关。*给定一组神经网络 N1, N2…NM，一个简单地对输出进行平均的集成很可能会产生显著的性能提升。然而，当训练
    (N1 + N2 +…Nm)/M 时，这种性能却没有实现。令人困惑……*
- en: '![Figure](../Images/5994f90abe1adde0378282ef8e21c384.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/5994f90abe1adde0378282ef8e21c384.png)'
- en: Source: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)'
- en: 'Mystery 2: Knowledge Distillation'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '神秘 2: 知识蒸馏'
- en: Ensemble models are high performance but ridiculously expensive and slow to
    run. Knowledge distillation is a technique in which a single model can be trained
    to match the performance of the ensemble. The success of knowledge distillation
    methods leads to more the second mystery of ensembles. *Why does matching the
    outputs of the ensemble produces better test accuracy compared to matching the
    true labels?*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 集成模型性能高，但运行成本极高且速度慢。知识蒸馏是一种可以训练单个模型以匹配集成性能的技术。知识蒸馏方法的成功引出了集成的第二个神秘问题。*为什么匹配集成的输出会比匹配真实标签产生更好的测试准确率？*
- en: 'Mystery 3: Self-Distillation'
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '神秘 3: 自我蒸馏'
- en: The third mystery of ensemble is very related to the second one but even more
    puzzling. Knowledge distillation shows that a smaller model can match the performance
    of a larger ensemble. A parallel phenomenon known as self-distillation is even
    more puzzling. Self-distillation is based on performing knowledge distillation
    against individual models which also increases the performance! *Basically, self-distillation
    is based on training the same model using itself as a teacher. Why does that approach
    produces a performance boost remains a mystery.*
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 集成的第三个神秘问题与第二个密切相关，但更加扑朔迷离。知识蒸馏表明，一个较小的模型可以匹配较大集成的性能。一个称为自我蒸馏的现象更加令人困惑。自我蒸馏基于对单个模型进行知识蒸馏，这也能提高性能！*基本上，自我蒸馏是基于使用自身作为教师来训练相同的模型。为什么这种方法会产生性能提升仍然是一个谜。*
- en: '![Figure](../Images/28553b8695abef2b45b535346d149c74.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/28553b8695abef2b45b535346d149c74.png)'
- en: Source: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)'
- en: Some Answers
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一些答案
- en: Microsoft Research conducted all sorts of experiments to understand some of
    the aforementioned mysteries of ensemble learning. The initial work produced some
    interesting results.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究院进行了各种实验，以理解上述集成学习的一些神秘现象。初步工作产生了一些有趣的结果。
- en: 1) Deep Learning Ensembles vs. Feature Mapping
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1) 深度学习集成与特征映射
- en: The best-known form of ensemble learning is what is called random feature mappings
    in which models are trained in random number of features. That type of technique
    works well in linear models and is very well understood so that it can be used
    as a baseline to analyze the performance of deep learning ensembles. The initial
    results of Microsoft Research experiments showed that deep learning ensembles
    behaved very similarly to feature mappings. However, knowledge distillation doesn’t
    quite work the same.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最著名的集成学习形式是所谓的随机特征映射，其中模型在随机特征数量下进行训练。这种技术在线性模型中效果很好，并且被很好地理解，因此可以作为分析深度学习集成性能的基准。微软研究院的初步实验结果显示，深度学习集成的行为与特征映射非常相似。然而，知识蒸馏的效果却不完全相同。
- en: '![Figure](../Images/990bf05f80a817577d014532964cea39.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/990bf05f80a817577d014532964cea39.png)'
- en: Source: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)'
- en: 2) Multi-views Datasets are Necessary for Ensembles to work
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2) 多视角数据集对集成模型的有效性至关重要
- en: One of the most revealing results of the Microsoft Research study is based on
    the nature of the data. A multi-view dataset is based on a structure where each
    class of the data has multiple view features. For instance, a car image can be
    classified as a car by looking at the headlights, the wheels, or the windows.
    Microsoft Research shows that datasets with multi-view structures are likely to
    boost the performance of ensemble models whereas datasets without that structure
    does not have the same impact.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究的一项最具启发性的结果是基于数据的性质。多视角数据集是基于一个结构，其中数据的每个类别都有多个视角特征。例如，通过查看车灯、车轮或窗户，可以将汽车图像分类为汽车。微软研究显示，具有多视角结构的数据集更有可能提升集成模型的性能，而没有这种结构的数据集则没有相同的效果。
- en: '![Figure](../Images/927b0bbe029e3aa456ade2473cba6702.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图示](../Images/927b0bbe029e3aa456ade2473cba6702.png)'
- en: Source: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '来源: [https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/](https://www.microsoft.com/en-us/research/blog/three-mysteries-in-deep-learning-ensemble-knowledge-distillation-and-self-distillation/)'
- en: The Microsoft Research paper is one of the most advanced work in deep learning
    ensembles in the last few year. The paper covers many other findings but this
    summary should give you a very concrete idea of the main contributions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 微软研究院的论文是近年来深度学习集成领域最先进的工作之一。论文涵盖了许多其他发现，但这个总结应该能给你一个关于主要贡献的非常具体的概念。
- en: '[Original](https://medium.com/dataseries/microsoft-explores-three-key-mysteries-of-ensemble-learning-88dc4df831bd).
    Reposted with permission.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/dataseries/microsoft-explores-three-key-mysteries-of-ensemble-learning-88dc4df831bd)。经许可转载。'
- en: '**Related:**'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关：**'
- en: '[XGBoost: What it is, and when to use it](/2020/12/xgboost-what-when.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[XGBoost：它是什么，以及何时使用它](/2020/12/xgboost-what-when.html)'
- en: '[Microsoft Uses Transformer Networks to Answer Questions About Images With
    Minimum Training](/2021/01/microsoft-transformer-networks-answer-questions-minimum-training.html)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微软利用 Transformer 网络回答有关图像的问题，训练最小化](/2021/01/microsoft-transformer-networks-answer-questions-minimum-training.html)'
- en: '[Implementing the AdaBoost Algorithm From Scratch](/2020/12/implementing-adaboost-algorithm-from-scratch.html)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[从头实现 AdaBoost 算法](/2020/12/implementing-adaboost-algorithm-from-scratch.html)'
- en: More On This Topic
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关话题
- en: '[Thomas Miller, PhD, explores Northwestern University’s Online…](https://www.kdnuggets.com/2024/05/nwu/thomas-miller-phd-explores-northwestern-universitys-online-graduate-programs-in-data-science)'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[托马斯·米勒博士探讨了西北大学的数据科学在线研究生项目](https://www.kdnuggets.com/2024/05/nwu/thomas-miller-phd-explores-northwestern-universitys-online-graduate-programs-in-data-science)'
- en: '[Ensemble Learning with Examples](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[带示例的集成学习](https://www.kdnuggets.com/2022/10/ensemble-learning-examples.html)'
- en: '[Ensemble Learning Techniques: A Walkthrough with Random Forests in Python](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[集成学习技术：Python 中随机森林的详细讲解](https://www.kdnuggets.com/ensemble-learning-techniques-a-walkthrough-with-random-forests-in-python)'
- en: '[Three R Libraries Every Data Scientist Should Know (Even if You Use Python)](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个数据科学家都应该知道的三种 R 库（即使你使用 Python）](https://www.kdnuggets.com/2021/12/three-r-libraries-every-data-scientist-know-even-python.html)'
- en: '[When Would Ensemble Techniques be a Good Choice?](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[什么时候使用集成技术是一个好的选择？](https://www.kdnuggets.com/2022/07/would-ensemble-techniques-good-choice.html)'
- en: '[Automate Microsoft Excel and Word Using Python](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用 Python 自动化 Microsoft Excel 和 Word](https://www.kdnuggets.com/2021/08/automate-microsoft-excel-word-python.html)'
