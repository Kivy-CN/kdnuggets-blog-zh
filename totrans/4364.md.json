["```py\nwine_quality = pd.read_csv(\"https://raw.githubusercontent.com/hadrienj/essential_math_for_data_science/master/data/winequality-red.csv\",\n                           sep=\";\")\nwine_quality.columns \n```", "```py\nIndex(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol', 'quality'],\n      dtype='object') \n```", "```py\nwine_quality[\"quality\"].unique() \n```", "```py\narray([5, 6, 7, 4, 8, 3]) \n```", "```py\nX = wine_quality.drop(\"quality\", axis=1).values\ny = wine_quality[\"quality\"] >= 7 \n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=13) \n```", "```py\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_train_stand = scaler.fit_transform(X_train)\nX_test_stand = scaler.transform(X_test) \n```", "```py\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nlog_reg = LogisticRegression(random_state=123, penalty=\"none\")\nlog_reg.fit(X_train_stand, y_train)\ny_pred = log_reg.predict(X_test_stand)\naccuracy_score(y_test, y_pred) \n```", "```py\n0.8729166666666667 \n```", "```py\n(y_train == 0).sum() / y_train.shape[0] \n```", "```py\n0.8650580875781948 \n```", "```py\n(y_train == 1).sum() / y_train.shape[0] \n```", "```py\n0.13494191242180517 \n```", "```py\nnp.random.seed(1)\ny_pred_random_proba = np.random.uniform(0, 0.5, y_test.shape[0])\ny_pred_random_proba \n```", "```py\narray([2.08511002e-01, 3.60162247e-01, 5.71874087e-05, ...,\n       4.45509477e-01, 1.36436118e-02, 2.61025624e-01]) \n```", "```py\ndef binarize(y_hat, threshold):\n    return (y_hat > threshold).astype(int)\n\ny_pred_random = binarize(y_pred_random_proba, threshold=0.5)\ny_pred_random \n```", "```py\narray([0, 0, 0, ..., 0, 0, 0]) \n```", "```py\naccuracy_score(y_test, y_pred_random) \n```", "```py\n0.8625 \n```", "```py\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_pred_random) \n```", "```py\narray([[414,   0],\n       [ 66,   0]]) \n```", "```py\nfrom sklearn.metrics import roc_curve\nfpr_random, tpr_random, thresholds_random = roc_curve(y_test, y_pred_random_proba) \n```", "```py\nfpr_random \n```", "```py\narray([0\\.        , 0\\.        , 0.07246377, ..., 0.96859903, 0.96859903,\n       1\\.        ]) \n```", "```py\ntpr_random \n```", "```py\narray([0\\.        , 0.01515152, 0.01515152, ..., 0.98484848, 1\\.        ,\n       1\\.        ]) \n```", "```py\nthresholds_random \n```", "```py\narray([1.49866143e+00, 4.98661425e-01, 4.69443239e-01, ...,\n       9.68347894e-03, 9.32364469e-03, 5.71874087e-05]) \n```", "```py\nplt.plot(fpr_random, tpr_random)\n# [...] Add axes, labels etc. \n```", "```py\ny_pred_proba = log_reg.predict_proba(X_test_stand)\ny_pred_proba \n```", "```py\narray([[0.50649705, 0.49350295],\n       [0.94461852, 0.05538148],\n       [0.97427601, 0.02572399],\n       ...,\n       [0.82742897, 0.17257103],\n       [0.48688505, 0.51311495],\n       [0.8809794 , 0.1190206 ]]) \n```", "```py\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba[:, 1])\nplt.plot(fpr, tpr)\n# [...] Add axes, labels etc. \n```", "```py\ndef g_2x(x):\n    return 2 * x \n```", "```py\ndelta_x = 1\nx = np.arange(0, 7, delta_x)\nx \n```", "```py\narray([0, 1, 2, 3, 4, 5, 6]) \n```", "```py\ny = g_2x(x)\ny \n```", "```py\narray([ 0,  2,  4,  6,  8, 10, 12]) \n```", "```py\nslice_area_all = np.zeros(y.shape[0])\nfor i in range(1, len(x)):\n    slice_area_all[i] = delta_x * y[i-1]\nslice_area_all \n```", "```py\narray([ 0.,  0.,  2.,  4.,  6.,  8., 10.]) \n```", "```py\nslice_area_all = slice_area_all.cumsum()\nslice_area_all \n```", "```py\narray([ 0.,  0.,  2.,  6., 12., 20., 30.]) \n```", "```py\nplt.plot(x, x ** 2, label='True')\nplt.plot(x, slice_area_all, label='Estimated') \n```", "```py\ndelta_x = 0.1\nx = np.arange(0, 7, delta_x)\ny = g_2x(x)\n#  [...] Calculate and plot slice_area_all \n```", "```py\nplt.plot(fpr_random, tpr_random, label=\"Random\")\nplt.plot(fpr, tpr, label=\"Logistic regression\")\n# [...] Add axes, labels etc. \n```", "```py\nfpr_random[1:] - fpr_random[:-1] \n```", "```py\narray([0.00241546, 0.01207729, 0\\.        , ..., 0.01207729, 0\\.        ,\n       0.06038647]) \n```", "```py\n(tpr_random[1:] * (fpr_random[1:] - fpr_random[:-1])).sum() \n```", "```py\n0.5743302591128678 \n```", "```py\nfrom sklearn.metrics import roc_auc_score\n\nroc_auc_score(y_test, y_pred_random_proba) \n```", "```py\n0.5743302591128678 \n```", "```py\nroc_auc_score(y_test, y_pred_proba[:, 1]) \n```", "```py\n0.8752378861074513 \n```"]