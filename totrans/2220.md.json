["```py\n# Conv layers \nself.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size)\nself.conv2 = nn.Conv2d(in_channels, out_channels, kernel_size)\n\n# Pooling layer\nself.pool = nn.MaxPool2d(kernel_size)\n\n# Fully-connected layers \nself.fc1 = nn.Linear(in_features, out_features)\nself.fc2 = nn.Linear(in_features, out_features)\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\n\ntransform = torchvision.transforms.Compose(\n    [torchvision.transforms.ToTensor()]\n)\n\ntrain = torchvision.datasets.CIFAR10(\n    root=\"data\", train=True, download=True, transform=transform\n)\n\ntest = torchvision.datasets.CIFAR10(\n    root=\"data\", train=False, download=True, transform=transform\n)\n```", "```py\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n\n100%|██████████| 170498071/170498071 [00:10<00:00, 15853600.54it/s]\n\nExtracting data/cifar-10-python.tar.gz to data\nFiles already downloaded and verified\n```", "```py\nbatch_size = 32\ntrainloader = torch.utils.data.DataLoader(\n    train, batch_size=batch_size, shuffle=True\n)\ntestloader = torch.utils.data.DataLoader(\n    test, batch_size=batch_size, shuffle=True\n)\n```", "```py\nfrom torchvision.utils import make_grid\nimport matplotlib.pyplot as plt\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images[:64], nrow=8).permute(1, 2, 0))\n        break\nshow_batch(trainloader)\n```", "```py\nclass CNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=1, padding=1)\n        self.act1 = nn.ReLU()\n        self.drop1 = nn.Dropout(0.3)\n\n        self.conv2 = nn.Conv2d(32, 32, kernel_size=(3,3), stride=1, padding=1)\n        self.act2 = nn.ReLU()\n        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n\n        self.flat = nn.Flatten()\n\n        self.fc3 = nn.Linear(8192, 512)\n        self.act3 = nn.ReLU()\n        self.drop3 = nn.Dropout(0.5)\n\n        self.fc4 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        # input 3x32x32, output 32x32x32\n        x = self.act1(self.conv1(x))\n        x = self.drop1(x)\n        # input 32x32x32, output 32x32x32\n        x = self.act2(self.conv2(x))\n        # input 32x32x32, output 32x16x16\n        x = self.pool2(x)\n        # input 32x16x16, output 8192\n        x = self.flat(x)\n        # input 8192, output 512\n        x = self.act3(self.fc3(x))\n        x = self.drop3(x)\n        # input 512, output 10\n        x = self.fc4(x)\n        return x\n```", "```py\nmodel = CNNModel()\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n```", "```py\nn_epochs = 10\nfor epoch in range(n_epochs):\n    for i, (images, labels) in enumerate(trainloader):\n        # Forward pass \n        outputs = model(images)\n        loss = loss_fn(outputs, labels)\n\n        # Backward pass and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in testloader:\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print('Epoch %d: Accuracy: %d %%' % (epoch,(100 * correct / total))) \n```", "```py\nEpoch 0: Accuracy: 41 %\nEpoch 1: Accuracy: 46 %\nEpoch 2: Accuracy: 48 %\nEpoch 3: Accuracy: 50 %\nEpoch 4: Accuracy: 52 %\nEpoch 5: Accuracy: 53 %\nEpoch 6: Accuracy: 53 %\nEpoch 7: Accuracy: 56 %\nEpoch 8: Accuracy: 56 %\nEpoch 9: Accuracy: 57 % \n```"]