- en: Phishytics – Machine Learning for Detecting Phishing Websites
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Phishytics – 检测网络钓鱼网站的机器学习
- en: 原文：[https://www.kdnuggets.com/2020/03/phishytics-machine-learning-detecting-phishing-websites.html](https://www.kdnuggets.com/2020/03/phishytics-machine-learning-detecting-phishing-websites.html)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://www.kdnuggets.com/2020/03/phishytics-machine-learning-detecting-phishing-websites.html](https://www.kdnuggets.com/2020/03/phishytics-machine-learning-detecting-phishing-websites.html)
- en: '[comments](#comments)'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '[评论](#comments)'
- en: '**By [Faizan Ahmad](http://faizanahmad.tech/), University of Virginia**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**作者 [Faizan Ahmad](http://faizanahmad.tech/)，弗吉尼亚大学**'
- en: '[![Phishing Detection with Machine Learning](../Images/25eb8aef7508a3c43436ef8774c205f8.png)](https://faizanahmad.tech/blog/2020/02/phishytics-machine-learning-for-phishing-websites-detection/)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '[![机器学习检测网络钓鱼](../Images/25eb8aef7508a3c43436ef8774c205f8.png)](https://faizanahmad.tech/blog/2020/02/phishytics-machine-learning-for-phishing-websites-detection/)'
- en: There is hardly a week when you go to Google News and don’t find a news article
    about Phishing. Just in the last week, hackers are [sending phishing emails to
    Disney+ subscribers](https://www.cordcuttersnews.com/disney-hackers-are-sending-phishing-emails-heres-how-to-stay-safe/), [‘Shark
    Tank’ star Barbara Corcoran lost almost $400K in phishing scam](https://pagesix.com/2020/02/26/shark-tank-star-barbara-corcoran-loses-almost-400k-in-phishing-scam/), [a
    bank issues phishing warnings](https://www.kcci.com/article/bank-issues-warning-over-phishing-attempts-and-phone-scams/31112737#),
    and [almost three-quarter of all phishing websites now use SSL](https://www.helpnetsecurity.com/2020/02/26/phishing-ssl/).
    Since phishing is such a widespread problem in the cybersecurity domain, let us
    take a look at the application of ***machine learning for phishing website detection***.
    Although there have been many articles and research papers on this topic [[Malicious
    URL Detection](https://arxiv.org/pdf/1701.07179.pdf)] [[Phishing Website Detection
    by Visual Whitelists](https://arxiv.org/abs/1909.00300)] [[Novel Techniques for
    Detecting Phishing](https://arxiv.org/pdf/1510.06501.pdf)], they do not always
    provide open-source code and dive deeper into the analysis. This post is written
    to address these gaps. We will use a large phishing website corpus and apply a
    few simple machine learning methods to garner highly accurate results.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎每周你都会看到关于网络钓鱼的新闻。在过去的一周里，黑客们正在[向 Disney+ 用户发送网络钓鱼邮件](https://www.cordcuttersnews.com/disney-hackers-are-sending-phishing-emails-heres-how-to-stay-safe/)，[‘Shark
    Tank’ 明星巴巴拉·科克伦在网络钓鱼骗局中损失了近 40 万美元](https://pagesix.com/2020/02/26/shark-tank-star-barbara-corcoran-loses-almost-400k-in-phishing-scam/)，[某银行发布了网络钓鱼警告](https://www.kcci.com/article/bank-issues-warning-over-phishing-attempts-and-phone-scams/31112737#)，而且[现在几乎四分之三的网络钓鱼网站都使用
    SSL](https://www.helpnetsecurity.com/2020/02/26/phishing-ssl/)。由于网络钓鱼在网络安全领域是一个如此广泛的问题，让我们来深入探讨一下***机器学习在网络钓鱼网站检测中的应用***。尽管已有许多关于此主题的文章和研究论文[[恶意
    URL 检测](https://arxiv.org/pdf/1701.07179.pdf)] [[通过视觉白名单检测网络钓鱼网站](https://arxiv.org/abs/1909.00300)]
    [[检测网络钓鱼的新技术](https://arxiv.org/pdf/1510.06501.pdf)]，它们并不总是提供开源代码并深入分析。本文旨在填补这些空白。我们将使用一个大规模的网络钓鱼网站语料库，并应用一些简单的机器学习方法来获得高精度的结果。
- en: Data
  id: totrans-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: 'The best part about tackling this problem with machine learning is the availability
    of well-collected phishing website data sets, [one](http://www.fcsit.unimas.my/research/legit-phish-set) of
    which is collected by folks at the Universiti Malaysia Sarawak. The ***[‘Phishing
    Dataset – A Phishing and Legitimate Dataset for Rapid Benchmarking’](http://www.fcsit.unimas.my/research/legit-phish-set)*** dataset
    consists of 30,000 websites out of which 15,000 are phishing and 15,000 are legitimate.
    Each website in the data set comes with HTML code, whois info, URL, and all the
    files embedded in the web page. This is a goldmine for someone looking to apply
    machine learning for phishing detection. There are several ways this data set
    can be used. We can try to detect phishing websites by looking at the URLs and
    whois information and manually extracting features as some previous studies have
    done [[1](https://arxiv.org/pdf/1701.07179.pdf)]. However, we are going to use
    the raw HTML code of the web pages to see if we can effectively combat phishing
    websites by building a machine learning system. Among URLs, whois information,
    and HTML code, the last is the most difficult to obfuscate or change if an attacker
    is trying to prevent a system from detecting his/her phishing websites, hence
    the use of HTML code in our system. Another approach is to combine all three sources,
    which should give better and more robust results but for the sake of simplicity,
    we will only use HTML code and show that it alone garners effective results for
    phishing website detection. One final note on the data set: we will only be using
    20,000 total samples because of computing constraints. We will also only consider
    websites written in *English* since data for other languages is sparse.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的最佳部分是有良好收集的网络钓鱼网站数据集，其中[一个](http://www.fcsit.unimas.my/research/legit-phish-set)由马来西亚沙捞越大学的研究人员收集。这个***[‘钓鱼数据集
    – 钓鱼与合法数据集用于快速基准测试’](http://www.fcsit.unimas.my/research/legit-phish-set)***数据集包含30,000个网站，其中15,000个是钓鱼网站，15,000个是合法网站。数据集中的每个网站都包含HTML代码、whois信息、URL以及网页中嵌入的所有文件。这对那些希望应用机器学习进行钓鱼检测的人来说是一个宝贵的资源。这个数据集有几种使用方式。我们可以通过查看URL和whois信息来尝试检测钓鱼网站，并像之前的一些研究那样手动提取特征[[1](https://arxiv.org/pdf/1701.07179.pdf)]。然而，我们将使用网页的原始HTML代码来看看是否可以通过构建机器学习系统有效对抗钓鱼网站。在URL、whois信息和HTML代码中，HTML代码是最难被混淆或更改的，如果攻击者试图阻止系统检测其钓鱼网站，因此我们在系统中使用HTML代码。另一种方法是将三种来源结合起来，这应该能提供更好、更稳健的结果，但为了简化起见，我们将仅使用HTML代码，并证明仅靠它即可获得有效的钓鱼网站检测结果。关于数据集的最后一点：由于计算限制，我们将仅使用20,000个样本。我们还将仅考虑用*英语*编写的网站，因为其他语言的数据稀缺。
- en: Byte Pair Encoding for HTML Code
  id: totrans-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HTML代码的字节对编码
- en: For a naive person, HTML code does not look as simple as a language. Moreover,
    developers often do not follow all the good practices while writing code. This
    makes it hard to parse HTML code and extract words/tokens. Another challenge is
    the scarcity of many words and tokens in HTML code. For instance, if a web page
    is using a special library with a complex name, we might not find that name on
    other websites. Finally, since we want to deploy our system in the real world,
    there might be new web pages using completely different libraries and code practices
    that our model has not seen before. This makes it harder to use simple language
    tokenizers and split code into tokens based on space or any other tag or character.
    Fortunately, we have an algorithm called **[Byte Pair Encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding)** (BPE)
    that* splits the text into sub-word tokens* based on the frequency and solves
    the challenge of unknown words. In BPE, we start by considering each character
    as a token and iteratively merge tokens based on the highest frequencies. For
    instance, if a new word “*googlefacebook*” comes, BPE will split it into *“google”*
    and *“facebook”* as these words could be frequently there in the corpus. BPE has
    been widely used in recent deep learning models [[2](https://arxiv.org/abs/1508.07909)].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一个初学者来说，HTML 代码看起来并不像一种简单的语言。此外，开发者在编写代码时常常不遵循所有良好的实践。这使得解析 HTML 代码和提取词汇/标记变得困难。另一个挑战是
    HTML 代码中许多词汇和标记的稀缺性。例如，如果一个网页使用了一个复杂名称的特殊库，我们可能在其他网站上找不到这个名称。最后，由于我们希望将系统部署到实际环境中，可能会有新的网页使用我们模型之前未见过的完全不同的库和代码实践。这使得使用简单的语言标记器并根据空格或其他标签或字符将代码拆分为标记变得更加困难。幸运的是，我们有一个叫做**[字节对编码](https://en.wikipedia.org/wiki/Byte_pair_encoding)**（BPE）的算法，它*根据频率将文本拆分为子词标记*，并解决了未知词汇的问题。在
    BPE 中，我们首先将每个字符视为一个标记，并根据最高频率迭代合并标记。例如，如果出现了一个新词“*googlefacebook*”，BPE 会将其拆分为*“google”*和*“facebook”*，因为这些词在语料库中可能会频繁出现。BPE
    已被广泛应用于最近的深度学习模型 [[2](https://arxiv.org/abs/1508.07909)]。
- en: There have been numerous libraries to train BPE on a text corpus. We will use
    a great one called **[tokenizer](https://github.com/huggingface/tokenizers)** by [Huggingface](https://huggingface.co/).
    It is extremely easy to follow the instruction on the [github repository](https://github.com/huggingface/tokenizers) of
    the library. We train BPE with a vocabulary size of **10,000 tokens** on top of
    raw HTML data. The beauty of BPE is that it automatically separates HTML keywords
    such as “tag”, “script”, “div” into individual tokens even though these tags are
    mostly written with brackets in an HTML file e.g <tag>, <script>. After training,
    we get a saved instance of the tokenizer which we can use to tokenize any HTML
    file into individual tokens. These tokens are used with machine learning models.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 BPE 的库有很多。我们将使用一个很棒的库，叫做**[tokenizer](https://github.com/huggingface/tokenizers)**，由[Huggingface](https://huggingface.co/)提供。按照这个库的[github
    仓库](https://github.com/huggingface/tokenizers)中的说明非常简单。我们在原始 HTML 数据上用**10,000
    tokens**的词汇量训练 BPE。BPE 的优点是它可以自动将 HTML 关键词如“tag”、“script”、“div”分离成单独的标记，即使这些标签在
    HTML 文件中大多是用括号书写的，例如 <tag>，<script>。训练后，我们得到一个保存的标记器实例，我们可以用它将任何 HTML 文件标记化为单独的标记。这些标记用于机器学习模型中。
- en: '![Figure](../Images/53aded7e5f0ccf06b2922c1d7ec60c43.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/53aded7e5f0ccf06b2922c1d7ec60c43.png)'
- en: 'Figure: Histogram of number of BPE tokens in HTML Code'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图：HTML 代码中 BPE 标记的数量直方图
- en: TFIDF with Byte Pair Encoding
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TFIDF 与字节对编码
- en: Once we have tokens from an HTML file, we can apply any model. However, contrary
    to what most people do these days, we will not be using a deep learning model
    such as a Convolutional Neural Network (CNN) or Recurrent Neural Network (RNN).
    This is mainly because of the computational complexity and the relatively small
    size of the data set for deep learning models. The figure above shows a histogram
    of tokens from BPE in 1000 HTML files. We can see that these files contain thousands
    of tokens whose processing will incur high computational cost in more complex
    models like CNN and RNN. Moreover, it is not necessary that token order matters
    for phishing detection. This will be empirically evident once we look at the results.
    Therefore, we will simply apple TFIDF weights on top of each token from the BPE.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们从 HTML 文件中获取了令牌，就可以应用任何模型。然而，与现在大多数人所做的不同，我们不会使用像卷积神经网络 (CNN) 或递归神经网络 (RNN)
    这样的深度学习模型。这主要是因为深度学习模型的计算复杂性和数据集相对较小。上图展示了 1000 个 HTML 文件中 BPE 令牌的直方图。我们可以看到，这些文件包含数千个令牌，其处理在像
    CNN 和 RNN 这样的复杂模型中将会产生较高的计算成本。此外，对于网络钓鱼检测，令牌顺序并不是必需的。这将在查看结果时显而易见。因此，我们将简单地在 BPE
    的每个令牌上应用 TFIDF 权重。
- en: As explained in the previous post on [Authorship Attribution](https://faizanahmad.tech/blog/2020/02/large-scale-authorship-attribution-machine-learning/),
    TFIDF stands for term frequency, inverse document frequency and can be calculated
    by the formula given below. Term frequency (tf) is the count of a term ***i*** in
    a document ***j*** while inverse document frequency (idf) indicates the rarity
    and importance of each word in the corpus. Document frequency is calculated by
    totaling the number of times a term ***i*** appears in all documents.  TF-IDF
    gives us weights as tfidf scores for each term in a document which is a product
    of tf and idf.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 正如在之前关于 [作者归属](https://faizanahmad.tech/blog/2020/02/large-scale-authorship-attribution-machine-learning/)
    的帖子中解释的那样，TFIDF 代表词频（term frequency）和逆文档频率（inverse document frequency），可以通过下面给出的公式计算。词频（tf）是文档
    ***j*** 中词 ***i*** 的计数，而逆文档频率（idf）表示每个词在语料库中的稀有性和重要性。文档频率是通过统计词 ***i*** 在所有文档中出现的次数来计算的。
    TF-IDF 给我们每个文档中每个词的权重，即 tf 和 idf 的乘积。
- en: (1) ![\begin{equation*} w_{i,j} = tf_{i,j} * df_i \end{equation*}](../Images/35939d2378d3032bd22800d8f9e61f66.png)
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: (1) ![\begin{equation*} w_{i,j} = tf_{i,j} * df_i \end{equation*}](../Images/35939d2378d3032bd22800d8f9e61f66.png)
- en: Machine Learning Classifier
  id: totrans-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习分类器
- en: Sticking with simplicity, we will use a [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) (RF)
    from scikit-learn. For training the classifier, we split the data into 90% training
    and 10% testing. No cross-validation is done since we are not trying to extensively
    tune any hyper-parameters. We will stick with the default hyperparameters of Random
    Forest from the scikit-learn implementation. Contrary to deep learning models
    that take a long time to train, RF takes less than 2 minutes on a CPU to train
    and demonstrate effective results as are shown next. To show robustness in performance,
    we train the model 5 times on different splits of the data and report the average
    test results.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持简洁，我们将使用来自 scikit-learn 的 [随机森林分类器](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
    (RF)。为了训练分类器，我们将数据分成 90% 的训练集和 10% 的测试集。由于我们不打算对任何超参数进行广泛调优，因此没有进行交叉验证。我们将使用 scikit-learn
    实现中的随机森林的默认超参数。与需要长时间训练的深度学习模型相比，RF 在 CPU 上训练时间不到 2 分钟，并且可以展示有效的结果，下一步将展示这些结果。为了展示性能的鲁棒性，我们在数据的不同划分上训练模型
    5 次，并报告平均测试结果。
- en: Results
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结果
- en: '| Accuracy | Precision | Recall | Fscore | AUC |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 准确率 | 精确率 | 召回率 | F1 分数 | AUC |'
- en: '| 98.55 | 98.29 | 98.82 | 98.55 | 99.68 |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 98.55 | 98.29 | 98.82 | 98.55 | 99.68 |'
- en: Phishing Website Detection Results
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 网络钓鱼网站检测结果
- en: The table above shows the results on test data averaged across 5 experiments.
    Looking at the surface, these seem like great results especially without any hyperparameter
    tuning and with a simple model. However, these are not so great. The model has
    98% precision for both classes which means it gives around 2% false positives
    when it is detecting phishing websites. That is a huge number in the security
    context. False positives are the websites that the machine learning model deems
    to be phishing but are in fact legitimate. If users frequently encounter false
    positives, they have a bad user experience and they might not want to use the
    model anymore. Moreover, the security folks [encounter threat alert fatigue](https://www.csoonline.com/article/3191379/false-positives-still-cause-alert-fatigue.html) when
    dealing with false positives. False positives are further quantified in the confusion
    matrix below where x-axis shows the actual classes and y-axis has the predicted
    classes. Even though the model is achieving a high accuracy score, there are 11
    instances where the model predicted “Phishing” for the website but in reality,
    it was a safe website.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上表显示了在 5 次实验中对测试数据的平均结果。乍一看，这些结果似乎非常好，尤其是在没有任何超参数调整和使用简单模型的情况下。然而，这些结果并没有那么出色。该模型对两个类别的精度都达到了
    98%，这意味着在检测网络钓鱼网站时，它会产生大约 2% 的假正例。这在安全上下文中是一个巨大的数字。假正例是指机器学习模型认为是网络钓鱼的网站，但实际上是合法的网站。如果用户经常遇到假正例，他们的用户体验会很差，可能不愿意再使用这个模型。此外，安全人员在处理假正例时会[遇到威胁警报疲劳](https://www.csoonline.com/article/3191379/false-positives-still-cause-alert-fatigue.html)。假正例在下方的混淆矩阵中得到了进一步量化，其中
    x 轴显示实际类别，y 轴显示预测类别。尽管模型实现了很高的准确率，但仍有 11 次实例中，模型预测“网络钓鱼”的网站实际上是一个安全的网站。
- en: '| 16 (False Negative) | 912 (True Negative) | **Legitimate** |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 16（假负例） | 912（真负例） | **合法** |'
- en: '| 920 (True Positive) | 11 (False Positive) | **Phishing** |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 920（真正例） | 11（假正例） | **网络钓鱼** |'
- en: '| **Phishing** | **Legitimate** | Predicted Class |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| **网络钓鱼** | **合法** | 预测类别 |'
- en: '| Actual Class |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 实际类别 |'
- en: Confusion matrix for the model
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的混淆矩阵
- en: Now that we know there is still a problem with the model and we cannot deploy
    it as it is, let us look at a potential solution. We are going to use the [Receiver
    Operating Curve (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) to
    look at the false and true positive rates. In the figure below, it is easy to
    see that for up to 80% true positive rate, we have a 0% false-positive rate which
    is something we can use for decision making.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们知道模型仍然存在问题，不能直接部署它，让我们看看一个潜在的解决方案。我们将使用[接收器操作特征曲线 (ROC)](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
    来查看假正例和真正例率。在下图中，可以很容易地看到，对于高达 80% 的真正例率，我们的假正例率为 0%，这可以用于决策。
- en: '![Figure](../Images/0ac09f5d79947d25d35c34f52f3aa575.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/0ac09f5d79947d25d35c34f52f3aa575.png)'
- en: 'Figure: ROC Curve'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图：ROC 曲线
- en: The ROC curve demonstrates that for a particular confidence threshold (**red
    dot**), the true positive rate would be around 80-90% while the false positive
    rate would be close to zero. To prove this, let us look at different confidence
    thresholds and plot metrics against them. To apply a confidence threshold of ***x%***,
    We will only keep websites where the model is more than ***x%*** confident that
    the website is either legitimate or a phishing one. When we do this, the total
    number of phishing websites (true positive rate) we can identify decreases but
    our accuracy increases considerably and precision also becomes close to 100%.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ROC 曲线显示，对于特定的置信度阈值（**红点**），真正例率大约为 80-90%，而假正例率接近零。为了证明这一点，让我们查看不同的置信度阈值并绘制与之相关的指标。为了应用
    ***x%*** 的置信度阈值，我们将仅保留模型对网站是合法网站还是网络钓鱼网站有超过 ***x%*** 置信度的网站。当我们这样做时，我们可以识别的网络钓鱼网站的总数（真正例率）会减少，但我们的准确率会显著提高，精度也接近
    100%。
- en: '![Figure](../Images/ac107008e1b165f321164654f1051663.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/ac107008e1b165f321164654f1051663.png)'
- en: 'Figure: Effect of Confidence Threshold on Accuracy, TPR, and FP'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图：置信度阈值对准确性、TPR 和 FP 的影响
- en: The above figure demonstrates the effect of confidence threshold on **test accuracy**, **the
    number of false positives**, and** the true positive rate**. We can see that when
    we are using the default threshold of 0.5, we have 11 false positives. As we start
    to increase our confidence score, our true positive rate decreases but the number
    of false positives starts getting very low. Finally, at the last point in the
    graph, we have zero false positives for precision. This means that whenever our
    model says a website is trying to phish, it is ***always*** accurate. However,
    since our true positive rate has declined to 82%, the model can only detect around
    82% phishing websites now. This is how machine learning could be used in cybersecurity
    by looking at the tradeoff between false positives and true positives. Most of
    the time, we want an extremely low false-positive rate. In such settings, one
    can adopt the approach above to get effective results from the model.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上图演示了置信度阈值对**测试准确率**、**假阳性数量**和**真正阳性率**的影响。我们可以看到，当我们使用默认阈值0.5时，我们有11个假阳性。随着我们开始提高置信度分数，真正阳性率下降，但假阳性数量变得非常低。最后，在图表的最后一点，我们的精度为零假阳性。这意味着每当我们的模型表示一个网站正在进行钓鱼时，它是***总是***准确的。然而，由于我们的真正阳性率已下降到82%，模型现在只能检测大约82%的钓鱼网站。这就是机器学习如何在网络安全中使用，通过观察假阳性和真正阳性之间的权衡。大多数时候，我们希望假阳性率极低。在这种情况下，可以采用上述方法从模型中获得有效的结果。
- en: Limitations
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 限制
- en: Before concluding this post, let us discuss a few limitations of the methods
    we have seen above. First, our data set is pretty decent sized but it is not comprehensive
    at all for all the types of phishing websites out there. There might have been
    millions of phishing websites in the last couple of years but the data set contains
    15,000 only. As hackers are advancing their techniques, newly made phishing websites
    might not be making the same mistakes that the old ones were making which might
    make them hard to detect using the model above. Secondly, since TFIDF feature
    representation does not take into account the order in which code is written,
    we can potentially lose information. This problem does not arise in deep learning
    methods as they can sequentially process sequences and take into account the order
    of the code. Moreover, since we are using raw HTML code, an attacker can observe
    the predictions of the model and spend some time trying to come up with obfuscations
    in the code that will render the model ineffective. Finally, someone can use off
    the shelf code obfuscators to obfuscate the HTML code which will again render
    the model useless since it has only seen plain HTML code files. However, despite
    some of these limitations, machine learning can still be very effective in complementing
    phishing blacklists such as the ones used by [Google Safe Browsing](https://safebrowsing.google.com/).
    Combining blacklists with machine learning systems can provide better results
    than relying on blacklists alone.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在结束这篇文章之前，让我们讨论一下我们上面看到的方法的一些局限性。首先，我们的数据集相当大，但对于所有类型的钓鱼网站来说，它并不全面。在过去的几年里，可能有数百万个钓鱼网站，但数据集中仅包含15,000个。随着黑客技术的进步，新出现的钓鱼网站可能不会犯旧有的错误，这可能使得使用上述模型来检测它们变得困难。其次，由于TFIDF特征表示并未考虑代码编写的顺序，我们可能会丢失信息。这个问题在深度学习方法中不会出现，因为它们可以顺序处理序列并考虑代码的顺序。此外，由于我们使用的是原始HTML代码，攻击者可以观察模型的预测结果，并花时间尝试在代码中设计混淆，使模型失效。最后，有人可以使用现成的代码混淆工具来混淆HTML代码，这将使模型再次失效，因为它只见过普通的HTML代码文件。然而，尽管有这些局限性，机器学习仍然可以非常有效地补充钓鱼黑名单，如[Google
    Safe Browsing](https://safebrowsing.google.com/)使用的那种。将黑名单与机器学习系统结合，可以提供比单独依赖黑名单更好的结果。
- en: Open-Source Code
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开源代码
- en: As I discussed in the first post of this blog, I will always open-source the
    code for the projects I discuss in this blog. Keeping the tradition alive, here
    is the link for replicating all experiments, training your own phishing detection
    models, and testing new websites using my pre-trained model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我在这个博客的第一篇文章中讨论的那样，我会始终开源我在博客中讨论的项目的代码。延续这一传统，这里是复制所有实验、训练自己钓鱼检测模型以及使用我预训练模型测试新网站的链接。
- en: '**Github Repository:** https://github.com/faizann24/phishytics-machine-learning-for-phishing'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**Github 仓库:** [https://github.com/faizann24/phishytics-machine-learning-for-phishing](https://github.com/faizann24/phishytics-machine-learning-for-phishing)'
- en: '**Bio: [Faizan Ahmad](http://faizanahmad.tech/)** is currently a Masters student
    at the University of Virginia (UVA) and works as a graduate research assistant
    at the Mcintire School of Commerce in UVA. He will be joining Facebook as a Security
    Engineer in June 2020\. His interests lie at the intersection of cyber security,
    machine learning, and business analytics and he has done plenty of research and
    industrial projects on these topics.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**简介: [Faizan Ahmad](http://faizanahmad.tech/)** 目前是弗吉尼亚大学（UVA）的硕士生，并在UVA的麦金泰尔商学院担任研究助理。他将于2020年6月加入Facebook担任安全工程师。他的兴趣在于网络安全、机器学习和商业分析的交叉点，他在这些领域做了大量的研究和工业项目。'
- en: '[Original](https://faizanahmad.tech/blog/2020/02/phishytics-machine-learning-for-phishing-websites-detection/).
    Reposted with permission.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[原文](https://faizanahmad.tech/blog/2020/02/phishytics-machine-learning-for-phishing-websites-detection/)
    。已获得许可转载。'
- en: '**Related:**'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关内容：**'
- en: '[Applying Data Science to Cybersecurity Network Attacks & Events](/2019/09/applying-data-science-cybersecurity-network-attacks-events.html)'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将数据科学应用于网络安全网络攻击与事件](/2019/09/applying-data-science-cybersecurity-network-attacks-events.html)'
- en: '[Top 7 Data Science Use Cases in Trust and Security](/2019/12/top-7-data-science-use-cases-trust-security.html)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[信任与安全中的7大数据科学应用案例](/2019/12/top-7-data-science-use-cases-trust-security.html)'
- en: '[Deepfakes Security Risks](/2020/01/deepfakes-security-risks.html)'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深度伪造技术的安全风险](/2020/01/deepfakes-security-risks.html)'
- en: '* * *'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Our Top 3 Course Recommendations
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的前三名课程推荐
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [Google Cybersecurity
    Certificate](https://www.kdnuggets.com/google-cybersecurity) - Get on the fast
    track to a career in cybersecurity.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 1\. [谷歌网络安全证书](https://www.kdnuggets.com/google-cybersecurity)
    - 快速通道进入网络安全职业。'
- en: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [Google Data Analytics
    Professional Certificate](https://www.kdnuggets.com/google-data-analytics) - Up
    your data analytics game'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/e225c49c3c91745821c8c0368bf04711.png) 2\. [谷歌数据分析专业证书](https://www.kdnuggets.com/google-data-analytics)
    - 提升你的数据分析技能'
- en: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [Google IT Support
    Professional Certificate](https://www.kdnuggets.com/google-itsupport) - Support
    your organization in IT'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![](../Images/0244c01ba9267c002ef39d4907e0b8fb.png) 3\. [谷歌IT支持专业证书](https://www.kdnuggets.com/google-itsupport)
    - 支持组织的IT工作'
- en: '* * *'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: More On This Topic
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多相关内容
- en: '[Scrape Images Easily from Websites in A No-Coding Way](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[无需编码即可轻松从网站抓取图像](https://www.kdnuggets.com/2022/06/octoparse-scrape-images-easily-websites-nocoding-way.html)'
- en: '[10 Websites to Get Amazing Data for Data Science Projects](https://www.kdnuggets.com/2023/04/10-websites-get-amazing-data-data-science-projects.html)'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[获取数据科学项目中惊人数据的10个网站](https://www.kdnuggets.com/2023/04/10-websites-get-amazing-data-data-science-projects.html)'
- en: '[Detecting Data Drift for Ensuring Production ML Model Quality Using Eurybia](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Eurybia检测数据漂移以确保生产ML模型质量](https://www.kdnuggets.com/2022/07/detecting-data-drift-ensuring-production-ml-model-quality-eurybia.html)'
- en: '[5 Free Tools For Detecting ChatGPT, GPT3, and GPT2](https://www.kdnuggets.com/2023/02/5-free-tools-detecting-chatgpt-gpt3-gpt2.html)'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测ChatGPT、GPT3和GPT2的5个免费工具](https://www.kdnuggets.com/2023/02/5-free-tools-detecting-chatgpt-gpt3-gpt2.html)'
- en: '[Top 10 Tools for Detecting ChatGPT, GPT-4, Bard, and Claude](https://www.kdnuggets.com/2023/05/top-10-tools-detecting-chatgpt-gpt4-bard-llms.html)'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[检测ChatGPT、GPT-4、Bard和Claude的10个最佳工具](https://www.kdnuggets.com/2023/05/top-10-tools-detecting-chatgpt-gpt4-bard-llms.html)'
- en: '[5 Machine Learning Skills Every Machine Learning Engineer Should…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[每个机器学习工程师都应该掌握的5项机器学习技能…](https://www.kdnuggets.com/2023/03/5-machine-learning-skills-every-machine-learning-engineer-know-2023.html)'
